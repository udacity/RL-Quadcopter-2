{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Train a Quadcopter How to Fly\n",
    "\n",
    "Design an agent to fly a quadcopter, and then train it using a reinforcement learning algorithm of your choice! \n",
    "\n",
    "Try to apply the techniques you have learnt, but also feel free to come up with innovative ideas and test them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Take a look at the files in the directory to better understand the structure of the project. \n",
    "\n",
    "- `task.py`: Define your task (environment) in this file.\n",
    "- `agents/`: Folder containing reinforcement learning agents.\n",
    "    - `policy_search.py`: A sample agent has been provided here.\n",
    "    - `agent.py`: Develop your agent here.\n",
    "- `physics_sim.py`: This file contains the simulator for the quadcopter.  **DO NOT MODIFY THIS FILE**.\n",
    "\n",
    "For this project, you will define your own task in `task.py`.  Although we have provided a example task to get you started, you are encouraged to change it.  Later in this notebook, you will learn more about how to amend this file.\n",
    "\n",
    "You will also design a reinforcement learning agent in `agent.py` to complete your chosen task.  \n",
    "\n",
    "You are welcome to create any additional files to help you to organize your code.  For instance, you may find it useful to define a `model.py` file defining any needed neural network architectures.\n",
    "\n",
    "## Controlling the Quadcopter\n",
    "\n",
    "We provide a sample agent in the code cell below to show you how to use the sim to control the quadcopter.  This agent is even simpler than the sample agent that you'll examine (in `agents/policy_search.py`) later in this notebook!\n",
    "\n",
    "The agent controls the quadcopter by setting the revolutions per second on each of its four rotors.  The provided agent in the `Basic_Agent` class below always selects a random action for each of the four rotors.  These four speeds are returned by the `act` method as a list of four floating-point numbers.  \n",
    "\n",
    "For this project, the agent that you will implement in `agents/agent.py` will have a far more intelligent method for selecting actions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Basic_Agent():\n",
    "    def __init__(self, task):\n",
    "        self.task = task\n",
    "    \n",
    "    def act(self):\n",
    "        new_thrust = random.gauss(450., 25.)\n",
    "        return [new_thrust + random.gauss(0., 1.) for x in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to have the agent select actions to control the quadcopter.  \n",
    "\n",
    "Feel free to change the provided values of `runtime`, `init_pose`, `init_velocities`, and `init_angle_velocities` below to change the starting conditions of the quadcopter.\n",
    "\n",
    "The `labels` list below annotates statistics that are saved while running the simulation.  All of this information is saved in a text file `data.txt` and stored in the dictionary `results`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions (x,y,z), reward: [  1.15348292e-03  -1.41110825e-03   1.02827231e+01] 272.61901266\n",
      "positions (x,y,z), reward: [  4.44569517e-03   6.15570901e-03   1.07297232e+01] 272.467126975\n",
      "positions (x,y,z), reward: [  5.06782298e-03   2.57065521e-02   1.10647996e+01] 272.42753727\n",
      "positions (x,y,z), reward: [ -5.75619618e-03   1.34656004e-01   1.19082093e+01] 271.479322427\n",
      "positions (x,y,z), reward: [ -1.15647694e-02   1.74953426e-01   1.21055084e+01] 271.138920786\n",
      "positions (x,y,z), reward: [ -0.07506286   0.52695063  13.24856985] 269.429655271\n",
      "positions (x,y,z), reward: [ -0.2660632    1.298998    14.75118647] 266.826640378\n",
      "positions (x,y,z), reward: [ -0.86911674   3.04855592  17.18376181] 261.553197866\n",
      "positions (x,y,z), reward: [ -0.95377156   3.26476271  17.44014852] 260.890153402\n",
      "positions (x,y,z), reward: [ -1.10734718   3.64513018  17.87880141] 259.912191292\n",
      "positions (x,y,z), reward: [ -1.24219951   3.96823478  18.24163475] 259.00282807\n",
      "positions (x,y,z), reward: [ -1.58332728   4.75173582  19.07144897] 256.662690164\n",
      "positions (x,y,z), reward: [ -1.79504805   5.21955809  19.53256134] 255.297207357\n",
      "positions (x,y,z), reward: [ -3.40392024   8.52980372  22.24761544] 246.133814747\n",
      "positions (x,y,z), reward: [ -3.59664803   8.90951889  22.51309324] 245.116791588\n",
      "positions (x,y,z), reward: [ -4.8697164   11.36098376  24.04979671] 238.898384346\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from task import Task\n",
    "\n",
    "# Modify the values below to give the quadcopter a different starting position.\n",
    "runtime = 5.                                     # time limit of the episode\n",
    "init_pose = np.array([0., 0., 10., 0., 0., 0.])  # initial pose\n",
    "init_velocities = np.array([0., 0., 0.])         # initial velocities\n",
    "init_angle_velocities = np.array([0., 0., 0.])   # initial angle velocities\n",
    "file_output = 'data.txt'                         # file name for saved results\n",
    "\n",
    "# Setup\n",
    "task = Task(init_pose, init_velocities, init_angle_velocities, runtime)\n",
    "agent = Basic_Agent(task)\n",
    "done = False\n",
    "labels = ['time', 'x', 'y', 'z', 'phi', 'theta', 'psi', 'x_velocity',\n",
    "          'y_velocity', 'z_velocity', 'phi_velocity', 'theta_velocity',\n",
    "          'psi_velocity', 'rotor_speed1', 'rotor_speed2', 'rotor_speed3', 'rotor_speed4']\n",
    "results = {x : [] for x in labels}\n",
    "\n",
    "# Run the simulation, and save the results.\n",
    "with open(file_output, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(labels)\n",
    "    while True:\n",
    "        rotor_speeds = agent.act()\n",
    "        _, _, done = task.step(rotor_speeds)\n",
    "        to_write = [task.sim.time] + list(task.sim.pose) + list(task.sim.v) + list(task.sim.angular_v) + list(rotor_speeds)\n",
    "        for ii in range(len(labels)):\n",
    "            results[labels[ii]].append(to_write[ii])\n",
    "        writer.writerow(to_write)\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to visualize how the position of the quadcopter evolved during the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcceb623438>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(results['time'], results['x'], label='x')\n",
    "plt.plot(results['time'], results['y'], label='y')\n",
    "plt.plot(results['time'], results['z'], label='z')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell visualizes the velocity of the quadcopter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccf3f3e080>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['x_velocity'], label='x_hat')\n",
    "plt.plot(results['time'], results['y_velocity'], label='y_hat')\n",
    "plt.plot(results['time'], results['z_velocity'], label='z_hat')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can plot the Euler angles (the rotation of the quadcopter over the $x$-, $y$-, and $z$-axes),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccf0066e80>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['phi'], label='phi')\n",
    "plt.plot(results['time'], results['theta'], label='theta')\n",
    "plt.plot(results['time'], results['psi'], label='psi')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before plotting the velocities (in radians per second) corresponding to each of the Euler angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcce9001ef0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['phi_velocity'], label='phi_velocity')\n",
    "plt.plot(results['time'], results['theta_velocity'], label='theta_velocity')\n",
    "plt.plot(results['time'], results['psi_velocity'], label='psi_velocity')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the code cell below to print the agent's choice of actions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcce6b41a90>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['rotor_speed1'], label='Rotor 1 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed2'], label='Rotor 2 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed3'], label='Rotor 3 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed4'], label='Rotor 4 revolutions / second')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specifying a task, you will derive the environment state from the simulator.  Run the code cell below to print the values of the following variables at the end of the simulation:\n",
    "- `task.sim.pose` (the position of the quadcopter in ($x,y,z$) dimensions and the Euler angles),\n",
    "- `task.sim.v` (the velocity of the quadcopter in ($x,y,z$) dimensions), and\n",
    "- `task.sim.angular_v` (radians/second for each of the three Euler angles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -7.10699653  15.41610517  26.15604578   0.32610169   0.1919362    0.        ]\n",
      "[-4.82088282  8.36895983  3.97822031]\n",
      "[ 0.07612306  0.07236226  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# the pose, velocity, and angular velocity of the quadcopter at the end of the episode\n",
    "print(task.sim.pose)\n",
    "print(task.sim.v)\n",
    "print(task.sim.angular_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample task in `task.py`, we use the 6-dimensional pose of the quadcopter to construct the state of the environment at each timestep.  However, when amending the task for your purposes, you are welcome to expand the size of the state vector by including the velocity information.  You can use any combination of the pose, velocity, and angular velocity - feel free to tinker here, and construct the state to suit your task.\n",
    "\n",
    "## The Task\n",
    "\n",
    "A sample task has been provided for you in `task.py`.  Open this file in a new window now. \n",
    "\n",
    "The `__init__()` method is used to initialize several variables that are needed to specify the task.  \n",
    "- The simulator is initialized as an instance of the `PhysicsSim` class (from `physics_sim.py`).  \n",
    "- Inspired by the methodology in the original DDPG paper, we make use of action repeats.  For each timestep of the agent, we step the simulation `action_repeats` timesteps.  If you are not familiar with action repeats, please read the **Results** section in [the DDPG paper](https://arxiv.org/abs/1509.02971).\n",
    "- We set the number of elements in the state vector.  For the sample task, we only work with the 6-dimensional pose information.  To set the size of the state (`state_size`), we must take action repeats into account.  \n",
    "- The environment will always have a 4-dimensional action space, with one entry for each rotor (`action_size=4`). You can set the minimum (`action_low`) and maximum (`action_high`) values of each entry here.\n",
    "- The sample task in this provided file is for the agent to reach a target position.  We specify that target position as a variable.\n",
    "\n",
    "The `reset()` method resets the simulator.  The agent should call this method every time the episode ends.  You can see an example of this in the code cell below.\n",
    "\n",
    "The `step()` method is perhaps the most important.  It accepts the agent's choice of action `rotor_speeds`, which is used to prepare the next state to pass on to the agent.  Then, the reward is computed from `get_reward()`.  The episode is considered done if the time limit has been exceeded, or the quadcopter has travelled outside of the bounds of the simulation.\n",
    "\n",
    "In the next section, you will learn how to test the performance of an agent on this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent\n",
    "\n",
    "The sample agent given in `agents/policy_search.py` uses a very simplistic linear policy to directly compute the action vector as a dot product of the state vector and a matrix of weights. Then, it randomly perturbs the parameters by adding some Gaussian noise, to produce a different policy. Based on the average reward obtained in each episode (`score`), it keeps track of the best set of parameters found so far, how the score is changing, and accordingly tweaks a scaling factor to widen or tighten the noise.\n",
    "\n",
    "Run the code cell below to see how the agent performs on the sample task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions (x,y,z), reward: [  3.90585152e-03  -6.35814729e-03   1.00189104e+01] 150.510255117\n",
      "positions (x,y,z), reward: [-2.43523137  1.82356715  2.66358074] 90.9845788471\n",
      "Episode =    1, score = 170.175 (best = 170.175), noise_scale = 0.05positions (x,y,z), reward: [ 0.24280329 -0.34904526  9.7409042 ] 69.8965993845\n",
      "positions (x,y,z), reward: [ 1.36858394 -1.15035784  8.06239097] 82.7316036851\n",
      "Episode =    2, score = 173.776 (best = 173.776), noise_scale = 0.025positions (x,y,z), reward: [ 0.09965266 -0.07832843  9.81706599] 65.817302299\n",
      "positions (x,y,z), reward: [ 1.54180335  0.57760349  6.9208276 ] 91.4423218846\n",
      "positions (x,y,z), reward: [ 3.57855108  2.01238209  0.22274362] 93.3674392065\n",
      "Episode =    3, score = 176.645 (best = 176.645), noise_scale = 0.0125positions (x,y,z), reward: [ 7.10053496 -1.08056841  0.76075937] 91.0026384038\n",
      "Episode =    4, score = 172.599 (best = 176.645), noise_scale = 0.025positions (x,y,z), reward: [-1.6357705  -1.06209295  8.41392452] 63.6092888984\n",
      "positions (x,y,z), reward: [-1.74508427 -1.16909815  8.15776457] 61.115073125\n",
      "Episode =    5, score = 155.655 (best = 176.645), noise_scale = 0.05positions (x,y,z), reward: [ -6.05113964e-04  -2.83056003e-02   1.00020726e+01] 96.9275211818\n",
      "positions (x,y,z), reward: [ 1.37810949 -0.48700559  6.88873901] 90.2054431206\n",
      "positions (x,y,z), reward: [ 1.79520046 -0.63150045  5.72616598] 95.6608305708\n",
      "Episode =    6, score = 182.471 (best = 182.471), noise_scale = 0.025positions (x,y,z), reward: [ 0.05259522  0.02136473  9.90997509] 75.0654017733\n",
      "positions (x,y,z), reward: [ 2.04653717  0.06763591  8.7343585 ] 87.939954471\n",
      "positions (x,y,z), reward: [ 6.01920211 -1.96815306  2.71088863] 81.8541858592\n",
      "Episode =    7, score = 165.598 (best = 182.471), noise_scale = 0.05positions (x,y,z), reward: [ 4.68431281 -5.82563122  3.9187822 ] 80.8294897574\n",
      "Episode =    8, score = 155.038 (best = 182.471), noise_scale = 0.1positions (x,y,z), reward: [ 0.97048792  0.06300727  9.23273689] 72.5641428577\n",
      "positions (x,y,z), reward: [ 2.70451679  0.07466165  6.76408096] 94.9435661101\n",
      "positions (x,y,z), reward: [ 2.84629872  0.03298712  6.37340922] 96.3825927525\n",
      "Episode =    9, score = 181.279 (best = 182.471), noise_scale = 0.2positions (x,y,z), reward: [ 0.08797383 -0.04052467  9.82608699] 70.2060255803\n",
      "positions (x,y,z), reward: [ 1.52972294  0.41677961  7.29181563] 76.897003835\n",
      "Episode =   10, score = 175.168 (best = 182.471), noise_scale = 0.4positions (x,y,z), reward: [-0.04384541 -0.07552093  9.89366862] 78.2496340273\n",
      "positions (x,y,z), reward: [ -2.71647131e-01   8.20540378e-03   9.69492666e+00] 75.5458005756\n",
      "positions (x,y,z), reward: [ -6.23593882e-01  -3.38483223e-03   9.47003966e+00] 64.0349509307\n",
      "positions (x,y,z), reward: [-1.34533842 -0.09174497  9.06790909] 69.5630324743\n",
      "Episode =   11, score = 140.519 (best = 182.471), noise_scale = 0.8positions (x,y,z), reward: [ 1.54076984 -0.0465053   8.08215211] 80.8085801681\n",
      "positions (x,y,z), reward: [ 2.43493339 -1.01780633  5.33431948] 94.7917400565\n",
      "positions (x,y,z), reward: [ 2.48254985 -1.09025866  4.93830631] 94.1058812292\n",
      "positions (x,y,z), reward: [ 2.9048833  -1.38775756  2.4856317 ] 95.9932556056\n",
      "Episode =   12, score = 179.674 (best = 182.471), noise_scale = 1.6positions (x,y,z), reward: [  3.06114769e-03  -1.05971991e-01   1.02976482e+01] 105.662001636\n",
      "positions (x,y,z), reward: [ 2.65633366 -0.33850825  7.71269544] 92.2006896593\n",
      "positions (x,y,z), reward: [ 4.2477432  -1.20189528  0.        ] 91.4833247791\n",
      "Episode =   13, score = 181.024 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [ -3.05660706e-02  -2.73290228e-03   1.01523786e+01] 102.926416041\n",
      "positions (x,y,z), reward: [-5.37461818 -0.31761227  6.21969889] 58.2203337657\n",
      "positions (x,y,z), reward: [-6.95361671 -1.88994663  0.69108988] 63.2441257089\n",
      "Episode =   14, score = 139.341 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [ -7.43059382e-03   5.40345448e-02   9.92443757e+00] 83.7393166417\n",
      "positions (x,y,z), reward: [-0.03195664  0.06593767  9.88221639] 79.5515529801\n",
      "positions (x,y,z), reward: [-0.15659107  0.03738615  9.71574944] 67.1425177477\n",
      "positions (x,y,z), reward: [-0.16854991  0.03048837  9.6801122 ] 65.1169153826\n",
      "positions (x,y,z), reward: [ 6.89729754 -2.42488795  6.8195715 ] 63.0700600024\n",
      "positions (x,y,z), reward: [ 11.87114057  -2.65376647   2.92310937] 66.4111698014\n",
      "Episode =   15, score = 144.778 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [  0.36841274  -0.14786655  10.16607273] 96.2654530753\n",
      "positions (x,y,z), reward: [  0.94105256  -1.3408835   10.38042227] 65.9950413373\n",
      "positions (x,y,z), reward: [  0.68660628  -2.08829902  10.21537324] 64.682264085\n",
      "positions (x,y,z), reward: [ 0.02064079 -3.06804434  9.90974682] 61.037803315\n",
      "positions (x,y,z), reward: [-0.99456943 -4.03923268  9.39552663] 52.3504710407\n",
      "positions (x,y,z), reward: [-2.85050086 -5.78813565  7.48040689] 56.4792188647\n",
      "positions (x,y,z), reward: [-3.03681548 -5.91136261  7.30637785] 55.2655388613\n",
      "positions (x,y,z), reward: [-6.82016562 -7.7424283   4.37715679] 48.7940376331\n",
      "positions (x,y,z), reward: [-8.23694649 -8.38482411  3.01698533] 35.3388029007\n",
      "Episode =   16, score = 130.340 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [ -1.13333767e-02   8.70221125e-03   1.00219343e+01] 130.716613726\n",
      "positions (x,y,z), reward: [ -1.16381664e-03   4.96320150e-03   1.00243375e+01] 122.511990916\n",
      "positions (x,y,z), reward: [ 2.10401923 -0.2433813   7.16838117] 74.3757259372\n",
      "positions (x,y,z), reward: [ 2.19641198 -0.23341803  6.98664803] 74.0245394236\n",
      "positions (x,y,z), reward: [ 2.71378673 -0.15880194  5.84886785] 91.2731946462\n",
      "positions (x,y,z), reward: [ 4.42525254  0.11067574  2.20663341] 95.1416661504\n",
      "Episode =   17, score = 172.694 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [  0.01650538   0.02332284  10.04014703] 138.857632453\n",
      "positions (x,y,z), reward: [ 1.37204866  0.90091779  9.6189355 ] 65.7940070302\n",
      "positions (x,y,z), reward: [ 1.52452089  1.00057991  9.5435075 ] 64.2820136571\n",
      "positions (x,y,z), reward: [ 3.51156955  2.21898846  8.47601732] 83.6255298953\n",
      "positions (x,y,z), reward: [ 11.12850151   5.08747295   0.94912309] 81.884497742\n",
      "Episode =   18, score = 169.986 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [  0.08958143   0.08537152  10.00361171] 95.7043617595\n",
      "positions (x,y,z), reward: [ 1.51530465 -0.80995739  7.97058677] 77.7850497471\n",
      "positions (x,y,z), reward: [ 4.22653261 -0.97069531  1.30161558] 99.0540271044\n",
      "Episode =   19, score = 181.159 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [-0.31238647  0.0277474   9.97973037] 69.7910824041\n",
      "positions (x,y,z), reward: [-1.13542769 -0.20695069  9.86164179] 65.9927004283\n",
      "positions (x,y,z), reward: [-2.54956518 -0.41576497  9.35223979] 59.6393502147\n",
      "positions (x,y,z), reward: [-2.75756192 -0.4401858   9.25477264] 57.1469664958\n",
      "positions (x,y,z), reward: [-5.20446811 -0.62197807  8.13847492] 56.1395146555\n",
      "positions (x,y,z), reward: [-10.09152388  -4.62671626   1.01773039] 30.7454287994\n",
      "Episode =   20, score = 101.958 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [ -1.73986504  -0.65535814  10.06604478] 65.091103726\n",
      "positions (x,y,z), reward: [ -1.72605816  -0.7327367   10.05966412] 59.274920699\n",
      "Episode =   21, score = 147.613 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [ 0.05755517 -0.0253769   9.98754108] 87.7239031951\n",
      "positions (x,y,z), reward: [ 0.30611939 -0.08186891  9.83864889] 81.4118852341\n",
      "positions (x,y,z), reward: [ 0.36159667 -0.10119617  9.82425236] 85.4105084176\n",
      "positions (x,y,z), reward: [ 0.49733279 -0.15207611  9.76981024] 71.3857181318\n",
      "positions (x,y,z), reward: [ 1.31026724 -0.4145291   8.42337857] 81.2511616995\n",
      "positions (x,y,z), reward: [ 2.07639998  0.05857138  5.53440452] 100.554170099\n",
      "positions (x,y,z), reward: [ 2.71940214  0.29722878  0.42882429] 97.0917133265\n",
      "Episode =   22, score = 178.370 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [  0.1214521   0.1450106  10.0886596] 98.5119438464\n",
      "positions (x,y,z), reward: [  0.01982976   0.20336922  10.04681004] 73.2635259318\n",
      "positions (x,y,z), reward: [ 0.42286544  0.70526462  9.50262045] 75.5117924762\n",
      "positions (x,y,z), reward: [ 1.33668372  1.03662454  6.6496311 ] 89.5703889388\n",
      "Episode =   23, score = 179.390 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [-1.36406958  0.03023772  9.3177207 ] 61.0978328089\n",
      "positions (x,y,z), reward: [-1.83342406 -0.25807632  8.91890696] 62.2481780006\n",
      "positions (x,y,z), reward: [-1.8839261  -0.49709614  8.6548661 ] 58.8281073496\n",
      "positions (x,y,z), reward: [-1.16527742 -1.70182719  7.59002616] 76.6307904354\n",
      "positions (x,y,z), reward: [-1.26912089 -2.0362257   6.84341187] 77.868408179\n",
      "Episode =   24, score = 156.778 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [-1.304002   -0.38102111  7.32843359] 75.8777192643\n",
      "positions (x,y,z), reward: [-1.1376835  -0.14041545  4.32577518] 84.6592092527\n",
      "Episode =   25, score = 168.494 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00580358] 155.803719385\n",
      "positions (x,y,z), reward: [-0.54806575 -0.22120192  9.64343121] 63.1574457568\n",
      "positions (x,y,z), reward: [-2.16261223 -1.22696817  8.1126358 ] 61.7274082977\n",
      "positions (x,y,z), reward: [-3.19255205 -1.44246527  7.09961086] 68.2575366939\n",
      "positions (x,y,z), reward: [-3.5933996  -1.5218556   6.75179673] 68.492115636\n",
      "positions (x,y,z), reward: [-5.49687786 -1.88569632  5.22836399] 63.3005578977\n",
      "positions (x,y,z), reward: [-10.81441211  -2.68413717   0.86922638] 23.1687075289\n",
      "positions (x,y,z), reward: [-11.50786738  -2.82898029   0.19143737] 18.0510335014\n",
      "Episode =   26, score = 129.967 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [  0.26212938  -0.05279522  10.06980087] 90.5792004201\n",
      "positions (x,y,z), reward: [  0.78243555   0.02120105  10.21145305] 93.7235433527\n",
      "positions (x,y,z), reward: [  1.64605348   0.55662617  10.17074629] 76.270130715\n",
      "positions (x,y,z), reward: [  1.86370157   0.71474479  10.16802585] 94.693611807\n",
      "positions (x,y,z), reward: [ 5.6676173   3.85203413  3.95378272] 98.7914751108\n",
      "positions (x,y,z), reward: [ 5.77245237  4.03929905  3.22330215] 97.3128327187\n",
      "Episode =   27, score = 182.371 (best = 182.471), noise_scale = 3.2positions (x,y,z), reward: [ 1.82801788  0.69578853  9.87418969] 85.1829591655\n",
      "positions (x,y,z), reward: [ 6.2672639   0.3562192   9.01312318] 78.5890310921\n",
      "positions (x,y,z), reward: [  8.85133207e+00   2.27960866e-03   5.55548501e+00] 88.052147233\n",
      "positions (x,y,z), reward: [ 9.67228413  0.02648171  3.68521589] 84.7946800748\n",
      "positions (x,y,z), reward: [ 10.8670192    0.08619671   0.60443678] 79.744599332\n",
      "positions (x,y,z), reward: [ 11.18022157   0.09076483   0.        ] 72.845656\n",
      "Episode =   28, score = 188.125 (best = 188.125), noise_scale = 1.6positions (x,y,z), reward: [ 0.61495663 -1.15056936  8.19893302] 89.0169571178\n",
      "positions (x,y,z), reward: [ 1.40961387 -2.10427953  6.1875734 ] 85.3168762182\n",
      "positions (x,y,z), reward: [ 2.41846444 -3.67056702  2.33387135] 95.2964544678\n",
      "Episode =   29, score = 185.555 (best = 188.125), noise_scale = 3.2positions (x,y,z), reward: [-0.08546836  0.01066901  9.97940192] 108.636644824\n",
      "positions (x,y,z), reward: [-1.77156403  0.35573405  8.00891966] 80.8913170297\n",
      "positions (x,y,z), reward: [-3.00530911  0.67099984  5.83803651] 71.9530437676\n",
      "Episode =   31, score = 181.874 (best = 188.125), noise_scale = 3.2positions (x,y,z), reward: [-0.0556986  -0.05337655  9.82111028] 79.0505945755\n",
      "positions (x,y,z), reward: [-0.15579878 -0.0740269   9.5389105 ] 75.463444496\n",
      "positions (x,y,z), reward: [-1.1069758  -0.53251709  7.06967519] 77.0708896363\n",
      "positions (x,y,z), reward: [-0.65588804 -1.36779871  2.86237939] 100.154286177\n",
      "positions (x,y,z), reward: [-0.61833565 -1.57498292  2.02344159] 99.8067700642\n",
      "positions (x,y,z), reward: [-0.59421299 -1.72939242  1.34945198] 99.4059402508\n",
      "Episode =   32, score = 181.677 (best = 188.125), noise_scale = 3.2positions (x,y,z), reward: [-1.62751898 -1.99896091  0.        ] 94.2401746584\n",
      "Episode =   33, score = 195.008 (best = 195.008), noise_scale = 1.6positions (x,y,z), reward: [  6.80834155e-02   2.16063693e-03   9.96225098e+00] 104.92072334\n",
      "positions (x,y,z), reward: [ 0.71466616  0.04696618  9.26208152] 88.3482315323\n",
      "positions (x,y,z), reward: [ 3.42459246 -0.29545023  6.78828922] 98.0618578728\n",
      "positions (x,y,z), reward: [ 5.50592302 -1.08470598  3.92232533] 103.431190808\n",
      "Episode =   34, score = 198.203 (best = 198.203), noise_scale = 0.8positions (x,y,z), reward: [ 3.08826364  2.07638554  6.47255132] 100.217244923\n",
      "positions (x,y,z), reward: [ 4.45549423  2.52647481  2.00453755] 94.8384704546\n",
      "Episode =   35, score = 195.484 (best = 198.203), noise_scale = 1.6positions (x,y,z), reward: [-0.02443609  0.16601787  6.69343126] 91.1689815944\n",
      "positions (x,y,z), reward: [ 0.38252318  0.11018124  5.48928614] 94.6081021758\n",
      "positions (x,y,z), reward: [ 2.84243274  0.67797476  0.        ] 97.7701344269\n",
      "Episode =   36, score = 191.862 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [ 0.62832991 -2.90867908  5.84920154] 90.5919029758\n",
      "positions (x,y,z), reward: [ 1.76389692 -3.85157064  2.20224717] 94.2234847178\n",
      "positions (x,y,z), reward: [ 1.95726982 -3.92391069  1.78953785] 94.644444482\n",
      "Episode =   37, score = 184.180 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [ 0.47753525 -1.36504244  6.21666766] 88.3844142682\n",
      "Episode =   38, score = 186.753 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [-0.41990109 -0.31531232  9.66921114] 86.7835438458\n",
      "positions (x,y,z), reward: [-2.84282765 -1.07564053  6.19120241] 72.5061110542\n",
      "positions (x,y,z), reward: [-3.67498893 -1.18918319  3.9247176 ] 81.8851725868\n",
      "positions (x,y,z), reward: [-4.03670606 -0.96362159  0.53781235] 86.6260051946\n",
      "Episode =   39, score = 170.374 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [-0.13166908 -0.8112832   9.42825523] 68.6941131233\n",
      "positions (x,y,z), reward: [ 0.40289024 -1.15837054  7.8298742 ] 84.089439338\n",
      "positions (x,y,z), reward: [ 1.49393413 -1.14907827  6.45781781] 94.4969753349\n",
      "positions (x,y,z), reward: [ 2.70623085 -1.18943939  4.66482705] 99.1272599339\n",
      "positions (x,y,z), reward: [ 3.68618983 -1.37696468  2.99608906] 100.869485817\n",
      "Episode =   40, score = 183.364 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [ 0.50500856 -0.36046526  9.62702091] 86.5927980179\n",
      "positions (x,y,z), reward: [ 0.29242481 -0.70999505  8.9104921 ] 81.6976838366\n",
      "positions (x,y,z), reward: [-1.96394576 -2.24298819  4.27734073] 85.5691652923\n",
      "positions (x,y,z), reward: [-3.10071276 -3.27347214  0.36883403] 85.2729848733\n",
      "Episode =   41, score = 181.517 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [ -9.67632457e-03   2.36575601e-02   9.98582910e+00] 104.100629606\n",
      "positions (x,y,z), reward: [-0.98000227 -0.59289181  7.92245964] 88.6345934602\n",
      "positions (x,y,z), reward: [-0.90365313 -0.88601465  6.95464049] 84.0815844413\n",
      "Episode =   42, score = 180.286 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [-0.24104638  0.29082091  9.78821555] 83.1294595171\n",
      "positions (x,y,z), reward: [-4.94768681  1.32807859  0.77190502] 84.3699999084\n",
      "Episode =   43, score = 169.089 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [ 0.24079643  0.01660978  9.92789425] 91.2681869761\n",
      "positions (x,y,z), reward: [  1.86306046e+00   3.51966695e-03   9.56907750e+00] 89.3454997123\n",
      "positions (x,y,z), reward: [ 3.95650758 -0.97349462  7.49940675] 89.3268502351\n",
      "Episode =   44, score = 182.680 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [  5.86065359e-03  -4.61709168e-04   1.00089698e+01] 136.986989511\n",
      "positions (x,y,z), reward: [-0.25196265  0.02491795  9.94053562] 120.741528397\n",
      "positions (x,y,z), reward: [-0.96219416  0.52583953  9.15639933] 69.4151788007\n",
      "positions (x,y,z), reward: [-0.97391529  0.66835988  8.96841419] 77.2552193189\n",
      "positions (x,y,z), reward: [ 0.35205457  1.3457765   7.11481862] 85.4932740495\n",
      "positions (x,y,z), reward: [ 0.55177391  1.39948048  6.88854613] 86.2008838362\n",
      "Episode =   45, score = 179.652 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [ -4.95086728e-02   5.18000118e-04   9.99734591e+00] 116.889942902\n",
      "positions (x,y,z), reward: [-0.90230386  0.02274667  9.56121716] 84.5847412788\n",
      "positions (x,y,z), reward: [-2.38881994  0.06914892  8.18417063] 78.1273479963\n",
      "Episode =   46, score = 159.040 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [-0.06544219 -0.02002683  9.89032929] 91.9490531502\n",
      "positions (x,y,z), reward: [-0.25302543  0.04475596  9.62850435] 87.5852132957\n",
      "positions (x,y,z), reward: [-2.48052089  1.30214138  7.04899997] 80.4071609977\n",
      "positions (x,y,z), reward: [-4.48088383  1.6445272   3.57263449] 73.3695616242\n",
      "Episode =   47, score = 172.433 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [ 0.19479635  0.69950998  9.21802537] 85.5841493969\n",
      "positions (x,y,z), reward: [ 0.8487151   1.26923964  7.62295189] 85.7383541983\n",
      "positions (x,y,z), reward: [ 0.92014921  1.33244474  7.48154549] 89.1754202444\n",
      "positions (x,y,z), reward: [ 1.75016002  1.87765848  5.36489293] 87.8436294675\n",
      "positions (x,y,z), reward: [ 2.3382788   2.14575843  3.58614708] 95.5904812393\n",
      "Episode =   48, score = 187.329 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [-0.79846379 -0.31455183  9.63208459] 86.9560358858\n",
      "positions (x,y,z), reward: [-1.16869981 -0.41958148  9.2768474 ] 80.6918711888\n",
      "positions (x,y,z), reward: [-2.16168258 -0.51189667  7.58699579] 81.1360791259\n",
      "Episode =   49, score = 173.047 (best = 198.203), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00469259] 151.216881403\n",
      "positions (x,y,z), reward: [ 0.66664452  0.13599918  9.67673269] 82.9851917912\n",
      "positions (x,y,z), reward: [ 4.59533349  0.07639999  7.33601556] 106.40814583\n",
      "Episode =   50, score = 200.161 (best = 200.161), noise_scale = 1.6positions (x,y,z), reward: [ 0.8679374  -0.95463807  8.54820469] 92.0814387532\n",
      "positions (x,y,z), reward: [ 1.3193369  -1.77517115  7.20006634] 95.1798269096\n",
      "positions (x,y,z), reward: [ 3.33075689 -2.36844307  1.88942358] 98.1703276811\n",
      "Episode =   51, score = 193.573 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 0.62046221 -0.08802563  9.34172468] 93.8283136669\n",
      "Episode =   52, score = 199.634 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  0.0746606    0.02598821  10.04147405] 125.313949914\n",
      "positions (x,y,z), reward: [  0.18759526   0.1116732   10.07087762] 121.494747656\n",
      "positions (x,y,z), reward: [  0.35905919   0.41629928  10.01880686] 82.2412207022\n",
      "positions (x,y,z), reward: [ 0.20115814  1.03068117  8.50731802] 85.1309984771\n",
      "positions (x,y,z), reward: [-0.03525912  1.28480831  7.25198668] 85.4220017708\n",
      "Episode =   53, score = 185.905 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  5.60490048e-03  -2.86384517e-03   1.00105127e+01] 142.919764526\n",
      "positions (x,y,z), reward: [  9.97997268e-03  -1.15597910e-02   1.00133709e+01] 137.841955757\n",
      "positions (x,y,z), reward: [-1.23605022 -0.26797648  9.03144503] 80.107410109\n",
      "Episode =   54, score = 168.752 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 0.57583114 -0.04978444  9.97517932] 84.5632662099\n",
      "positions (x,y,z), reward: [  9.53986718e-01  -8.79187095e-03   9.74469960e+00] 91.1087235089\n",
      "positions (x,y,z), reward: [ 1.15386877 -0.0823254   8.70200944] 92.6130853549\n",
      "positions (x,y,z), reward: [ 1.85588335 -0.17164487  3.35364414] 101.839986995\n",
      "Episode =   56, score = 192.625 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  5.17369632e-01  -8.20987940e-03   9.88964538e+00] 87.7888985314\n",
      "positions (x,y,z), reward: [ 0.93472386 -1.37401783  8.94858194] 92.1456769177\n",
      "positions (x,y,z), reward: [ 0.00773573 -4.00787008  3.95021211] 92.3700881889\n",
      "Episode =   57, score = 185.874 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [-0.02185921  0.15181925  9.63598463] 87.2005508553\n",
      "positions (x,y,z), reward: [-0.91104538  1.59203976  6.2172226 ] 76.7945785285\n",
      "positions (x,y,z), reward: [-1.46452016  2.48743659  1.64604035] 88.9822520207\n",
      "Episode =   58, score = 171.550 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 1.26078118 -0.33122203  9.3529563 ] 89.8940093837\n",
      "positions (x,y,z), reward: [ 7.61282241 -0.23213211  2.56936423] 99.2737881094\n",
      "Episode =   59, score = 199.227 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [-1.3523113   1.80908783  7.80138728] 83.0009516069\n",
      "Episode =   60, score = 174.139 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  0.10280693   0.02150567  10.02586158] 122.828548317\n",
      "positions (x,y,z), reward: [ 1.79546465 -0.99815961  8.34106734] 93.041450128\n",
      "positions (x,y,z), reward: [ 2.46771838 -1.31701615  6.92617304] 91.9978345448\n",
      "positions (x,y,z), reward: [ 4.98741314 -1.75138272  2.0427136 ] 90.19124314\n",
      "Episode =   62, score = 153.036 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  6.03094684e-03  -2.10281713e-03   1.00102466e+01] 141.003702161\n",
      "positions (x,y,z), reward: [ 0.11120779 -0.0459455   9.98100636] 107.082110168\n",
      "positions (x,y,z), reward: [ 4.3059218  -0.61135289  7.11660604] 99.911519959\n",
      "Episode =   63, score = 190.526 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  4.78277052e-02  -2.10440792e-03   9.95112517e+00] 108.296071334\n",
      "Episode =   64, score = 195.236 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  0.09585358   0.0284701   10.04408709] 115.505873529\n",
      "positions (x,y,z), reward: [ 0.02566511  0.29775997  9.9860239 ] 81.8836009584\n",
      "positions (x,y,z), reward: [-0.21589057  0.32536921  9.59360006] 82.5933028032\n",
      "positions (x,y,z), reward: [ 0.48932735 -1.59363956  6.73228285] 93.2949831956\n",
      "positions (x,y,z), reward: [ 0.54142643 -2.60662281  5.25996488] 96.8513879892\n",
      "positions (x,y,z), reward: [ 0.63711514 -3.86015864  2.61665061] 99.5746851684\n",
      "Episode =   65, score = 185.204 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00486889] 151.107512411\n",
      "positions (x,y,z), reward: [ -3.49051899e-03  -5.84992111e-03   1.00131485e+01] 146.950637237\n",
      "positions (x,y,z), reward: [ 0.03854019 -0.03503695  9.98159172] 101.073714775\n",
      "positions (x,y,z), reward: [ 2.2885603   0.9486151   7.38468013] 95.65734648\n",
      "positions (x,y,z), reward: [ 4.53282265  2.69521461  2.67039437] 98.2843236168\n",
      "Episode =   66, score = 189.264 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [-1.31602396 -0.26968063  7.18687616] 80.6361953253\n",
      "positions (x,y,z), reward: [-0.00876479 -1.09263686  3.60561168] 97.8847322163\n",
      "Episode =   67, score = 183.539 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [-0.1687754   0.08216901  9.87281497] 90.1440105778\n",
      "positions (x,y,z), reward: [-3.43937504  0.70792033  7.83244105] 68.2729923301\n",
      "positions (x,y,z), reward: [-5.54630141  1.28669281  5.6055604 ] 61.3060168628\n",
      "positions (x,y,z), reward: [-6.22939551  1.47866309  4.83466688] 55.2464526908\n",
      "positions (x,y,z), reward: [-9.17067496  1.62396349  0.08218305] 59.7054940259\n",
      "Episode =   68, score = 153.133 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 0.01150937  0.0551999   9.94812508] 96.2452325346\n",
      "positions (x,y,z), reward: [ 0.07713913  0.09379519  9.92424498] 94.9199257628\n",
      "positions (x,y,z), reward: [ 0.16475902  0.14287727  9.93874296] 111.575027831\n",
      "positions (x,y,z), reward: [  0.2611243    0.22263531  10.01868835] 117.75709694\n",
      "positions (x,y,z), reward: [ 0.65402778  0.65298579  9.89810911] 83.4224206067\n",
      "positions (x,y,z), reward: [ 4.90641962  3.39220025  1.43031913] 88.3705110188\n",
      "Episode =   69, score = 181.680 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 0.46411181  0.05064027  9.99575154] 106.763501979\n",
      "positions (x,y,z), reward: [ 5.54186356 -0.02175524  8.26317558] 100.456092714\n",
      "positions (x,y,z), reward: [ 6.04270308 -0.09865881  7.84737225] 107.251666699\n",
      "positions (x,y,z), reward: [ 6.80642722 -0.21526225  7.1144199 ] 108.667660178\n",
      "Episode =   70, score = 196.788 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 1.79884433 -1.50573527  6.55849161] 98.4925883883\n",
      "positions (x,y,z), reward: [ 2.58610852 -3.51246635  0.        ] 92.5660694444\n",
      "Episode =   71, score = 197.907 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  3.18766922e-03   4.71455826e-03   1.00085886e+01] 135.896229121\n",
      "positions (x,y,z), reward: [ 0.030163    0.1645441   9.74417443] 80.8021653692\n",
      "positions (x,y,z), reward: [ 0.06595484  0.23272162  9.56892994] 84.0945492477\n",
      "positions (x,y,z), reward: [ 0.05889185  1.28739225  7.54875466] 80.5131697352\n",
      "positions (x,y,z), reward: [ 0.79614926  2.44744711  3.04708202] 92.9052013683\n",
      "Episode =   72, score = 181.081 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ -3.66970961e-02   7.89203355e-03   1.00503310e+01] 147.017246169\n",
      "positions (x,y,z), reward: [-0.46119922 -0.59421208  7.58496977] 84.8116698864\n",
      "Episode =   73, score = 185.660 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 1.27486846  0.46754179  9.10503893] 87.5213743243\n",
      "positions (x,y,z), reward: [ 2.28949522  0.66364528  7.52997473] 94.2014332943\n",
      "positions (x,y,z), reward: [ 3.97569315  0.9647097   4.45046361] 99.191787569\n",
      "Episode =   74, score = 194.143 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  0.01496215   0.11766795  10.01649321] 96.8514019575\n",
      "positions (x,y,z), reward: [-0.11760574  0.14841378  9.11299427] 88.5643347387\n",
      "positions (x,y,z), reward: [ 0.01808996 -0.32014296  7.80647894] 85.8180385163\n",
      "positions (x,y,z), reward: [ 0.41715776 -0.52608371  6.40428237] 92.0108996309\n",
      "Episode =   75, score = 192.096 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [-0.82075435 -0.08994919  9.82824483] 84.5538020928\n",
      "positions (x,y,z), reward: [-1.08920754 -0.11135119  9.83074418] 98.7998949951\n",
      "positions (x,y,z), reward: [-1.2429171  -0.3352762   9.83020973] 93.4134503554\n",
      "positions (x,y,z), reward: [-1.69478717 -1.19001909  9.84120569] 84.3664019538\n",
      "positions (x,y,z), reward: [-1.83409472 -1.67096284  9.86532915] 68.1816763975\n",
      "Episode =   76, score = 119.618 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 0.51646977 -0.0782827   9.9703722 ] 78.6968937364\n",
      "positions (x,y,z), reward: [ 0.51855912 -0.14232262  9.91499662] 84.4174120469\n",
      "positions (x,y,z), reward: [ 0.44601336 -0.94761159  8.91054581] 86.608112179\n",
      "positions (x,y,z), reward: [-0.54842482 -3.89890986  4.34375283] 94.419407194\n",
      "Episode =   77, score = 186.019 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ -0.65603248   0.29865907  10.03359044] 106.30445747\n",
      "Episode =   78, score = 166.653 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [-0.86467687  0.41240747  8.95222822] 88.3194603398\n",
      "positions (x,y,z), reward: [-0.94809736  0.45688226  8.85511538] 87.3352569568\n",
      "positions (x,y,z), reward: [-1.79932542  0.69357175  7.852249  ] 73.819638582\n",
      "positions (x,y,z), reward: [-3.13219464  0.93319848  5.52545925] 70.2196847992\n",
      "positions (x,y,z), reward: [-4.63235247  1.09041941  0.20854379] 86.1532401343\n",
      "Episode =   79, score = 170.383 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00512035] 156.049450326\n",
      "positions (x,y,z), reward: [  3.14384166e-03  -1.59344212e-02   1.00235695e+01] 128.902964496\n",
      "positions (x,y,z), reward: [-0.2060743  -0.10321138  9.85674552] 77.4632740607\n",
      "positions (x,y,z), reward: [-0.2670439  -0.13089977  9.74385518] 72.0471051339\n",
      "positions (x,y,z), reward: [-0.57634862 -1.85475859  8.3197482 ] 75.3342173259\n",
      "positions (x,y,z), reward: [-0.71202014 -2.41290211  7.77532403] 75.0175870672\n",
      "positions (x,y,z), reward: [-1.49605567 -6.45375032  4.48032528] 83.0513998835\n",
      "positions (x,y,z), reward: [-1.64538847 -7.2770677   3.82193671] 82.3182548041\n",
      "positions (x,y,z), reward: [ -2.0918163  -10.07858745   1.15019209] 77.9902444506\n",
      "Episode =   80, score = 160.727 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  0.14514094  -0.08984119  10.02464707] 102.012104783\n",
      "positions (x,y,z), reward: [ 1.56982662 -1.05157673  7.31010315] 89.0257524287\n",
      "positions (x,y,z), reward: [ 2.91415588 -2.9477879   0.33570119] 93.9558900123\n",
      "Episode =   81, score = 192.473 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ -0.18186778   0.06151466  10.10690942] 114.429689467\n",
      "positions (x,y,z), reward: [-1.36391476  0.93352207  9.5240471 ] 69.8516740363\n",
      "positions (x,y,z), reward: [-1.77811787  1.26342749  8.8496324 ] 59.920544316\n",
      "positions (x,y,z), reward: [-2.07077695  1.46616539  8.13989591] 64.1215994319\n",
      "Episode =   82, score = 166.709 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [-0.4102193  -0.04796795  9.9874209 ] 86.8448008975\n",
      "positions (x,y,z), reward: [-1.28516927 -0.21359634  9.47440347] 76.7474832771\n",
      "positions (x,y,z), reward: [ 0.50892411 -0.38959492  9.03525979] 89.5519129726\n",
      "positions (x,y,z), reward: [ 1.41673334 -0.6713757   8.0532459 ] 95.7912100415\n",
      "positions (x,y,z), reward: [ 3.75885889 -0.48611478  5.50105982] 102.068742601\n",
      "Episode =   83, score = 186.999 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  2.19453862e-03  -1.00776358e-01   1.00608762e+01] 128.431667359\n",
      "positions (x,y,z), reward: [ 0.43579534 -2.54963576  8.89733822] 79.5389099038\n",
      "Episode =   84, score = 182.464 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  2.6934155    1.95918066  11.34903444] 74.7464765174\n",
      "positions (x,y,z), reward: [  3.15040389   2.31099195  11.16404146] 80.1651670471\n",
      "positions (x,y,z), reward: [  4.08720016   2.98108758  10.79447767] 89.8469664844\n",
      "positions (x,y,z), reward: [ 6.71996486  4.51483745  9.77920318] 87.0706473765\n",
      "positions (x,y,z), reward: [ 7.15954537  4.68387998  9.58371478] 94.5900750451\n",
      "positions (x,y,z), reward: [ 15.31525389   6.55656758   4.0025711 ] 74.8180443249\n",
      "Episode =   85, score = 178.846 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 2.12403255  0.2225566   9.85404356] 89.7585137432\n",
      "positions (x,y,z), reward: [ 4.10095046  0.23115727  9.33721499] 102.003937717\n",
      "positions (x,y,z), reward: [ 9.07359679  1.30181063  6.63487853] 100.167993897\n",
      "positions (x,y,z), reward: [ 10.17926019   1.80651813   5.11583754] 101.203445747\n",
      "positions (x,y,z), reward: [ 11.45409668   2.75486638   1.63375197] 79.2562242065\n",
      "Episode =   86, score = 190.886 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00494379] 151.034904209\n",
      "positions (x,y,z), reward: [-0.14801086 -0.04888817  9.99980714] 103.572404655\n",
      "positions (x,y,z), reward: [-2.48204504 -0.31293078  8.96069449] 68.4522577132\n",
      "positions (x,y,z), reward: [-2.92536598 -0.21891048  8.09773332] 76.4240447417\n",
      "positions (x,y,z), reward: [-3.89855424 -0.95327875  4.41084324] 82.1373261888\n",
      "positions (x,y,z), reward: [-3.91515604 -1.10863843  3.49754921] 84.5792993973\n",
      "positions (x,y,z), reward: [-3.86059203 -1.17480723  3.08497511] 84.736659335\n",
      "positions (x,y,z), reward: [-3.62563403 -1.25815269  1.92552364] 86.5154732692\n",
      "Episode =   87, score = 167.703 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 4.26862056  0.56884741  5.51869409] 103.354940171\n",
      "positions (x,y,z), reward: [ 5.32960981  0.72516846  2.29635042] 96.55783087\n",
      "Episode =   88, score = 195.411 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 0.02551109  0.16299185  9.66452139] 90.4468434342\n",
      "positions (x,y,z), reward: [ 0.24315869  1.03078254  8.88270045] 92.9342507461\n",
      "positions (x,y,z), reward: [ 0.38320638  1.12345364  7.77626593] 88.5297415992\n",
      "positions (x,y,z), reward: [ 0.98301298  0.40587017  3.22579173] 98.4051848612\n",
      "positions (x,y,z), reward: [ 1.249101    0.23543407  1.67920483] 99.1730329768\n",
      "Episode =   89, score = 192.706 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [-0.59209609  0.49067495  8.36098194] 87.1675925416\n",
      "positions (x,y,z), reward: [-0.30777137  0.41418306  7.52199474] 88.5991515759\n",
      "positions (x,y,z), reward: [-0.13556908  0.44295937  7.1904539 ] 94.3909394945\n",
      "Episode =   90, score = 189.614 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 0.0615522   0.01253323  9.90034743] 104.994820283\n",
      "positions (x,y,z), reward: [-0.63909181  0.06863028  8.0699376 ] 86.7155737871\n",
      "positions (x,y,z), reward: [-1.27790162  0.16893655  6.55614922] 83.6368914664\n",
      "positions (x,y,z), reward: [-3.01749773  0.0412257   0.8074306 ] 91.4041424684\n",
      "Episode =   91, score = 186.219 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 0.13104999  0.12616467  9.46197362] 81.5291193932\n",
      "positions (x,y,z), reward: [-0.32619335 -0.65223378  6.87010483] 85.9463334843\n",
      "positions (x,y,z), reward: [-0.63599423 -2.06758033  4.25202905] 89.37997947\n",
      "positions (x,y,z), reward: [-0.76640506 -3.316332    0.89336678] 92.900511233\n",
      "Episode =   92, score = 180.327 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 0.03125791 -0.23709812  9.68854824] 76.144698881\n",
      "positions (x,y,z), reward: [ 0.44204799 -1.95777547  8.06493897] 78.3654163821\n",
      "positions (x,y,z), reward: [ 0.65428963 -4.10127092  6.38726701] 90.4990830896\n",
      "positions (x,y,z), reward: [ 0.49221723 -5.43406079  5.15293239] 87.2409746513\n",
      "positions (x,y,z), reward: [ 0.09279874 -9.71399608  0.94079202] 91.8068520463\n",
      "positions (x,y,z), reward: [ 0.09646961 -9.96551921  0.69188128] 91.7892747598\n",
      "positions (x,y,z), reward: [  0.13752228 -10.69814797   0.        ] 91.4138246078\n",
      "Episode =   93, score = 177.741 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [  0.43271267   0.11680856  10.22449231] 111.213340049\n",
      "positions (x,y,z), reward: [  0.69927416   0.21797643  10.30505419] 116.665496685\n",
      "positions (x,y,z), reward: [ 1.73857588 -0.03682015  9.98257654] 86.4606190911\n",
      "positions (x,y,z), reward: [ 2.19301017 -0.53347052  9.39898681] 95.7700148503\n",
      "positions (x,y,z), reward: [ 2.24316227 -1.53317367  8.07139321] 98.9764784666\n",
      "positions (x,y,z), reward: [ 2.23565062 -1.84650865  7.69271399] 100.043573976\n",
      "Episode =   94, score = 199.293 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 3.93777275  0.05426281  4.67972221] 97.2958580563\n",
      "positions (x,y,z), reward: [ 4.51926349  0.25423069  3.52448127] 97.6594260735\n",
      "Episode =   95, score = 193.983 (best = 200.161), noise_scale = 3.2positions (x,y,z), reward: [ 3.19492794 -1.50056286  0.69845992] 98.0692065737\n",
      "Episode =   96, score = 201.337 (best = 201.337), noise_scale = 1.6positions (x,y,z), reward: [ 1.10214728 -0.22711377  9.84538219] 99.4069489563\n",
      "positions (x,y,z), reward: [ 1.5578907  -0.32292899  9.45723371] 93.9447462264\n",
      "positions (x,y,z), reward: [ 1.71241406 -0.37885682  9.2352705 ] 96.3131270962\n",
      "positions (x,y,z), reward: [ 3.18095654 -0.63356053  6.59333055] 104.975938043\n",
      "positions (x,y,z), reward: [ 3.71481152 -0.64222896  5.40197533] 94.6700902263\n",
      "positions (x,y,z), reward: [ 5.14151905 -0.81795438  1.17574623] 88.8997062141\n",
      "Episode =   97, score = 203.325 (best = 203.325), noise_scale = 0.8positions (x,y,z), reward: [  0.02294951  -0.01319339  10.00510388] 123.972312202\n",
      "positions (x,y,z), reward: [ 0.61939269 -0.12655332  9.97376412] 113.377087839\n",
      "positions (x,y,z), reward: [ 4.63736727  1.14883254  8.04845723] 107.812057209\n",
      "positions (x,y,z), reward: [ 6.85564964  2.26932118  6.18384011] 100.628139345\n",
      "positions (x,y,z), reward: [ 7.74447649  2.86103136  5.09799325] 94.9417623659\n",
      "positions (x,y,z), reward: [ 10.84288742   5.51227052   0.        ] 62.8059115288\n",
      "Episode =   98, score = 200.265 (best = 203.325), noise_scale = 1.6positions (x,y,z), reward: [ 0.22909467 -0.08011951  9.99923777] 121.761116928\n",
      "positions (x,y,z), reward: [ 0.56915935 -0.12939143  9.97522886] 93.5325726498\n",
      "positions (x,y,z), reward: [ 0.79211664 -0.15918912  9.78217449] 97.6922998934\n",
      "positions (x,y,z), reward: [ 0.87913777 -0.18338416  8.16318796] 96.826595877\n",
      "positions (x,y,z), reward: [ 0.95600872  0.13919996  7.0350529 ] 99.9763242348\n",
      "Episode =   99, score = 204.374 (best = 204.374), noise_scale = 0.8positions (x,y,z), reward: [ 0.32016327  0.03787162  9.33174804] 96.9463727567\n",
      "positions (x,y,z), reward: [ 0.36049979 -0.25742958  8.00306876] 98.6762173993\n",
      "positions (x,y,z), reward: [ 0.27351342 -0.99107921  5.75878043] 98.1148474766\n",
      "positions (x,y,z), reward: [ 0.23872931 -1.10597026  5.4049049 ] 98.7084837572\n",
      "positions (x,y,z), reward: [ 0.12267329 -2.48930951  1.48558565] 99.6496469037\n",
      "Episode =  100, score = 203.117 (best = 204.374), noise_scale = 1.6positions (x,y,z), reward: [ 0.33155186 -0.09115051  9.9452456 ] 101.371760413\n",
      "positions (x,y,z), reward: [  4.90777018e-01   2.92494710e-03   9.45676253e+00] 95.8264156307\n",
      "positions (x,y,z), reward: [ 1.41734688  0.24148432  7.94160489] 103.040044883\n",
      "positions (x,y,z), reward: [ 1.80003998  0.34375872  6.8269615 ] 105.226092385\n",
      "positions (x,y,z), reward: [ 2.23312364  0.59475986  3.84715327] 101.508437245\n",
      "positions (x,y,z), reward: [ 2.77734905  0.85732574  0.44973964] 95.5898996043\n",
      "positions (x,y,z), reward: [ 2.87912644  0.92454606  0.        ] 94.6025204891\n",
      "Episode =  101, score = 205.790 (best = 205.790), noise_scale = 0.8positions (x,y,z), reward: [  0.59112412  -0.22051423  10.02484392] 131.292623965\n",
      "positions (x,y,z), reward: [ 1.15641383 -0.82708237  9.42329604] 97.8135578315\n",
      "positions (x,y,z), reward: [ 1.83784076 -1.90340798  7.72325176] 104.17056746\n",
      "positions (x,y,z), reward: [ 1.99158763 -2.50339026  6.72100432] 103.954742665\n",
      "positions (x,y,z), reward: [ 2.19749094 -3.5698074   4.77664731] 97.8575108304\n",
      "positions (x,y,z), reward: [ 2.26538626 -3.91368657  4.06593011] 99.2229039112\n",
      "Episode =  102, score = 206.928 (best = 206.928), noise_scale = 0.4positions (x,y,z), reward: [  0.08897027  -0.02485554  10.02566946] 124.058875694\n",
      "positions (x,y,z), reward: [ 0.40076476 -0.11436153  9.94650289] 95.7310945058\n",
      "positions (x,y,z), reward: [ 1.0541981  -0.71446679  9.37206369] 93.0817728883\n",
      "positions (x,y,z), reward: [ 1.12150938 -0.83842201  9.2254412 ] 91.618860455\n",
      "Episode =  103, score = 200.827 (best = 206.928), noise_scale = 0.8positions (x,y,z), reward: [ 1.07577374 -0.36384999  7.43560163] 100.431288936\n",
      "Episode =  104, score = 208.318 (best = 208.318), noise_scale = 0.4positions (x,y,z), reward: [  0.04709762  -0.02003006  10.0199038 ] 130.48825217\n",
      "positions (x,y,z), reward: [ 0.1462351  -0.02653709  9.98923975] 111.379213768\n",
      "positions (x,y,z), reward: [ 0.16457193  0.01327055  9.95974651] 103.664296726\n",
      "positions (x,y,z), reward: [ 0.34354274  0.39020062  8.46887612] 94.3302651921\n",
      "positions (x,y,z), reward: [ 0.63469822  0.66111792  7.36259369] 98.0188458399\n",
      "positions (x,y,z), reward: [ 0.97414014  0.88815086  5.95538564] 93.6304608392\n",
      "positions (x,y,z), reward: [ 1.38773559  1.11661921  4.12892581] 95.914073932\n",
      "positions (x,y,z), reward: [ 1.80207952  1.34279805  2.75057592] 96.4933879516\n",
      "positions (x,y,z), reward: [ 2.07270045  1.51222391  1.75504982] 95.5127707556\n",
      "positions (x,y,z), reward: [ 2.13949068  1.55452564  1.49875788] 95.2279633613\n",
      "Episode =  105, score = 198.639 (best = 208.318), noise_scale = 0.8positions (x,y,z), reward: [  0.           0.          10.00391068] 151.465726705\n",
      "positions (x,y,z), reward: [ 0.28866108 -0.09974247  9.72557089] 90.2458346006\n",
      "positions (x,y,z), reward: [ 0.02848143 -0.19562691  9.2213809 ] 93.4200275762\n",
      "positions (x,y,z), reward: [ 0.30696827 -0.04320503  7.66052108] 101.356685543\n",
      "Episode =  106, score = 200.477 (best = 208.318), noise_scale = 1.6positions (x,y,z), reward: [-0.0345664   0.17966041  9.75738273] 99.9022398884\n",
      "positions (x,y,z), reward: [-0.70892309  0.62428869  8.75827289] 87.8644305776\n",
      "positions (x,y,z), reward: [-0.84020222  0.72242268  8.50110218] 88.8772477544\n",
      "positions (x,y,z), reward: [ 0.0663352   2.47272202  2.99393909] 91.4111114467\n",
      "positions (x,y,z), reward: [ 0.82948723  2.77123049  0.54224053] 93.1779592321\n",
      "Episode =  107, score = 188.825 (best = 208.318), noise_scale = 3.2positions (x,y,z), reward: [ -9.47676084e-03  -3.05483100e-01   9.85659166e+00] 96.3679386277\n",
      "positions (x,y,z), reward: [ 0.16589975 -3.6498994   5.59390586] 97.1312247635\n",
      "Episode =  108, score = 201.335 (best = 208.318), noise_scale = 3.2positions (x,y,z), reward: [ 0.45866463 -0.15470102  9.04838518] 90.7235990026\n",
      "positions (x,y,z), reward: [ 0.63078388 -0.09601419  8.44909435] 87.9543055301\n",
      "positions (x,y,z), reward: [ 0.82856366  0.23398646  6.40673635] 99.405229802\n",
      "positions (x,y,z), reward: [ 0.77921172  0.39021199  5.16836456] 100.566208238\n",
      "Episode =  109, score = 201.025 (best = 208.318), noise_scale = 3.2positions (x,y,z), reward: [  0.4083188   -0.11022314  10.05024985] 127.711596286\n",
      "positions (x,y,z), reward: [  1.56959892  -0.82382177  10.2826809 ] 104.71906036\n",
      "positions (x,y,z), reward: [ 2.61709177 -2.15331249  9.69560658] 93.7615613492\n",
      "positions (x,y,z), reward: [ 4.95560398 -4.87390433  0.78701413] 86.7889635711\n",
      "Episode =  110, score = 197.486 (best = 208.318), noise_scale = 3.2positions (x,y,z), reward: [  4.63957600e-03   1.80363591e-03   1.00062490e+01] 137.658188321\n",
      "positions (x,y,z), reward: [ 0.04280782  0.01694432  9.9993874 ] 118.411385937\n",
      "positions (x,y,z), reward: [ 0.72788494 -0.21686868  9.13520219] 98.7522667448\n",
      "positions (x,y,z), reward: [ 1.39054461 -0.88878461  7.37289173] 94.5398916067\n",
      "positions (x,y,z), reward: [ 1.34056472 -1.53363147  0.20537049] 98.6446484684\n",
      "Episode =  111, score = 196.866 (best = 208.318), noise_scale = 3.2positions (x,y,z), reward: [ 4.2820676   0.43200736  7.93118123] 110.008776513\n",
      "positions (x,y,z), reward: [ 5.67282195  0.82724782  6.53447218] 107.236742773\n",
      "positions (x,y,z), reward: [ 8.44675958  1.63541286  2.19630298] 92.4573212458\n",
      "positions (x,y,z), reward: [ 8.67945157  1.72924459  1.64308604] 89.6796868083\n",
      "Episode =  112, score = 210.597 (best = 210.597), noise_scale = 1.6positions (x,y,z), reward: [ 0.03489105  0.20615413  9.96950331] 105.57063197\n",
      "positions (x,y,z), reward: [ 0.03941205  0.30523615  9.9174836 ] 101.019801889\n",
      "positions (x,y,z), reward: [ 0.01422851  0.40634152  9.82948501] 100.439808835\n",
      "positions (x,y,z), reward: [-1.49298057  2.78591473  5.49140722] 87.1290604435\n",
      "positions (x,y,z), reward: [-1.59912634  2.92679547  4.95699766] 85.7659378811\n",
      "positions (x,y,z), reward: [-1.66409237  3.16391475  3.74175511] 87.7259622846\n",
      "Episode =  113, score = 190.763 (best = 210.597), noise_scale = 3.2positions (x,y,z), reward: [ 1.85983303  0.05240583  1.25342833] 98.0829345499\n",
      "positions (x,y,z), reward: [ 1.91070453  0.01573446  0.65896473] 97.816947292\n",
      "Episode =  114, score = 205.905 (best = 210.597), noise_scale = 3.2positions (x,y,z), reward: [  0.92468081   0.21328693  10.29838222] 107.04012616\n",
      "positions (x,y,z), reward: [ 2.1700537   0.6208532   9.60415094] 102.283618848\n",
      "Episode =  115, score = 215.245 (best = 215.245), noise_scale = 1.6positions (x,y,z), reward: [-0.03344249 -0.02822528  9.98136469] 113.875167308\n",
      "positions (x,y,z), reward: [-1.79093089 -1.94935797  8.21523575] 87.9303235847\n",
      "positions (x,y,z), reward: [-3.95850307 -2.94765825  5.41332016] 83.6375319429\n",
      "positions (x,y,z), reward: [-4.59964379 -3.05752233  4.40774555] 83.3960512247\n",
      "positions (x,y,z), reward: [-5.17141625 -3.28522952  3.31168739] 80.317136029\n",
      "positions (x,y,z), reward: [-5.58394205 -3.52327031  1.99309493] 79.8538540098\n",
      "Episode =  116, score = 184.330 (best = 215.245), noise_scale = 3.2positions (x,y,z), reward: [ 0.43194543  0.39593049  8.53967903] 96.8491342404\n",
      "positions (x,y,z), reward: [ 0.87878577  0.35490521  7.45470634] 99.0021962798\n",
      "positions (x,y,z), reward: [ 2.90147718  1.30031128  1.38171831] 97.5958663183\n",
      "Episode =  117, score = 203.563 (best = 215.245), noise_scale = 3.2positions (x,y,z), reward: [-1.6322454   0.04712805  7.72756728] 86.541624889\n",
      "positions (x,y,z), reward: [-3.47048512 -0.35324708  3.66451097] 80.2976238215\n",
      "positions (x,y,z), reward: [-3.70288796 -0.37541055  3.06536817] 80.4957435276\n",
      "positions (x,y,z), reward: [-4.32030626 -0.50507539  1.11517441] 83.1562471982\n",
      "Episode =  118, score = 184.840 (best = 215.245), noise_scale = 3.2positions (x,y,z), reward: [ 4.43009837 -0.87199059  5.38374987] 105.158729262\n",
      "positions (x,y,z), reward: [ 4.98075556 -1.02972647  4.33005072] 99.106432871\n",
      "Episode =  119, score = 199.741 (best = 215.245), noise_scale = 3.2positions (x,y,z), reward: [ 0.15515443 -0.38779956  9.72621189] 95.704067116\n",
      "positions (x,y,z), reward: [-0.15589637 -1.11394291  6.3232231 ] 99.0756438984\n",
      "positions (x,y,z), reward: [-0.48957047 -2.12617316  2.24841657] 99.0004274683\n",
      "Episode =  120, score = 203.327 (best = 215.245), noise_scale = 3.2positions (x,y,z), reward: [-1.22333418 -0.30172572  9.31615889] 96.9384715245\n",
      "positions (x,y,z), reward: [-3.24801832  0.31480849  5.92392022] 84.3510197036\n",
      "positions (x,y,z), reward: [-3.65895058  0.52145158  4.91916798] 90.106765577\n",
      "Episode =  121, score = 198.156 (best = 215.245), noise_scale = 3.2positions (x,y,z), reward: [  6.39553291e-03  -4.22032078e-02   1.00269937e+01] 145.999160085\n",
      "positions (x,y,z), reward: [ -0.01114841  -0.1263198   10.02391204] 108.405665411\n",
      "positions (x,y,z), reward: [-2.47044965 -2.91394014  7.82804309] 87.1364516003\n",
      "positions (x,y,z), reward: [-2.59495303 -5.55716952  0.85161542] 91.4637023871\n",
      "Episode =  122, score = 197.048 (best = 215.245), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00300409] 151.707526834\n",
      "positions (x,y,z), reward: [-0.01368298 -0.01701788  9.97302031] 121.704969055\n",
      "positions (x,y,z), reward: [ 0.16081798 -0.23110378  9.68978496] 106.431672049\n",
      "positions (x,y,z), reward: [ 0.7056256  -0.21010101  9.27027927] 109.461104672\n",
      "positions (x,y,z), reward: [ 1.06325557 -0.1744264   8.82331032] 103.986396035\n",
      "positions (x,y,z), reward: [ 3.03326995 -0.06680521  5.71723214] 108.411300077\n",
      "positions (x,y,z), reward: [ 3.80517726 -0.0079495   3.99066922] 102.479420546\n",
      "positions (x,y,z), reward: [ 5.10312651  0.04688724  0.66106733] 96.7909583634\n",
      "Episode =  123, score = 216.072 (best = 216.072), noise_scale = 1.6positions (x,y,z), reward: [-0.09439044 -0.42159751  9.50052613] 105.629377619\n",
      "positions (x,y,z), reward: [-0.07714399 -0.46894775  9.47272434] 106.058351148\n",
      "positions (x,y,z), reward: [-0.0211946  -0.70771757  9.22607245] 102.788999475\n",
      "Episode =  124, score = 210.035 (best = 216.072), noise_scale = 3.2positions (x,y,z), reward: [ -9.06492968e-03   3.05666956e-02   1.00155719e+01] 125.258758571\n",
      "positions (x,y,z), reward: [ -0.02249385   0.03596293  10.00837611] 122.707544629\n",
      "positions (x,y,z), reward: [ 0.46215444  0.79237244  8.98891905] 113.548496536\n",
      "positions (x,y,z), reward: [ 0.48453624  1.56881465  7.53949358] 108.02138458\n",
      "positions (x,y,z), reward: [ 0.10995802  2.14483349  5.29298231] 104.471668399\n",
      "positions (x,y,z), reward: [-0.27293793  3.03251078  0.43748539] 97.8446066575\n",
      "Episode =  125, score = 220.669 (best = 220.669), noise_scale = 1.6positions (x,y,z), reward: [-1.67755418 -0.27806766  8.82952007] 100.226538251\n",
      "positions (x,y,z), reward: [-4.01426984 -1.17009488  4.05941373] 90.5213776618\n",
      "positions (x,y,z), reward: [-5.10817424 -1.29126088  0.79477649] 89.4083874555\n",
      "Episode =  126, score = 208.405 (best = 220.669), noise_scale = 3.2positions (x,y,z), reward: [-0.31788758 -0.11852402  7.53479315] 103.800534053\n",
      "positions (x,y,z), reward: [-0.35413304 -0.18727699  7.11290525] 102.164581882\n",
      "positions (x,y,z), reward: [-0.49138838 -0.28169157  6.20312899] 102.003742956\n",
      "positions (x,y,z), reward: [-0.36317622 -0.13273115  1.67583788] 102.739266329\n",
      "Episode =  127, score = 214.741 (best = 220.669), noise_scale = 3.2positions (x,y,z), reward: [  2.52557275e-03   1.32488063e-02   1.00009347e+01] 128.090900907\n",
      "positions (x,y,z), reward: [-0.57691511  0.32595616  9.10546156] 107.822869307\n",
      "positions (x,y,z), reward: [-1.103993    1.93098624  6.42346594] 99.9964726619\n",
      "positions (x,y,z), reward: [-1.58793435  5.41346157  0.        ] 95.7738858941\n",
      "Episode =  128, score = 212.317 (best = 220.669), noise_scale = 3.2positions (x,y,z), reward: [-0.07341119 -0.04633289  9.67047165] 119.40519672\n",
      "positions (x,y,z), reward: [-0.19757212 -0.11228152  9.20590045] 109.576104704\n",
      "positions (x,y,z), reward: [-0.25748317 -0.89659167  0.        ] 99.4958557699\n",
      "Episode =  129, score = 219.094 (best = 220.669), noise_scale = 3.2positions (x,y,z), reward: [ 0.49945097 -0.08479592  9.54913629] 115.353442838\n",
      "positions (x,y,z), reward: [ 3.83610503  0.16594525  2.9090337 ] 104.43729959\n",
      "Episode =  130, score = 221.718 (best = 221.718), noise_scale = 1.6positions (x,y,z), reward: [ -3.67181654e-03   3.10734471e-05   1.00032445e+01] 139.765150808\n",
      "positions (x,y,z), reward: [ 0.82683732 -0.17614114  8.0630965 ] 108.569231257\n",
      "positions (x,y,z), reward: [ 1.21672981 -0.14992077  6.30573002] 108.089758894\n",
      "positions (x,y,z), reward: [ 2.14014746 -0.19420049  1.44427703] 101.963981572\n",
      "Episode =  131, score = 221.507 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [-0.27038548 -0.15690562  9.06711488] 109.195909632\n",
      "positions (x,y,z), reward: [ 1.00246267 -0.33748907  2.91756148] 102.350309174\n",
      "Episode =  132, score = 217.406 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [ 2.39249084 -1.35286642  1.5416579 ] 98.9826797401\n",
      "Episode =  133, score = 217.407 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [-0.68590608 -0.87128943  9.08284385] 102.07045574\n",
      "positions (x,y,z), reward: [-0.54237332 -1.57503673  7.8991757 ] 97.1572910669\n",
      "positions (x,y,z), reward: [-0.48111033 -1.86461999  7.14094935] 99.2894701094\n",
      "positions (x,y,z), reward: [-0.14456921 -2.48025044  5.250643  ] 105.077555813\n",
      "Episode =  134, score = 213.275 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [ -8.82768448e-03   1.43267594e-02   9.97807854e+00] 126.332959668\n",
      "positions (x,y,z), reward: [-1.9348497   0.02748351  6.44413468] 105.031733762\n",
      "Episode =  135, score = 212.748 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [ -1.43669139e-02  -4.56713422e-03   1.00062470e+01] 144.81095909\n",
      "positions (x,y,z), reward: [-0.46970069  0.09305142  9.2493852 ] 101.642441566\n",
      "positions (x,y,z), reward: [-1.81299941 -0.03622245  0.        ] 97.7851493542\n",
      "positions (x,y,z), reward: [-1.8020147  -0.02505185  0.        ] 97.9660437061\n",
      "Episode =  136, score = 204.650 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [ -0.01081899   0.0118653   10.00737939] 143.797958672\n",
      "positions (x,y,z), reward: [-0.70372311  0.50553583  9.61739428] 107.577349252\n",
      "positions (x,y,z), reward: [-0.70629804  0.53893365  9.58585451] 107.588175287\n",
      "positions (x,y,z), reward: [-0.52108398  1.72532778  8.05894857] 98.3516445029\n",
      "positions (x,y,z), reward: [-0.58598004  2.29016719  6.59144062] 95.4018238837\n",
      "positions (x,y,z), reward: [-0.5899133   2.42771793  6.26724113] 94.9336323248\n",
      "positions (x,y,z), reward: [-0.38455726  3.72515461  2.40584073] 94.6330570983\n",
      "Episode =  137, score = 209.013 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00151784] 146.903718612\n",
      "positions (x,y,z), reward: [  4.83210727e-03  -1.35193326e-03   7.75403666e+00] 104.282379533\n",
      "positions (x,y,z), reward: [ 0.26311794 -0.38989046  5.40234026] 104.978959918\n",
      "Episode =  138, score = 219.664 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [-0.19131147 -0.02929689  9.97916254] 118.270932954\n",
      "positions (x,y,z), reward: [-1.75060147 -1.41878862  6.91254632] 102.17195629\n",
      "positions (x,y,z), reward: [-2.19361725 -1.75032427  5.47370537] 97.7166323869\n",
      "Episode =  139, score = 211.717 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [-0.0550925  -0.02158929  9.93508746] 121.119411794\n",
      "positions (x,y,z), reward: [ 1.4573754   1.55946793  7.84514759] 108.171071441\n",
      "Episode =  140, score = 217.554 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [ -5.07863128e-03   5.89770522e-02   9.95286593e+00] 121.690113763\n",
      "positions (x,y,z), reward: [-1.77030073  0.38830215  8.66258975] 101.369788458\n",
      "positions (x,y,z), reward: [-2.32954191  0.29808433  7.87788723] 96.3036114134\n",
      "positions (x,y,z), reward: [-3.40456064  0.06501732  4.9740561 ] 97.2363691223\n",
      "positions (x,y,z), reward: [-4.62816694 -0.19361285  0.83407015] 90.0761730444\n",
      "Episode =  141, score = 202.413 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [ -8.32778450e-03   7.39990067e-02   9.71286222e+00] 115.223128664\n",
      "positions (x,y,z), reward: [-0.35602769  1.28870319  8.17337628] 101.825400685\n",
      "positions (x,y,z), reward: [-0.09891199  1.87445252  4.93882883] 102.815686333\n",
      "Episode =  142, score = 213.943 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [ 0.17788605  0.40175129  9.43314297] 110.077625286\n",
      "positions (x,y,z), reward: [ 0.10486688  0.98377692  4.79845765] 103.350065244\n",
      "Episode =  143, score = 216.672 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [-0.03398544  0.08761622  9.92579059] 122.452736895\n",
      "positions (x,y,z), reward: [-0.24262063  0.82955698  8.80398156] 112.475009773\n",
      "positions (x,y,z), reward: [-0.46013458  1.15897232  7.59611876] 103.444128564\n",
      "Episode =  145, score = 217.760 (best = 221.718), noise_scale = 3.2positions (x,y,z), reward: [ -5.04103941e-03   2.80899692e-03   9.99890210e+00] 126.520774352\n",
      "positions (x,y,z), reward: [  9.56690840e-03  -3.93236883e-02   9.77837690e+00] 116.407917507\n",
      "positions (x,y,z), reward: [ 0.19153871 -0.1847045   9.12573376] 112.283601013\n",
      "positions (x,y,z), reward: [ 2.39448591 -0.27138067  1.65025246] 104.454742648\n",
      "Episode =  146, score = 223.626 (best = 223.626), noise_scale = 1.6positions (x,y,z), reward: [ -5.39807988e-03  -4.09806454e-02   9.98688412e+00] 120.704674481\n",
      "positions (x,y,z), reward: [ 0.40786633 -0.31863253  9.62993627] 114.657032151\n",
      "positions (x,y,z), reward: [ 2.30329495 -0.97130362  5.99717831] 110.719253464\n",
      "positions (x,y,z), reward: [ 2.60016581 -1.08345661  5.12915625] 110.383928779\n",
      "Episode =  147, score = 223.560 (best = 223.626), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00187165] 146.812223546\n",
      "positions (x,y,z), reward: [ -7.25692313e-03   1.88362467e-03   1.00051122e+01] 143.697214547\n",
      "positions (x,y,z), reward: [ 0.6562065   0.13248886  8.94019006] 112.497788174\n",
      "positions (x,y,z), reward: [ 1.59476958  1.29666068  4.77310571] 106.332459187\n",
      "positions (x,y,z), reward: [ 1.8982609   1.70474052  2.88703985] 102.58244922\n",
      "positions (x,y,z), reward: [ 1.96668093  1.80006154  2.3804851 ] 101.409986703\n",
      "Episode =  148, score = 220.893 (best = 223.626), noise_scale = 3.2positions (x,y,z), reward: [ 0.49012556  1.2490743   6.90505172] 107.991462701\n",
      "positions (x,y,z), reward: [ 0.43850323  1.68086004  2.39743614] 102.808613159\n",
      "positions (x,y,z), reward: [ 0.40686534  1.78386047  0.78851268] 100.192433726\n",
      "positions (x,y,z), reward: [ 0.4125463   1.85354741  0.        ] 98.9353871484\n",
      "Episode =  149, score = 223.627 (best = 223.627), noise_scale = 1.6positions (x,y,z), reward: [  7.23346515e-02   4.06101114e-03   9.93145101e+00] 124.152764989\n",
      "positions (x,y,z), reward: [ 1.68111641  0.65722549  8.41122619] 113.691191109\n",
      "positions (x,y,z), reward: [ 3.17510925  1.4247718   5.97492447] 106.683877406\n",
      "positions (x,y,z), reward: [ 3.95658944  1.7827691   4.4129376 ] 104.194649103\n",
      "positions (x,y,z), reward: [ 5.58597642  2.44543227  0.72006834] 93.2959136461\n",
      "Episode =  150, score = 219.506 (best = 223.627), noise_scale = 3.2positions (x,y,z), reward: [ 3.7558965   1.21199963  4.86206467] 103.26097753\n",
      "positions (x,y,z), reward: [ 5.70466398  1.57290275  0.50988356] 92.8887624752\n",
      "Episode =  151, score = 225.283 (best = 225.283), noise_scale = 1.6positions (x,y,z), reward: [ 0.03665141 -0.02265657  9.95898464] 127.209841006\n",
      "positions (x,y,z), reward: [-1.38034969  1.18453574  5.87704073] 104.218237588\n",
      "Episode =  153, score = 219.239 (best = 225.283), noise_scale = 3.2positions (x,y,z), reward: [-0.20132018  0.09361943  9.62586932] 120.177676183\n",
      "positions (x,y,z), reward: [-0.23077847  0.11469134  9.56760559] 119.157439818\n",
      "positions (x,y,z), reward: [-1.33616323  0.82253028  7.80136087] 109.108448333\n",
      "positions (x,y,z), reward: [-3.32404873  2.40650609  1.85690707] 98.2365707853\n",
      "Episode =  154, score = 217.687 (best = 225.283), noise_scale = 3.2positions (x,y,z), reward: [ 0.77159415  0.96012298  7.22037151] 107.201531452\n",
      "positions (x,y,z), reward: [ 1.40848281  1.37866987  5.404879  ] 102.418921471\n",
      "positions (x,y,z), reward: [ 2.60954332  2.15957685  0.76815243] 94.7371329622\n",
      "Episode =  155, score = 218.041 (best = 225.283), noise_scale = 3.2positions (x,y,z), reward: [  1.43491337e-02  -2.27175169e-03   9.99470144e+00] 126.420568657\n",
      "positions (x,y,z), reward: [ 0.19038496 -0.69308071  9.4033287 ] 108.64891356\n",
      "positions (x,y,z), reward: [-0.64995582 -4.77470296  0.        ] 90.8245408748\n",
      "Episode =  156, score = 208.163 (best = 225.283), noise_scale = 3.2positions (x,y,z), reward: [-0.13896727  0.0924385   9.7073444 ] 122.229324179\n",
      "positions (x,y,z), reward: [-0.22524341  0.12642684  9.4848045 ] 118.655115157\n",
      "positions (x,y,z), reward: [-0.28017058  1.69635842  1.37847596] 99.2642022867\n",
      "positions (x,y,z), reward: [-0.29657874  1.788236    0.77747485] 98.2159460153\n",
      "Episode =  157, score = 226.785 (best = 226.785), noise_scale = 1.6positions (x,y,z), reward: [  0.           0.          10.00174635] 146.831287851\n",
      "positions (x,y,z), reward: [-0.16702387 -0.04747718  9.97836786] 120.592721686\n",
      "positions (x,y,z), reward: [ -2.10546330e-01  -4.41469253e-03   9.95744484e+00] 120.360831996\n",
      "positions (x,y,z), reward: [ 0.86278509  0.60210132  9.23882552] 117.08135253\n",
      "positions (x,y,z), reward: [ 1.54587714  0.88369267  8.58719728] 117.919419417\n",
      "positions (x,y,z), reward: [ 1.90518699  0.98949001  8.31419837] 117.524661423\n",
      "positions (x,y,z), reward: [ 2.43767417  1.16558931  7.81958723] 115.780314345\n",
      "positions (x,y,z), reward: [ 4.56799603  1.95979989  4.48099827] 104.278678201\n",
      "positions (x,y,z), reward: [ 5.48534622  2.4493089   2.35618326] 97.6327971679\n",
      "Episode =  158, score = 226.974 (best = 226.974), noise_scale = 0.8positions (x,y,z), reward: [-0.01096945 -0.0701275   9.95877454] 123.929632426\n",
      "positions (x,y,z), reward: [-0.08175628 -0.12273734  9.5081632 ] 117.493477593\n",
      "positions (x,y,z), reward: [ 0.17428553  0.07023895  8.52235972] 112.768720981\n",
      "positions (x,y,z), reward: [ 0.35377663  0.2894797   6.99440453] 109.632317342\n",
      "positions (x,y,z), reward: [ 0.52423783  0.40977235  6.276513  ] 108.98605288\n",
      "Episode =  159, score = 225.689 (best = 226.974), noise_scale = 1.6positions (x,y,z), reward: [-0.05806631 -0.04006728  9.9295392 ] 122.050228074\n",
      "positions (x,y,z), reward: [-0.13367654 -0.05122238  9.83618679] 120.313267797\n",
      "positions (x,y,z), reward: [-4.66605144  0.24600353  5.87654869] 94.6705366246\n",
      "positions (x,y,z), reward: [-4.81838189  0.26554199  5.68587598] 93.8971409277\n",
      "positions (x,y,z), reward: [-5.1038336   0.30577856  5.26958545] 91.895175211\n",
      "positions (x,y,z), reward: [-7.74000519  0.87835828  0.7342411 ] 81.3920047217\n",
      "Episode =  160, score = 206.847 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [ -8.41528330e-04   6.39694489e-03   9.99883033e+00] 127.099463646\n",
      "positions (x,y,z), reward: [-0.75051787  0.57154889  7.42137083] 103.880627138\n",
      "Episode =  161, score = 217.945 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [-0.98043426  0.86742242  8.63008973] 112.66850418\n",
      "positions (x,y,z), reward: [-3.80618346  1.06726829  3.73457457] 92.537928528\n",
      "positions (x,y,z), reward: [-3.98965622  1.04146633  3.28238651] 92.7551216497\n",
      "positions (x,y,z), reward: [-4.1529306   1.02100444  2.8265617 ] 93.5013419118\n",
      "Episode =  162, score = 213.835 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [ 0.09151368 -0.05151323  9.88324104] 124.157811692\n",
      "positions (x,y,z), reward: [-0.10327455 -1.16315889  8.14029478] 108.423863195\n",
      "positions (x,y,z), reward: [-0.78579726 -2.84994891  4.23228939] 101.655689991\n",
      "Episode =  163, score = 220.822 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [ 0.62416193 -2.45922684  8.09073853] 113.120099195\n",
      "Episode =  164, score = 220.535 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [ 0.05322886 -0.01954513  9.96361664] 127.11493008\n",
      "positions (x,y,z), reward: [ 0.16715389 -0.0351571   9.93653774] 120.843977281\n",
      "positions (x,y,z), reward: [ 0.38155983  0.0471422   9.69691374] 114.627049926\n",
      "positions (x,y,z), reward: [ 0.44560081  0.13372181  9.56389691] 113.545890996\n",
      "positions (x,y,z), reward: [ 3.21805584  3.70817819  6.08932879] 99.0469090358\n",
      "positions (x,y,z), reward: [ 5.22082318  5.80495399  2.39056375] 86.6514340171\n",
      "Episode =  165, score = 210.857 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [-0.09418155 -0.2152746   9.71215747] 118.171551928\n",
      "positions (x,y,z), reward: [-0.20567383 -0.26093942  9.20266654] 112.309031469\n",
      "positions (x,y,z), reward: [-0.8036347  -0.01877023  7.88520871] 112.3005531\n",
      "positions (x,y,z), reward: [-1.29360075  0.12449253  6.75950378] 111.012453702\n",
      "positions (x,y,z), reward: [-1.44108108  0.14650585  6.40205958] 109.254604203\n",
      "positions (x,y,z), reward: [-1.5191822   0.1593948   6.21710003] 108.321916201\n",
      "Episode =  166, score = 219.507 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [-0.40982186 -0.03514012  9.00622009] 112.62329519\n",
      "positions (x,y,z), reward: [-0.77870189 -0.19741481  8.35042634] 108.884765352\n",
      "positions (x,y,z), reward: [-0.87785473 -0.27689833  8.09903387] 110.12742531\n",
      "positions (x,y,z), reward: [-1.05916829 -0.4001096   7.7085968 ] 108.476793214\n",
      "positions (x,y,z), reward: [-1.26921485 -0.53060591  7.25594141] 104.837055561\n",
      "positions (x,y,z), reward: [-2.17228955 -1.41314114  3.56782963] 97.9679552077\n",
      "Episode =  167, score = 219.067 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [  6.18295675e-03   3.46339492e-02   9.90684021e+00] 121.204939706\n",
      "positions (x,y,z), reward: [  4.69103152e-03   3.15569228e-02   9.87448012e+00] 119.913314641\n",
      "positions (x,y,z), reward: [-0.7680607   0.42048559  8.01634757] 113.192416164\n",
      "positions (x,y,z), reward: [-0.91394427  1.16282872  5.94527872] 110.181741867\n",
      "positions (x,y,z), reward: [-1.31653791  2.41312905  0.86266959] 95.4491193349\n",
      "Episode =  168, score = 220.613 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [-0.30272141 -0.14456829  9.02748847] 111.279533236\n",
      "Episode =  169, score = 213.914 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [ 0.75255557  0.34356539  8.86804581] 113.635108202\n",
      "positions (x,y,z), reward: [ 1.24768259  1.17856479  5.84552536] 110.296799211\n",
      "positions (x,y,z), reward: [ 1.46905655  1.84027892  2.72174449] 103.789441259\n",
      "Episode =  170, score = 224.356 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [ -1.12989016e-02  -8.50780418e-03   1.00356540e+01] 148.671659241\n",
      "positions (x,y,z), reward: [-0.13199579 -0.07408693  9.83037796] 115.345525217\n",
      "positions (x,y,z), reward: [-0.81572955 -0.94297794  8.5519718 ] 111.228281909\n",
      "positions (x,y,z), reward: [-1.04421508 -1.40950945  7.69980457] 106.502737267\n",
      "positions (x,y,z), reward: [-2.56438607 -2.88630535  1.28093411] 94.6874198926\n",
      "Episode =  171, score = 217.215 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [-0.14177     0.07748052  9.7709578 ] 114.664551952\n",
      "positions (x,y,z), reward: [-0.12690166  0.12699099  9.56687571] 112.846218198\n",
      "positions (x,y,z), reward: [ 0.80031588  1.24907939  3.65604034] 105.21132097\n",
      "positions (x,y,z), reward: [ 0.86893149  1.3440894   2.87923071] 103.914499109\n",
      "Episode =  172, score = 217.754 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [  4.56480692e-03  -2.35446199e-02   9.98962030e+00] 128.187249386\n",
      "positions (x,y,z), reward: [ 3.11422911  3.54557144  4.66054898] 105.245744762\n",
      "Episode =  173, score = 223.438 (best = 226.974), noise_scale = 3.2positions (x,y,z), reward: [-0.29279824 -0.113204    5.36779687] 110.007079361\n",
      "positions (x,y,z), reward: [-0.25125639 -0.11915358  5.14636579] 109.200777591\n",
      "positions (x,y,z), reward: [ 0.17836747 -0.15366599  1.83009861] 100.743550734\n",
      "Episode =  174, score = 228.231 (best = 228.231), noise_scale = 1.6positions (x,y,z), reward: [  0.           0.          10.00159833] 146.841474628\n",
      "positions (x,y,z), reward: [ -2.23973017e-03  -1.35761618e-02   9.98878613e+00] 127.807079259\n",
      "positions (x,y,z), reward: [-0.23430043 -0.03543432  9.64052263] 122.600432504\n",
      "Episode =  175, score = 224.944 (best = 228.231), noise_scale = 3.2positions (x,y,z), reward: [ 3.72592563 -0.40841652  7.80674563] 109.568840372\n",
      "positions (x,y,z), reward: [ 7.01542934 -0.91937581  4.49545522] 82.2705199453\n",
      "Episode =  176, score = 208.737 (best = 228.231), noise_scale = 3.2positions (x,y,z), reward: [-2.05837026 -0.16679231  7.31614976] 108.735690225\n",
      "positions (x,y,z), reward: [-2.82386895 -0.24951078  6.06379904] 108.269651387\n",
      "positions (x,y,z), reward: [-4.36394596 -0.42057598  1.72274305] 95.0831498906\n",
      "Episode =  177, score = 222.202 (best = 228.231), noise_scale = 3.2positions (x,y,z), reward: [ 0.03624888  0.55683906  6.45029831] 117.061494282\n",
      "positions (x,y,z), reward: [-0.14827619  0.46456378  5.84146885] 115.797954132\n",
      "positions (x,y,z), reward: [-1.15726372 -0.48351761  0.87649061] 98.8471119887\n",
      "Episode =  178, score = 230.701 (best = 230.701), noise_scale = 1.6positions (x,y,z), reward: [  1.64930409e-03  -2.75490901e-03   9.99219341e+00] 128.74003004\n",
      "positions (x,y,z), reward: [-0.53677004 -5.25285789  4.43495674] 91.0580473202\n",
      "Episode =  179, score = 211.391 (best = 230.701), noise_scale = 3.2positions (x,y,z), reward: [ 1.78714916  0.56166345  7.69408182] 105.718124796\n",
      "positions (x,y,z), reward: [ 3.16347815  0.08748673  6.06685693] 96.2564676362\n",
      "positions (x,y,z), reward: [ 6.24803389 -1.18634401  1.68173633] 90.2149079624\n",
      "Episode =  180, score = 218.526 (best = 230.701), noise_scale = 3.2positions (x,y,z), reward: [-0.28366601  0.0279926   9.68128247] 123.095816494\n",
      "positions (x,y,z), reward: [-0.52454259  0.04794761  9.39838011] 120.328550221\n",
      "positions (x,y,z), reward: [-0.73435388  0.08206296  9.11880689] 117.964401916\n",
      "Episode =  181, score = 215.888 (best = 230.701), noise_scale = 3.2positions (x,y,z), reward: [-0.29564138  0.21553485  7.80773459] 114.268058222\n",
      "positions (x,y,z), reward: [ 1.3990723  -0.31494416  0.41801929] 97.8570747611\n",
      "Episode =  182, score = 225.734 (best = 230.701), noise_scale = 3.2positions (x,y,z), reward: [  1.06784782e-02  -5.02744659e-03   1.00014507e+01] 138.684254942\n",
      "positions (x,y,z), reward: [ 0.02604818  0.26820891  9.47933712] 121.2296791\n",
      "positions (x,y,z), reward: [ 2.00876294  1.76785725  5.84923432] 104.574086309\n",
      "positions (x,y,z), reward: [ 2.24477023  1.98012727  5.35983448] 101.276272703\n",
      "positions (x,y,z), reward: [ 3.19180161  2.9417268   2.90126265] 86.3800116989\n",
      "positions (x,y,z), reward: [ 3.77472222  3.60082438  0.90954363] 88.6671559859\n",
      "Episode =  183, score = 216.933 (best = 230.701), noise_scale = 3.2positions (x,y,z), reward: [ 0.01237543 -0.17979338  9.80706378] 121.814381816\n",
      "positions (x,y,z), reward: [-0.77084112 -0.4690931   6.73112394] 111.646132356\n",
      "Episode =  184, score = 231.312 (best = 231.312), noise_scale = 1.6positions (x,y,z), reward: [-0.15144447 -0.54638385  9.00585856] 116.974917127\n",
      "positions (x,y,z), reward: [-0.19691002 -0.66492159  8.54960637] 120.160627303\n",
      "positions (x,y,z), reward: [-0.35023699 -1.26561857  6.01538209] 114.529641885\n",
      "positions (x,y,z), reward: [-0.29395314 -1.52976517  4.48410601] 107.848383214\n",
      "Episode =  185, score = 228.503 (best = 231.312), noise_scale = 3.2positions (x,y,z), reward: [ 0.6972293   0.20556513  9.53362043] 119.37302113\n",
      "positions (x,y,z), reward: [ 3.07263233  0.43157025  7.55923563] 111.682015901\n",
      "positions (x,y,z), reward: [ 3.55110086  0.4765102   6.69403119] 110.112120034\n",
      "Episode =  186, score = 222.417 (best = 231.312), noise_scale = 3.2positions (x,y,z), reward: [  0.34762681   0.03283173  10.20139159] 151.575434634\n",
      "positions (x,y,z), reward: [  0.48827809   0.01474224  10.19020754] 128.312738615\n",
      "positions (x,y,z), reward: [  0.43630752  -0.05284805  10.08423262] 128.273893934\n",
      "positions (x,y,z), reward: [-0.89876148  0.32343302  4.37694479] 109.796534038\n",
      "positions (x,y,z), reward: [-1.29934701  0.65044838  1.42379012] 99.9823970588\n",
      "positions (x,y,z), reward: [-1.30169181  0.66853201  1.18653738] 99.4980743054\n",
      "Episode =  187, score = 246.970 (best = 246.970), noise_scale = 1.6positions (x,y,z), reward: [-0.12212365 -0.02164414  9.91652228] 115.601632908\n",
      "positions (x,y,z), reward: [-0.47177403 -0.01939034  9.49721568] 113.985784039\n",
      "positions (x,y,z), reward: [-0.02920415 -0.0176908   8.14596921] 117.262589302\n",
      "positions (x,y,z), reward: [-0.01939714 -0.02492703  8.04605381] 116.904327751\n",
      "positions (x,y,z), reward: [ 0.05939838 -0.04026806  7.42946052] 116.403648615\n",
      "positions (x,y,z), reward: [ 0.21269232 -0.13794018  6.42295254] 112.008257292\n",
      "Episode =  188, score = 227.078 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.18529556 -0.25308503  9.16541309] 115.485367893\n",
      "positions (x,y,z), reward: [-0.19753529 -0.36743568  7.29687709] 109.700292419\n",
      "positions (x,y,z), reward: [ 0.3001832  -0.3930105   4.05893337] 102.472544538\n",
      "Episode =  189, score = 222.875 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.08679729 -0.35870881  9.43855631] 115.125875886\n",
      "positions (x,y,z), reward: [-0.02579119 -0.53658788  9.10395018] 114.340625152\n",
      "positions (x,y,z), reward: [ 1.15085549 -2.11686289  5.03888287] 101.894452614\n",
      "positions (x,y,z), reward: [ 1.36520631 -2.57566578  3.55130728] 100.85899331\n",
      "positions (x,y,z), reward: [ 1.74095885 -3.14795193  1.35667182] 90.210225483\n",
      "Episode =  190, score = 224.092 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.14996021  1.17104167  4.27169521] 106.089787013\n",
      "Episode =  191, score = 224.885 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.04464328  -0.01905384  10.02820521] 126.101468343\n",
      "positions (x,y,z), reward: [-1.53318056 -3.01512013  2.43762398] 99.3647023374\n",
      "Episode =  192, score = 233.528 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.13374421e-03   6.42858584e-04   1.00053341e+01] 145.807348943\n",
      "positions (x,y,z), reward: [ 0.59577387 -1.27145612  7.85253995] 113.691074337\n",
      "Episode =  193, score = 224.366 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.12028776  0.1300022   9.82892316] 110.568714897\n",
      "positions (x,y,z), reward: [ 0.2687982   0.67179757  8.10507275] 113.697530488\n",
      "positions (x,y,z), reward: [ 0.3680372   0.76114206  7.5235345 ] 115.044835256\n",
      "positions (x,y,z), reward: [ 0.89194259  1.14503207  5.32878429] 110.496136953\n",
      "Episode =  194, score = 224.232 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.30194089  0.97315488  8.70140468] 119.156692822\n",
      "Episode =  195, score = 222.352 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.28644736   0.01041982  10.09427312] 151.927089138\n",
      "positions (x,y,z), reward: [ 0.57768132  2.36991608  8.1139165 ] 115.341648315\n",
      "positions (x,y,z), reward: [ 0.55037414  2.88334549  7.50651709] 108.056592213\n",
      "Episode =  196, score = 228.041 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.59606362e-02   3.46808305e-04   1.00185166e+01] 141.816637535\n",
      "positions (x,y,z), reward: [  0.08752358  -0.10244419  10.00817118] 123.949921826\n",
      "positions (x,y,z), reward: [ 0.04609603 -0.18517744  9.45964953] 111.233844813\n",
      "positions (x,y,z), reward: [ 0.08074325 -0.14502851  9.26087593] 112.706361116\n",
      "positions (x,y,z), reward: [ 0.11283604 -0.10153807  9.02974183] 116.272378109\n",
      "positions (x,y,z), reward: [ 2.09556477  0.31836807  3.48885792] 101.921041944\n",
      "positions (x,y,z), reward: [ 2.78478447  0.402488    1.54713252] 96.7479255432\n",
      "positions (x,y,z), reward: [ 3.0383259   0.43975664  0.77459082] 96.5189289466\n",
      "Episode =  197, score = 227.806 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.59684379  0.59675753  9.22716005] 105.998941432\n",
      "positions (x,y,z), reward: [ 0.35545088  2.08604459  4.23680975] 109.316256446\n",
      "Episode =  198, score = 224.092 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.38881778  0.23383436  9.29410128] 118.315161328\n",
      "positions (x,y,z), reward: [-0.65712442  0.44144042  8.14735168] 111.255366805\n",
      "positions (x,y,z), reward: [-0.68970899  0.50503482  7.60470153] 111.957350965\n",
      "positions (x,y,z), reward: [-0.87633219  0.73271838  5.70538976] 108.33066263\n",
      "positions (x,y,z), reward: [-0.83756716  1.38917823  0.        ] 95.9888441702\n",
      "Episode =  199, score = 224.104 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.11453715 -0.03021012  9.92722987] 112.698461154\n",
      "positions (x,y,z), reward: [ 0.31080022 -0.22810934  9.72935872] 112.616049138\n",
      "positions (x,y,z), reward: [ 0.39376248 -0.4267085   9.51856527] 113.124936658\n",
      "positions (x,y,z), reward: [ 2.28360825 -2.62599222  5.02896072] 91.0224383768\n",
      "positions (x,y,z), reward: [ 3.17875824 -4.18759257  0.77341781] 91.1413070486\n",
      "Episode =  200, score = 206.045 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.93352810e-02   5.85202297e-03   9.87586641e+00] 121.421429568\n",
      "positions (x,y,z), reward: [ 2.15515664 -0.20633006  6.47224413] 103.416302697\n",
      "Episode =  201, score = 214.955 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.4037757   1.0913591   8.22971868] 111.7208097\n",
      "positions (x,y,z), reward: [ 3.20918714  1.43478438  6.94981628] 108.265065938\n",
      "Episode =  203, score = 216.753 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.52012596e-02  -7.42733258e-03   9.97051553e+00] 123.018741329\n",
      "positions (x,y,z), reward: [-0.02701778 -0.30244462  8.61679993] 100.911838459\n",
      "positions (x,y,z), reward: [ 0.6992504  -0.66838838  5.82802065] 103.341077697\n",
      "positions (x,y,z), reward: [ 1.74672246 -1.13532025  2.88442745] 99.8352840651\n",
      "positions (x,y,z), reward: [ 2.30512933 -1.40130295  1.03233888] 95.9708098661\n",
      "positions (x,y,z), reward: [ 2.38356815 -1.44148598  0.74978462] 95.3469354001\n",
      "Episode =  204, score = 209.928 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  7.31351629e-02   2.98204334e-03   9.99623820e+00] 124.871186372\n",
      "positions (x,y,z), reward: [ 1.11175033  0.92016374  8.23789061] 112.086583357\n",
      "positions (x,y,z), reward: [ 1.11377947  1.84501735  4.44641829] 106.612538742\n",
      "Episode =  205, score = 217.997 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04414159  0.10707165  9.16980117] 119.624119101\n",
      "positions (x,y,z), reward: [  2.93594825e-01  -1.67480135e-04   7.34543111e+00] 113.984116659\n",
      "positions (x,y,z), reward: [ 0.27573313 -0.11410377  5.33458774] 111.440886382\n",
      "positions (x,y,z), reward: [ 0.0596166  -0.23758887  0.11866545] 100.062973329\n",
      "Episode =  206, score = 224.426 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00126532] 146.738929951\n",
      "positions (x,y,z), reward: [  4.24476083e-03   3.45198545e-04   1.00221447e+01] 132.51053468\n",
      "positions (x,y,z), reward: [ 1.15370519  0.08998548  8.20067016] 108.265967599\n",
      "positions (x,y,z), reward: [ 3.8099104   0.09870328  3.68431607] 100.496494112\n",
      "Episode =  207, score = 218.975 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.86369948  0.19103382  8.78576414] 115.283034228\n",
      "positions (x,y,z), reward: [ 1.53115435  0.26201963  6.51586689] 106.951206754\n",
      "positions (x,y,z), reward: [ 2.02395331  0.17109238  3.85732965] 105.705087003\n",
      "Episode =  208, score = 221.233 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.27768893 -0.2975681   6.45304081] 107.136304843\n",
      "positions (x,y,z), reward: [-0.26304593 -0.41606419  5.91106644] 105.13881576\n",
      "positions (x,y,z), reward: [ 0.52827907 -0.95219568  1.24868665] 101.081141414\n",
      "Episode =  209, score = 218.558 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.20849187  0.03677832  9.98426625] 118.285456607\n",
      "Episode =  210, score = 213.849 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.58144772 -0.04417903  9.70956838] 111.49341085\n",
      "positions (x,y,z), reward: [-1.22911655  0.11282694  8.41844279] 120.786249539\n",
      "positions (x,y,z), reward: [-3.18527021  0.77601878  1.66232444] 99.7738346394\n",
      "Episode =  211, score = 227.928 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.019262   -0.02617214  9.68686814] 108.630245303\n",
      "positions (x,y,z), reward: [ 0.67110717  0.5708534   7.49910105] 113.868835716\n",
      "positions (x,y,z), reward: [ 1.06638207  0.99348027  5.30638653] 110.169942588\n",
      "positions (x,y,z), reward: [ 1.18476324  1.15194686  4.1799977 ] 106.831235611\n",
      "positions (x,y,z), reward: [ 1.22780276  1.21718687  3.69554148] 105.00082238\n",
      "Episode =  212, score = 221.440 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.61207842 -0.54298275  5.40440571] 112.530283234\n",
      "positions (x,y,z), reward: [-2.18066773 -0.55242683  3.60311747] 107.303483672\n",
      "positions (x,y,z), reward: [-2.38762896 -0.46537843  2.65006592] 104.007964882\n",
      "positions (x,y,z), reward: [-2.43823599 -0.42260776  2.2352287 ] 102.88456757\n",
      "positions (x,y,z), reward: [-2.46663612 -0.38289952  1.80860047] 102.042365272\n",
      "Episode =  213, score = 230.466 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.56436228 -0.30928974  8.55937365] 108.234569566\n",
      "Episode =  214, score = 218.948 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.60657812  0.69865337  7.73198944] 114.341143718\n",
      "positions (x,y,z), reward: [ 0.98440705  0.86372376  6.78525608] 110.183379543\n",
      "Episode =  215, score = 219.241 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.09700468  -0.07363214  10.00552615] 122.668508473\n",
      "positions (x,y,z), reward: [-0.07220146 -0.25865716  9.71808433] 118.872579988\n",
      "positions (x,y,z), reward: [-0.20449231 -0.63046394  8.360429  ] 116.876576847\n",
      "positions (x,y,z), reward: [ 0.30189181 -1.14339324  5.57981051] 108.361890867\n",
      "positions (x,y,z), reward: [ 0.62144364 -2.00049217  0.25458888] 96.8398712137\n",
      "Episode =  216, score = 230.302 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00089179] 145.745482191\n",
      "positions (x,y,z), reward: [  3.23935359e-02  -2.70849906e-03   9.99993383e+00] 125.275449321\n",
      "positions (x,y,z), reward: [ 0.14330221 -0.48486114  9.66202766] 117.155675249\n",
      "positions (x,y,z), reward: [ 0.11900745 -0.80710856  9.1226912 ] 109.196417571\n",
      "positions (x,y,z), reward: [ 0.12684527 -0.8648939   9.0409285 ] 111.045729359\n",
      "positions (x,y,z), reward: [ 0.13775085 -0.98061273  8.86425139] 113.507830843\n",
      "Episode =  217, score = 219.174 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.15582639  0.04482986  9.81827834] 124.624625286\n",
      "positions (x,y,z), reward: [ 0.06268116  0.14550907  8.44803719] 115.716421515\n",
      "positions (x,y,z), reward: [ 0.02483846  0.2147355   7.81566347] 115.552498951\n",
      "Episode =  218, score = 225.478 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  6.98479613e-02  -4.96701494e-03   1.00005305e+01] 123.702708875\n",
      "positions (x,y,z), reward: [ 3.38776971 -0.46244755  6.27145966] 93.2759017951\n",
      "positions (x,y,z), reward: [ 3.79334876 -0.56380323  5.35260025] 95.2110412545\n",
      "Episode =  219, score = 208.577 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.23361831  0.02168144  9.73547505] 117.326300711\n",
      "positions (x,y,z), reward: [ 0.43318013  0.25070409  7.86337852] 111.936139445\n",
      "positions (x,y,z), reward: [ 1.58594401  0.60283342  1.87420691] 92.2351056039\n",
      "positions (x,y,z), reward: [ 1.774875    0.66136097  1.15948225] 93.9697636333\n",
      "Episode =  220, score = 218.784 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.61177383  0.04372287  9.66121891] 111.559156607\n",
      "positions (x,y,z), reward: [ 0.99307768 -0.01353503  9.43283751] 110.543199771\n",
      "positions (x,y,z), reward: [ 3.0884777  -0.18618869  6.19903023] 94.2963862609\n",
      "Episode =  221, score = 211.844 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.06063959 -0.07895304  8.67791484] 117.676032292\n",
      "positions (x,y,z), reward: [-1.27386219 -0.07661853  8.35116283] 117.03611744\n",
      "positions (x,y,z), reward: [-4.56837262  1.15428527  1.86009707] 100.967292282\n",
      "Episode =  222, score = 222.193 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.09234968  0.20138884  7.00203464] 108.666784237\n",
      "Episode =  223, score = 225.125 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.79329664 -1.85424319  4.64095923] 109.269674074\n",
      "positions (x,y,z), reward: [-1.10309731 -2.95901855  0.02638152] 97.0453187521\n",
      "Episode =  224, score = 222.783 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.07667483 -0.07679945  9.64220655] 113.439367453\n",
      "positions (x,y,z), reward: [ 0.44687874 -0.39125919  9.07102349] 112.927629741\n",
      "Episode =  225, score = 215.461 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.22556873e-02   1.89177726e-03   1.00059063e+01] 143.022544633\n",
      "positions (x,y,z), reward: [ 0.32431712 -0.41373588  9.78876217] 116.558673326\n",
      "positions (x,y,z), reward: [ 1.91451003 -5.10053211  3.1806518 ] 94.865141003\n",
      "Episode =  226, score = 212.205 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.15888375 -0.11237587  9.950588  ] 132.732279528\n",
      "positions (x,y,z), reward: [ 0.10889357 -0.44924396  9.72001626] 122.408067876\n",
      "positions (x,y,z), reward: [-0.03989104 -0.74246508  9.22862417] 123.299149832\n",
      "positions (x,y,z), reward: [-0.13306044 -0.85576379  8.23695598] 118.645560077\n",
      "positions (x,y,z), reward: [-0.21331411 -1.21946842  3.59622981] 104.885759337\n",
      "positions (x,y,z), reward: [-0.07396871 -1.27721056  0.        ] 95.5343555013\n",
      "Episode =  227, score = 231.157 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -4.37511694e-02   2.30113942e-03   9.79663181e+00] 117.017621116\n",
      "positions (x,y,z), reward: [-0.35396717 -0.09625096  9.20399931] 110.567582449\n",
      "positions (x,y,z), reward: [-0.56826725 -0.1765736   8.57020758] 113.06533254\n",
      "positions (x,y,z), reward: [-0.61478797 -0.67647333  6.6343091 ] 108.482011376\n",
      "positions (x,y,z), reward: [-0.27680634 -1.25673984  2.63970305] 104.531948649\n",
      "Episode =  228, score = 222.746 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.15350875  -0.0329381   10.0151676 ] 140.399787578\n",
      "positions (x,y,z), reward: [  0.17701992  -0.03927123  10.01805972] 134.558790043\n",
      "positions (x,y,z), reward: [  0.18304556  -0.04394089  10.00731303] 124.731328826\n",
      "positions (x,y,z), reward: [-0.21676436 -0.30483724  9.30001493] 124.815728141\n",
      "positions (x,y,z), reward: [-1.00136155 -1.3412884   5.1766172 ] 110.459364668\n",
      "positions (x,y,z), reward: [-1.21982587 -1.56794345  2.19844053] 102.465881746\n",
      "Episode =  229, score = 234.455 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.14902655  0.01528022  9.97405297] 108.529085984\n",
      "positions (x,y,z), reward: [-0.66840587  0.02321026  9.76664308] 118.148917681\n",
      "positions (x,y,z), reward: [-1.32667404 -0.29648901  9.19519248] 114.638188004\n",
      "positions (x,y,z), reward: [-1.8243165  -0.3356672   8.61127581] 115.199564478\n",
      "Episode =  230, score = 222.771 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.37439365 -0.41113289  6.8393397 ] 110.856823702\n",
      "positions (x,y,z), reward: [ 1.50491281 -0.40737186  6.56154921] 109.185703142\n",
      "positions (x,y,z), reward: [ 4.19723954 -0.16172936  1.45118031] 95.0845397572\n",
      "Episode =  231, score = 221.796 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -7.44029404e-03   8.06170598e-04   9.85110817e+00] 117.291739058\n",
      "positions (x,y,z), reward: [ 1.2338968   0.4295624   3.58946145] 106.661196975\n",
      "positions (x,y,z), reward: [ 1.3197132   0.46810624  3.15292704] 105.817830667\n",
      "positions (x,y,z), reward: [ 1.83300802  0.73658418  0.        ] 97.5404613513\n",
      "Episode =  232, score = 224.824 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.8437714  -2.0593155   7.57344558] 107.052811255\n",
      "positions (x,y,z), reward: [ 1.47268847 -4.25176708  3.09606171] 99.8311076854\n",
      "Episode =  233, score = 212.111 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.35551541  0.47898965  8.93998521] 116.688052599\n",
      "positions (x,y,z), reward: [ 0.59834065  0.58661234  8.00969737] 114.044781585\n",
      "positions (x,y,z), reward: [ 0.64752535  0.61219177  7.78748533] 114.439645137\n",
      "positions (x,y,z), reward: [ 0.87207647  0.65213894  6.72528238] 111.703947531\n",
      "positions (x,y,z), reward: [ 1.03119202  0.68085123  4.81691373] 109.284552049\n",
      "positions (x,y,z), reward: [ 1.3886276   0.71255101  0.9573886 ] 96.9414662145\n",
      "Episode =  234, score = 222.622 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00213281] 146.69147088\n",
      "positions (x,y,z), reward: [-0.53825294 -0.97326944  8.16853167] 117.858869924\n",
      "positions (x,y,z), reward: [-1.05557111 -1.15293218  7.04905866] 115.192322531\n",
      "positions (x,y,z), reward: [-1.80405259 -1.2433496   4.47849895] 108.556631486\n",
      "positions (x,y,z), reward: [-2.10264716 -1.22471483  3.43144461] 105.675398139\n",
      "positions (x,y,z), reward: [-2.25856282 -1.17819736  2.84492752] 103.824117501\n",
      "positions (x,y,z), reward: [-2.30862859 -1.1574867   2.63741779] 103.225870839\n",
      "positions (x,y,z), reward: [-2.47928983 -1.05937448  1.74604536] 100.946894812\n",
      "positions (x,y,z), reward: [-2.64577524 -0.85970534  0.        ] 96.8080800562\n",
      "Episode =  235, score = 223.126 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.62506123e-02   8.09682296e-03   1.00305558e+01] 146.470804731\n",
      "positions (x,y,z), reward: [ 0.38764108  1.7441159   5.85069113] 104.864516811\n",
      "Episode =  236, score = 228.249 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.68725868e-03   3.10103690e-04   1.00026905e+01] 144.770484219\n",
      "Episode =  237, score = 218.886 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.13412596 -0.19448877  6.19545874] 111.821393222\n",
      "positions (x,y,z), reward: [ 5.08240734 -0.88671923  0.49346053] 88.8405595477\n",
      "Episode =  238, score = 213.662 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.09331642 -0.05127765  9.62806027] 116.055824567\n",
      "positions (x,y,z), reward: [ 0.53707206 -0.54386925  7.59347073] 115.750256943\n",
      "positions (x,y,z), reward: [ 0.71799445 -0.61643365  6.11075433] 111.320536909\n",
      "Episode =  239, score = 224.711 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -5.02222453e-03   2.34789607e-02   1.00068982e+01] 122.387432182\n",
      "positions (x,y,z), reward: [-0.14138103 -1.1320762   8.68727352] 100.791302435\n",
      "Episode =  240, score = 216.029 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.78244657  0.2802885   9.73668421] 120.128962896\n",
      "positions (x,y,z), reward: [ 1.46562501  0.71516355  9.46073886] 120.032990349\n",
      "positions (x,y,z), reward: [ 3.32541189  1.99442861  6.73153933] 106.039541017\n",
      "positions (x,y,z), reward: [ 3.81348026  2.37839337  5.505257  ] 100.509115507\n",
      "positions (x,y,z), reward: [ 4.35986047  2.81640648  3.94148163] 98.6625311857\n",
      "Episode =  241, score = 217.169 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.14591605  -0.04250832  10.00884605] 141.222077605\n",
      "positions (x,y,z), reward: [ 0.67558608 -1.44407331  4.96866353] 107.962749658\n",
      "positions (x,y,z), reward: [ 1.1754281  -2.15914575  0.49073339] 95.5235977925\n",
      "Episode =  242, score = 232.107 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.63363709 -0.12156468  4.20648391] 110.049838005\n",
      "positions (x,y,z), reward: [-0.85909487 -0.16514374  2.53161233] 105.225448399\n",
      "Episode =  243, score = 230.674 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.31773477  0.07974076  9.95013964] 126.169651512\n",
      "positions (x,y,z), reward: [ 3.18933546  1.39256161  4.64601527] 101.794114261\n",
      "positions (x,y,z), reward: [ 3.85036329  1.64541384  2.47130683] 93.1776450171\n",
      "Episode =  244, score = 220.833 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.02909077  0.03887354  9.97129831] 130.717206683\n",
      "positions (x,y,z), reward: [-2.46565319  0.93068761  8.54611599] 118.979250883\n",
      "positions (x,y,z), reward: [-2.4916848   2.58880328  5.41573625] 103.829939099\n",
      "positions (x,y,z), reward: [-2.17196561  4.16567755  1.93226576] 95.8035777218\n",
      "positions (x,y,z), reward: [-2.06992137  4.79436868  0.34002462] 93.8060009285\n",
      "Episode =  245, score = 236.632 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.33430836e-02   1.99363475e-04   9.99628480e+00] 136.663238984\n",
      "positions (x,y,z), reward: [ 0.38116771  0.30505788  9.64788192] 118.341496959\n",
      "positions (x,y,z), reward: [ 0.95987702  0.65461591  9.2538566 ] 119.767751781\n",
      "positions (x,y,z), reward: [ 2.41570911  1.48686674  8.43476682] 116.786432156\n",
      "positions (x,y,z), reward: [ 10.96558628   5.05055197   0.37164707] 78.5501431179\n",
      "Episode =  246, score = 213.196 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.74331542 -2.56862595  0.        ] 87.8193888178\n",
      "Episode =  247, score = 207.244 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.18713082  0.56843546  8.9544812 ] 112.427985326\n",
      "positions (x,y,z), reward: [-1.09754282  1.18449784  5.7239198 ] 110.918921439\n",
      "Episode =  248, score = 225.289 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.53626629  0.13048077  8.93396541] 119.425531111\n",
      "positions (x,y,z), reward: [-0.55709904  0.12831732  8.69335241] 118.072089586\n",
      "Episode =  249, score = 229.251 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.42883169e-03  -1.39094662e-03   9.97111353e+00] 125.061702498\n",
      "positions (x,y,z), reward: [ -7.68632299e-03  -8.38488189e-04   9.94685145e+00] 123.775175063\n",
      "positions (x,y,z), reward: [-0.43042511  0.2898822   9.21088172] 116.709353681\n",
      "positions (x,y,z), reward: [-0.51826887  0.35644474  8.91995093] 113.3416798\n",
      "positions (x,y,z), reward: [-1.15988206  0.37505687  7.3328724 ] 113.808903492\n",
      "positions (x,y,z), reward: [-2.37852062  0.58209605  4.68999783] 109.489594435\n",
      "Episode =  250, score = 223.846 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.34019844 -0.7141088   8.34843628] 112.983075282\n",
      "positions (x,y,z), reward: [-0.34358096 -0.80724218  7.60044713] 115.22052924\n",
      "positions (x,y,z), reward: [-0.26183883 -1.10545959  4.0311291 ] 108.52609172\n",
      "Episode =  251, score = 225.515 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.04558012e-01  -2.80645046e-03   9.96875309e+00] 119.572354272\n",
      "positions (x,y,z), reward: [ 6.19904619  2.41592747  3.73906524] 92.9769772884\n",
      "positions (x,y,z), reward: [ 7.33538301  2.6005407   2.47317453] 95.4752101873\n",
      "Episode =  252, score = 216.557 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.70518165e-03   6.59134713e-03   1.00132472e+01] 149.265709794\n",
      "positions (x,y,z), reward: [-0.13533968 -0.1099336   9.84156404] 114.65101235\n",
      "positions (x,y,z), reward: [-0.33976721 -0.27823666  9.64182092] 110.569819967\n",
      "positions (x,y,z), reward: [-1.25650916 -0.99390839  7.03656629] 113.060987318\n",
      "positions (x,y,z), reward: [-2.00840979 -1.31062196  4.15393455] 106.296141583\n",
      "Episode =  253, score = 221.236 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.45238660e-02  -3.98544343e-03   9.89727490e+00] 119.827162037\n",
      "positions (x,y,z), reward: [ 0.01929017  0.02611547  9.830078  ] 117.318223857\n",
      "positions (x,y,z), reward: [ 0.0164895   0.04322718  9.8037365 ] 116.758936504\n",
      "positions (x,y,z), reward: [ 0.62776569  0.48204448  8.3045316 ] 110.245902752\n",
      "positions (x,y,z), reward: [ 1.26662207  0.58033079  7.06267711] 108.858841922\n",
      "Episode =  254, score = 217.363 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.10413284 -0.29169841  9.75886361] 113.472532273\n",
      "positions (x,y,z), reward: [ 0.01269469 -0.54181229  8.46562194] 117.519857094\n",
      "positions (x,y,z), reward: [ 0.42196015 -0.9441558   6.999054  ] 112.106369773\n",
      "positions (x,y,z), reward: [ 0.45476786 -1.02320003  6.71528199] 111.75407678\n",
      "positions (x,y,z), reward: [ 0.48369027 -1.10329214  6.4132186 ] 111.467660969\n",
      "positions (x,y,z), reward: [ 0.49764223 -1.14360281  6.25571684] 111.303183326\n",
      "positions (x,y,z), reward: [ 0.53907348 -1.26553601  5.75741081] 111.231229688\n",
      "Episode =  255, score = 226.136 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.32715106  0.2998939   9.2251229 ] 117.40159824\n",
      "positions (x,y,z), reward: [-0.42662592  0.43038574  8.73195222] 120.905955725\n",
      "positions (x,y,z), reward: [-0.82720742  0.84293989  6.87201627] 114.943642091\n",
      "positions (x,y,z), reward: [-2.034915    1.63557859  1.70366202] 99.4268901021\n",
      "Episode =  256, score = 226.856 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -6.98727374e-03   6.74802199e-03   1.00156389e+01] 141.850590437\n",
      "positions (x,y,z), reward: [-0.37675726 -0.09617428  5.58467956] 112.999372129\n",
      "positions (x,y,z), reward: [-0.36850986 -0.08090166  4.94658744] 111.53813054\n",
      "positions (x,y,z), reward: [-0.48087352 -0.14143978  1.45266921] 103.241866106\n",
      "positions (x,y,z), reward: [-0.5937075  -0.21662495  0.        ] 100.083517021\n",
      "Episode =  257, score = 225.782 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -5.29108732e-06   3.90320296e-04   1.00057373e+01] 145.781930966\n",
      "positions (x,y,z), reward: [ -4.67831282e-03   3.74854634e-03   1.00222751e+01] 135.186330429\n",
      "positions (x,y,z), reward: [ 1.85695523 -3.48370541  0.22154307] 85.7416939669\n",
      "Episode =  258, score = 222.227 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.00654517  1.0337315   8.24381417] 108.521372534\n",
      "positions (x,y,z), reward: [ 2.96820134  1.44715893  5.34862289] 100.482575669\n",
      "positions (x,y,z), reward: [ 3.93846017  1.53138007  3.5541683 ] 99.3862081706\n",
      "positions (x,y,z), reward: [ 5.3809459   1.74785215  0.46649959] 95.2244222226\n",
      "Episode =  259, score = 216.096 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.14126776  0.24898704  8.51607915] 120.754783763\n",
      "positions (x,y,z), reward: [-0.68883463  0.3733564   6.96400898] 114.988140025\n",
      "positions (x,y,z), reward: [-0.93761698  0.19001747  5.35093095] 111.43662177\n",
      "positions (x,y,z), reward: [-0.92669202  0.03032451  4.26143882] 106.281967791\n",
      "positions (x,y,z), reward: [-0.93167016 -0.45211502  1.50138018] 103.165263726\n",
      "Episode =  260, score = 230.186 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.40201274e-02   9.27801322e-03   1.00018767e+01] 123.551785268\n",
      "positions (x,y,z), reward: [ 2.66559804  1.07455166  7.93614685] 106.452629287\n",
      "positions (x,y,z), reward: [ 3.51419085  1.37136347  6.89236721] 100.188426984\n",
      "Episode =  261, score = 209.115 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  5.93577854e-02  -9.85322628e-03   9.97845093e+00] 123.010291686\n",
      "positions (x,y,z), reward: [-0.80659965  0.35590242  7.0974754 ] 115.150283771\n",
      "positions (x,y,z), reward: [-0.84634728  0.3617559   6.91902303] 114.708047544\n",
      "Episode =  262, score = 227.441 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.37703860e-03   6.40223878e-05   1.00037899e+01] 144.270305968\n",
      "positions (x,y,z), reward: [-0.14956371  0.24351047  7.91583862] 113.895406959\n",
      "positions (x,y,z), reward: [-0.36849938  0.2693529   6.85448864] 114.741827323\n",
      "positions (x,y,z), reward: [-0.72136668  0.32791544  5.35087423] 111.439637019\n",
      "positions (x,y,z), reward: [-0.95722361  0.82645961  0.        ] 95.716531032\n",
      "Episode =  263, score = 222.727 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.01820081 -0.05003012  9.78061339] 110.126302354\n",
      "positions (x,y,z), reward: [-0.05884811 -0.60035876  7.49742382] 110.953010741\n",
      "positions (x,y,z), reward: [-0.11981187 -1.33868285  3.28466285] 104.00846726\n",
      "Episode =  264, score = 219.004 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 3.68606953  1.67201345  8.85166222] 108.745702989\n",
      "positions (x,y,z), reward: [ 3.82205423  1.73445101  8.77183562] 106.680318174\n",
      "positions (x,y,z), reward: [ 3.96006896  1.7990255   8.69371711] 104.541682612\n",
      "positions (x,y,z), reward: [ 7.35443077  3.23820039  6.61278342] 95.7517433471\n",
      "positions (x,y,z), reward: [ 9.42880561  3.93017085  5.02396287] 90.1709218938\n",
      "positions (x,y,z), reward: [ 9.81222223  4.0669427   4.64664409] 87.8570282072\n",
      "positions (x,y,z), reward: [ 10.51480667   4.32410625   3.84861472] 89.0874074567\n",
      "Episode =  265, score = 208.878 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.11029054  0.60718139  9.65937256] 119.756542845\n",
      "positions (x,y,z), reward: [ 0.39450242  1.16378366  9.16557333] 121.606526214\n",
      "positions (x,y,z), reward: [ 1.34886628  2.76031824  5.52648149] 101.297896322\n",
      "positions (x,y,z), reward: [ 1.44127511  2.93491287  4.76787212] 99.9150282576\n",
      "positions (x,y,z), reward: [ 1.4881534   3.01097259  4.37084441] 98.6354374235\n",
      "Episode =  266, score = 219.846 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.85471513  0.39583284  8.1255647 ] 102.809731816\n",
      "positions (x,y,z), reward: [ 3.08358957  0.43144326  7.89444777] 105.353745054\n",
      "Episode =  267, score = 209.436 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.58738474 -0.24179708  9.25827087] 103.223673421\n",
      "positions (x,y,z), reward: [ 1.42773478 -0.52561773  7.14155289] 112.16716975\n",
      "Episode =  268, score = 212.982 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -7.82978751e-03   3.56807663e-03   9.91406750e+00] 121.203515847\n",
      "positions (x,y,z), reward: [ 0.02774513 -0.02651573  9.72309047] 115.393113042\n",
      "positions (x,y,z), reward: [ 0.4072722  -0.97554915  6.9094551 ] 113.263032067\n",
      "positions (x,y,z), reward: [ 0.44827385 -1.19587256  5.76162381] 106.213693707\n",
      "Episode =  269, score = 218.156 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.13104885e-02  -4.74821963e-03   9.96075456e+00] 124.44551116\n",
      "positions (x,y,z), reward: [-0.13278235 -0.14666699  9.4671262 ] 113.510438415\n",
      "positions (x,y,z), reward: [-0.28090933 -0.16498445  9.18448321] 114.545622115\n",
      "positions (x,y,z), reward: [-0.3945881   0.03780107  8.61989517] 115.802337383\n",
      "positions (x,y,z), reward: [ 0.1510313   1.80671672  3.29569501] 101.89830964\n",
      "Episode =  270, score = 223.606 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-5.39021197  0.81754091  0.85724608] 91.5278796098\n",
      "Episode =  271, score = 224.122 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.18626801 -0.69011926  9.22457797] 112.445840668\n",
      "positions (x,y,z), reward: [-0.70986997 -2.82293003  3.46078962] 104.10517027\n",
      "Episode =  272, score = 219.334 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.11202372   0.0562569   10.05444454] 145.864503699\n",
      "positions (x,y,z), reward: [ 0.71406109  0.4112742   9.98750503] 123.137641108\n",
      "positions (x,y,z), reward: [ 1.04138395  0.60718113  9.90504281] 116.838194448\n",
      "positions (x,y,z), reward: [ 7.34562646  5.78129837  3.57611718] 94.503965783\n",
      "positions (x,y,z), reward: [ 7.97600609  6.67962734  1.77642812] 89.3255642221\n",
      "positions (x,y,z), reward: [ 8.43474228  7.44834386  0.        ] 68.6459628548\n",
      "Episode =  273, score = 216.516 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.13829171  0.01605427  9.93328313] 114.070796561\n",
      "positions (x,y,z), reward: [ -1.53312618e-01   8.95460930e-03   9.89794125e+00] 112.31728937\n",
      "Episode =  274, score = 215.798 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.46599795e-01  -3.52749072e-03   9.92147013e+00] 124.366265965\n",
      "positions (x,y,z), reward: [ 0.58585558  0.08652573  9.82753511] 124.145865876\n",
      "positions (x,y,z), reward: [ 0.93709131  0.25512557  9.67211661] 116.59990577\n",
      "Episode =  275, score = 208.730 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  4.98154517e-03  -3.25526915e-01   9.03214076e+00] 105.836449571\n",
      "positions (x,y,z), reward: [ 0.13833029 -1.27575879  6.28584935] 104.496066497\n",
      "Episode =  276, score = 212.035 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.10302171 -0.04856584  9.77518104] 123.080607077\n",
      "positions (x,y,z), reward: [ 0.83235188  0.71493614  6.45637565] 111.056922811\n",
      "positions (x,y,z), reward: [ 0.86297479  0.75778828  6.29090224] 110.712404673\n",
      "Episode =  277, score = 222.902 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.16704680e-02  -5.09366405e-03   9.98441533e+00] 116.597044265\n",
      "positions (x,y,z), reward: [  1.85591669e-01   1.10756765e-03   9.07958886e+00] 119.397030428\n",
      "positions (x,y,z), reward: [ 0.31318785  0.1408202   7.87539451] 113.149074155\n",
      "positions (x,y,z), reward: [-0.21760115  0.77454734  0.        ] 97.8114001839\n",
      "Episode =  278, score = 226.422 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.94910421 -0.23715147  9.34173597] 117.870008833\n",
      "positions (x,y,z), reward: [ 1.16123399 -0.73735665  7.92814823] 117.098755367\n",
      "positions (x,y,z), reward: [ 0.95641299 -1.51776745  5.11666347] 109.786841131\n",
      "Episode =  279, score = 227.320 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-2.09430834 -1.14629246  4.79766993] 107.426360513\n",
      "Episode =  280, score = 215.510 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.34552722e-03   4.83565676e-03   1.00235455e+01] 141.390732127\n",
      "positions (x,y,z), reward: [-0.05706861  0.06333032  9.98503798] 117.865041458\n",
      "positions (x,y,z), reward: [-0.12655366  0.05807498  9.9340974 ] 115.467073109\n",
      "positions (x,y,z), reward: [-1.85513454  0.16797809  5.3727686 ] 106.78637049\n",
      "positions (x,y,z), reward: [-1.98616844  0.13473072  4.49394263] 103.974845866\n",
      "Episode =  281, score = 222.417 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.24022693 -0.03170782  9.99630673] 119.765507326\n",
      "positions (x,y,z), reward: [  6.61287476e-01  -1.84596239e-03   9.84624783e+00] 112.851206745\n",
      "positions (x,y,z), reward: [ 2.21463373  0.69835072  7.97828895] 92.3827851647\n",
      "Episode =  282, score = 212.564 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.77912425  0.6912103   9.68316264] 120.134295984\n",
      "positions (x,y,z), reward: [ 1.07678934  1.21596635  8.8968761 ] 119.213896023\n",
      "positions (x,y,z), reward: [ 1.37946248  1.9501029   7.43148572] 105.510600767\n",
      "positions (x,y,z), reward: [ 1.63571411  2.26426101  6.2365445 ] 103.262764845\n",
      "positions (x,y,z), reward: [ 3.2926295   3.13351951  0.13756934] 88.9312533616\n",
      "Episode =  283, score = 219.593 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.09904018  0.24321655  9.61802246] 116.699388937\n",
      "positions (x,y,z), reward: [-0.11941046  0.34801587  9.45437856] 117.052085829\n",
      "positions (x,y,z), reward: [-0.09309058  0.57555255  8.64284962] 119.94720839\n",
      "positions (x,y,z), reward: [-0.01142714  0.88106028  7.12750885] 116.927141749\n",
      "positions (x,y,z), reward: [ 0.16002869  1.02196025  5.35057865] 109.29858474\n",
      "positions (x,y,z), reward: [ 0.32792074  1.00231856  4.45437583] 107.575499795\n",
      "Episode =  284, score = 226.678 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.23897922  0.72961448  7.57858327] 111.011628526\n",
      "positions (x,y,z), reward: [ 1.87969584  1.10217445  5.80713604] 106.851434449\n",
      "Episode =  285, score = 220.749 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.78165352e-01  -1.00864581e-03   9.88080722e+00] 117.085574502\n",
      "positions (x,y,z), reward: [-0.34366009  0.00998273  9.69926567] 116.91856191\n",
      "positions (x,y,z), reward: [-0.94437816  0.29441356  7.83883905] 113.614135976\n",
      "Episode =  286, score = 225.794 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.27727633 -0.07201585  9.44532046] 108.96624155\n",
      "positions (x,y,z), reward: [-0.6900929  -0.1710316   8.64862131] 110.352066781\n",
      "positions (x,y,z), reward: [-0.74194613 -0.1475965   8.44090531] 111.693017053\n",
      "positions (x,y,z), reward: [-0.78234181  0.14419679  5.95291534] 113.420411099\n",
      "positions (x,y,z), reward: [-0.69393961  0.27410869  4.45410695] 109.783927291\n",
      "Episode =  287, score = 224.354 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.08797049  0.40099856  8.207984  ] 114.994093198\n",
      "Episode =  288, score = 225.356 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -6.59165629e-02   8.74540379e-03   9.96595190e+00] 116.623454581\n",
      "positions (x,y,z), reward: [-0.33620568 -0.0747003   9.73003957] 112.403843006\n",
      "positions (x,y,z), reward: [-0.38116885 -0.06906257  9.67999759] 112.288708753\n",
      "positions (x,y,z), reward: [-0.43947279 -0.03889691  9.0506936 ] 111.224025531\n",
      "positions (x,y,z), reward: [-0.44774258 -0.06165413  8.96048722] 110.713039478\n",
      "positions (x,y,z), reward: [-0.3772969  -0.85243266  3.05039352] 106.487406909\n",
      "Episode =  289, score = 222.081 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.02389602 -0.03989507  9.80534422] 116.747448661\n",
      "positions (x,y,z), reward: [ 0.08768871 -1.24528066  5.37086532] 105.61354656\n",
      "positions (x,y,z), reward: [ 0.08310678 -1.42590861  4.29319547] 102.389835586\n",
      "positions (x,y,z), reward: [ 0.15574832 -1.63859806  2.10210808] 94.6749076564\n",
      "positions (x,y,z), reward: [ 0.34731378 -1.86019222  0.13017301] 90.6969022104\n",
      "Episode =  290, score = 216.559 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.66817916 -0.78177861  8.17948109] 107.626306989\n",
      "positions (x,y,z), reward: [ 0.82048354 -0.91232873  7.73321366] 108.902122328\n",
      "positions (x,y,z), reward: [ 2.40584335 -2.44195801  1.80989092] 98.3311375233\n",
      "Episode =  291, score = 216.384 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.2247441   0.01974959  9.79247176] 112.274252338\n",
      "positions (x,y,z), reward: [ 1.19947658 -0.24685769  8.20516896] 107.042213644\n",
      "positions (x,y,z), reward: [ 1.44072655 -0.53465576  4.45631809] 102.598413479\n",
      "Episode =  292, score = 218.281 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.36273006  0.37124571  9.43362202] 112.388329102\n",
      "positions (x,y,z), reward: [-0.40780048  0.369253    9.16662527] 111.65279568\n",
      "positions (x,y,z), reward: [-1.804534    0.53846631  4.99474941] 108.947239999\n",
      "Episode =  293, score = 224.268 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.11295915  0.21793988  9.40442772] 103.821581353\n",
      "positions (x,y,z), reward: [ 2.464824    0.40929633  8.06383779] 113.172167851\n",
      "positions (x,y,z), reward: [ 6.01344815  1.30350801  1.2721935 ] 94.6150380188\n",
      "Episode =  294, score = 212.350 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.09149773  0.18456328  9.88835941] 112.741931988\n",
      "positions (x,y,z), reward: [ 0.68260081  0.37404377  9.81793134] 128.521459579\n",
      "positions (x,y,z), reward: [ 1.18302051  0.56147819  9.81885137] 120.435356986\n",
      "positions (x,y,z), reward: [ 3.48103604  1.09721772  5.33937359] 99.0866595785\n",
      "positions (x,y,z), reward: [ 4.43659265  1.20759251  1.48078335] 94.5987601428\n",
      "Episode =  295, score = 223.759 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.14026697 -0.05454795  9.88371295] 108.982637994\n",
      "positions (x,y,z), reward: [-0.14346296 -0.12338736  9.81202298] 111.553747071\n",
      "positions (x,y,z), reward: [-0.61548491 -0.42235351  7.47612591] 111.561842743\n",
      "Episode =  296, score = 225.979 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  5.48995541e-02  -5.10849396e-03   1.00188023e+01] 135.046527544\n",
      "positions (x,y,z), reward: [-0.72610728 -0.14756403  8.1386116 ] 119.612452388\n",
      "positions (x,y,z), reward: [-2.38445346 -0.38620185  5.22230179] 110.386589301\n",
      "Episode =  297, score = 229.349 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.82118389  0.35587454  9.87632998] 119.825549688\n",
      "positions (x,y,z), reward: [ 5.02279066  2.00337049  7.14596277] 101.560732932\n",
      "positions (x,y,z), reward: [ 6.42923501  2.65606035  5.73272821] 92.153481454\n",
      "positions (x,y,z), reward: [ 8.29771387  3.52851969  3.29894962] 97.3101277899\n",
      "Episode =  298, score = 215.112 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.91082246e-02   9.33937139e-03   9.94046928e+00] 113.804187597\n",
      "positions (x,y,z), reward: [  3.79705898e-01   4.84215424e-03   9.75478429e+00] 113.172850135\n",
      "positions (x,y,z), reward: [ 0.79081381 -0.1930179   9.38116462] 114.096314885\n",
      "positions (x,y,z), reward: [ 1.78860071 -0.4757941   3.32617086] 104.717687772\n",
      "Episode =  299, score = 224.589 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.3582281  -0.24556946  7.33534519] 107.528133967\n",
      "positions (x,y,z), reward: [ 1.41339716 -0.2827772   7.03220813] 103.070604369\n",
      "Episode =  300, score = 214.739 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.44341285e-03   1.55388736e-04   1.00054637e+01] 145.664961922\n",
      "positions (x,y,z), reward: [ 2.02160691  0.94148634  8.60687501] 114.123034788\n",
      "positions (x,y,z), reward: [ 2.96741714  1.34937877  7.10761118] 106.30568515\n",
      "positions (x,y,z), reward: [ 3.31838216  1.51079163  6.51282534] 103.321479825\n",
      "positions (x,y,z), reward: [ 4.79698092  2.09741196  3.91103507] 98.2920026081\n",
      "Episode =  301, score = 223.252 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.16364551 -0.47492572  9.17707625] 111.993068635\n",
      "positions (x,y,z), reward: [ 0.69361087 -0.80060092  6.90142557] 106.086601385\n",
      "positions (x,y,z), reward: [ 1.47835941 -1.21021038  5.25903607] 102.506709413\n",
      "Episode =  302, score = 217.643 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.48569547e-02  -1.54567690e-03   9.93878504e+00] 118.550325219\n",
      "positions (x,y,z), reward: [-0.44282204  0.27136577  7.36468096] 113.504051653\n",
      "positions (x,y,z), reward: [-0.78917334  0.92776892  0.53802995] 90.5042408954\n",
      "Episode =  303, score = 216.340 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.62986898  0.248724    9.52397688] 120.267163145\n",
      "positions (x,y,z), reward: [ 3.94784533  0.83384889  4.35323045] 101.844145151\n",
      "positions (x,y,z), reward: [ 4.61884992  0.88992007  3.08852405] 89.637239827\n",
      "Episode =  304, score = 214.297 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.51059261  0.19270183  8.87920524] 115.971089455\n",
      "positions (x,y,z), reward: [ 4.24373329  0.98898386  5.09550921] 96.872210669\n",
      "Episode =  305, score = 216.708 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  7.44123285e-03  -4.21764957e-03   9.94089923e+00] 122.155138143\n",
      "positions (x,y,z), reward: [-0.7115882   0.36660138  4.25964749] 108.722635578\n",
      "Episode =  306, score = 227.132 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.59668269e-02   6.72770576e-03   1.00155099e+01] 134.465518952\n",
      "positions (x,y,z), reward: [ 1.58040239  1.97703511  4.86297197] 101.88291757\n",
      "positions (x,y,z), reward: [ 1.72004121  2.2595194   3.90609707] 94.9185015072\n",
      "Episode =  308, score = 220.020 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00112562] 146.733930479\n",
      "positions (x,y,z), reward: [  5.74599057e-02   3.65827049e-03   1.00457999e+01] 134.881910947\n",
      "positions (x,y,z), reward: [ 0.07334893 -0.28783001  9.07736433] 113.16343679\n",
      "positions (x,y,z), reward: [ 0.11208662 -0.29755213  8.96336352] 112.887295853\n",
      "positions (x,y,z), reward: [ 0.2692834  -0.33640279  8.59379239] 113.024380015\n",
      "Episode =  309, score = 224.628 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.06835125 -0.06266477  8.05167846] 116.802179628\n",
      "positions (x,y,z), reward: [ 0.03880343 -0.01903047  7.03683526] 115.39171826\n",
      "positions (x,y,z), reward: [ 0.03512827 -0.01101392  6.88138388] 115.366658513\n",
      "positions (x,y,z), reward: [-0.03192139  0.01169421  5.89970887] 113.724109225\n",
      "Episode =  310, score = 225.195 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.54106583 -2.70730199  6.97736082] 108.383432712\n",
      "positions (x,y,z), reward: [ 2.70913726 -4.4904929   2.70977633] 93.4191350751\n",
      "positions (x,y,z), reward: [ 3.15447554 -5.04203367  0.97901434] 91.3992817762\n",
      "positions (x,y,z), reward: [ 3.47682591 -5.44900757  0.        ] 89.5776607843\n",
      "Episode =  311, score = 209.953 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.34261332e-02  -5.09374707e-04   9.99719890e+00] 126.491160024\n",
      "positions (x,y,z), reward: [ -2.90672629e-02  -1.90382743e-03   9.97926100e+00] 123.499124175\n",
      "positions (x,y,z), reward: [-0.12657504 -0.05063945  9.68309843] 109.116884394\n",
      "positions (x,y,z), reward: [-0.43304705 -0.76293281  8.25298392] 114.749525963\n",
      "positions (x,y,z), reward: [-0.72978814 -1.02882478  7.34767988] 113.469527124\n",
      "positions (x,y,z), reward: [-1.73372834 -2.10042541  3.54760294] 104.204792514\n",
      "Episode =  312, score = 220.781 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.05027671  -0.03080026  10.07050411] 137.254210566\n",
      "positions (x,y,z), reward: [-0.13589485 -0.2474679   9.80315933] 127.387440957\n",
      "Episode =  313, score = 237.201 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.05038025 -0.26487127  7.57013703] 112.606233419\n",
      "positions (x,y,z), reward: [-0.03964168  0.67223335  4.04749417] 108.634298758\n",
      "positions (x,y,z), reward: [-0.13722534  1.57587315  0.61123386] 100.128871599\n",
      "Episode =  314, score = 223.040 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  9.77635221e-06   5.66306429e-03   1.00182681e+01] 122.98337347\n",
      "positions (x,y,z), reward: [-0.9799111  -1.10551645  8.87203992] 112.554700554\n",
      "Episode =  315, score = 225.231 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.81446294e-03   2.62062091e-03   1.00089179e+01] 119.335420436\n",
      "positions (x,y,z), reward: [-0.99418677 -2.20468942  3.92849952] 106.961794724\n",
      "Episode =  316, score = 232.624 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.50062546e-03   8.55454189e-03   1.00140007e+01] 135.977354301\n",
      "positions (x,y,z), reward: [ 0.38950345  0.01413762  9.75838078] 111.10318041\n",
      "Episode =  318, score = 218.600 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.05632287   0.0173127   10.03880725] 137.840023511\n",
      "Episode =  319, score = 227.882 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.12489035 -0.16699704  9.73887957] 114.394822158\n",
      "positions (x,y,z), reward: [ 0.18953307 -0.97147881  8.37582626] 111.178671903\n",
      "positions (x,y,z), reward: [ 3.13176566 -1.06586423  1.26709019] 90.4680803247\n",
      "Episode =  321, score = 225.952 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.37158337e-03   1.65023634e-04   1.00036828e+01] 144.235179902\n",
      "positions (x,y,z), reward: [ 0.65331041  0.49747786  8.09122793] 113.829991449\n",
      "positions (x,y,z), reward: [ 0.74869175  0.2748727   4.83935122] 110.962951054\n",
      "positions (x,y,z), reward: [ 0.74713446  0.26531926  4.63503832] 110.584183089\n",
      "Episode =  322, score = 225.860 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.07315851 -0.12644912  9.69990822] 108.473912778\n",
      "positions (x,y,z), reward: [-0.44761978 -0.77532428  7.79286902] 111.826455384\n",
      "positions (x,y,z), reward: [-0.48598    -0.8437985   7.18864525] 113.626724132\n",
      "positions (x,y,z), reward: [-0.48377704 -0.87681484  6.7206159 ] 113.960657261\n",
      "positions (x,y,z), reward: [-0.46560487 -0.89028008  6.40058655] 113.945470268\n",
      "Episode =  323, score = 222.186 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  7.10144354e-03  -5.61559455e-03   9.98088346e+00] 126.385437289\n",
      "positions (x,y,z), reward: [ 0.02565483 -0.0144111   9.91977844] 121.611325135\n",
      "positions (x,y,z), reward: [ 0.04508285 -0.01020477  9.89118673] 120.420699724\n",
      "positions (x,y,z), reward: [ 0.66396919  0.62063597  9.27299611] 115.490855883\n",
      "positions (x,y,z), reward: [ 1.74212035  1.36743241  7.79190762] 113.878634061\n",
      "positions (x,y,z), reward: [ 3.0778249   2.80825597  3.21752687] 101.559302858\n",
      "positions (x,y,z), reward: [ 3.31340747  3.21508619  1.62139412] 98.7409469511\n",
      "Episode =  324, score = 219.706 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.15868565 -0.05241277  9.85841394] 109.732324841\n",
      "positions (x,y,z), reward: [-0.14971704 -0.25177998  9.44232456] 102.335976239\n",
      "positions (x,y,z), reward: [-0.56217644 -0.85079005  7.90569451] 103.566248154\n",
      "positions (x,y,z), reward: [-0.66650793 -0.93038959  7.65331478] 103.539136919\n",
      "positions (x,y,z), reward: [-0.82500996 -1.18299324  6.68683828] 100.687487514\n",
      "positions (x,y,z), reward: [-1.06786038 -1.61574737  4.77053245] 105.693520903\n",
      "positions (x,y,z), reward: [-1.24535599 -1.85163082  3.38659465] 103.589073084\n",
      "Episode =  325, score = 214.000 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.86460508  2.25856602  8.65229857] 113.357740166\n",
      "positions (x,y,z), reward: [ 3.21460281  3.71059888  5.42262578] 95.870036639\n",
      "positions (x,y,z), reward: [ 3.3566001   3.81398056  5.02646823] 91.770767565\n",
      "positions (x,y,z), reward: [ 3.77054106  4.08796832  3.70480575] 90.611608691\n",
      "positions (x,y,z), reward: [ 4.26681421  4.39115255  1.9910658 ] 81.8297954502\n",
      "Episode =  326, score = 224.872 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.21319714e-03   1.03362341e-02   1.00073001e+01] 121.187452853\n",
      "positions (x,y,z), reward: [-0.40023753 -0.52364283  7.68706993] 111.721498969\n",
      "positions (x,y,z), reward: [-0.39840028 -0.54049201  7.41957481] 111.781397977\n",
      "positions (x,y,z), reward: [-0.37726081 -0.56102422  7.11978195] 112.465488575\n",
      "positions (x,y,z), reward: [-0.26173179 -0.92706888  4.43265864] 106.24771255\n",
      "positions (x,y,z), reward: [-0.20133364 -1.02209335  3.37038471] 102.413660478\n",
      "Episode =  327, score = 219.790 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.13888432   0.05620146  10.0009353 ] 126.126920873\n",
      "positions (x,y,z), reward: [ 0.21483009  0.09988871  9.95888772] 126.564762563\n",
      "positions (x,y,z), reward: [ 2.3573821   0.32243212  6.86148333] 100.226809012\n",
      "positions (x,y,z), reward: [ 4.96832778  0.52116473  1.97047788] 97.895194605\n",
      "Episode =  328, score = 219.558 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04763607  0.31606973  8.38654922] 108.935053161\n",
      "positions (x,y,z), reward: [ 2.13876426  1.00894013  2.73115847] 95.9557238753\n",
      "Episode =  329, score = 214.276 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.28595855  0.45963637  8.39982419] 110.954454015\n",
      "positions (x,y,z), reward: [-0.44557887  1.31633188  1.58225973] 98.7217538961\n",
      "Episode =  330, score = 223.092 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -4.17359775e-02   4.85974009e-03   1.00141084e+01] 144.082126596\n",
      "positions (x,y,z), reward: [ 1.27418491  1.00294528  8.45395157] 109.660575091\n",
      "positions (x,y,z), reward: [ 1.60302781  1.07980997  8.13706288] 110.626710788\n",
      "positions (x,y,z), reward: [ 4.02950645  1.38702956  5.84378788] 103.000024122\n",
      "positions (x,y,z), reward: [ 6.8095706   1.83628212  2.80134014] 83.7082535426\n",
      "Episode =  331, score = 212.178 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.18513475 -0.0689012   9.67121723] 106.802848655\n",
      "positions (x,y,z), reward: [-0.37314411 -0.81786781  7.3015541 ] 106.336165669\n",
      "positions (x,y,z), reward: [-0.37804807 -1.01853218  6.80201021] 105.65283949\n",
      "positions (x,y,z), reward: [-0.39956637 -1.3245213   5.91632179] 104.880786887\n",
      "positions (x,y,z), reward: [ 0.1885875  -2.70976892  0.03139615] 90.9694364631\n",
      "Episode =  332, score = 214.136 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.30731829 -0.3553709   9.27611401] 119.73500393\n",
      "positions (x,y,z), reward: [-0.3171328  -0.38443573  9.18668345] 120.014262398\n",
      "positions (x,y,z), reward: [-0.38716973 -0.50714525  8.80287151] 114.994249183\n",
      "positions (x,y,z), reward: [-2.41791679 -2.45796015  0.        ] 92.482621447\n",
      "Episode =  333, score = 224.818 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.09348151 -0.03108641  9.83134498] 116.106929409\n",
      "positions (x,y,z), reward: [-0.13322451 -0.04192582  9.79235571] 115.555274333\n",
      "positions (x,y,z), reward: [-0.26206976 -0.04035547  9.64681175] 115.350149625\n",
      "positions (x,y,z), reward: [-0.521535    0.14201373  9.18075486] 114.30626059\n",
      "positions (x,y,z), reward: [-0.55986984  0.54325595  8.30915838] 114.75844426\n",
      "positions (x,y,z), reward: [-0.5328895   0.60206119  8.1661549 ] 114.708437472\n",
      "positions (x,y,z), reward: [ 0.04742079  0.99110838  6.01011996] 109.927990681\n",
      "Episode =  334, score = 226.276 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.27685257  0.82962688  8.13994872] 112.409372764\n",
      "positions (x,y,z), reward: [-0.10751948  1.61895957  5.33901116] 109.265470034\n",
      "Episode =  335, score = 221.965 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.11845951 -0.02418869  9.73253498] 107.502295029\n",
      "positions (x,y,z), reward: [ 0.7244073  -0.99129987  7.60755647] 103.275926344\n",
      "Episode =  336, score = 211.066 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.32914598e-01  -3.18078743e-03   9.92224343e+00] 112.413069414\n",
      "positions (x,y,z), reward: [ -1.59189134e-01  -8.72457636e-03   9.88899650e+00] 110.902394745\n",
      "positions (x,y,z), reward: [-1.79316396 -1.39071954  1.78111829] 101.950168227\n",
      "Episode =  337, score = 219.474 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.09560779  0.11774074  9.77727553] 122.505379931\n",
      "positions (x,y,z), reward: [ 0.09433282  0.4737892   9.00597642] 123.337529036\n",
      "Episode =  338, score = 222.812 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  4.62888626e-02   9.01880488e-03   1.00331157e+01] 151.277049024\n",
      "positions (x,y,z), reward: [-0.94892738  0.97944566  8.19864555] 118.498133053\n",
      "Episode =  339, score = 240.079 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 3.12401737 -1.03678989  6.05506545] 98.1665910716\n",
      "Episode =  340, score = 202.467 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.50875441 -0.60128434  8.48830869] 113.545921904\n",
      "positions (x,y,z), reward: [ 0.54697432 -0.75132829  8.1783008 ] 113.551405809\n",
      "positions (x,y,z), reward: [ 0.34995114 -2.09712156  4.03482877] 107.820290925\n",
      "Episode =  341, score = 221.690 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.21946827  0.08548647  9.70305047] 115.021667886\n",
      "positions (x,y,z), reward: [-0.32371774  0.11676662  9.61449214] 114.336291237\n",
      "positions (x,y,z), reward: [-2.44723142  1.37635545  4.16670441] 107.745123062\n",
      "positions (x,y,z), reward: [-4.01827599  1.71761     0.48904133] 96.7846331216\n",
      "Episode =  342, score = 226.765 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.07773005 -0.93031463  5.4682981 ] 107.449026714\n",
      "positions (x,y,z), reward: [-0.48840345 -1.63020764  1.33051865] 95.7510482183\n",
      "Episode =  343, score = 219.365 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -4.00364597e-02   6.15019086e-03   1.00021777e+01] 133.035368802\n",
      "positions (x,y,z), reward: [-2.09154342 -0.67337988  5.41217351] 108.747195273\n",
      "positions (x,y,z), reward: [-2.69089687 -0.52248479  0.85708163] 97.6455456134\n",
      "Episode =  344, score = 220.823 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.84685032 -1.74655728  4.49890208] 104.410691604\n",
      "positions (x,y,z), reward: [ 1.52296613 -2.2655223   1.84807599] 96.2464698535\n",
      "positions (x,y,z), reward: [ 1.8071222  -2.47330351  0.68271676] 93.3812091684\n",
      "Episode =  345, score = 215.590 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04880834 -0.53691028  9.13025335] 112.325973918\n",
      "positions (x,y,z), reward: [ 1.42592441 -1.56378997  3.56181757] 102.739648497\n",
      "Episode =  346, score = 221.953 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.16372039 -0.19789876  9.18184875] 116.657824916\n",
      "positions (x,y,z), reward: [-0.27842248 -0.26888283  8.38546228] 115.740624093\n",
      "positions (x,y,z), reward: [-0.57451287 -0.41224614  5.28750522] 106.112400539\n",
      "positions (x,y,z), reward: [-0.24108239 -0.34813169  3.59287396] 99.9832152831\n",
      "Episode =  347, score = 218.754 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.03323319  0.52445166  6.12773009] 108.073090359\n",
      "positions (x,y,z), reward: [ 1.5903683   0.77990718  1.55089871] 101.690165258\n",
      "Episode =  348, score = 222.832 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.14765640e-01   5.72774056e-04   9.72665923e+00] 108.777981435\n",
      "positions (x,y,z), reward: [ 0.21429378  0.03789902  9.61941552] 109.632712476\n",
      "positions (x,y,z), reward: [ 0.70017792  0.12263558  8.92629196] 120.484379441\n",
      "positions (x,y,z), reward: [ 0.95897249  0.19417123  8.09566596] 110.826189692\n",
      "positions (x,y,z), reward: [ 1.02339828  0.23253483  7.6615447 ] 110.824447656\n",
      "Episode =  349, score = 219.991 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.13159936  0.51229825  7.4355342 ] 117.085731989\n",
      "Episode =  350, score = 226.548 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.12239066  0.48859754  8.29654946] 119.962608971\n",
      "positions (x,y,z), reward: [-1.1575272   0.4978303   8.18857728] 119.993713374\n",
      "Episode =  351, score = 221.091 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.0136003  -0.05161821  9.79946364] 119.503452802\n",
      "positions (x,y,z), reward: [-0.27413901 -0.12087634  9.38260968] 116.285411356\n",
      "positions (x,y,z), reward: [-0.48895409 -0.10225727  8.36342848] 116.414037484\n",
      "positions (x,y,z), reward: [-0.5083106  -0.15610521  7.94634495] 114.887440862\n",
      "positions (x,y,z), reward: [-1.17671286 -0.43248727  4.77566105] 110.744584743\n",
      "Episode =  352, score = 227.835 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.13018453e-03   1.21725015e-02   9.91694386e+00] 122.379933799\n",
      "positions (x,y,z), reward: [ 0.90837744 -0.23938077  9.35261419] 111.988841099\n",
      "positions (x,y,z), reward: [ 1.15685229 -0.45807976  9.1813799 ] 106.360796974\n",
      "positions (x,y,z), reward: [ 2.60540103 -1.75253737  7.56363194] 91.682931124\n",
      "positions (x,y,z), reward: [ 3.03039239 -2.19839066  6.89315647] 88.4407328987\n",
      "positions (x,y,z), reward: [ 3.36812932 -2.49968454  6.38358342] 84.8724831001\n",
      "positions (x,y,z), reward: [ 4.32364071 -3.20486297  5.07357243] 91.2658821128\n",
      "positions (x,y,z), reward: [ 5.09226836 -3.83803447  3.82618389] 87.2566616922\n",
      "positions (x,y,z), reward: [ 5.72675849 -4.36556013  2.68198764] 77.1612627266\n",
      "positions (x,y,z), reward: [ 7.12785698 -5.31028267  0.39432249] 74.0582920798\n",
      "Episode =  353, score = 196.040 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.95028827  0.58637645  1.3954171 ] 101.192074409\n",
      "Episode =  354, score = 232.237 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.         0.        10.001374] 146.833338394\n",
      "positions (x,y,z), reward: [ -1.01531327e-02  -8.36377049e-03   9.34973615e+00] 120.91053187\n",
      "Episode =  355, score = 221.168 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.82633580e-03  -7.29017244e-03   9.85090840e+00] 117.179258158\n",
      "positions (x,y,z), reward: [ 0.34722405 -0.37695038  1.95095392] 99.0115198549\n",
      "Episode =  356, score = 224.273 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.65488944  0.62088691  4.73657342] 110.384175014\n",
      "Episode =  357, score = 227.307 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.50682488e-03   4.99335579e-04   1.00067706e+01] 150.712820419\n",
      "positions (x,y,z), reward: [ 0.00926386  0.23485196  8.93534495] 115.837186829\n",
      "positions (x,y,z), reward: [ 0.59210061  0.3202156   8.03039282] 110.060233658\n",
      "positions (x,y,z), reward: [ 1.16661533  0.34554768  7.36299071] 108.549241844\n",
      "positions (x,y,z), reward: [ 3.38461415  0.5217971   3.21461506] 99.0220643536\n",
      "Episode =  358, score = 221.373 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.66754954  0.41797756  8.21684035] 116.81706713\n",
      "Episode =  359, score = 225.161 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.07395105  0.01112042  9.99666105] 137.098460972\n",
      "positions (x,y,z), reward: [-0.73147392 -0.06853147  9.52355229] 121.810703521\n",
      "positions (x,y,z), reward: [-0.80874239 -0.07205093  9.44732656] 121.497124201\n",
      "positions (x,y,z), reward: [-2.61484321 -0.26283172  6.7071707 ] 110.464833601\n",
      "positions (x,y,z), reward: [-3.94208586 -0.35119979  3.85620076] 99.5746805132\n",
      "Episode =  360, score = 227.813 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.98813789e-02   9.86284740e-04   9.99904567e+00] 136.961656195\n",
      "positions (x,y,z), reward: [ 0.04808422  0.55476936  7.95367834] 108.775959397\n",
      "Episode =  361, score = 226.678 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.24834058 -0.92789814  9.20798598] 119.127067533\n",
      "positions (x,y,z), reward: [ 0.63873736 -2.1450621   6.99340955] 107.251475238\n",
      "positions (x,y,z), reward: [ 1.94130416 -3.82007556  0.58250087] 80.1980707857\n",
      "Episode =  362, score = 217.783 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.57444408e-03   9.72861990e-04   1.00039637e+01] 145.736065971\n",
      "positions (x,y,z), reward: [ 0.19660806  0.14145115  9.80492143] 118.288640395\n",
      "positions (x,y,z), reward: [ 1.3932895   0.98649965  8.81210952] 118.771453299\n",
      "positions (x,y,z), reward: [ 5.03691987  3.43437283  6.07710279] 98.0982043202\n",
      "positions (x,y,z), reward: [ 5.44940553  3.73003471  5.66565577] 98.3414506417\n",
      "positions (x,y,z), reward: [ 5.72561387  3.9204596   5.37859101] 98.8612795882\n",
      "positions (x,y,z), reward: [ 7.44005519  5.2191301   3.17821066] 94.711145181\n",
      "positions (x,y,z), reward: [ 7.95243627  5.60981574  2.37048526] 92.4055051476\n",
      "positions (x,y,z), reward: [ 8.37382336  5.89899557  1.72588348] 89.4505561063\n",
      "Episode =  363, score = 212.764 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.05465062e-02  -9.96810734e-04   9.99442246e+00] 127.491861491\n",
      "positions (x,y,z), reward: [ 0.05457619 -1.03028701  7.97009738] 113.210480408\n",
      "positions (x,y,z), reward: [-0.12653227 -1.63132524  5.57588669] 105.587024072\n",
      "positions (x,y,z), reward: [ 0.82185197 -2.95389305  0.        ] 88.4577604524\n",
      "Episode =  364, score = 213.911 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.06905196 -0.04805281  9.73126561] 107.552653892\n",
      "positions (x,y,z), reward: [ 0.09831888 -0.38477008  8.61133291] 106.812080529\n",
      "positions (x,y,z), reward: [ 1.35050584 -0.91321893  3.46982261] 105.113390217\n",
      "Episode =  365, score = 220.289 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.04162379e-01  -2.71285306e-03   9.61076147e+00] 109.94233976\n",
      "positions (x,y,z), reward: [ 0.8230519  -0.08021127  8.76643368] 114.419247054\n",
      "positions (x,y,z), reward: [ 1.04596451 -0.1262462   8.49250431] 111.586742116\n",
      "positions (x,y,z), reward: [ 4.21991577 -0.06532024  3.15960693] 97.3197634021\n",
      "positions (x,y,z), reward: [ 4.69122837 -0.08628232  1.51455545] 95.5641328867\n",
      "Episode =  366, score = 214.770 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.14714025  0.16830806  9.9359161 ] 117.745006836\n",
      "Episode =  367, score = 228.408 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.92378714e-03  -4.30433208e-04   9.99858155e+00] 129.710009883\n",
      "positions (x,y,z), reward: [ 0.09360544  0.61657254  9.31441552] 121.493613452\n",
      "positions (x,y,z), reward: [ 0.10893291  0.68960902  9.11917382] 122.259661155\n",
      "positions (x,y,z), reward: [ 0.14488517  0.84428808  8.67442713] 122.1872697\n",
      "positions (x,y,z), reward: [ 0.17765067  0.98542765  8.17795224] 119.652206995\n",
      "positions (x,y,z), reward: [ 0.19025013  1.16747018  7.31277139] 117.242464012\n",
      "positions (x,y,z), reward: [ 0.23811299  1.21462071  6.7976685 ] 115.302563389\n",
      "Episode =  368, score = 229.088 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.03033805  0.02892129  9.85127914] 119.104191966\n",
      "positions (x,y,z), reward: [-0.07299421  0.05880631  9.78034668] 118.72626311\n",
      "Episode =  369, score = 228.979 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.62410234 -0.40544501  3.97572839] 107.236281815\n",
      "positions (x,y,z), reward: [-1.99873412 -0.54142395  2.56608059] 104.222543789\n",
      "Episode =  370, score = 221.507 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.24742981 -1.16981012  6.69724437] 111.804372139\n",
      "Episode =  371, score = 220.579 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.03190977  0.22754094  9.44071451] 119.478554606\n",
      "positions (x,y,z), reward: [ 0.59474484  1.0403457   3.40318398] 99.6459116194\n",
      "Episode =  372, score = 223.151 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.24514131e-03  -5.21538964e-04   1.00014876e+01] 139.683661482\n",
      "positions (x,y,z), reward: [ 0.01665509 -0.01597183  9.95121935] 123.693113965\n",
      "positions (x,y,z), reward: [ 0.01409466 -0.02492094  9.92647914] 122.151979605\n",
      "positions (x,y,z), reward: [ 0.03352893 -0.09860232  9.8232859 ] 118.996949328\n",
      "positions (x,y,z), reward: [ 0.06635246 -0.19000223  9.73952792] 117.465535736\n",
      "Episode =  373, score = 214.099 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.45113949  0.54445184  9.05425127] 116.785523504\n",
      "positions (x,y,z), reward: [-0.34760211  0.56061951  8.78071969] 116.638057193\n",
      "positions (x,y,z), reward: [-0.33959444  0.56842256  8.64415691] 116.092325773\n",
      "positions (x,y,z), reward: [-0.32555665  0.65062305  8.20475542] 114.557790027\n",
      "positions (x,y,z), reward: [-0.25198508  0.7107065   7.85201589] 116.459403002\n",
      "positions (x,y,z), reward: [-0.51515424  1.05595753  3.69280617] 108.370553227\n",
      "Episode =  374, score = 225.091 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.57373226e-02   6.57794738e-03   9.89851789e+00] 119.633651035\n",
      "positions (x,y,z), reward: [ 1.07619887  0.59166963  9.09701871] 119.668957768\n",
      "positions (x,y,z), reward: [ 1.4996659   0.64658496  8.47638021] 117.21794215\n",
      "positions (x,y,z), reward: [ 2.12024215  1.36805552  6.43806445] 111.20317359\n",
      "positions (x,y,z), reward: [ 3.54339363  3.54903444  0.62573326] 90.7534087573\n",
      "Episode =  375, score = 221.521 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.30688131 -0.09608709  8.18128603] 117.150453148\n",
      "positions (x,y,z), reward: [-0.04750288 -0.43362358  6.34566336] 111.055766869\n",
      "positions (x,y,z), reward: [-0.06136616 -0.46132313  6.15464819] 110.702091992\n",
      "positions (x,y,z), reward: [-0.19235565 -0.80005309  4.16459606] 106.744038493\n",
      "Episode =  376, score = 225.645 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.26992854  0.21773225  6.92621055] 110.234794252\n",
      "positions (x,y,z), reward: [ -3.32594804e+00  -1.85456307e-03   0.00000000e+00] 97.2232739885\n",
      "Episode =  377, score = 224.735 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.25505668  0.12196921  9.76640161] 118.663045853\n",
      "positions (x,y,z), reward: [ 0.45220058  0.13533914  9.61476696] 116.93071191\n",
      "positions (x,y,z), reward: [ 1.01897467  0.21207916  9.08076542] 111.060106836\n",
      "positions (x,y,z), reward: [ 1.07995501  0.22078057  8.99190924] 111.998498506\n",
      "positions (x,y,z), reward: [ 1.72081182  0.23853971  7.7401487 ] 105.685476125\n",
      "positions (x,y,z), reward: [ 3.01606256  0.22055506  3.69522296] 99.9876006801\n",
      "Episode =  378, score = 222.564 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.11268267  0.10634812  9.40268963] 112.264447558\n",
      "positions (x,y,z), reward: [ 0.4654577   0.8879676   7.34765594] 111.147380965\n",
      "positions (x,y,z), reward: [ 0.63986479  2.2052479   3.30017021] 106.31597011\n",
      "positions (x,y,z), reward: [ 0.67888763  2.90545376  0.60159041] 99.7698035845\n",
      "Episode =  379, score = 221.618 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.46141439 -0.34312728  8.4543992 ] 104.214757472\n",
      "positions (x,y,z), reward: [ 2.17477972 -1.56768039  1.51893018] 97.474895436\n",
      "Episode =  380, score = 213.502 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.10153705  0.03732795  9.79628229] 122.465366887\n",
      "positions (x,y,z), reward: [ 0.36544979  0.02663616  7.88383052] 114.175774375\n",
      "positions (x,y,z), reward: [  5.60907703e-01  -2.62818413e-03   6.73341875e+00] 107.841820393\n",
      "positions (x,y,z), reward: [ 1.30998471 -0.26533293  0.22882708] 92.10331003\n",
      "Episode =  381, score = 225.286 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.66016457e-03  -1.39455467e-05   9.99976459e+00] 139.74716012\n",
      "positions (x,y,z), reward: [ 3.29612737  1.85129835  3.04910259] 88.8138276997\n",
      "Episode =  382, score = 213.316 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.06372793  0.02333373  9.93316493] 120.365451409\n",
      "positions (x,y,z), reward: [ 0.0650052   0.03492483  9.9157351 ] 119.66808009\n",
      "positions (x,y,z), reward: [ 0.03480663  0.05460814  9.8367772 ] 118.30786372\n",
      "positions (x,y,z), reward: [-0.10793848  0.17216261  9.55547331] 117.351395088\n",
      "Episode =  383, score = 225.410 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.61875391e-03   2.36103910e-04   1.00045260e+01] 145.828317936\n",
      "positions (x,y,z), reward: [ 1.78576435  0.31642264  9.67333391] 110.723233414\n",
      "positions (x,y,z), reward: [ 6.16605343  0.90420697  7.70005853] 98.0178494981\n",
      "Episode =  384, score = 192.469 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.42577809  0.13599858  9.78040338] 113.456931515\n",
      "positions (x,y,z), reward: [-0.5452127   0.5598798   9.07811443] 121.470066516\n",
      "positions (x,y,z), reward: [-1.37554813  0.28441421  5.25703297] 112.451774036\n",
      "positions (x,y,z), reward: [-1.94760919  0.1157297   3.51405162] 108.593953341\n",
      "Episode =  385, score = 227.072 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.51189597  0.43310144  8.20328274] 112.784655978\n",
      "positions (x,y,z), reward: [ 2.30728963  0.47186912  6.87041444] 108.556048958\n",
      "positions (x,y,z), reward: [ 3.65306846  0.50787417  4.77178063] 103.484733362\n",
      "positions (x,y,z), reward: [ 5.4320938   0.55547846  1.12551361] 95.1676276021\n",
      "Episode =  387, score = 223.144 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00107473] 146.836891705\n",
      "positions (x,y,z), reward: [ 0.11865715  0.21741956  9.69059182] 121.025693176\n",
      "positions (x,y,z), reward: [ 0.13702839  0.32222529  9.48813088] 121.953776687\n",
      "positions (x,y,z), reward: [ 0.11607136  0.45764329  9.14630087] 122.460755721\n",
      "positions (x,y,z), reward: [-0.17099108  0.90776144  8.03002053] 121.652728498\n",
      "positions (x,y,z), reward: [-0.26529804  1.20680281  7.16950922] 116.179411771\n",
      "positions (x,y,z), reward: [-0.30950382  1.32716709  6.73081808] 111.929671446\n",
      "positions (x,y,z), reward: [-0.6226163   1.72809646  4.25043354] 105.423126843\n",
      "positions (x,y,z), reward: [-0.62824782  1.80586589  2.69129166] 97.5084801559\n",
      "Episode =  388, score = 227.164 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.50752324  0.24644112  9.53772381] 113.64310778\n",
      "positions (x,y,z), reward: [ 0.35070433  0.66828882  8.9209828 ] 121.77897467\n",
      "positions (x,y,z), reward: [ 2.15902078  1.05022695  7.98144513] 110.709741619\n",
      "positions (x,y,z), reward: [ 2.48934682  1.09718576  7.79836898] 99.6443553095\n",
      "positions (x,y,z), reward: [ 5.95423974  1.59149696  4.63300314] 91.6414694182\n",
      "positions (x,y,z), reward: [ 6.59367668  1.68691655  3.92011819] 90.5221874939\n",
      "Episode =  389, score = 211.058 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.27596952  0.14685944  9.97675542] 122.011773371\n",
      "positions (x,y,z), reward: [ 0.5071946   0.28910233  9.88132574] 122.694165597\n",
      "positions (x,y,z), reward: [ 0.75280081  1.04138317  9.30803344] 120.215252086\n",
      "positions (x,y,z), reward: [ 1.942273    2.07317969  6.38015325] 95.0798338753\n",
      "positions (x,y,z), reward: [ 3.56517452  2.44236112  2.79045899] 80.6593110493\n",
      "Episode =  390, score = 219.704 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.35029716 -0.14099796  8.40111954] 115.106696297\n",
      "positions (x,y,z), reward: [ 0.80705612 -0.18905839  6.85426627] 107.86559353\n",
      "positions (x,y,z), reward: [ 1.30704568 -0.19394546  5.5553482 ] 108.372446908\n",
      "positions (x,y,z), reward: [ 1.58735635 -0.17465417  4.59805555] 105.23620768\n",
      "Episode =  391, score = 221.124 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.47238044 -0.10996078  9.5809717 ] 116.113098069\n",
      "positions (x,y,z), reward: [ 1.10565297 -0.61659589  7.45407481] 112.934261212\n",
      "positions (x,y,z), reward: [ 1.24324812 -0.70997371  6.73261681] 108.242120064\n",
      "positions (x,y,z), reward: [ 1.39740625 -0.77182311  6.16751818] 107.584700985\n",
      "positions (x,y,z), reward: [ 1.61818757 -0.85286466  5.38789813] 103.805454096\n",
      "positions (x,y,z), reward: [ 2.35962682 -1.12055706  1.65334151] 99.058305014\n",
      "positions (x,y,z), reward: [ 2.45597568 -1.15701758  1.08980178] 97.3636899204\n",
      "positions (x,y,z), reward: [ 2.50471199 -1.17758285  0.7993137 ] 96.5837915474\n",
      "Episode =  392, score = 223.385 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 3.21498674  1.43376605  8.16005963] 105.962823469\n",
      "positions (x,y,z), reward: [ 3.65180131  1.60696986  7.65997089] 106.682419771\n",
      "positions (x,y,z), reward: [ 3.97474218  1.7364323   7.25018927] 101.067368785\n",
      "positions (x,y,z), reward: [ 4.81068269  2.06166144  6.12245088] 81.5199367283\n",
      "positions (x,y,z), reward: [ 5.78780208  2.33555812  4.80002442] 90.5221175412\n",
      "positions (x,y,z), reward: [ 7.87948547  3.04562634  0.53477381] 88.7350005391\n",
      "Episode =  393, score = 213.258 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.45901756  0.23899194  9.01282232] 115.936187885\n",
      "positions (x,y,z), reward: [ 2.27711056  0.70343852  7.591901  ] 100.233789726\n",
      "positions (x,y,z), reward: [ 2.56636486  0.78650136  6.96281305] 99.0094533938\n",
      "Episode =  394, score = 216.029 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.01505216 -0.81162848  9.11471979] 114.43908614\n",
      "positions (x,y,z), reward: [-0.11388308 -1.16848573  8.22052032] 116.658292939\n",
      "positions (x,y,z), reward: [ 0.04618851 -1.22061311  5.98513837] 107.912694976\n",
      "Episode =  395, score = 223.019 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.46375599 -0.18950883  9.5389964 ] 114.209363713\n",
      "positions (x,y,z), reward: [-1.42186242 -0.11936861  8.00165434] 110.528880701\n",
      "Episode =  396, score = 222.870 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.70027055 -1.67143873  7.06156843] 99.7123231967\n",
      "positions (x,y,z), reward: [ 2.90765844 -2.74047502  4.40185583] 91.6865946537\n",
      "positions (x,y,z), reward: [ 4.14829974 -3.56067279  1.5865213 ] 82.7586104481\n",
      "Episode =  397, score = 211.718 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00104599] 146.810216939\n",
      "positions (x,y,z), reward: [ 0.06362119  0.03265387  9.27777929] 121.415872059\n",
      "positions (x,y,z), reward: [ 0.282456    0.66948849  4.84939099] 106.133008297\n",
      "Episode =  398, score = 223.536 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 5.69452508  3.19649681  4.54005453] 87.4233494924\n",
      "Episode =  399, score = 214.736 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  6.12108347e-03   4.34078432e-03   1.00128583e+01] 154.384659397\n",
      "positions (x,y,z), reward: [  0.10541544   0.03253466  10.03675247] 134.140038283\n",
      "positions (x,y,z), reward: [ 1.55203248 -0.7716548   5.23479392] 103.923892235\n",
      "positions (x,y,z), reward: [ 2.21603069 -0.86481646  1.96079725] 100.078428461\n",
      "Episode =  400, score = 223.774 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -9.24513451e-03   3.63807238e-03   1.00297212e+01] 137.681269267\n",
      "positions (x,y,z), reward: [-0.01224282 -0.16431554  7.45237235] 116.107065737\n",
      "positions (x,y,z), reward: [ 0.08181376 -0.3545944   5.42804518] 108.734745738\n",
      "Episode =  401, score = 230.073 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.0512728  -0.03055371  9.76951964] 111.194879383\n",
      "positions (x,y,z), reward: [-0.15066759 -0.01143062  9.61140021] 110.546796248\n",
      "positions (x,y,z), reward: [ 1.08443548  0.24625658  6.33290053] 107.48880398\n",
      "positions (x,y,z), reward: [ 3.61871395  0.08424403  0.34003592] 92.8465995301\n",
      "Episode =  402, score = 216.687 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.88718754  1.06381167  7.94766257] 113.726572541\n",
      "positions (x,y,z), reward: [ 1.06090245  1.2265898   7.52047104] 113.503551\n",
      "positions (x,y,z), reward: [ 2.67393601  1.8649261   4.06535921] 100.778213383\n",
      "Episode =  403, score = 222.205 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.24472272e-03   2.25471187e-02   1.00289128e+01] 140.619463185\n",
      "positions (x,y,z), reward: [ -8.25242554e-03   2.89117983e-02   1.00325482e+01] 126.582812199\n",
      "positions (x,y,z), reward: [ 0.19269755  0.48353202  9.25369106] 114.449326823\n",
      "positions (x,y,z), reward: [-0.03708384  0.7805174   8.37402443] 116.67472054\n",
      "positions (x,y,z), reward: [-1.98834466  2.46466155  2.44539498] 100.56691197\n",
      "Episode =  404, score = 224.450 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00130572] 146.75851754\n",
      "positions (x,y,z), reward: [ 0.44913458  0.19781189  9.90616254] 122.718829796\n",
      "positions (x,y,z), reward: [ 0.68603638  0.28852825  9.75447002] 117.723098067\n",
      "positions (x,y,z), reward: [ 1.32702477  0.34022818  9.39298491] 113.384518971\n",
      "positions (x,y,z), reward: [ 3.6644785   0.78575041  5.74361207] 99.5925811713\n",
      "positions (x,y,z), reward: [ 4.63868969  0.92788401  3.85054842] 89.9265696418\n",
      "Episode =  405, score = 217.425 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.46167901 -0.22961703  6.12597721] 109.604442265\n",
      "positions (x,y,z), reward: [ 0.15051734 -0.16065244  4.11934463] 109.191594651\n",
      "positions (x,y,z), reward: [ 1.51416477 -0.2409248   0.89167516] 93.4506138\n",
      "Episode =  406, score = 219.193 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.01941902 -0.03980513  9.79400273] 116.325751027\n",
      "positions (x,y,z), reward: [ 0.34609996 -0.51109108  8.79158602] 110.353691762\n",
      "positions (x,y,z), reward: [ 0.75561602 -1.08015879  4.94897899] 103.392678243\n",
      "Episode =  407, score = 216.553 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.33907800e-02  -8.94750201e-04   9.99697705e+00] 126.291658486\n",
      "positions (x,y,z), reward: [ 1.09275016 -0.11832983  8.10361056] 107.25153958\n",
      "positions (x,y,z), reward: [ 1.68186762 -0.88336052  3.30727456] 101.463815938\n",
      "positions (x,y,z), reward: [ 1.82592157 -1.13462626  1.46113754] 96.7251119897\n",
      "Episode =  408, score = 216.261 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.32126484e-01   1.70481236e-04   7.35304253e+00] 116.515856569\n",
      "positions (x,y,z), reward: [-0.86733193  0.13862133  4.62895868] 107.793732837\n",
      "Episode =  409, score = 227.688 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.9383321   0.35974437  9.98562655] 119.972776318\n",
      "positions (x,y,z), reward: [ 1.37597146  0.56327804  9.85509443] 115.091281538\n",
      "positions (x,y,z), reward: [ 2.59827635  1.21545105  9.35013204] 104.110969673\n",
      "positions (x,y,z), reward: [ 6.95300697  4.38307258  5.28592531] 90.1224785401\n",
      "positions (x,y,z), reward: [ 7.12855652  4.49822236  5.07376797] 92.3679700277\n",
      "positions (x,y,z), reward: [ 9.04424452  6.01757979  2.19446343] 90.4014035044\n",
      "Episode =  410, score = 214.584 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.65826933 -1.2412053   9.36225928] 112.877155782\n",
      "positions (x,y,z), reward: [ 1.70974467 -1.5982158   7.70342527] 102.752210123\n",
      "positions (x,y,z), reward: [ 2.06676662 -1.68222232  6.83516559] 91.9848772877\n",
      "positions (x,y,z), reward: [ 4.15463883 -2.03590926  1.79845908] 92.909186235\n",
      "positions (x,y,z), reward: [ 4.42764086 -2.09517847  0.95604938] 90.2796591808\n",
      "positions (x,y,z), reward: [ 4.68999859 -2.15314155  0.09234612] 88.9914433208\n",
      "Episode =  411, score = 224.826 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.03277658  0.01197768  9.9941344 ] 118.64971039\n",
      "positions (x,y,z), reward: [-0.31684738 -0.12755535  9.74655892] 115.184789705\n",
      "positions (x,y,z), reward: [-1.07171904  0.28652192  5.63088055] 111.915253365\n",
      "positions (x,y,z), reward: [-1.29451557  0.41964311  4.37425062] 109.210250104\n",
      "positions (x,y,z), reward: [-1.43881767  0.50694762  3.47094147] 107.067920938\n",
      "positions (x,y,z), reward: [-1.75266629  0.69910276  1.25166877] 101.723065513\n",
      "positions (x,y,z), reward: [-1.8944877   0.79491275  0.18735632] 99.3078913335\n",
      "positions (x,y,z), reward: [-1.93108145  0.82074367  0.        ] 98.8232778582\n",
      "Episode =  412, score = 227.853 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.14524034  0.09773542  9.88538581] 113.972503481\n",
      "positions (x,y,z), reward: [-0.24328604  0.86738482  8.48671958] 115.403264342\n",
      "Episode =  413, score = 229.359 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.40429677  0.229691    9.09249226] 121.768613433\n",
      "positions (x,y,z), reward: [ 0.512929    0.29734658  8.69306754] 116.204909423\n",
      "Episode =  414, score = 216.341 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.33335625  0.05834396  8.23829239] 108.735198158\n",
      "positions (x,y,z), reward: [  4.11609106e+00   4.12765261e-03   6.70512133e+00] 105.894469948\n",
      "positions (x,y,z), reward: [ 4.94220526  0.03619515  5.5637565 ] 99.2253317559\n",
      "positions (x,y,z), reward: [ 6.90182559 -0.01935124  1.73800327] 94.4966949107\n",
      "Episode =  415, score = 214.047 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.50974382 -0.88453359  3.7271214 ] 108.043101685\n",
      "Episode =  416, score = 229.132 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.78369155 -0.09968098  8.99056024] 112.377343625\n",
      "positions (x,y,z), reward: [ 1.34984571 -0.42636483  6.9239776 ] 100.241748556\n",
      "positions (x,y,z), reward: [ 1.85015208 -0.6705463   5.44431531] 100.374147237\n",
      "Episode =  417, score = 215.866 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-2.60549177  1.76032695  2.50009363] 101.038192261\n",
      "Episode =  418, score = 225.224 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.          0.         10.0012504] 146.77289284\n",
      "positions (x,y,z), reward: [  1.53238494e-03   3.22589990e-04   1.00045937e+01] 145.819392064\n",
      "positions (x,y,z), reward: [ 0.41684043 -0.40476727  9.1119427 ] 111.927780626\n",
      "positions (x,y,z), reward: [ 0.48198197 -0.40737889  8.80683439] 111.192310224\n",
      "positions (x,y,z), reward: [ 1.82631258 -0.67767397  5.74485196] 106.859682006\n",
      "positions (x,y,z), reward: [ 3.38443433 -0.6762224   2.29963914] 99.3020953554\n",
      "Episode =  419, score = 218.903 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.01401187  0.0333267   9.68413575] 119.625440461\n",
      "positions (x,y,z), reward: [  2.12101660e-01   5.58561795e-03   9.46853644e+00] 117.934282596\n",
      "positions (x,y,z), reward: [ 0.94165435  0.10693219  8.81178492] 111.748946485\n",
      "positions (x,y,z), reward: [ 1.7737833   0.20352551  7.90668457] 112.182629818\n",
      "positions (x,y,z), reward: [ 3.86733462  0.18943691  4.8956501 ] 92.3276893297\n",
      "positions (x,y,z), reward: [ 5.29434968  0.20065253  2.34846298] 95.0153531982\n",
      "Episode =  420, score = 215.820 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.08116927  0.04534537  9.93903181] 115.412935362\n",
      "positions (x,y,z), reward: [-0.49452021  1.46231272  6.39128971] 111.426322845\n",
      "positions (x,y,z), reward: [-0.38329137  2.83092206  1.11656354] 93.2557785545\n",
      "Episode =  421, score = 222.772 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.27827013  0.10749605  9.92360236] 115.665336928\n",
      "positions (x,y,z), reward: [ 0.3588308   0.13559561  9.9045789 ] 114.585614759\n",
      "positions (x,y,z), reward: [ 1.52992995  0.17681405  9.06086063] 103.237801888\n",
      "positions (x,y,z), reward: [ 1.8000606   0.19276126  8.8071497 ] 102.381480129\n",
      "positions (x,y,z), reward: [ 2.8822891   0.30517871  7.797857  ] 112.137676045\n",
      "positions (x,y,z), reward: [ 6.45958452  0.54194928  3.01309283] 92.7573900567\n",
      "positions (x,y,z), reward: [ 7.76164108  0.58605548  1.06902742] 88.2481246445\n",
      "Episode =  422, score = 209.083 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 6.12532456  1.32280938  1.69546572] 94.4878519939\n",
      "Episode =  423, score = 213.630 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.24861424 -0.024131    7.81294471] 108.273155354\n",
      "positions (x,y,z), reward: [-0.6109966   0.16549955  3.96847692] 105.474169125\n",
      "Episode =  424, score = 224.502 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.68572885  0.27456646  8.98594401] 111.177742592\n",
      "positions (x,y,z), reward: [ 1.05742726  0.13511212  8.2345175 ] 114.412537616\n",
      "positions (x,y,z), reward: [ 1.41080425 -0.07069199  5.88680472] 106.756039986\n",
      "Episode =  425, score = 223.071 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.02228091 -0.03010159  9.28751436] 123.081388468\n",
      "positions (x,y,z), reward: [-0.42095023 -0.22250723  7.18447764] 108.280883225\n",
      "positions (x,y,z), reward: [-0.25102566 -0.38841366  5.8306732 ] 107.514718169\n",
      "Episode =  426, score = 227.762 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00144453] 146.68480255\n",
      "positions (x,y,z), reward: [-0.10135432  0.02508012  9.96036355] 116.811746137\n",
      "positions (x,y,z), reward: [-2.98874215 -1.32149195  3.86620852] 103.516258823\n",
      "Episode =  427, score = 213.606 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.91277786e-02  -3.31703359e-03   9.97894370e+00] 119.534803601\n",
      "positions (x,y,z), reward: [ 0.65638742  0.37792757  8.50624609] 108.996003371\n",
      "positions (x,y,z), reward: [ 2.07771392  0.85767408  4.04405191] 100.427627515\n",
      "Episode =  428, score = 218.515 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.12026064 -1.18949737  6.64241301] 110.110210721\n",
      "positions (x,y,z), reward: [ 0.17017996 -1.8641756   3.30747491] 102.946112565\n",
      "positions (x,y,z), reward: [ 0.22286113 -2.16768982  1.73847473] 98.769519085\n",
      "positions (x,y,z), reward: [ 0.26639556 -2.57376285  0.        ] 95.9429616461\n",
      "Episode =  429, score = 220.490 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.20066545  0.40848281  8.12712717] 115.108449464\n",
      "positions (x,y,z), reward: [-0.05922091 -0.24189606  5.69810919] 113.94464368\n",
      "positions (x,y,z), reward: [-0.19172045 -0.63462801  3.76402334] 109.64012176\n",
      "Episode =  430, score = 229.918 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.26430566  0.01547795  9.54374706] 107.126735254\n",
      "positions (x,y,z), reward: [ 1.93454296 -0.02169463  7.6171588 ] 105.895507064\n",
      "Episode =  431, score = 206.344 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.42139105e-02   9.51662099e-03   1.00091251e+01] 120.206887543\n",
      "positions (x,y,z), reward: [-2.77374797  0.8021655   4.03221452] 106.323441503\n",
      "positions (x,y,z), reward: [-4.06864426  1.3040298   0.9404682 ] 96.6008817559\n",
      "Episode =  432, score = 223.850 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00158601] 146.698912442\n",
      "positions (x,y,z), reward: [ 0.96400894  0.31677481  8.95812807] 115.1420306\n",
      "positions (x,y,z), reward: [ 2.15605848  0.27174208  0.80583426] 99.2130175455\n",
      "Episode =  433, score = 222.237 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.82670171e-03  -8.00568038e-06   1.00003211e+01] 139.763516066\n",
      "positions (x,y,z), reward: [ 3.86526297 -0.20228678  3.33686981] 85.2064414171\n",
      "positions (x,y,z), reward: [ 4.91491562  0.04659251  0.3353312 ] 92.5743996588\n",
      "Episode =  434, score = 211.996 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.03086812  0.21973832  8.95515948] 121.666157887\n",
      "positions (x,y,z), reward: [ 0.04605445  0.23839981  5.82418597] 110.480459785\n",
      "positions (x,y,z), reward: [ 0.03494086  0.19471909  5.27604265] 109.477338972\n",
      "positions (x,y,z), reward: [-0.10325831 -0.01685878  0.        ] 97.624964933\n",
      "Episode =  435, score = 225.024 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.08282453 -0.11241532  9.44270296] 115.845582949\n",
      "positions (x,y,z), reward: [ 0.81024174  0.54046174  4.5352407 ] 107.638404375\n",
      "Episode =  436, score = 221.187 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00126638] 146.758670685\n",
      "positions (x,y,z), reward: [ 3.3728125   1.06906844  8.85795836] 108.389059838\n",
      "positions (x,y,z), reward: [ 4.85276715  1.67094147  8.0760254 ] 93.6169001994\n",
      "positions (x,y,z), reward: [ 6.59144258  2.37897135  6.98546681] 92.1404586335\n",
      "positions (x,y,z), reward: [ 11.88392363   4.17046597   1.962849  ] 83.2654233353\n",
      "Episode =  437, score = 200.679 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.05821866  1.15325992  7.51296889] 117.756142449\n",
      "positions (x,y,z), reward: [ 0.32578646  1.20892814  5.77360386] 108.690779819\n",
      "positions (x,y,z), reward: [ 0.35756352  1.20497028  5.60121987] 108.446496908\n",
      "Episode =  438, score = 225.239 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.33340558 -1.16146841  7.56789599] 113.32821799\n",
      "positions (x,y,z), reward: [ 2.53038724 -2.87219854  0.82517352] 80.9129367052\n",
      "Episode =  439, score = 212.398 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.06100298  0.16437674  9.87398411] 117.028652407\n",
      "positions (x,y,z), reward: [-0.59667112  1.50203971  7.44399581] 113.672256789\n",
      "positions (x,y,z), reward: [-1.06182274  2.0653815   5.9965629 ] 111.950531706\n",
      "positions (x,y,z), reward: [-2.08394927  3.00612693  2.71727919] 100.881993704\n",
      "Episode =  440, score = 226.067 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.09929739e-02   2.44914292e-03   1.00149855e+01] 141.42977075\n",
      "positions (x,y,z), reward: [ 0.28654966  0.87744229  9.37978366] 120.384522235\n",
      "positions (x,y,z), reward: [ 0.08626475  2.3643027   5.03975026] 104.899012405\n",
      "Episode =  441, score = 233.116 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.45550886e-02   3.75025769e-04   1.00042637e+01] 138.02440473\n",
      "positions (x,y,z), reward: [ 0.10529387  0.09775447  9.82455017] 122.235381758\n",
      "positions (x,y,z), reward: [ 0.57807908  0.78388733  8.06975407] 120.050408834\n",
      "positions (x,y,z), reward: [ 4.47662438  3.21542606  0.57472045] 87.65227018\n",
      "positions (x,y,z), reward: [ 4.77800178  3.34742117  0.        ] 84.1061448316\n",
      "Episode =  442, score = 220.812 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.4637414  -0.54404449  9.76038718] 114.496731155\n",
      "positions (x,y,z), reward: [ 0.64706645 -1.04912095  9.21763661] 112.64468153\n",
      "positions (x,y,z), reward: [ 1.57372315 -4.2920375   3.65248187] 101.277945876\n",
      "positions (x,y,z), reward: [ 1.63235502 -4.62355059  2.91090791] 98.6139359658\n",
      "Episode =  443, score = 217.222 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.36856257e-03   2.28248662e-02   9.98309672e+00] 117.594603442\n",
      "positions (x,y,z), reward: [ 0.11220783 -0.27917312  9.26112048] 103.126479317\n",
      "positions (x,y,z), reward: [-0.8547996  -1.62648518  0.54406014] 100.002481432\n",
      "Episode =  444, score = 225.003 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.32603269 -0.9526432   4.2288851 ] 108.313719138\n",
      "Episode =  445, score = 227.179 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.0812276  -0.0573681   9.58610901] 113.033586058\n",
      "positions (x,y,z), reward: [-0.51896716 -0.3691448   4.25601343] 109.45417194\n",
      "positions (x,y,z), reward: [-0.56979222 -0.37645139  3.58727982] 108.172110162\n",
      "Episode =  446, score = 224.020 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.07303443e-03  -5.98683794e-04   9.94623258e+00] 122.357008625\n",
      "positions (x,y,z), reward: [-0.0181816   0.01767303  9.86967536] 119.75359548\n",
      "positions (x,y,z), reward: [-0.03780745  0.02527794  9.83608448] 119.657472135\n",
      "positions (x,y,z), reward: [-0.11857936  0.06374623  9.70317778] 119.615024005\n",
      "positions (x,y,z), reward: [-1.04647191  0.54373873  8.00900148] 117.852639385\n",
      "Episode =  447, score = 226.344 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00159948] 146.705472772\n",
      "positions (x,y,z), reward: [ -4.27582517e-02   6.26892057e-03   9.99633081e+00] 123.104324931\n",
      "positions (x,y,z), reward: [ 0.51869913  1.43880681  8.24050291] 109.276613146\n",
      "positions (x,y,z), reward: [ 1.44677892  2.55846007  6.63355628] 112.755879003\n",
      "positions (x,y,z), reward: [ 1.84090258  3.00195516  5.74832383] 109.257596322\n",
      "positions (x,y,z), reward: [ 1.91823941  3.09084407  5.55876001] 107.986885296\n",
      "positions (x,y,z), reward: [ 3.18314047  4.50477126  2.27195048] 84.291963039\n",
      "Episode =  448, score = 214.860 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.32624704 -0.45331086  8.93929998] 112.724529756\n",
      "positions (x,y,z), reward: [-0.51170754 -0.84275258  7.61925823] 109.142248614\n",
      "positions (x,y,z), reward: [-0.46745194 -0.99099599  7.16434843] 108.891847372\n",
      "positions (x,y,z), reward: [ 0.17475043 -1.7211186   3.85548524] 104.21719776\n",
      "Episode =  449, score = 219.304 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.28281294 -0.7014443   6.97762734] 112.137937845\n",
      "positions (x,y,z), reward: [-1.59923981 -0.95870798  5.77774861] 109.072202163\n",
      "Episode =  450, score = 219.381 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.38781698 -0.28560815  9.45485677] 103.64643414\n",
      "positions (x,y,z), reward: [ 8.53199832 -1.68119561  0.        ] 83.6264873344\n",
      "Episode =  451, score = 196.462 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.12217602 -0.05680318  9.67927541] 112.483428153\n",
      "positions (x,y,z), reward: [ 0.32454831 -0.0507258   9.52752922] 111.152313096\n",
      "positions (x,y,z), reward: [ 0.40779766 -0.05829675  9.46773578] 110.956472965\n",
      "positions (x,y,z), reward: [ 0.49347246 -0.07394152  9.40356954] 111.048865122\n",
      "positions (x,y,z), reward: [ 3.0548357  -0.697576    0.70644689] 98.2460877974\n",
      "Episode =  452, score = 218.400 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.50867599  0.07811662  9.71693339] 111.221749135\n",
      "positions (x,y,z), reward: [-0.72630467  0.24926207  9.30577007] 118.597034784\n",
      "positions (x,y,z), reward: [-1.27350549  0.23257057  6.82533709] 115.715264878\n",
      "positions (x,y,z), reward: [-1.46653616  0.27400378  5.91065853] 114.617312225\n",
      "positions (x,y,z), reward: [-2.03278028  0.45906228  3.71931101] 107.455658872\n",
      "Episode =  453, score = 227.548 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.30173371e-02   1.58361714e-03   1.00079505e+01] 143.142273817\n",
      "positions (x,y,z), reward: [ 1.53258272 -2.02919816  7.32009464] 100.474704284\n",
      "Episode =  454, score = 208.905 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.11693907  0.63340208  9.26083326] 124.096068942\n",
      "positions (x,y,z), reward: [-0.08927092  0.71148318  9.10630363] 123.426297757\n",
      "positions (x,y,z), reward: [ 2.77142886  1.26119603  3.7684278 ] 100.350016071\n",
      "Episode =  455, score = 223.637 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.53671909 -0.03688566  8.07664483] 114.460898761\n",
      "positions (x,y,z), reward: [ 2.72088203  0.10754666  5.42068237] 103.058917467\n",
      "positions (x,y,z), reward: [ 3.99524082  0.11994021  2.87890027] 96.3051443815\n",
      "positions (x,y,z), reward: [ 4.83186629  0.10520937  1.0309282 ] 95.8392545765\n",
      "Episode =  456, score = 217.137 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.21147689 -0.22942097  9.73897071] 117.903978031\n",
      "positions (x,y,z), reward: [ 0.43681341 -1.20608046  7.75730626] 109.383204244\n",
      "positions (x,y,z), reward: [ 0.67863412 -2.03203972  5.85056091] 106.547731109\n",
      "positions (x,y,z), reward: [ 0.66033142 -3.94360206  0.        ] 94.9990422521\n",
      "Episode =  457, score = 221.589 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.12016298  0.03773065  9.84227437] 121.579894282\n",
      "positions (x,y,z), reward: [ 0.49759575  0.07681593  9.49208619] 120.942698103\n",
      "positions (x,y,z), reward: [ 1.18468713 -0.03245184  8.61778476] 111.169339902\n",
      "positions (x,y,z), reward: [ 2.55965748 -0.20886775  7.20341543] 105.126422779\n",
      "positions (x,y,z), reward: [ 3.08170479 -0.33248491  6.62483772] 102.940378982\n",
      "positions (x,y,z), reward: [ 3.47569017 -0.42786893  6.17297943] 102.938162892\n",
      "positions (x,y,z), reward: [ 4.12026937 -0.56538386  5.33736782] 103.150902644\n",
      "positions (x,y,z), reward: [ 4.50626745 -0.63982884  4.77847129] 102.278620919\n",
      "positions (x,y,z), reward: [ 5.549563   -0.83558323  3.13193424] 95.3219603468\n",
      "Episode =  458, score = 214.893 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.06051287  0.39301457  8.68828893] 118.546109689\n",
      "positions (x,y,z), reward: [ 2.71220331  0.48820571  7.21551776] 114.541469603\n",
      "positions (x,y,z), reward: [ 3.0518472   0.58226526  5.48285194] 109.92522349\n",
      "positions (x,y,z), reward: [ 3.59361105  0.8186987   2.06105185] 93.596290029\n",
      "Episode =  459, score = 224.407 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.01566039 -0.37914441  9.64278593] 117.64164851\n",
      "positions (x,y,z), reward: [-0.03571999 -0.49184762  8.48222146] 105.718951876\n",
      "Episode =  460, score = 225.223 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.1051252  -0.01853257  9.7407713 ] 107.560302106\n",
      "positions (x,y,z), reward: [ 0.47447142 -0.1736445   8.84648477] 105.654490778\n",
      "positions (x,y,z), reward: [ 1.89804505 -0.50726945  5.69705489] 102.727867464\n",
      "positions (x,y,z), reward: [ 2.18432378 -0.64546185  4.5074265 ] 103.795501518\n",
      "positions (x,y,z), reward: [ 2.4913824  -0.80835216  2.90816316] 102.227758195\n",
      "Episode =  461, score = 212.238 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.15413949 -0.01703727  9.76272477] 115.077265645\n",
      "positions (x,y,z), reward: [ 2.19548651 -0.05749351  5.92992145] 101.875379855\n",
      "positions (x,y,z), reward: [ 3.94323483  0.15101607  0.30048664] 94.3749740997\n",
      "positions (x,y,z), reward: [ 4.16973701  0.17066977  0.        ] 95.4185468254\n",
      "Episode =  462, score = 214.477 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -4.66932658e-02   1.15820791e-03   9.96505382e+00] 119.392127851\n",
      "positions (x,y,z), reward: [ 0.6066554   0.58449729  5.85004572] 105.786792896\n",
      "positions (x,y,z), reward: [ 1.49583189  0.64386929  1.47166537] 101.22836494\n",
      "Episode =  463, score = 220.322 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.99516561  0.11177561  5.19498984] 108.968515076\n",
      "Episode =  464, score = 225.149 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -8.13165618e-02  -1.64424938e-03   9.95271729e+00] 116.064635343\n",
      "positions (x,y,z), reward: [-0.76750398  0.07038674  8.5993048 ] 120.230730032\n",
      "positions (x,y,z), reward: [-0.98716514  0.06773727  6.86759293] 115.617160877\n",
      "positions (x,y,z), reward: [-0.7613589  -0.14619386  1.96138278] 101.553100005\n",
      "Episode =  465, score = 229.165 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04650455 -0.09279549  9.83790607] 118.906668868\n",
      "positions (x,y,z), reward: [-0.02053483 -0.26882008  9.63927583] 115.83078076\n",
      "positions (x,y,z), reward: [-0.64930348 -1.34997471  5.58164018] 111.498742423\n",
      "positions (x,y,z), reward: [-0.80016516 -2.0747818   2.04069532] 100.961998336\n",
      "Episode =  466, score = 225.448 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.82267088e-02   6.56552436e-03   1.00231771e+01] 132.61310473\n",
      "positions (x,y,z), reward: [-0.11171037 -0.08086654  9.86012512] 125.984842437\n",
      "positions (x,y,z), reward: [-0.28138994  0.02336326  9.57942387] 126.013685918\n",
      "positions (x,y,z), reward: [-0.35339222  0.36421734  8.98555148] 123.305675867\n",
      "Episode =  467, score = 228.759 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.17021183  0.11855403  9.99793583] 127.284488712\n",
      "positions (x,y,z), reward: [ 0.29741514  0.35478629  9.83251811] 121.562662759\n",
      "positions (x,y,z), reward: [ 0.45814765  0.80779866  8.9944187 ] 110.780385221\n",
      "positions (x,y,z), reward: [ 0.99284799  1.19388115  6.16789288] 109.035169952\n",
      "Episode =  468, score = 226.158 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.02330156 -0.04250896  9.69548274] 108.074694745\n",
      "positions (x,y,z), reward: [ 1.30167056 -0.54822702  5.88167637] 103.34756975\n",
      "positions (x,y,z), reward: [ 1.44682344 -0.5813398   5.11106982] 103.538573912\n",
      "positions (x,y,z), reward: [ 1.78539834 -0.5889713   2.92857297] 103.667362182\n",
      "Episode =  469, score = 213.785 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.14158121  0.07320723  9.75528524] 120.301723153\n",
      "positions (x,y,z), reward: [-0.15117875  1.05559714  1.56612881] 95.4545453817\n",
      "positions (x,y,z), reward: [-0.06605587  1.2252452   0.20543814] 85.2769660028\n",
      "Episode =  470, score = 225.028 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -0.02040736   0.01495897  10.03210057] 135.686320389\n",
      "positions (x,y,z), reward: [ 2.03111602  1.0750116   0.59160425] 98.4894180936\n",
      "positions (x,y,z), reward: [ 2.075236    1.1268586   0.04282887] 96.9602358615\n",
      "Episode =  471, score = 225.409 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.90343626e-02  -6.39122467e-03   9.94854626e+00] 119.134994013\n",
      "positions (x,y,z), reward: [ 0.16667528  0.01993531  9.74126515] 110.565561825\n",
      "positions (x,y,z), reward: [ 3.87223205  1.55020281  1.45429417] 96.589234329\n",
      "positions (x,y,z), reward: [ 4.21511878  1.64636703  0.13307775] 93.312747432\n",
      "positions (x,y,z), reward: [ 4.35352437  1.69589847  0.        ] 92.5253452061\n",
      "Episode =  472, score = 217.280 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 3.48879455 -1.3039614   2.75869858] 100.633466554\n",
      "Episode =  473, score = 212.806 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.0712874  -0.03422522  9.94129121] 119.797600976\n",
      "positions (x,y,z), reward: [ 0.17430387 -1.17039714  7.94695983] 114.885182541\n",
      "Episode =  474, score = 222.582 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.11367692 -0.0556264   9.9874721 ] 124.018957522\n",
      "positions (x,y,z), reward: [ 0.08663665 -0.12948066  9.88723266] 123.216459186\n",
      "positions (x,y,z), reward: [ 0.04205193 -0.19227323  9.74662703] 122.835850477\n",
      "positions (x,y,z), reward: [ 0.29770637 -2.50018287  1.20161033] 98.2422337385\n",
      "Episode =  475, score = 224.201 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-3.68338435 -0.84053372  6.46843614] 111.73034749\n",
      "Episode =  476, score = 232.026 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.06892627 -0.07938626  9.72024173] 122.711478148\n",
      "positions (x,y,z), reward: [ -7.96353512e-03  -1.04821688e-01   9.17050583e+00] 120.412555673\n",
      "positions (x,y,z), reward: [ 0.17712639 -0.05599512  6.15881465] 112.462351082\n",
      "positions (x,y,z), reward: [ 0.24380097  0.03065901  5.29883579] 109.442487986\n",
      "Episode =  477, score = 226.220 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.54982097  1.77082758  7.83373875] 106.791594503\n",
      "positions (x,y,z), reward: [ 2.64331892  1.87679409  7.62691321] 106.815000925\n",
      "positions (x,y,z), reward: [ 5.36213179  4.66046026  0.20573035] 80.1616402732\n",
      "Episode =  478, score = 209.751 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.70068646  1.17232471  7.26330005] 113.820443102\n",
      "positions (x,y,z), reward: [ 0.27651189  1.82344776  4.58307362] 107.094092122\n",
      "Episode =  479, score = 226.175 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00166778] 146.774859989\n",
      "positions (x,y,z), reward: [ 0.80020871 -0.59075037  6.33285911] 108.445806118\n",
      "Episode =  481, score = 224.036 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.40747531 -0.04824888  9.3781926 ] 120.339269662\n",
      "positions (x,y,z), reward: [-0.50060869 -0.05379527  9.20022663] 119.698737694\n",
      "positions (x,y,z), reward: [-0.72119988 -0.14297787  8.6566466 ] 118.186782656\n",
      "positions (x,y,z), reward: [-0.90452458 -0.20946265  8.30527428] 115.723584573\n",
      "positions (x,y,z), reward: [-2.24947674 -0.52438105  5.80471601] 111.268048685\n",
      "positions (x,y,z), reward: [-3.28646557 -0.71868738  3.30656618] 104.279605319\n",
      "Episode =  482, score = 225.796 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.33248228 -0.28000419  8.17637112] 115.862219494\n",
      "positions (x,y,z), reward: [ 0.18469188  0.25416451  5.82586674] 112.980173235\n",
      "positions (x,y,z), reward: [ 0.79891684  1.13036968  2.20170473] 94.0225615094\n",
      "Episode =  483, score = 227.755 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.96600724  0.28311693  9.22635071] 113.375993401\n",
      "positions (x,y,z), reward: [ 1.28224276  0.23553864  8.67170472] 113.630115219\n",
      "positions (x,y,z), reward: [ 1.4508944   0.17048242  8.00917017] 114.830584609\n",
      "Episode =  484, score = 222.220 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.72648173 -0.92361454  8.74350195] 105.448827103\n",
      "positions (x,y,z), reward: [ 1.48207491 -1.54192377  7.60376345] 108.529037895\n",
      "positions (x,y,z), reward: [ 1.60822342 -1.67347962  7.38384434] 107.960863423\n",
      "Episode =  485, score = 211.731 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.68410435e-02   8.16108974e-03   1.00164500e+01] 122.880315365\n",
      "positions (x,y,z), reward: [ 0.19501526 -0.14738109  6.02663308] 108.58810417\n",
      "positions (x,y,z), reward: [ 0.2443151  -0.75773291  1.82350852] 93.9449395188\n",
      "Episode =  486, score = 222.147 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.12351092  0.09384837  9.97962144] 124.736659041\n",
      "positions (x,y,z), reward: [ 0.99654711  0.32297549  9.0993772 ] 107.320702974\n",
      "Episode =  487, score = 214.654 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.00742620e-02  -7.42429309e-03   9.89309857e+00] 115.109455121\n",
      "positions (x,y,z), reward: [ 0.27529193 -0.11590375  9.16502613] 113.603984448\n",
      "positions (x,y,z), reward: [ 0.2563546  -0.1377089   9.01933312] 113.78453379\n",
      "positions (x,y,z), reward: [ 0.22401232 -0.16429059  8.84992948] 114.530746573\n",
      "Episode =  488, score = 221.584 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.56533668  1.21408156  8.10488442] 117.918290408\n",
      "positions (x,y,z), reward: [ 0.31709013  1.93516281  6.14109831] 109.535592658\n",
      "positions (x,y,z), reward: [ 0.21687089  2.24809401  4.38593258] 102.034312366\n",
      "positions (x,y,z), reward: [ 0.25457499  2.50474074  1.3559369 ] 93.3150216254\n",
      "Episode =  489, score = 223.465 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.18516823  0.54007666  8.783413  ] 122.844255884\n",
      "positions (x,y,z), reward: [-0.18516584  0.63795738  8.32613575] 119.645925888\n",
      "positions (x,y,z), reward: [ 1.38341543  0.12854516  3.86231822] 102.784987313\n",
      "positions (x,y,z), reward: [ 2.31644284 -0.30631786  1.55333572] 93.6511851314\n",
      "Episode =  490, score = 224.462 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.14894699  0.20900559  9.42621924] 118.534630159\n",
      "positions (x,y,z), reward: [-0.14381298  0.31221383  9.00522005] 119.3557118\n",
      "positions (x,y,z), reward: [ 0.18377509  0.41419248  4.99724566] 106.883861741\n",
      "positions (x,y,z), reward: [ 0.65014733  0.23035744  3.09364256] 102.753231043\n",
      "positions (x,y,z), reward: [ 0.70553537  0.20541908  2.84108622] 102.451407612\n",
      "positions (x,y,z), reward: [ 0.87005707  0.13265487  2.06635528] 100.963056341\n",
      "positions (x,y,z), reward: [ 1.34301975 -0.05526528  0.        ] 95.2683370956\n",
      "Episode =  491, score = 226.176 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.14227587   0.10608028  10.09703734] 134.92643886\n",
      "positions (x,y,z), reward: [  0.14741714   0.12715308  10.09985684] 133.894956858\n",
      "positions (x,y,z), reward: [  0.10750826   0.25833169  10.01356056] 120.175415061\n",
      "positions (x,y,z), reward: [-0.02352784  0.42114966  9.73340025] 121.633385488\n",
      "positions (x,y,z), reward: [-1.95317611  1.21849209  5.54719767] 108.141182155\n",
      "Episode =  492, score = 231.502 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.04520443  0.03383339  9.82360398] 122.547747053\n",
      "positions (x,y,z), reward: [-0.25363794  0.21851499  9.14456554] 121.322417204\n",
      "positions (x,y,z), reward: [ 1.42904944 -0.11957469  5.65679767] 111.234759446\n",
      "positions (x,y,z), reward: [ 1.88455337 -0.26974731  4.30136646] 106.662209574\n",
      "Episode =  493, score = 226.192 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 4.17385313  0.58081004  4.5329542 ] 97.8631075957\n",
      "Episode =  494, score = 217.765 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.6156442   0.45154097  9.0415162 ] 116.197589372\n",
      "positions (x,y,z), reward: [ 1.22626613  1.23464747  5.32389922] 107.902510991\n",
      "positions (x,y,z), reward: [ 1.23622539  1.2656801   5.11239306] 107.419380814\n",
      "positions (x,y,z), reward: [ 1.29615586  1.58286589  2.32755235] 98.5981299816\n",
      "Episode =  495, score = 224.836 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.09226316 -0.05634633  9.86983227] 119.189615613\n",
      "positions (x,y,z), reward: [ 0.13030865 -0.07567177  9.82544762] 117.857134004\n",
      "positions (x,y,z), reward: [ 2.28875296 -0.43956294  8.33760079] 111.706633577\n",
      "positions (x,y,z), reward: [ 6.20631447 -0.81410782  1.82701374] 92.7555917671\n",
      "Episode =  496, score = 209.863 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.27855602 -0.64372556  8.86402249] 122.668405974\n",
      "positions (x,y,z), reward: [-1.36158587 -0.92926059  6.25265199] 113.52330066\n",
      "positions (x,y,z), reward: [-1.8269988  -0.97302345  4.38287448] 107.249748093\n",
      "positions (x,y,z), reward: [-1.78933178 -0.98400873  3.04211741] 104.193278585\n",
      "positions (x,y,z), reward: [-1.72979124 -0.95406837  1.96545137] 104.266217623\n",
      "Episode =  497, score = 229.217 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.03827633  0.06392058  9.9758213 ] 122.765202763\n",
      "positions (x,y,z), reward: [ 0.0498198   0.11535086  9.86409879] 123.034059329\n",
      "positions (x,y,z), reward: [ 0.15062062  0.1810041   9.40092938] 117.03947376\n",
      "positions (x,y,z), reward: [ 0.33998745  0.05835914  5.02519734] 107.549152697\n",
      "positions (x,y,z), reward: [ 0.46683385 -0.12082943  3.00836489] 103.158402738\n",
      "positions (x,y,z), reward: [ 0.59837135 -0.23744497  0.91931109] 98.4414452971\n",
      "Episode =  498, score = 227.278 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.27627853  0.04116714  9.75998427] 107.983078221\n",
      "positions (x,y,z), reward: [ 0.82481742 -0.20347819  9.05462801] 101.765698754\n",
      "positions (x,y,z), reward: [ 1.21969997 -0.30988334  8.61617415] 102.702351921\n",
      "positions (x,y,z), reward: [ 3.43969936 -1.35952178  2.00647335] 96.2173337038\n",
      "Episode =  499, score = 205.955 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.62113224e-02   5.28262979e-03   9.91075812e+00] 119.944665082\n",
      "positions (x,y,z), reward: [-0.21815525  0.10832565  9.57378379] 115.367885642\n",
      "positions (x,y,z), reward: [-0.20029552  0.35913386  9.18677059] 117.806798438\n",
      "positions (x,y,z), reward: [ 0.72579553  0.7470933   8.20586353] 120.410160497\n",
      "positions (x,y,z), reward: [ 1.58231385  0.9613936   7.62645765] 118.365460475\n",
      "positions (x,y,z), reward: [ 5.37265517  1.26497931  4.63335179] 98.2543956234\n",
      "Episode =  500, score = 221.757 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.09670718 -0.72831397  8.82458671] 111.738578787\n",
      "Episode =  501, score = 220.527 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.37409411 -0.21092555  8.4720924 ] 112.012366623\n",
      "positions (x,y,z), reward: [ 0.27071462 -0.40948796  5.02753616] 111.185556152\n",
      "positions (x,y,z), reward: [ 1.11547914 -0.94551431  1.32229426] 103.765816484\n",
      "positions (x,y,z), reward: [ 1.4013424  -1.07833277  0.        ] 100.833391865\n",
      "Episode =  502, score = 224.869 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.07485707e-03   7.67557408e-02   9.69468885e+00] 121.747190696\n",
      "positions (x,y,z), reward: [-0.97648893  1.39905599  0.        ] 96.9629261778\n",
      "Episode =  503, score = 227.181 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.37114689 -0.57007888  9.00883544] 112.123800922\n",
      "positions (x,y,z), reward: [ 0.34208595 -0.97089641  8.47322821] 115.320119323\n",
      "positions (x,y,z), reward: [ 0.32465489 -1.03604896  8.36878626] 115.643764373\n",
      "positions (x,y,z), reward: [ 0.24036684 -1.27407467  7.88853722] 115.223768071\n",
      "positions (x,y,z), reward: [ 0.18844545 -1.58185506  7.17431671] 107.954877871\n",
      "positions (x,y,z), reward: [-0.05505789 -2.20201465  5.68748212] 108.77539479\n",
      "Episode =  504, score = 219.242 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.09245906 -0.24375484  9.48965557] 121.986974617\n",
      "positions (x,y,z), reward: [-1.05549262 -0.5384451   7.80086006] 117.931630382\n",
      "positions (x,y,z), reward: [-1.87152227 -0.76664093  6.26520958] 113.081537379\n",
      "positions (x,y,z), reward: [-3.53478125 -1.24806738  2.12138003] 99.9263565422\n",
      "Episode =  505, score = 227.831 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -4.71984522e-02   3.13592968e-03   1.00331543e+01] 137.058800988\n",
      "positions (x,y,z), reward: [-0.98913904  0.30450976  9.34402194] 116.925946998\n",
      "Episode =  506, score = 223.788 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.27396273e-03   5.74127616e-04   1.00043119e+01] 145.806616928\n",
      "positions (x,y,z), reward: [ 0.35252457  0.05327979  9.71868614] 122.229422911\n",
      "positions (x,y,z), reward: [ 0.50678198  0.04579181  9.60760233] 122.953728337\n",
      "positions (x,y,z), reward: [ 0.64047361  0.0329384   9.49286356] 121.05382947\n",
      "positions (x,y,z), reward: [ 7.05048659 -0.57031722  0.93603303] 89.8361555694\n",
      "Episode =  507, score = 214.619 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.54102183  0.22318671  6.9566221 ] 107.956341335\n",
      "positions (x,y,z), reward: [ 2.76667329  0.33239446  5.15166122] 103.669684669\n",
      "positions (x,y,z), reward: [ 4.76016644  0.59942304  1.72197224] 95.3067065611\n",
      "Episode =  508, score = 212.594 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.09265903 -0.29925404  9.69809357] 121.812318926\n",
      "positions (x,y,z), reward: [-0.85952882 -3.55251994  0.21875855] 93.101412559\n",
      "Episode =  509, score = 224.055 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00169774] 146.731115485\n",
      "positions (x,y,z), reward: [-1.08533595  0.46020957  8.80566948] 123.496131746\n",
      "positions (x,y,z), reward: [-1.44405274  0.45561683  8.57619545] 121.398983888\n",
      "positions (x,y,z), reward: [-4.04131437  1.02702187  6.36332657] 112.494414572\n",
      "positions (x,y,z), reward: [-4.66016177  1.28199485  5.94269231] 109.752097671\n",
      "positions (x,y,z), reward: [-6.66290535  1.50457699  2.70431117] 86.7754466224\n",
      "Episode =  510, score = 215.783 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -4.40978436e-02   6.14742150e-03   9.99554056e+00] 132.740896499\n",
      "positions (x,y,z), reward: [-0.55622242 -0.19921991  9.4772061 ] 104.939916038\n",
      "positions (x,y,z), reward: [-1.40541861 -1.78223233  4.0871679 ] 106.745435593\n",
      "Episode =  511, score = 214.207 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.44542962e-03   1.40474314e-04   1.00032898e+01] 144.160121831\n",
      "positions (x,y,z), reward: [ 0.04319263  1.21947648  5.85264341] 110.502363904\n",
      "positions (x,y,z), reward: [ 0.43512887  1.20907575  3.53111987] 107.053234869\n",
      "Episode =  512, score = 221.963 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.20746086  0.17790989  9.65092214] 116.330097446\n",
      "positions (x,y,z), reward: [-1.87420887  2.856876    2.89984971] 100.12211258\n",
      "positions (x,y,z), reward: [-2.06733048  3.19367706  0.67552651] 94.7026787613\n",
      "Episode =  513, score = 223.239 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00127877] 146.709178131\n",
      "positions (x,y,z), reward: [ 0.77833268 -0.01240392  9.55390261] 112.540165172\n",
      "positions (x,y,z), reward: [ 2.04577532 -1.19776976  7.09177025] 111.250084337\n",
      "positions (x,y,z), reward: [ 2.89168179 -2.63658868  3.05922465] 87.860594631\n",
      "Episode =  514, score = 210.185 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.05445281   0.01353934  10.01581675] 134.738051366\n",
      "positions (x,y,z), reward: [ 0.2939068   0.08506914  9.91850824] 119.748835534\n",
      "positions (x,y,z), reward: [ 0.76524689  0.32859753  9.02261671] 121.019371465\n",
      "positions (x,y,z), reward: [ 0.98114479  0.41187638  7.80499642] 102.859855841\n",
      "positions (x,y,z), reward: [ 1.41005515  0.61651033  6.733523  ] 93.5716271256\n",
      "positions (x,y,z), reward: [ 4.18304743  1.53296417  0.        ] 94.3930895158\n",
      "Episode =  515, score = 217.559 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.0486965   0.06398459  9.98708375] 133.206970366\n",
      "positions (x,y,z), reward: [-0.31766412  1.07067266  7.79813734] 118.301699525\n",
      "positions (x,y,z), reward: [-0.1909466   1.55880987  6.47539065] 110.446040705\n",
      "positions (x,y,z), reward: [ 0.26944592  2.08756652  3.80225609] 102.585728346\n",
      "Episode =  516, score = 227.244 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.05789316 -1.52256443  7.29799978] 101.311692911\n",
      "positions (x,y,z), reward: [ 0.14616947 -1.71688517  6.88234201] 101.746136028\n",
      "positions (x,y,z), reward: [ 0.41582394 -2.62256258  4.92456092] 97.9542847474\n",
      "positions (x,y,z), reward: [ 1.15190809 -3.78359916  1.93505411] 96.8388261771\n",
      "Episode =  517, score = 210.893 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.2064641  -0.01872808  9.75268486] 117.794730614\n",
      "positions (x,y,z), reward: [-1.75289244 -0.60656126  6.22694648] 108.221264488\n",
      "positions (x,y,z), reward: [-1.96290964 -0.80352735  4.75917231] 106.749942679\n",
      "Episode =  518, score = 222.492 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.48959102 -0.51614799  7.94500503] 103.78086762\n",
      "positions (x,y,z), reward: [-0.52701539 -0.6099297   7.6389677 ] 103.3846917\n",
      "Episode =  519, score = 212.500 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.39686973 -1.25154837  6.66031256] 105.272594558\n",
      "positions (x,y,z), reward: [ 0.49785606 -1.94363739  5.10793695] 106.405722158\n",
      "positions (x,y,z), reward: [ 0.50588675 -2.09434063  4.72571241] 106.245773827\n",
      "Episode =  521, score = 228.058 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00198116] 146.705924291\n",
      "positions (x,y,z), reward: [-1.0873425  -1.53690601  6.51028367] 101.685845718\n",
      "positions (x,y,z), reward: [-1.39412483 -2.31678715  4.32484303] 106.083588373\n",
      "Episode =  522, score = 212.090 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.14616172 -0.01851143  9.83072573] 109.081391215\n",
      "positions (x,y,z), reward: [-0.13844724 -0.13387072  9.60952519] 110.954521306\n",
      "positions (x,y,z), reward: [-0.29241815 -0.45404257  9.12920392] 114.035739338\n",
      "positions (x,y,z), reward: [-0.49941954 -0.67270736  8.63174725] 114.664287189\n",
      "positions (x,y,z), reward: [-0.78091083 -0.97301655  7.39320506] 104.631231781\n",
      "positions (x,y,z), reward: [-0.70177713 -1.72185411  3.52947102] 103.70337537\n",
      "positions (x,y,z), reward: [-0.69760649 -1.86062087  2.78809394] 102.390495159\n",
      "Episode =  523, score = 216.817 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.03838885  0.19240957  9.67383249] 116.531486149\n",
      "Episode =  524, score = 228.430 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.06370938 -0.03343658  9.95022905] 123.333885621\n",
      "Episode =  525, score = 229.946 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.76862181  1.77058765  5.67318219] 109.863899602\n",
      "positions (x,y,z), reward: [ 0.77316099  1.88748788  5.29482127] 109.294756379\n",
      "positions (x,y,z), reward: [ 0.7661996   2.12312994  4.49407827] 107.936020018\n",
      "Episode =  526, score = 225.550 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.44959282e-02   3.84500083e-03   1.00107044e+01] 125.971617358\n",
      "positions (x,y,z), reward: [ 0.07712229 -0.03554765  9.91765244] 118.241821443\n",
      "positions (x,y,z), reward: [ 1.38111653 -1.77989338  5.02081166] 105.314160647\n",
      "Episode =  527, score = 220.241 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.64165339  0.04875194  9.04697488] 121.438646682\n",
      "positions (x,y,z), reward: [-1.97840529  0.16446692  8.72790796] 119.509002023\n",
      "positions (x,y,z), reward: [-4.84018808  1.90337723  4.55322992] 104.758749988\n",
      "Episode =  528, score = 223.692 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.02811748  0.01549527  9.85589966] 119.323650154\n",
      "positions (x,y,z), reward: [ 0.01699406  0.04547222  9.78681745] 118.196355198\n",
      "positions (x,y,z), reward: [-0.02869722  0.25056355  9.4733324 ] 118.299802781\n",
      "positions (x,y,z), reward: [ 0.05660702  0.58212137  8.6883321 ] 118.706334273\n",
      "positions (x,y,z), reward: [ 0.06592562  0.61207537  8.56167448] 117.176686608\n",
      "positions (x,y,z), reward: [ 0.10271641  0.69949072  8.03482117] 116.553722709\n",
      "positions (x,y,z), reward: [ 0.21017604  1.84016384  2.34330408] 102.698420416\n",
      "Episode =  529, score = 226.768 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.18915867 -0.75315026  8.98941538] 109.705292686\n",
      "positions (x,y,z), reward: [ 0.28284708 -0.99463878  8.18389375] 111.927124747\n",
      "positions (x,y,z), reward: [ 0.39720147 -1.11855391  7.7367426 ] 113.369443247\n",
      "positions (x,y,z), reward: [ 1.64521537 -2.50909025  1.70451343] 98.4565946445\n",
      "Episode =  530, score = 220.321 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00155892] 146.73389947\n",
      "positions (x,y,z), reward: [ 0.88362873  0.88879612  9.79420322] 107.807300529\n",
      "positions (x,y,z), reward: [ 3.8219539   2.92791557  6.85178227] 105.967564805\n",
      "positions (x,y,z), reward: [ 5.93137582  3.81094966  4.20466515] 91.0468015818\n",
      "positions (x,y,z), reward: [ 6.60729023  4.03459938  3.30361332] 86.8055959953\n",
      "Episode =  531, score = 213.954 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.03984735 -0.81892376  8.76289798] 114.416037999\n",
      "positions (x,y,z), reward: [-0.49456437 -1.49934393  7.26730395] 115.105236628\n",
      "positions (x,y,z), reward: [-0.93848849 -1.87329482  6.16187446] 112.710880489\n",
      "positions (x,y,z), reward: [-2.31185503 -2.89382644  2.26098881] 100.976861726\n",
      "positions (x,y,z), reward: [-2.92729305 -3.3137473   0.2834    ] 94.0610537081\n",
      "Episode =  532, score = 222.653 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00172675] 146.775401354\n",
      "positions (x,y,z), reward: [ 0.96835065 -1.23810476  8.82700387] 97.1546748867\n",
      "positions (x,y,z), reward: [ 0.92641346 -1.52271007  8.56273485] 110.226655408\n",
      "positions (x,y,z), reward: [ 0.89773588 -1.81022269  8.26362748] 113.513380896\n",
      "positions (x,y,z), reward: [ 0.81626217 -2.20167493  7.80791446] 113.661279182\n",
      "positions (x,y,z), reward: [ 0.19595705 -4.20127372  4.70874358] 105.60696276\n",
      "positions (x,y,z), reward: [-0.40419474 -5.8383057   1.65837341] 95.3043266848\n",
      "Episode =  533, score = 219.618 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.4774776  -0.07683294  9.42973687] 113.812809587\n",
      "positions (x,y,z), reward: [ 0.4141751  -0.18724671  8.64219955] 115.260458924\n",
      "positions (x,y,z), reward: [ 0.58137554 -0.13905215  7.72143003] 107.301973397\n",
      "positions (x,y,z), reward: [ 1.101986   -0.14286506  6.27258848] 107.046842412\n",
      "positions (x,y,z), reward: [ 1.65622303 -0.02682112  4.73843196] 106.21468043\n",
      "Episode =  534, score = 222.815 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.06436578 -0.57557659  7.16131634] 106.449161796\n",
      "positions (x,y,z), reward: [ 0.29118214 -1.14240422  5.40378139] 104.886723714\n",
      "Episode =  535, score = 210.821 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.04979527  0.2481902   9.05961438] 119.424840527\n",
      "positions (x,y,z), reward: [-0.97132964  2.22738842  2.75755783] 95.1940107318\n",
      "Episode =  536, score = 223.444 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.03192243  0.09549548  9.51518538] 122.382384991\n",
      "positions (x,y,z), reward: [-0.39268612  0.36581272  7.96245527] 119.414503622\n",
      "positions (x,y,z), reward: [-0.55324804  0.60674638  6.37180661] 115.172095057\n",
      "positions (x,y,z), reward: [-0.63615263  0.74025554  5.69015333] 113.159225013\n",
      "positions (x,y,z), reward: [-0.79369581  1.01674385  4.39598669] 106.732200514\n",
      "positions (x,y,z), reward: [-0.82053807  1.1377788   3.58380181] 102.416289629\n",
      "positions (x,y,z), reward: [-1.04722485  1.50399268  0.        ] 96.9035543298\n",
      "Episode =  537, score = 228.567 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.60515314 -0.18604727  9.79277701] 114.311407543\n",
      "positions (x,y,z), reward: [ 3.83502975 -2.53465682  2.220287  ] 91.9058843793\n",
      "positions (x,y,z), reward: [ 4.01670075 -2.70689977  1.11633027] 91.9759931174\n",
      "Episode =  538, score = 211.853 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 3.99583184 -0.16177147  2.94282226] 96.4658077603\n",
      "positions (x,y,z), reward: [ 4.63296232 -0.16174962  0.38389591] 78.7855401842\n",
      "Episode =  539, score = 221.728 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.29344773  0.16098363  9.42832619] 119.180536999\n",
      "positions (x,y,z), reward: [ 0.44345844  0.19596816  5.55706937] 112.490274888\n",
      "positions (x,y,z), reward: [ 0.80401008  0.05671239  4.10422888] 106.058273407\n",
      "positions (x,y,z), reward: [ 0.91443731  0.0261291   3.7464841 ] 103.663925296\n",
      "positions (x,y,z), reward: [ 1.51190989 -0.11806126  1.61535713] 101.308938959\n",
      "positions (x,y,z), reward: [ 1.81025961 -0.17544747  0.23326968] 98.9492619801\n",
      "Episode =  540, score = 227.572 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00146954] 146.66339951\n",
      "positions (x,y,z), reward: [-0.10300833  0.01708525  9.66982503] 109.892087906\n",
      "positions (x,y,z), reward: [ 0.25760752  0.33307789  7.78679254] 111.258912318\n",
      "positions (x,y,z), reward: [ 0.39739546  0.42253589  6.09691987] 108.98563268\n",
      "Episode =  541, score = 219.673 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.47947801  0.35262921  9.60461653] 121.652001685\n",
      "positions (x,y,z), reward: [-1.46261604  0.56229657  2.66660824] 101.128758393\n",
      "Episode =  542, score = 225.509 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00161126] 146.767026061\n",
      "positions (x,y,z), reward: [ 0.16777934 -0.72536506  9.90475022] 110.825873288\n",
      "positions (x,y,z), reward: [-0.09334277 -3.16837482  7.91724495] 98.1589272999\n",
      "positions (x,y,z), reward: [-0.54478358 -4.17980882  6.76410001] 91.4781475338\n",
      "positions (x,y,z), reward: [-1.46185409 -7.6964253   1.86412769] 93.2714415759\n",
      "Episode =  543, score = 210.351 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.21672481 -0.40095176  8.68080794] 109.229849733\n",
      "positions (x,y,z), reward: [ 0.45149123 -0.7255089   6.61050407] 109.387723035\n",
      "Episode =  544, score = 218.903 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.05605458  0.01383742  9.97910193] 117.655477792\n",
      "positions (x,y,z), reward: [ -1.11033628e-01   8.31776082e-04   9.93453674e+00] 116.335499651\n",
      "positions (x,y,z), reward: [ 0.40775805  0.72328559  4.86104927] 108.262594004\n",
      "positions (x,y,z), reward: [ 0.59284278  0.7059184   4.23058036] 106.821835308\n",
      "Episode =  545, score = 226.297 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.04206559   0.01946647  10.04263829] 151.700841208\n",
      "positions (x,y,z), reward: [  0.22328614   0.25815323  10.10260487] 136.783038265\n",
      "positions (x,y,z), reward: [ 0.59676365  0.82595969  9.91043134] 121.565468403\n",
      "positions (x,y,z), reward: [ 1.73602824  2.72919433  8.8228842 ] 111.715487533\n",
      "Episode =  546, score = 218.839 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.01819879e-02   1.23388607e-03   1.00085517e+01] 144.100493483\n",
      "positions (x,y,z), reward: [  3.24235164e-02   3.95706319e-03   1.00138829e+01] 141.646697611\n",
      "positions (x,y,z), reward: [ 0.78108985  0.27064047  9.51412011] 113.101762629\n",
      "positions (x,y,z), reward: [ 1.00827435  0.3439357   9.00660828] 109.335682892\n",
      "positions (x,y,z), reward: [ 1.10423428  0.57416479  6.12920036] 111.729266322\n",
      "positions (x,y,z), reward: [ 0.99509199  0.64504103  3.00967342] 102.118121577\n",
      "Episode =  547, score = 223.509 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.48129016e-02   7.27558570e-03   1.00220973e+01] 139.270558312\n",
      "positions (x,y,z), reward: [ 0.29847881  0.17790956  9.50404071] 112.329284151\n",
      "positions (x,y,z), reward: [ 0.35391569  0.1408734   9.26850325] 112.968962476\n",
      "positions (x,y,z), reward: [ 0.27299665 -0.10646587  7.52362903] 116.767507281\n",
      "positions (x,y,z), reward: [ 0.07813835 -0.24313898  5.69153409] 111.148131335\n",
      "Episode =  548, score = 228.389 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.08464563 -0.06201657  9.90649569] 118.342515341\n",
      "positions (x,y,z), reward: [ 0.11951708 -1.05056449  8.42278651] 111.932378271\n",
      "positions (x,y,z), reward: [ 0.57267927 -1.3976335   7.32026159] 111.618374187\n",
      "positions (x,y,z), reward: [ 1.28012488 -2.09472167  5.67288177] 101.048299247\n",
      "positions (x,y,z), reward: [ 2.02628684 -2.86367234  4.00122415] 97.2682777455\n",
      "Episode =  549, score = 215.383 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-3.6811948  -2.40178219  3.01982258] 100.131576425\n",
      "positions (x,y,z), reward: [-4.09869762 -2.66406868  1.963574  ] 96.490923174\n",
      "Episode =  550, score = 222.065 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  7.42986490e-03   3.35579415e-03   1.00152601e+01] 154.474980583\n",
      "positions (x,y,z), reward: [  0.24078347   0.35524275  10.16802129] 137.647573581\n",
      "positions (x,y,z), reward: [  0.20435577   0.58483627  10.11836491] 127.499071656\n",
      "Episode =  551, score = 235.183 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.88264187  0.39751971  8.29750206] 119.481482943\n",
      "positions (x,y,z), reward: [-1.31688174  0.46711497  7.05411429] 115.907104342\n",
      "positions (x,y,z), reward: [-2.49109503  0.63970233  2.6419081 ] 102.000047554\n",
      "Episode =  552, score = 228.716 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00167087] 146.634819595\n",
      "Episode =  553, score = 218.798 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00105939] 146.76174208\n",
      "positions (x,y,z), reward: [ 0.84965612  0.63101209  9.32086448] 117.834026803\n",
      "positions (x,y,z), reward: [ 0.89977287  0.69759638  9.13993628] 118.164391627\n",
      "positions (x,y,z), reward: [ 1.32661406  1.29211596  6.50881866] 106.513350306\n",
      "positions (x,y,z), reward: [ 1.37714861  1.68788898  4.27206611] 100.593805334\n",
      "positions (x,y,z), reward: [ 1.79773394  2.10755345  1.18671017] 88.6418681032\n",
      "Episode =  554, score = 227.377 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.25199486 -0.18132224  9.59769981] 107.282330172\n",
      "Episode =  555, score = 214.105 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.63072101  0.66572368  8.95314046] 114.901885815\n",
      "positions (x,y,z), reward: [ 0.72157667  1.06847337  7.61747717] 114.306235565\n",
      "positions (x,y,z), reward: [ 0.72616264  1.13377699  7.31147841] 114.37961627\n",
      "positions (x,y,z), reward: [ 0.91816504  1.98883741  2.11966122] 96.3788401966\n",
      "Episode =  556, score = 227.218 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  4.75864656e-03  -1.15780980e-04   9.99002942e+00] 127.735379737\n",
      "positions (x,y,z), reward: [ 0.46795462  0.02978324  8.7151759 ] 116.728351269\n",
      "positions (x,y,z), reward: [ 0.44691926 -0.05192375  7.42920054] 117.433058374\n",
      "positions (x,y,z), reward: [ 0.39495408 -0.17402669  5.4695591 ] 105.277322004\n",
      "positions (x,y,z), reward: [ 0.99176536 -0.6976089   0.        ] 96.6148339053\n",
      "Episode =  557, score = 224.757 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00092867] 145.839246399\n",
      "positions (x,y,z), reward: [ 0.24870911  0.39408731  9.44792455] 118.549956996\n",
      "positions (x,y,z), reward: [ 0.38377608  0.61564331  9.21828551] 112.956454581\n",
      "positions (x,y,z), reward: [ 1.49769285  2.2250145   5.7207427 ] 86.6800607006\n",
      "positions (x,y,z), reward: [ 3.09000141  3.27195815  0.97516975] 90.6420909328\n",
      "Episode =  558, score = 212.897 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.45783107  0.84948801  7.47395451] 115.786209474\n",
      "positions (x,y,z), reward: [ 0.37515936  1.27326232  5.82354231] 113.05504457\n",
      "positions (x,y,z), reward: [ 0.3180207   1.78178732  3.55487767] 104.210039462\n",
      "Episode =  559, score = 229.754 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.06339585 -0.02299162  9.89591932] 120.733537871\n",
      "positions (x,y,z), reward: [ 3.38383721  0.04124621  5.96921483] 94.1379170678\n",
      "positions (x,y,z), reward: [ 3.86911304  0.06053479  5.20651206] 94.8524829146\n",
      "positions (x,y,z), reward: [ 4.38445858  0.06224962  4.38221153] 95.1263811001\n",
      "positions (x,y,z), reward: [ 6.00403328  0.09785743  1.29216075] 94.4457583013\n",
      "positions (x,y,z), reward: [ 6.59774859  0.11584952  0.        ] 92.6398575786\n",
      "Episode =  560, score = 211.644 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.57614004  -0.40765242  10.03428782] 119.466770549\n",
      "positions (x,y,z), reward: [ 1.3379797  -1.52634264  8.96900135] 108.509235441\n",
      "positions (x,y,z), reward: [ 1.51731977 -4.20081066  3.25880159] 96.2946860515\n",
      "Episode =  561, score = 216.598 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.08598621e-01   5.18133383e-03   9.99411546e+00] 124.980970435\n",
      "positions (x,y,z), reward: [ 1.0592261   0.07277039  8.82454894] 108.549433\n",
      "positions (x,y,z), reward: [ 6.58496453  0.60382323  1.73351723] 94.1163195275\n",
      "positions (x,y,z), reward: [ 7.79608447  0.72329866  0.        ] 89.2781218304\n",
      "Episode =  562, score = 209.195 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.48482596e-02  -7.07927725e-03   9.98158500e+00] 124.887997812\n",
      "positions (x,y,z), reward: [ 0.01238512 -0.11426847  9.78281766] 124.49200641\n",
      "positions (x,y,z), reward: [-0.05850058 -0.22607798  9.54096909] 124.376377097\n",
      "positions (x,y,z), reward: [-0.08451032 -0.25839607  9.46916369] 124.278989237\n",
      "Episode =  563, score = 228.078 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.78098659e-02  -3.29616264e-03   9.94774949e+00] 118.659794064\n",
      "positions (x,y,z), reward: [ 0.19032357 -0.02461911  9.41127551] 109.976952749\n",
      "positions (x,y,z), reward: [ 1.64700553 -0.13904496  6.26585444] 108.178708484\n",
      "positions (x,y,z), reward: [ 2.89035087 -0.3935354   1.3011215 ] 96.8412047602\n",
      "positions (x,y,z), reward: [ 3.07307358 -0.45047898  0.27142538] 96.1933219862\n",
      "positions (x,y,z), reward: [ 3.11728284 -0.46364755  0.00567252] 95.9277175858\n",
      "Episode =  564, score = 210.023 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.05397973  0.1727043   9.9047882 ] 130.655237068\n",
      "positions (x,y,z), reward: [-0.07253365  0.27691393  9.88609899] 120.708448578\n",
      "positions (x,y,z), reward: [ 0.1872559   1.44506857  7.89277999] 108.77501394\n",
      "positions (x,y,z), reward: [ 0.82194297  3.13828539  1.43972007] 87.5990793947\n",
      "positions (x,y,z), reward: [  1.02430392e+00   3.35075275e+00   9.80586445e-04] 84.5868499597\n",
      "Episode =  565, score = 220.412 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.36866615e-02   1.98351857e-04   1.00038405e+01] 137.138249664\n",
      "positions (x,y,z), reward: [ -1.25706738e-01   6.57673569e-03   9.97279407e+00] 115.426290437\n",
      "positions (x,y,z), reward: [-0.04139128  0.43881153  9.26136326] 116.631774552\n",
      "positions (x,y,z), reward: [ 0.58346806  0.64173899  8.12012847] 109.846169527\n",
      "positions (x,y,z), reward: [ 1.52424524  0.75571461  6.74290161] 105.257531069\n",
      "positions (x,y,z), reward: [ 3.01169949  0.82916373  4.58394928] 100.82484832\n",
      "positions (x,y,z), reward: [ 3.56675174  0.87202262  3.7689245 ] 98.5945941793\n",
      "positions (x,y,z), reward: [ 4.54562988  0.9485265   2.1988254 ] 97.1487710802\n",
      "positions (x,y,z), reward: [ 5.25018231  1.01594017  0.94363264] 93.0631359214\n",
      "Episode =  566, score = 218.903 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.01567897  0.01933893  9.92330396] 122.66664924\n",
      "positions (x,y,z), reward: [ 0.20133483  0.2250362   9.36418423] 117.488264847\n",
      "positions (x,y,z), reward: [ 0.06284735  0.5719707   8.21775994] 118.891740873\n",
      "positions (x,y,z), reward: [-0.05241304  0.76035854  7.68464998] 116.733153562\n",
      "positions (x,y,z), reward: [-0.16039252  1.01158267  6.95856976] 114.31608591\n",
      "positions (x,y,z), reward: [-0.25006934  1.17140339  6.4897494 ] 113.471219839\n",
      "positions (x,y,z), reward: [-0.28448336  1.22488547  6.32591736] 113.077755729\n",
      "positions (x,y,z), reward: [-0.77985817  1.98570336  3.93066099] 100.626360476\n",
      "Episode =  567, score = 223.857 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -5.97951758e-02  -3.56029208e-03   9.91800144e+00] 116.862829343\n",
      "positions (x,y,z), reward: [-1.03530972  0.614805    5.78282501] 113.22863333\n",
      "positions (x,y,z), reward: [-1.289572    0.70833684  4.85997128] 110.942649708\n",
      "Episode =  568, score = 225.192 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.57091801  0.13131449  8.71360267] 114.871639371\n",
      "positions (x,y,z), reward: [ 2.02287439  0.20238124  8.35607078] 105.93872471\n",
      "positions (x,y,z), reward: [ 2.90409702  0.39836918  7.51391226] 103.507209675\n",
      "positions (x,y,z), reward: [ 3.13290234  0.46789835  7.24954483] 100.136524091\n",
      "positions (x,y,z), reward: [ 3.24436632  0.50483192  7.10729397] 100.899382551\n",
      "Episode =  569, score = 216.959 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.07838622 -0.48809812  9.37985088] 119.034417765\n",
      "positions (x,y,z), reward: [ 0.69972136 -2.822869    5.20194331] 108.834205781\n",
      "positions (x,y,z), reward: [ 0.75275926 -3.69506682  3.14436947] 102.911878208\n",
      "positions (x,y,z), reward: [ 0.71540145 -4.34743485  1.46299363] 97.7629462852\n",
      "positions (x,y,z), reward: [ 0.65035518 -4.91142474  0.        ] 95.288365419\n",
      "Episode =  570, score = 225.159 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.05426606e-03  -1.36291663e-04   1.00008124e+01] 139.751344043\n",
      "positions (x,y,z), reward: [ 0.83370947  0.79139666  8.87767047] 111.73643684\n",
      "positions (x,y,z), reward: [ 2.27621214  2.24961898  5.65756104] 102.494569493\n",
      "Episode =  571, score = 211.590 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.49894141  0.54642019  7.97195846] 114.320069963\n",
      "positions (x,y,z), reward: [ 0.00985283  0.52592396  7.19364418] 116.115227384\n",
      "positions (x,y,z), reward: [ 1.7563625  -0.3024808   2.40655196] 106.488889707\n",
      "Episode =  572, score = 225.547 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.02708201  0.02014983  9.88487189] 121.878902828\n",
      "positions (x,y,z), reward: [ 0.61897408 -0.04371964  9.26963659] 120.838711674\n",
      "positions (x,y,z), reward: [ 1.19001829 -0.037313    8.86121603] 118.499267734\n",
      "positions (x,y,z), reward: [ 3.72024464 -0.06224765  6.87441658] 104.602321596\n",
      "positions (x,y,z), reward: [ 5.39479401  0.02274514  5.19883246] 99.2107582669\n",
      "positions (x,y,z), reward: [ 5.97193604  0.05367616  4.47889708] 97.6855775248\n",
      "Episode =  573, score = 218.532 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.46441729  0.0131159   9.27869178] 105.171345017\n",
      "positions (x,y,z), reward: [ 0.88591293  0.0939524   8.83943159] 108.206825165\n",
      "positions (x,y,z), reward: [ 2.90240252  0.75327247  5.91549131] 93.1190708851\n",
      "positions (x,y,z), reward: [ 3.95267991  0.959222    4.34333805] 101.40282847\n",
      "positions (x,y,z), reward: [ 5.72250015  1.38129804  0.51937335] 96.6686410298\n",
      "positions (x,y,z), reward: [ 5.81557407  1.40465302  0.26329797] 96.122966921\n",
      "Episode =  574, score = 213.121 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.03914892  0.01340209  9.959909  ] 109.01942199\n",
      "positions (x,y,z), reward: [-0.32977975 -0.05518537  9.39041445] 111.539781988\n",
      "positions (x,y,z), reward: [-0.52222804  0.06628526  6.67490492] 114.593740109\n",
      "positions (x,y,z), reward: [-0.47079749  0.00760925  4.29447822] 110.028536209\n",
      "positions (x,y,z), reward: [-0.48958785 -0.02665074  3.71288885] 108.896180495\n",
      "Episode =  575, score = 221.123 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -5.56656780e-03   2.39834594e-03   1.00117629e+01] 149.024082011\n",
      "Episode =  576, score = 221.465 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.11608691  0.30268644  9.56963068] 122.564884889\n",
      "positions (x,y,z), reward: [-0.67804308  0.7673964   6.12491831] 115.135337941\n",
      "positions (x,y,z), reward: [-1.81297567  0.87234971  1.94798006] 103.018094174\n",
      "Episode =  577, score = 230.047 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.99059218  1.0859469   9.48433129] 120.343059638\n",
      "positions (x,y,z), reward: [ 2.60112038  2.67331283  2.57900523] 99.3575373047\n",
      "Episode =  578, score = 229.926 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.3118441   0.2551229   5.45968471] 113.599929368\n",
      "positions (x,y,z), reward: [-0.75238364  0.30147499  2.11021134] 105.144509919\n",
      "Episode =  579, score = 230.340 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.44522646  0.16234309  5.52326959] 110.71448833\n",
      "positions (x,y,z), reward: [-0.57843977  0.06391269  4.12855231] 107.959725764\n",
      "positions (x,y,z), reward: [-0.62910435  0.00562156  3.37033605] 104.966454707\n",
      "Episode =  580, score = 228.084 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.02054514e-02  -3.75356178e-03   9.97796154e+00] 125.050696548\n",
      "positions (x,y,z), reward: [ 0.96411129 -0.5933851   8.24904178] 112.195585241\n",
      "positions (x,y,z), reward: [ 1.60335989 -1.17142747  5.72183507] 101.955587924\n",
      "positions (x,y,z), reward: [ 1.84673449 -1.61515455  3.81808851] 102.065647905\n",
      "Episode =  581, score = 217.165 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -4.01733002e-02   7.80904191e-03   1.00046303e+01] 133.029257418\n",
      "positions (x,y,z), reward: [-0.07896272  0.03670425  9.99262141] 117.490591675\n",
      "positions (x,y,z), reward: [-0.35876566 -0.02387649  9.86599901] 115.233977473\n",
      "positions (x,y,z), reward: [-1.44876529  0.22374051  4.61068336] 109.431324803\n",
      "positions (x,y,z), reward: [-0.99065128  0.23479801  0.7410474 ] 98.0265525534\n",
      "positions (x,y,z), reward: [-0.89824601  0.21740693  0.16245584] 97.6945939177\n",
      "Episode =  582, score = 228.522 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.00666306e-02   8.38335236e-04   1.00111411e+01] 149.134498272\n",
      "positions (x,y,z), reward: [ 0.78907039  0.22875417  9.98755997] 123.612210526\n",
      "positions (x,y,z), reward: [ 0.86227744  0.241275    9.96637186] 121.623776062\n",
      "positions (x,y,z), reward: [ 1.07778433  0.27597305  9.87937724] 117.539009866\n",
      "positions (x,y,z), reward: [ 2.48298477  0.35048098  9.16348779] 108.455926527\n",
      "positions (x,y,z), reward: [ 3.61814547  0.54707249  7.92908939] 101.943293579\n",
      "positions (x,y,z), reward: [ 5.36236947  0.76894273  3.43160022] 97.5792516978\n",
      "Episode =  583, score = 220.055 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.02420845  0.2682035   8.49774643] 113.545589715\n",
      "positions (x,y,z), reward: [ 0.96607948  0.64312868  5.64687566] 106.730179696\n",
      "Episode =  584, score = 222.213 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.29978945e-03   1.87464620e-04   1.00028105e+01] 144.788183549\n",
      "positions (x,y,z), reward: [ 2.79949134 -4.343856    2.01492811] 82.6421102976\n",
      "positions (x,y,z), reward: [ 3.44173218 -4.7848486   0.41728095] 82.4593684969\n",
      "Episode =  585, score = 208.300 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.97891289  0.01072494  9.15958562] 118.83495459\n",
      "positions (x,y,z), reward: [  2.01686366e+00   1.36937642e-03   7.82487542e+00] 116.149797222\n",
      "positions (x,y,z), reward: [ 2.06064633  0.0077788   7.71291642] 115.582617679\n",
      "positions (x,y,z), reward: [ 2.88282201  0.12089907  5.70642084] 102.426938487\n",
      "positions (x,y,z), reward: [ 3.57754533  0.17154065  3.63197056] 102.508809046\n",
      "positions (x,y,z), reward: [ 4.71861906  0.17659642  0.        ] 91.3419845256\n",
      "Episode =  586, score = 222.945 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.34689995e-04   6.45366945e-04   1.00057145e+01] 145.769786451\n",
      "positions (x,y,z), reward: [  1.48783342e-02   6.62291801e-03   1.00281769e+01] 147.455614202\n",
      "positions (x,y,z), reward: [ 0.6539199  -1.04932973  4.38110099] 108.626063373\n",
      "positions (x,y,z), reward: [ 0.97424417 -1.2033764   2.33480066] 101.401109412\n",
      "Episode =  587, score = 230.856 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.07789186  0.01191574  9.8900606 ] 121.551415191\n",
      "positions (x,y,z), reward: [ 1.78906651  0.04061055  8.24106577] 116.465576873\n",
      "positions (x,y,z), reward: [ 6.11220159  1.14521291  1.67955146] 93.0038901764\n",
      "positions (x,y,z), reward: [ 6.5848729   1.27776657  0.69739712] 90.4821822867\n",
      "positions (x,y,z), reward: [ 6.82924376  1.33791308  0.19381726] 88.553886181\n",
      "Episode =  588, score = 218.850 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.80112205  1.97361566  3.85866211] 104.308325614\n",
      "positions (x,y,z), reward: [ 2.02672485  2.20485027  1.65126526] 98.8429129685\n",
      "Episode =  589, score = 225.745 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.17356660e-03   7.33636979e-04   1.00045708e+01] 145.798737424\n",
      "positions (x,y,z), reward: [-0.51566291 -0.21874502  7.99448557] 112.267092457\n",
      "positions (x,y,z), reward: [-0.9748917  -0.37406215  5.35886059] 110.894031593\n",
      "positions (x,y,z), reward: [-1.18341108 -0.41829231  3.7584911 ] 104.950831259\n",
      "positions (x,y,z), reward: [-1.2981558  -0.59691052  1.95459646] 102.024762977\n",
      "positions (x,y,z), reward: [-1.32093511 -0.625235    1.67813923] 101.527224262\n",
      "Episode =  590, score = 223.504 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.09876278 -0.22802141  9.83435943] 119.417349962\n",
      "positions (x,y,z), reward: [ 0.05870055 -0.38500788  9.74066358] 118.047381705\n",
      "positions (x,y,z), reward: [-0.80630665 -1.72519835  7.0149572 ] 106.927400287\n",
      "Episode =  591, score = 219.493 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.19594894  0.17383363  9.77021954] 119.897945779\n",
      "positions (x,y,z), reward: [ 1.41359659  0.4106232   7.46285581] 115.195970829\n",
      "positions (x,y,z), reward: [ 2.08845626  0.57072738  3.17270098] 102.174249391\n",
      "Episode =  592, score = 223.702 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.06801859  1.38889059  7.93244286] 112.697334022\n",
      "positions (x,y,z), reward: [ 1.18966511  1.46099259  7.66109482] 111.212086711\n",
      "positions (x,y,z), reward: [ 1.70550132  1.93164206  5.67144667] 108.680144241\n",
      "positions (x,y,z), reward: [ 1.73986331  1.97395327  5.4779367 ] 108.286444224\n",
      "positions (x,y,z), reward: [ 2.23541832  2.68697463  2.38491549] 91.0333937629\n",
      "positions (x,y,z), reward: [ 2.55041763  2.97030998  0.84600373] 91.4458668532\n",
      "positions (x,y,z), reward: [ 2.78334151  3.19754618  0.        ] 92.0809860794\n",
      "Episode =  593, score = 220.987 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.16996988 -0.3211851   7.66631549] 116.331684433\n",
      "positions (x,y,z), reward: [ 1.35539452 -0.41612325  4.55854291] 110.997551285\n",
      "positions (x,y,z), reward: [ 1.71284742 -0.43986475  2.76052011] 106.798108771\n",
      "positions (x,y,z), reward: [ 2.02749811 -0.42423639  0.86912889] 101.882716555\n",
      "Episode =  594, score = 227.040 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.09887161  0.11260285  9.77479284] 120.730471554\n",
      "positions (x,y,z), reward: [-0.76769131  0.45709731  8.43218047] 118.643781679\n",
      "positions (x,y,z), reward: [-2.78240972  0.56359561  2.30601719] 100.49910033\n",
      "Episode =  595, score = 227.107 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -6.70940494e-05  -2.48037563e-03   9.95041132e+00] 122.709866079\n",
      "positions (x,y,z), reward: [ 0.17297152  0.09706634  9.61546037] 113.566594882\n",
      "positions (x,y,z), reward: [ 0.18202016  0.24604481  8.26263817] 108.716365441\n",
      "positions (x,y,z), reward: [ 0.41122222  0.16886257  4.18584274] 108.334140282\n",
      "positions (x,y,z), reward: [ 0.34651366  0.13694153  2.86187448] 106.030439901\n",
      "positions (x,y,z), reward: [ 0.20093374  0.11057468  0.83333711] 101.484757876\n",
      "Episode =  596, score = 225.303 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.07344475 -0.01196462  9.93454468] 119.613113786\n",
      "positions (x,y,z), reward: [ 4.94587759 -0.82899728  2.59273301] 96.4745663304\n",
      "positions (x,y,z), reward: [ 5.66729959 -0.94918889  1.26042611] 90.7063473634\n",
      "Episode =  597, score = 207.839 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.57712448  0.21314033  9.32888739] 115.205804776\n",
      "positions (x,y,z), reward: [ 1.23518794 -0.04178799  8.55869253] 103.401994785\n",
      "positions (x,y,z), reward: [ 1.5059903  -0.24932024  7.95582863] 101.680692913\n",
      "Episode =  598, score = 220.660 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.04196131 -0.42198131  9.3414008 ] 105.97380527\n",
      "positions (x,y,z), reward: [-0.09798024 -1.23271862  7.03428279] 112.731668644\n",
      "positions (x,y,z), reward: [ 0.47636232 -1.76535604  2.69905015] 104.146005783\n",
      "Episode =  599, score = 219.324 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00110495] 146.830617321\n",
      "positions (x,y,z), reward: [ -4.14284031e-03   1.48967125e-01   9.85720470e+00] 117.985460998\n",
      "positions (x,y,z), reward: [ 1.91174713  1.67191403  8.22298055] 116.497612411\n",
      "positions (x,y,z), reward: [ 3.90399591  3.56438386  0.        ] 86.6179361039\n",
      "Episode =  600, score = 223.065 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.0128571  -0.01817551  9.79586506] 111.286141366\n",
      "positions (x,y,z), reward: [ 0.02327677  0.37914699  8.99802467] 113.583402439\n",
      "positions (x,y,z), reward: [ 0.65289898  1.14510655  5.4957798 ] 106.003914411\n",
      "positions (x,y,z), reward: [ 0.95529411  1.46038382  2.96239048] 92.521153643\n",
      "positions (x,y,z), reward: [ 1.22523663  1.61003703  0.82753227] 95.7142922905\n",
      "Episode =  601, score = 213.447 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.78083751  1.47522284  7.96217077] 108.981867085\n",
      "positions (x,y,z), reward: [ 2.18037263  1.78933761  7.2188709 ] 105.036003473\n",
      "positions (x,y,z), reward: [ 3.84851824  2.89635068  2.94617024] 93.0874242395\n",
      "positions (x,y,z), reward: [ 4.64675011  3.33695923  0.61035645] 78.848265754\n",
      "Episode =  602, score = 214.482 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.13760426 -0.09601805  9.87863509] 119.818465312\n",
      "positions (x,y,z), reward: [ 0.3998177  -0.62676945  9.57795721] 118.384409516\n",
      "positions (x,y,z), reward: [ 0.68270772 -1.90116367  8.21731525] 106.158535653\n",
      "positions (x,y,z), reward: [ 0.91816173 -2.29843994  7.45886209] 99.9879711203\n",
      "positions (x,y,z), reward: [ 1.89826146 -3.97624896  4.47971349] 98.8096755788\n",
      "Episode =  603, score = 211.077 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.06739197 -0.04727604  9.79304794] 119.100471705\n",
      "positions (x,y,z), reward: [-3.52844476 -1.65197268  0.        ] 94.8289837435\n",
      "Episode =  604, score = 227.769 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.06108159 -0.0374822   9.89822338] 121.904507167\n",
      "positions (x,y,z), reward: [-0.04564774  0.03833879  9.31390176] 119.864946664\n",
      "positions (x,y,z), reward: [ 0.21160565  1.08670124  3.53228632] 104.165628872\n",
      "Episode =  605, score = 224.309 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.22197027 -0.10930365  7.97332901] 116.324840497\n",
      "positions (x,y,z), reward: [-0.16496554 -0.20875129  7.15523191] 115.170707134\n",
      "positions (x,y,z), reward: [ 0.02894272  0.12095416  0.79741705] 94.317462567\n",
      "positions (x,y,z), reward: [ 0.06287341  0.16318197  0.23958973] 92.322065815\n",
      "Episode =  606, score = 223.148 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.84091460e-03   2.31410735e-04   1.00036206e+01] 144.828177525\n",
      "positions (x,y,z), reward: [ 0.06777653  0.02170284  9.9312535 ] 120.161136487\n",
      "positions (x,y,z), reward: [-0.90642782  1.03854969  6.85726282] 112.788091559\n",
      "positions (x,y,z), reward: [-0.94304979  1.08635541  6.66613912] 111.468359074\n",
      "positions (x,y,z), reward: [-1.54646485  1.79817169  2.92541418] 98.0969990628\n",
      "Episode =  607, score = 225.009 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.19847387 -0.3673564   6.83924301] 112.587606729\n",
      "positions (x,y,z), reward: [-0.43656732 -0.53639889  5.00986757] 110.292087259\n",
      "positions (x,y,z), reward: [-0.63447482 -0.55785492  3.10236982] 104.623648598\n",
      "Episode =  608, score = 228.491 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.37575538 -0.40774792  6.88678095] 113.360218197\n",
      "positions (x,y,z), reward: [ 3.57934717 -0.97950398  1.07810122] 96.9547237765\n",
      "Episode =  609, score = 217.007 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04481969 -0.05387984  9.79798677] 116.773531875\n",
      "positions (x,y,z), reward: [ 0.1026379  -0.80037328  8.19834895] 111.736728683\n",
      "positions (x,y,z), reward: [ 0.11604114 -0.89593129  7.73452515] 112.231097493\n",
      "positions (x,y,z), reward: [ 0.13004373 -0.97293295  7.41028336] 113.528812781\n",
      "positions (x,y,z), reward: [-0.07767383 -1.88655896  3.72906886] 105.062897642\n",
      "positions (x,y,z), reward: [-0.23392614 -2.41637531  0.96462052] 94.3109645469\n",
      "positions (x,y,z), reward: [-0.24528333 -2.51064303  0.41220228] 91.8179956739\n",
      "Episode =  610, score = 218.782 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.26395841e-02  -4.26902992e-03   9.95764448e+00] 124.445882184\n",
      "positions (x,y,z), reward: [-0.43363112  0.97440575  8.49828696] 119.792453004\n",
      "positions (x,y,z), reward: [-0.53671986  1.08906114  8.13606484] 118.476663141\n",
      "positions (x,y,z), reward: [-0.625509    1.15798189  7.88665956] 117.997757696\n",
      "positions (x,y,z), reward: [-1.36862977  1.68625474  5.33774423] 99.1772321715\n",
      "positions (x,y,z), reward: [-1.64057937  1.88442189  3.91954007] 98.4541123452\n",
      "positions (x,y,z), reward: [-2.09017438  2.19163706  0.        ] 91.6679591847\n",
      "Episode =  611, score = 222.078 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.24520162 -0.1302393   9.52393302] 107.040068932\n",
      "positions (x,y,z), reward: [-0.73107678 -0.41923438  7.49447874] 113.0436673\n",
      "positions (x,y,z), reward: [-1.6993335  -0.90518732  3.98374601] 107.171708133\n",
      "Episode =  612, score = 219.663 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.60865812 -0.25829562  9.70619081] 115.415903159\n",
      "positions (x,y,z), reward: [-1.88620735 -0.79444334  7.17690193] 112.996582889\n",
      "positions (x,y,z), reward: [-4.16264635 -0.38503091  2.4374398 ] 100.580176059\n",
      "positions (x,y,z), reward: [-4.32381734 -0.32642421  2.00334262] 99.3179913693\n",
      "Episode =  613, score = 224.645 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 10.96505287   1.29349206   0.41241381] 79.7290419381\n",
      "Episode =  614, score = 207.190 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.24240623e-03  -8.71959837e-04   9.99041987e+00] 127.96462247\n",
      "positions (x,y,z), reward: [ -2.57771881e-02  -5.12158451e-03   9.81026197e+00] 116.066608584\n",
      "positions (x,y,z), reward: [-0.2762794  -0.0454102   9.37044189] 113.414606997\n",
      "positions (x,y,z), reward: [-0.36389888 -0.01147337  8.74940481] 119.579168192\n",
      "positions (x,y,z), reward: [-1.65492829 -0.07645365  2.82659518] 107.134279268\n",
      "Episode =  615, score = 228.568 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.         0.        10.001123] 146.765459605\n",
      "positions (x,y,z), reward: [ 0.54300479 -1.00711932  8.81322469] 105.09977882\n",
      "positions (x,y,z), reward: [ 2.2981755  -2.05253688  5.68871396] 102.374503225\n",
      "positions (x,y,z), reward: [ 3.68233855 -2.92203232  1.8638744 ] 87.8013981709\n",
      "Episode =  616, score = 217.198 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -7.95277198e-02   2.60364680e-03   9.97698844e+00] 119.319517867\n",
      "positions (x,y,z), reward: [-0.29775987  0.03237209  9.84769191] 112.618089342\n",
      "positions (x,y,z), reward: [-0.77409608  0.21317755  9.38031359] 113.935254187\n",
      "positions (x,y,z), reward: [-1.83944503  0.5794514   7.55289137] 111.065395735\n",
      "Episode =  617, score = 214.626 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -7.57614095e-02   1.37989691e-03   9.98504155e+00] 118.544538395\n",
      "positions (x,y,z), reward: [ -9.82879811e-02   2.24170661e-03   9.97549157e+00] 115.930481447\n",
      "positions (x,y,z), reward: [-1.28897411 -0.85019681  5.34682708] 108.967715094\n",
      "positions (x,y,z), reward: [-2.41879669 -1.37893476  0.86536947] 95.5923093452\n",
      "Episode =  618, score = 217.451 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.92501151  0.21023431  3.98601948] 108.380108129\n",
      "positions (x,y,z), reward: [ 2.89323332  0.02004401  0.        ] 98.2481548585\n",
      "Episode =  619, score = 222.412 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.89916098  0.31001295  9.52454318] 121.824759822\n",
      "positions (x,y,z), reward: [ 1.05349587  0.32338551  9.37062019] 113.993554105\n",
      "positions (x,y,z), reward: [ 1.30907134  0.29958412  9.0891104 ] 108.007434764\n",
      "positions (x,y,z), reward: [ 2.87712901 -0.02192345  7.43448437] 106.085062986\n",
      "Episode =  620, score = 215.372 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.23166928e-01   4.19638909e-03   9.95499862e+00] 110.431943673\n",
      "positions (x,y,z), reward: [ 4.06294861 -0.59277767  6.97170028] 91.1840029294\n",
      "Episode =  621, score = 209.822 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.05724769 -0.33043535  8.14745371] 118.034124916\n",
      "positions (x,y,z), reward: [-0.29888091 -0.50715808  6.87243857] 113.241104357\n",
      "positions (x,y,z), reward: [-1.4680229  -0.96379715  0.74129189] 97.1775209891\n",
      "Episode =  622, score = 222.937 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.07311876 -0.30709495  8.94696897] 111.797563984\n",
      "positions (x,y,z), reward: [ 2.43783773 -0.621914    4.94880155] 102.12483334\n",
      "Episode =  623, score = 218.038 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.17145094 -1.03983922  5.82445352] 107.280192049\n",
      "positions (x,y,z), reward: [-1.20788525 -1.0902299   5.42137267] 107.124346252\n",
      "Episode =  624, score = 212.991 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.66414984e-02  -2.89457793e-03   9.98723354e+00] 125.241299965\n",
      "positions (x,y,z), reward: [ 0.13815985  0.0100944   9.82978434] 114.476175203\n",
      "positions (x,y,z), reward: [ 1.91118246  0.72633638  8.58085338] 111.856737919\n",
      "positions (x,y,z), reward: [ 2.49888318  0.81405548  7.75608536] 104.868357428\n",
      "positions (x,y,z), reward: [ 2.83412305  0.86868589  7.03567779] 105.747053998\n",
      "positions (x,y,z), reward: [ 4.21775988  1.16788523  0.54659493] 96.0577107983\n",
      "Episode =  625, score = 218.643 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.13185566e-03  -3.76870780e-04   1.00011715e+01] 138.778152501\n",
      "positions (x,y,z), reward: [-0.15436755  0.27980499  8.67789608] 107.44007959\n",
      "positions (x,y,z), reward: [-0.13780134  0.29851378  8.59336125] 108.033919163\n",
      "positions (x,y,z), reward: [ 0.18938278  0.19638169  7.19084178] 107.666376918\n",
      "Episode =  626, score = 216.483 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.16961641  0.01438494  9.85450981] 115.61250451\n",
      "positions (x,y,z), reward: [-1.01153393  0.26081606  7.08962834] 117.442376964\n",
      "positions (x,y,z), reward: [-1.11156373  0.20338498  4.32821497] 105.854608039\n",
      "positions (x,y,z), reward: [-1.16465622  0.09881388  1.88228302] 102.937770085\n",
      "Episode =  627, score = 226.237 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.37039521 -1.75743545  6.70507688] 110.204396003\n",
      "positions (x,y,z), reward: [ 1.87245967 -2.48411479  5.14049705] 101.311809423\n",
      "positions (x,y,z), reward: [ 1.9379304  -2.57474624  4.92944939] 99.6869201763\n",
      "Episode =  628, score = 210.874 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.04367133e-02  -5.62282885e-03   9.95366085e+00] 116.002810594\n",
      "positions (x,y,z), reward: [-1.52792774 -2.80291063  0.        ] 95.2121779056\n",
      "Episode =  629, score = 225.123 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.15915642 -1.31813049  6.75986436] 115.662901328\n",
      "positions (x,y,z), reward: [ 0.0522941  -1.60952048  4.66342095] 108.634661656\n",
      "Episode =  630, score = 234.496 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.01684194  0.09634038  9.87946854] 119.855955151\n",
      "positions (x,y,z), reward: [ -4.52241352e-03   1.61806901e-01   9.74255748e+00] 118.227955061\n",
      "positions (x,y,z), reward: [ 0.24309186  0.40815966  9.17319523] 113.640290167\n",
      "positions (x,y,z), reward: [ 0.44564974  0.46932095  8.84507218] 110.999581728\n",
      "Episode =  631, score = 222.829 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.04244357 -0.02483331  9.91227743] 117.572962993\n",
      "positions (x,y,z), reward: [-0.32971167  0.05626123  9.63753515] 108.647259887\n",
      "positions (x,y,z), reward: [-0.46698847  0.29498913  8.92380311] 108.350280741\n",
      "positions (x,y,z), reward: [ 0.25015164  0.2430517   4.6126413 ] 109.871125833\n",
      "Episode =  632, score = 218.855 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.1154483   0.20642775  9.79886552] 125.277700204\n",
      "positions (x,y,z), reward: [ 0.33736152  1.77497589  5.65090651] 104.665358065\n",
      "positions (x,y,z), reward: [ 0.07868538  2.56891036  1.9578038 ] 94.6192248214\n",
      "Episode =  633, score = 225.463 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.12180451  0.20690047  9.75632057] 120.755355561\n",
      "positions (x,y,z), reward: [ 0.59092049  1.12703245  7.65469767] 117.452976613\n",
      "positions (x,y,z), reward: [ 0.81556967  1.2019791   5.03064121] 106.950878428\n",
      "positions (x,y,z), reward: [ 0.87629997  1.15884652  4.04666546] 104.031598098\n",
      "Episode =  634, score = 225.742 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.07063478  0.09866456  9.67222582] 119.825648594\n",
      "positions (x,y,z), reward: [-0.38544786  0.51563365  8.5729887 ] 119.275263604\n",
      "positions (x,y,z), reward: [-0.76364162  0.77907183  7.62937757] 117.498156869\n",
      "positions (x,y,z), reward: [-2.5938962   1.31972195  4.32937873] 106.070971007\n",
      "positions (x,y,z), reward: [-3.89693412  1.58308592  1.69370913] 97.336442466\n",
      "Episode =  635, score = 225.539 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 3.40249787  1.26406763  3.66799635] 97.3853572674\n",
      "positions (x,y,z), reward: [ 4.189137    1.20409759  2.14327635] 94.7638992693\n",
      "Episode =  636, score = 223.985 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.64546297 -0.11642081  8.6976029 ] 106.908753929\n",
      "positions (x,y,z), reward: [-1.4027072  -0.39295393  2.42261482] 104.576339875\n",
      "Episode =  637, score = 218.702 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.72516049 -0.4042401   1.42782296] 100.446142287\n",
      "Episode =  638, score = 217.470 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.29171105e-03   6.12980117e-03   1.00217842e+01] 122.597775137\n",
      "positions (x,y,z), reward: [ 0.02067466 -0.01887856  9.9350801 ] 114.017714089\n",
      "positions (x,y,z), reward: [ 0.27171861 -0.31973236  9.57982097] 110.536482157\n",
      "positions (x,y,z), reward: [ 0.59464    -1.42492758  6.27495851] 106.381311045\n",
      "positions (x,y,z), reward: [ 0.58542457 -1.47591208  6.08067086] 105.542487394\n",
      "positions (x,y,z), reward: [ 0.48657189 -2.00893949  4.18877435] 102.157734473\n",
      "positions (x,y,z), reward: [ 0.37653301 -2.39095103  2.54834554] 101.751123251\n",
      "Episode =  639, score = 218.172 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.05970886 -0.19479939  9.70082116] 113.957891067\n",
      "positions (x,y,z), reward: [-0.42946519 -1.08124726  2.79593222] 104.381641715\n",
      "positions (x,y,z), reward: [-0.40151387 -1.17656573  2.03172174] 103.089272751\n",
      "Episode =  640, score = 223.144 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  7.91274438e-03   1.77613839e-02   9.89788258e+00] 118.597650268\n",
      "positions (x,y,z), reward: [ -7.88338163e-04   2.69896794e-01   9.75626816e+00] 119.397366416\n",
      "positions (x,y,z), reward: [ 0.12844357  0.42840854  9.59562137] 119.865860808\n",
      "positions (x,y,z), reward: [ 0.27507434  0.57990094  9.32895588] 119.341068565\n",
      "Episode =  641, score = 218.021 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.33480685 -0.2680538   9.23275869] 108.507990668\n",
      "positions (x,y,z), reward: [ 0.36526775 -0.29834925  8.9647252 ] 108.871329198\n",
      "positions (x,y,z), reward: [ 3.12857072 -0.50103128  4.34100524] 98.9504844813\n",
      "Episode =  642, score = 217.206 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.98773176  0.75172356  7.64753721] 113.184857757\n",
      "positions (x,y,z), reward: [ 1.39076346  1.05881486  6.92350064] 110.923501946\n",
      "positions (x,y,z), reward: [ 4.05467716  2.82933745  2.41283364] 91.9001017388\n",
      "Episode =  643, score = 212.415 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  5.78093798e-02   2.35835768e-03   9.85044449e+00] 116.634389767\n",
      "positions (x,y,z), reward: [-0.16236999 -0.08443011  9.42207832] 113.495952404\n",
      "positions (x,y,z), reward: [ 0.02479787 -0.26329909  7.17029177] 112.697510505\n",
      "Episode =  644, score = 225.069 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.1798941  -0.11055745  6.6681236 ] 108.014743901\n",
      "positions (x,y,z), reward: [-0.14751666 -0.20257758  4.68024564] 109.886705927\n",
      "positions (x,y,z), reward: [-0.1959556  -0.24228406  2.66621859] 106.467566369\n",
      "Episode =  645, score = 222.586 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 4.9041919  -1.10464842  0.05257709] 91.1991682023\n",
      "Episode =  646, score = 208.892 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.84604073e-03   9.07731134e-03   1.00179078e+01] 154.897100959\n",
      "Episode =  647, score = 221.175 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.30879189 -0.44995431  9.19970538] 121.725665327\n",
      "positions (x,y,z), reward: [-0.99203265 -0.7797233   6.38591097] 116.526388885\n",
      "positions (x,y,z), reward: [-1.02227196 -1.01061546  4.98927021] 112.813273046\n",
      "Episode =  648, score = 236.624 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.0455554   0.03924697  9.97073009] 116.868470253\n",
      "positions (x,y,z), reward: [-0.76765389  0.35030568  6.47037032] 117.948358378\n",
      "positions (x,y,z), reward: [-0.90809602  0.35805841  6.0878419 ] 116.814860876\n",
      "positions (x,y,z), reward: [-1.33259874  0.58482321  3.95307804] 103.041008875\n",
      "positions (x,y,z), reward: [-1.81177914  0.67600613  0.31402447] 99.0790097681\n",
      "Episode =  649, score = 229.652 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.1844638  -0.02591813  9.82027981] 116.357257713\n",
      "positions (x,y,z), reward: [ 0.76165797 -0.30137535  4.72529929] 107.886120943\n",
      "positions (x,y,z), reward: [ 0.76946324 -0.39804188  1.19109231] 101.924950848\n",
      "Episode =  650, score = 222.862 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.67170389 -0.04348777  8.43354875] 117.892063029\n",
      "positions (x,y,z), reward: [ 1.18687626 -0.03800942  6.39355074] 106.827484527\n",
      "positions (x,y,z), reward: [ 1.40850521 -0.0577471   5.91333309] 105.374480433\n",
      "positions (x,y,z), reward: [ 2.34418422 -0.1372619   3.02802499] 102.568109606\n",
      "Episode =  651, score = 222.659 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.46282627  0.90561545  6.08297736] 106.388402545\n",
      "positions (x,y,z), reward: [ 5.28571626  1.48912343  0.03004016] 92.999018265\n",
      "Episode =  652, score = 224.379 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.96247519 -0.21040147  8.54408671] 107.149830305\n",
      "positions (x,y,z), reward: [ 2.12954555 -0.70662446  6.16414899] 103.519138292\n",
      "positions (x,y,z), reward: [ 2.7857439  -0.89742031  4.8445414 ] 98.1581585008\n",
      "positions (x,y,z), reward: [ 2.88347625 -0.92263255  4.6448278 ] 97.9454070267\n",
      "positions (x,y,z), reward: [ 3.08284908 -0.9704042   4.23018355] 97.6714955924\n",
      "positions (x,y,z), reward: [ 4.51633498 -1.21181975  1.42729176] 82.7235958213\n",
      "Episode =  653, score = 209.940 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.57040848 -2.79894877  1.75902712] 92.9213683736\n",
      "Episode =  654, score = 215.294 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.59731015  0.10701851  9.65759631] 109.011978953\n",
      "positions (x,y,z), reward: [ 1.8078064   0.09628998  8.49094913] 108.701732934\n",
      "positions (x,y,z), reward: [ 1.93131942  0.11021622  8.38856391] 109.64079562\n",
      "positions (x,y,z), reward: [ 2.73163279  0.14827678  7.69760061] 109.430551865\n",
      "positions (x,y,z), reward: [ 3.87382551  0.09983513  6.58624549] 100.151542629\n",
      "positions (x,y,z), reward: [ 4.78981937  0.03921262  5.65130722] 101.570765054\n",
      "positions (x,y,z), reward: [ 7.69050631  0.03986189  1.64013737] 89.4287749446\n",
      "positions (x,y,z), reward: [ 8.39709128  0.06121782  0.34704539] 90.4071680079\n",
      "positions (x,y,z), reward: [ 8.7938611   0.07710661  0.        ] 87.6099000844\n",
      "Episode =  655, score = 211.076 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.17809718e-03   3.72618873e-03   9.97511523e+00] 116.60118933\n",
      "positions (x,y,z), reward: [ 1.03585871 -0.39687602  9.04043178] 118.841527076\n",
      "positions (x,y,z), reward: [ 1.16680858 -0.7831122   7.90203429] 115.675802296\n",
      "positions (x,y,z), reward: [ 1.24985726 -1.08028797  6.97093035] 110.984110328\n",
      "Episode =  657, score = 215.840 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.67628767  0.74592039  8.30292016] 110.528648678\n",
      "positions (x,y,z), reward: [-0.74794611  0.85127327  7.11970482] 113.435309028\n",
      "positions (x,y,z), reward: [-0.76589652  0.86273769  6.75137425] 112.808594431\n",
      "positions (x,y,z), reward: [-0.83778297  0.87644029  5.75607087] 110.3219289\n",
      "positions (x,y,z), reward: [-1.00168367  0.93544315  4.19615355] 106.583260995\n",
      "positions (x,y,z), reward: [-1.16754006  1.0903099   0.56086065] 99.431371566\n",
      "Episode =  658, score = 233.719 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00108248] 146.777533822\n",
      "positions (x,y,z), reward: [ 1.34242716 -1.04726914  6.05885396] 110.013365234\n",
      "positions (x,y,z), reward: [ 1.71394309 -1.41205683  4.55323713] 108.259618304\n",
      "positions (x,y,z), reward: [ 1.90919121 -1.61049079  3.57979404] 106.349212073\n",
      "positions (x,y,z), reward: [ 1.98518509 -1.68659355  3.16197085] 105.329308731\n",
      "Episode =  659, score = 217.563 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.38844246  0.40300676  7.18502396] 113.07261873\n",
      "positions (x,y,z), reward: [-0.51637853  0.63460732  5.05564676] 110.126710327\n",
      "Episode =  660, score = 228.751 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  8.16779319e-03  -3.53980975e-04   9.97711000e+00] 126.066631017\n",
      "positions (x,y,z), reward: [ 0.08712073  0.87781075  8.63226683] 119.191273824\n",
      "positions (x,y,z), reward: [-0.01700632  1.20908509  7.92849904] 117.068555652\n",
      "positions (x,y,z), reward: [-0.53495133  2.61800693  4.04320672] 104.896377802\n",
      "positions (x,y,z), reward: [-0.59108407  2.88283035  3.09017388] 99.6016405559\n",
      "positions (x,y,z), reward: [-0.600643    2.940414    2.84263959] 99.403261891\n",
      "positions (x,y,z), reward: [-0.61243493  2.99773191  2.59117927] 98.9013685713\n",
      "Episode =  661, score = 225.776 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.02720423  0.27432292  9.62415667] 113.512374077\n",
      "positions (x,y,z), reward: [ 1.44759757  1.51358172  6.92565124] 112.575149093\n",
      "Episode =  662, score = 223.676 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.0466688   0.52224467  9.45067079] 122.659292027\n",
      "positions (x,y,z), reward: [ 0.0551467   1.0281859   7.90037028] 116.86890165\n",
      "positions (x,y,z), reward: [-0.33201252  1.06531079  5.58846952] 111.194181286\n",
      "positions (x,y,z), reward: [-0.56215976  0.99400739  3.92425588] 107.263810727\n",
      "positions (x,y,z), reward: [-0.94700017  0.69974572  0.80488643] 99.1307866388\n",
      "Episode =  663, score = 229.178 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  5.75807928e-03  -6.94010966e-03   9.94366333e+00] 122.357526877\n",
      "positions (x,y,z), reward: [-0.20080283 -0.20852088  9.34780767] 113.231336141\n",
      "positions (x,y,z), reward: [-0.24004982 -0.22711836  9.26643736] 113.077930598\n",
      "positions (x,y,z), reward: [-0.48253284 -0.05942924  4.95288874] 110.633975463\n",
      "Episode =  664, score = 225.592 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.27570679  2.15478905  7.63962924] 108.019566166\n",
      "positions (x,y,z), reward: [ 3.15167785  2.95690794  5.68149327] 99.4836043491\n",
      "positions (x,y,z), reward: [ 3.96820848  3.42674771  3.879411  ] 87.9935314921\n",
      "positions (x,y,z), reward: [ 4.06086775  3.47455698  3.65148593] 88.9334845784\n",
      "Episode =  665, score = 219.611 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.51817918e-03   1.28606942e-03   1.00060401e+01] 145.476835069\n",
      "positions (x,y,z), reward: [-0.49278996 -1.48735939  8.54380557] 98.1923985193\n",
      "positions (x,y,z), reward: [-0.59956134 -1.86167076  7.96264268] 95.827375504\n",
      "positions (x,y,z), reward: [-0.56139391 -4.61431095  1.75159719] 97.7255257798\n",
      "Episode =  666, score = 211.468 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.49926079  0.07183669  8.52565209] 107.566545623\n",
      "positions (x,y,z), reward: [ 3.29442431  0.11123169  7.98288891] 105.447379532\n",
      "positions (x,y,z), reward: [ 5.17315521  0.09219984  6.2950373 ] 99.7446748017\n",
      "Episode =  667, score = 211.591 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00127482] 146.795187847\n",
      "positions (x,y,z), reward: [ 0.05223273 -0.36057893  9.42333431] 111.226443951\n",
      "positions (x,y,z), reward: [-0.11578894 -0.82000399  8.51889499] 110.485022596\n",
      "positions (x,y,z), reward: [ 0.24219442 -1.74119477  5.4789797 ] 107.331951632\n",
      "positions (x,y,z), reward: [ 0.26185439 -2.43861596  3.39989197] 103.081497497\n",
      "positions (x,y,z), reward: [ 0.24328996 -3.3337716   0.3155159 ] 96.8700314661\n",
      "positions (x,y,z), reward: [ 0.24501511 -3.41034284  0.04302816] 95.6923433263\n",
      "Episode =  668, score = 220.197 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -8.98980534e-03   1.54545250e-02   1.00108641e+01] 134.262504706\n",
      "positions (x,y,z), reward: [-0.27687057 -0.45876715  9.51236283] 108.069322375\n",
      "positions (x,y,z), reward: [-1.25640566 -1.98523078  4.20211167] 104.821765462\n",
      "Episode =  669, score = 219.243 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.17585858 -0.06697817  9.82632549] 114.771622103\n",
      "positions (x,y,z), reward: [ 0.81608612 -0.91850294  7.69038867] 106.377896894\n",
      "Episode =  670, score = 218.911 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-2.80134712  0.14053555  2.35674523] 104.687825003\n",
      "positions (x,y,z), reward: [-2.87913785  0.15765697  2.12574559] 104.127994493\n",
      "Episode =  671, score = 228.989 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.08610503 -0.32358755  9.30931279] 112.641324012\n",
      "positions (x,y,z), reward: [ 0.13826776 -1.50122745  7.18128116] 102.138239732\n",
      "positions (x,y,z), reward: [ 0.15594068 -1.5967329   7.00742235] 103.760736115\n",
      "Episode =  672, score = 215.349 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.87560402   0.12017766  10.05883809] 123.456267397\n",
      "positions (x,y,z), reward: [ 2.31673285  1.1235859   8.31746293] 109.41210534\n",
      "positions (x,y,z), reward: [ 3.07830873  1.64732921  7.14012641] 98.7733374059\n",
      "positions (x,y,z), reward: [ 3.74790383  1.99110432  6.18249933] 98.3405197956\n",
      "Episode =  673, score = 222.846 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.48534545 -0.0475863   8.44771797] 113.974734362\n",
      "positions (x,y,z), reward: [ 1.69321908 -0.06883352  8.23462135] 112.994588903\n",
      "positions (x,y,z), reward: [ 2.25695351 -0.06328629  7.67544747] 111.774615848\n",
      "positions (x,y,z), reward: [ 3.82798896  0.02185757  5.79654223] 107.953572883\n",
      "positions (x,y,z), reward: [ 4.28019028  0.03672501  5.06617246] 105.267735107\n",
      "positions (x,y,z), reward: [ 5.9166064  0.0488079  1.5977074] 98.549699263\n",
      "Episode =  674, score = 220.677 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.08258236 -0.02889748  9.99521533] 123.855992384\n",
      "positions (x,y,z), reward: [-0.17606459 -0.29225801  9.30876881] 121.735060733\n",
      "positions (x,y,z), reward: [-1.95563252 -1.17682823  4.85802949] 106.756505475\n",
      "Episode =  675, score = 227.957 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.15254283 -0.07091571  9.79594762] 115.303980218\n",
      "positions (x,y,z), reward: [ 0.73686018 -1.17233797  8.38959607] 110.140186087\n",
      "positions (x,y,z), reward: [ 1.06722987 -2.62100115  4.19795617] 106.221812243\n",
      "positions (x,y,z), reward: [ 1.07155723 -2.75433891  3.56160013] 104.688651837\n",
      "positions (x,y,z), reward: [ 1.07349216 -2.79888141  3.34360429] 104.187723919\n",
      "positions (x,y,z), reward: [ 1.10746029 -3.16360228  1.4651265 ] 98.4005265181\n",
      "positions (x,y,z), reward: [ 1.18064662 -3.43520424  0.16588463] 92.8568185021\n",
      "Episode =  676, score = 219.688 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.24998431e-02   2.95528634e-04   1.00031793e+01] 137.102882425\n",
      "positions (x,y,z), reward: [ -1.77589325e-01   5.02671257e-03   9.93734117e+00] 111.369294262\n",
      "Episode =  677, score = 223.761 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.26514381  0.10654237  9.84588691] 114.919667619\n",
      "positions (x,y,z), reward: [ 7.23845865  1.74173104  0.0337236 ] 90.6111258977\n",
      "Episode =  678, score = 217.820 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.0673275  -0.20221464  9.79974022] 119.030354738\n",
      "positions (x,y,z), reward: [ 0.20353845 -0.71895108  8.43058953] 116.662102954\n",
      "positions (x,y,z), reward: [ 0.38486268 -0.84341728  7.3178462 ] 115.1435368\n",
      "positions (x,y,z), reward: [ 0.41064256 -0.84998301  7.17645173] 113.980844642\n",
      "positions (x,y,z), reward: [ 1.2903654  -1.21980013  3.10206498] 102.936801311\n",
      "Episode =  679, score = 228.340 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.87942451e-02  -5.52400387e-03   9.98381313e+00] 125.9346978\n",
      "positions (x,y,z), reward: [-0.22827797  0.15674251  9.46771469] 117.979719713\n",
      "positions (x,y,z), reward: [-0.52590764  0.32545077  4.53362197] 109.962996945\n",
      "positions (x,y,z), reward: [-0.54085374  0.31153725  4.2969735 ] 109.367171251\n",
      "positions (x,y,z), reward: [-0.63110278 -0.05780037  1.17792387] 101.959660135\n",
      "Episode =  680, score = 229.190 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.65063652  0.58699682  9.1427479 ] 119.162303157\n",
      "positions (x,y,z), reward: [ 1.49814795  1.68440887  1.0796351 ] 99.2060083085\n",
      "Episode =  681, score = 224.005 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.64086296e-02  -7.42630011e-03   9.95685229e+00] 116.103027025\n",
      "positions (x,y,z), reward: [ 1.00913129 -1.38389128  6.00652767] 106.848103759\n",
      "positions (x,y,z), reward: [ 1.17773711 -1.43961263  5.64220471] 106.112551191\n",
      "positions (x,y,z), reward: [ 1.73518234 -1.61570204  4.49898568] 100.911400942\n",
      "Episode =  682, score = 219.744 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04233146 -0.01871681  9.94986921] 122.79440998\n",
      "positions (x,y,z), reward: [-0.39306579  0.37767055  8.19951733] 113.764492838\n",
      "positions (x,y,z), reward: [-0.72219555  0.60292175  7.14625396] 113.453649118\n",
      "positions (x,y,z), reward: [-0.9854101   0.7107627   6.14129412] 112.495704776\n",
      "positions (x,y,z), reward: [-1.10487923  0.75378801  5.62664129] 111.695054969\n",
      "positions (x,y,z), reward: [-1.35130561  0.85258743  3.51855756] 105.548408869\n",
      "Episode =  683, score = 224.950 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.79509804  0.61288137  9.13627745] 120.5865681\n",
      "positions (x,y,z), reward: [ 1.52713269  1.07061298  5.96589424] 105.434246189\n",
      "positions (x,y,z), reward: [ 2.65729974  1.03943684  0.7160251 ] 97.5066933248\n",
      "Episode =  684, score = 235.362 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.17122842 -0.44453319  9.46755946] 113.114442716\n",
      "Episode =  685, score = 212.007 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.32078568 -0.26537177  9.18376968] 109.869842979\n",
      "positions (x,y,z), reward: [ 0.6500775  -0.58547431  7.86644195] 110.727522019\n",
      "positions (x,y,z), reward: [ 0.87649122 -0.69736411  7.26755957] 110.447133121\n",
      "positions (x,y,z), reward: [ 1.56845357 -1.00315227  4.76816745] 99.8380324503\n",
      "positions (x,y,z), reward: [ 1.77719125 -1.04895791  3.93374433] 101.380219495\n",
      "positions (x,y,z), reward: [ 2.5835484  -1.16355909  0.44021051] 85.1164936692\n",
      "Episode =  686, score = 212.554 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.5743563   0.34181055  8.28207413] 117.354198686\n",
      "positions (x,y,z), reward: [ 0.53376441 -0.06632468  3.71356979] 107.949378785\n",
      "positions (x,y,z), reward: [ 0.82750313 -0.22897614  0.98799785] 100.421533825\n",
      "Episode =  687, score = 227.743 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.26300494 -0.13060359  9.35670565] 118.300454951\n",
      "positions (x,y,z), reward: [-1.06866593  0.41848115  7.31393348] 113.887657914\n",
      "positions (x,y,z), reward: [-1.2708491   0.5764142   6.76143372] 112.189361727\n",
      "positions (x,y,z), reward: [-3.30672522  1.92643133  1.66303862] 95.6269597341\n",
      "Episode =  688, score = 222.776 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.21522786 -0.3880934   8.41312427] 110.681736978\n",
      "positions (x,y,z), reward: [-0.0724135  -0.48726974  7.57233182] 115.76609613\n",
      "positions (x,y,z), reward: [ 0.61202577 -0.82419163  1.73918528] 91.295589181\n",
      "Episode =  689, score = 218.967 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.04867236e-01  -3.02730357e-03   9.49207602e+00] 110.776333337\n",
      "positions (x,y,z), reward: [ 0.80759009 -0.14397483  8.60300414] 105.463281793\n",
      "positions (x,y,z), reward: [ 1.66174224 -1.37641692  0.14143538] 95.321098597\n",
      "Episode =  690, score = 215.674 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.16830349 -0.26589074  9.80063827] 115.049683659\n",
      "positions (x,y,z), reward: [ 2.15590459 -2.35197375  2.2967707 ] 95.0714030037\n",
      "Episode =  691, score = 220.690 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.64316228  0.46742436  8.42315134] 115.019247732\n",
      "positions (x,y,z), reward: [ 1.04495553  0.73598483  7.39432451] 108.903174575\n",
      "positions (x,y,z), reward: [ 1.59831741  0.90451647  6.04686163] 107.58916344\n",
      "Episode =  692, score = 223.919 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.01579411  0.44604644  9.05845792] 110.832208661\n",
      "positions (x,y,z), reward: [-1.45794166  0.69335269  7.64961289] 109.849788717\n",
      "positions (x,y,z), reward: [-1.27484062  0.96243299  6.03024648] 109.428256173\n",
      "positions (x,y,z), reward: [-1.31429355  1.15544768  4.4513128 ] 110.061013216\n",
      "positions (x,y,z), reward: [-1.33349785  1.23130085  3.66892392] 108.283203671\n",
      "positions (x,y,z), reward: [-1.34729287  1.26918384  3.25544473] 107.100072347\n",
      "positions (x,y,z), reward: [-1.53158046  1.43721146  1.21552384] 100.736579794\n",
      "Episode =  693, score = 220.832 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.77541214e-01   8.12711300e-03   9.78603459e+00] 114.01479633\n",
      "positions (x,y,z), reward: [ 1.45212944  0.09073486  9.42679056] 117.201654183\n",
      "positions (x,y,z), reward: [ 2.55783248 -0.16996643  7.95369068] 116.141881751\n",
      "positions (x,y,z), reward: [ 2.69146482 -0.26149722  7.43865316] 115.234559024\n",
      "Episode =  694, score = 222.745 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.55104494  0.51120009  7.93701054] 112.536473765\n",
      "positions (x,y,z), reward: [ 0.62164837  0.66643991  7.38293317] 113.099636639\n",
      "positions (x,y,z), reward: [ 1.28716673  1.80623273  1.74252448] 98.6354322531\n",
      "positions (x,y,z), reward: [ 1.38272827  1.9504779   0.641611  ] 96.3822876595\n",
      "Episode =  695, score = 226.479 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.01974894 -0.0378232   9.8779274 ] 114.058225754\n",
      "positions (x,y,z), reward: [ 0.02093604 -0.05003195  9.83582397] 111.086606311\n",
      "positions (x,y,z), reward: [ 0.25210314 -0.13870536  9.48158488] 102.730948233\n",
      "positions (x,y,z), reward: [ 1.49985904 -0.66110469  7.45489241] 106.288749004\n",
      "positions (x,y,z), reward: [ 1.9636771  -0.78778688  6.97968074] 108.203165962\n",
      "positions (x,y,z), reward: [ 4.63104976 -1.19649289  3.83244053] 95.6393134013\n",
      "Episode =  696, score = 204.151 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -0.01424128   0.01509672  10.01033593] 121.501345386\n",
      "positions (x,y,z), reward: [ -0.01174897   0.01809199  10.00179361] 119.918325856\n",
      "positions (x,y,z), reward: [ 2.61371529  2.10928614  6.32980211] 105.365986678\n",
      "positions (x,y,z), reward: [ 3.37380946  2.7183392   4.39645616] 100.980043321\n",
      "Episode =  697, score = 219.935 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.20508432  1.63447653  5.07164524] 106.008348685\n",
      "positions (x,y,z), reward: [-0.03918445  2.30134424  1.89292091] 99.0827764917\n",
      "Episode =  698, score = 225.478 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.6349394  -0.6967185   9.41093795] 115.022612598\n",
      "positions (x,y,z), reward: [ 2.70502337 -1.30318916  8.06992645] 100.322619165\n",
      "positions (x,y,z), reward: [ 4.28123811 -2.92875958  1.20810451] 85.2366540634\n",
      "Episode =  699, score = 211.543 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  5.91309938e-03  -4.21123616e-03   9.97963429e+00] 126.592487446\n",
      "positions (x,y,z), reward: [-0.16237813 -0.17513774  9.41399339] 112.367756961\n",
      "positions (x,y,z), reward: [ 0.56203381  0.0350431   4.02366446] 101.276534796\n",
      "positions (x,y,z), reward: [ 0.80098298  0.05760621  3.04980476] 94.9273319293\n",
      "positions (x,y,z), reward: [ 1.53890692  0.0838634   0.38745953] 85.6176619338\n",
      "Episode =  700, score = 216.490 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.99702444 -0.18076155  7.75839245] 105.783336006\n",
      "positions (x,y,z), reward: [ 3.20773589 -0.15420205  7.6298616 ] 106.078812395\n",
      "positions (x,y,z), reward: [ 10.41562742   0.72364385   2.59038139] 85.8695126624\n",
      "positions (x,y,z), reward: [ 12.42521047   0.81129702   0.71034624] 85.1051618672\n",
      "Episode =  701, score = 210.604 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.19950218  0.01263951  9.8946549 ] 116.650188865\n",
      "positions (x,y,z), reward: [  4.29269579e-01  -8.46131399e-03   9.75594445e+00] 113.872708695\n",
      "positions (x,y,z), reward: [ 1.11860909  0.2288986   9.02185491] 110.994883397\n",
      "positions (x,y,z), reward: [ 2.78962656  1.11460338  2.5837325 ] 99.9836448773\n",
      "Episode =  702, score = 216.812 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.42261367 -0.60593286  8.95634884] 109.223879688\n",
      "positions (x,y,z), reward: [ 3.69096914 -1.48592709  5.01235941] 95.2694699003\n",
      "positions (x,y,z), reward: [ 4.98633888 -2.19022721  0.04176034] 90.0127028658\n",
      "Episode =  703, score = 216.071 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.32893846e-02   1.18607940e-04   1.00030908e+01] 137.772378485\n",
      "positions (x,y,z), reward: [ 0.45678538 -1.12651377  7.56436462] 109.728659485\n",
      "positions (x,y,z), reward: [ 0.49857092 -1.17489341  7.42326247] 108.338559365\n",
      "positions (x,y,z), reward: [ 0.79707247 -1.41031365  6.65092535] 106.262130125\n",
      "positions (x,y,z), reward: [ 1.29239972 -1.68262388  5.60716525] 102.899730622\n",
      "positions (x,y,z), reward: [ 3.18966283 -2.69737794  0.85975907] 91.9817700594\n",
      "positions (x,y,z), reward: [ 3.28119644 -2.74673208  0.59140162] 91.6153582696\n",
      "Episode =  704, score = 217.851 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.82087299  0.15298945  9.09981508] 107.506617661\n",
      "positions (x,y,z), reward: [-1.08004448  0.21721442  7.93322165] 115.846792203\n",
      "positions (x,y,z), reward: [-1.45400147  0.40808422  5.93031807] 111.127654591\n",
      "positions (x,y,z), reward: [-1.47012055  0.7456107   3.64352977] 104.184471649\n",
      "positions (x,y,z), reward: [-1.49040985  0.89912391  2.62510185] 101.791551177\n",
      "Episode =  705, score = 223.099 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.09164208  -0.01819875  10.00468187] 135.201181673\n",
      "positions (x,y,z), reward: [ 0.14344459 -0.03367658  9.98977257] 126.587070164\n",
      "positions (x,y,z), reward: [ 0.04452231  0.18673001  9.70757882] 125.924939466\n",
      "positions (x,y,z), reward: [  8.59980114e-03   3.01790022e-01   9.42540729e+00] 121.67859178\n",
      "positions (x,y,z), reward: [ 0.44305934  0.44871051  7.94877001] 114.653420514\n",
      "Episode =  706, score = 230.961 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.72425859e-03   2.58071257e-05   1.00021618e+01] 144.803724328\n",
      "positions (x,y,z), reward: [ 0.04237062 -0.01853597  9.96083347] 124.00656145\n",
      "positions (x,y,z), reward: [ 0.01234356 -0.10743253  9.74706213] 123.474556579\n",
      "positions (x,y,z), reward: [-0.08005605 -0.17713185  9.54694382] 123.666150462\n",
      "Episode =  707, score = 221.445 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.30321171  0.5142056   9.06343912] 115.831216775\n",
      "positions (x,y,z), reward: [-0.27386352  0.55708454  8.96953343] 116.142754477\n",
      "positions (x,y,z), reward: [ 0.15066838  1.03212192  6.89498112] 112.927342594\n",
      "positions (x,y,z), reward: [ 0.58574658  2.72572351  1.48328866] 101.382799988\n",
      "Episode =  708, score = 225.043 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.79794784  2.28760706  3.66498717] 103.576855109\n",
      "positions (x,y,z), reward: [ 1.85698851  2.40045255  3.18833678] 102.918845952\n",
      "Episode =  709, score = 224.325 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.60317008 -0.78996388  7.58214032] 108.416261709\n",
      "positions (x,y,z), reward: [-0.69043654 -1.64971497  4.8682976 ] 106.361558289\n",
      "Episode =  710, score = 218.290 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  7.75341456e-03   8.92859583e-03   9.93156446e+00] 124.520339898\n",
      "positions (x,y,z), reward: [ 0.23822577  0.03095655  9.71123258] 123.453936049\n",
      "positions (x,y,z), reward: [ 1.24275667 -0.43388284  8.39792288] 116.503054093\n",
      "positions (x,y,z), reward: [ 1.7465105  -0.46247351  7.6235801 ] 107.992957019\n",
      "positions (x,y,z), reward: [ 1.82028064 -0.46341201  7.51542993] 107.533055329\n",
      "positions (x,y,z), reward: [ 5.4237961  -0.41017886  2.56154398] 97.5795896327\n",
      "Episode =  711, score = 214.433 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.98128286 -0.10343446  9.53369187] 115.691682342\n",
      "positions (x,y,z), reward: [ 2.85706822  2.03803675  3.07593646] 95.3652737177\n",
      "positions (x,y,z), reward: [ 2.97419285  2.2292577   2.21789159] 93.9121231889\n",
      "Episode =  712, score = 215.224 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.61369639 -1.89020044  4.18965609] 103.250045109\n",
      "positions (x,y,z), reward: [ 0.68463399 -2.46692744  1.4977906 ] 98.9073232806\n",
      "Episode =  713, score = 223.007 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.09162921 -0.23232017  9.31939069] 110.927909191\n",
      "Episode =  714, score = 214.773 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.18245696  0.01549174  9.85930356] 109.909861617\n",
      "positions (x,y,z), reward: [ 2.13685591  0.16856425  8.23675189] 105.089101913\n",
      "positions (x,y,z), reward: [ 2.40191512  0.1842648   7.84844389] 100.639549254\n",
      "positions (x,y,z), reward: [ 4.21024432  0.30322232  4.18564762] 96.0827466792\n",
      "positions (x,y,z), reward: [ 4.78501778  0.34838055  3.02976003] 92.8245051899\n",
      "positions (x,y,z), reward: [ 5.01033511  0.36990573  2.55558832] 91.3028383885\n",
      "positions (x,y,z), reward: [ 5.78326569  0.45069991  0.76604668] 93.0005610245\n",
      "Episode =  715, score = 209.435 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.09394296  0.94225759  8.56406448] 116.56344367\n",
      "positions (x,y,z), reward: [-0.92245824  1.73187647  6.01930237] 111.097035915\n",
      "positions (x,y,z), reward: [-1.7794334   2.45289458  2.8945633 ] 102.494063255\n",
      "Episode =  716, score = 225.123 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.09196394 -1.18268538  5.11547645] 109.66410243\n",
      "positions (x,y,z), reward: [ 0.00986606 -1.29390257  4.29443637] 107.788034991\n",
      "positions (x,y,z), reward: [-0.37405811 -1.64038498  1.30867168] 101.717126573\n",
      "Episode =  717, score = 228.263 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.59816464e-02  -2.63053372e-03   9.96927801e+00] 125.066642621\n",
      "positions (x,y,z), reward: [ 0.17102542  0.04360995  9.81604421] 121.248270772\n",
      "positions (x,y,z), reward: [ 0.91744297  0.01557556  9.10408425] 119.421663329\n",
      "positions (x,y,z), reward: [ 3.62184719  0.71394195  3.36999182] 103.334237358\n",
      "Episode =  718, score = 225.198 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.33302358 -0.19606961  9.68787682] 125.985560521\n",
      "positions (x,y,z), reward: [-0.45971276 -0.25910334  9.54749677] 125.442971282\n",
      "positions (x,y,z), reward: [-0.93845278 -0.37828724  9.05344449] 123.324749643\n",
      "positions (x,y,z), reward: [-1.19498416 -0.39612752  8.66641644] 120.278303273\n",
      "Episode =  719, score = 230.935 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.23802878 -0.25189532  8.68791392] 120.926112492\n",
      "positions (x,y,z), reward: [-0.62839932 -0.40758692  7.54512924] 117.795449206\n",
      "positions (x,y,z), reward: [-1.83512791 -0.67828591  4.56303957] 108.283518347\n",
      "positions (x,y,z), reward: [-2.18161444 -0.72270079  3.67654835] 105.694178435\n",
      "positions (x,y,z), reward: [-3.4603409  -0.88013476  0.41430739] 95.6416660512\n",
      "positions (x,y,z), reward: [-3.7968762  -0.93306819  0.        ] 90.6452820256\n",
      "Episode =  720, score = 231.648 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.1689992  -0.03392302  9.60908501] 107.331417852\n",
      "positions (x,y,z), reward: [ 0.65039128 -0.01350933  9.28654181] 113.560927625\n",
      "positions (x,y,z), reward: [ 3.15058926  0.20292642  7.90526365] 110.431365974\n",
      "positions (x,y,z), reward: [ 3.87214918  0.36582672  7.22776282] 98.7268624487\n",
      "positions (x,y,z), reward: [ 4.83860111  0.66603849  5.90846803] 96.0201490104\n",
      "Episode =  721, score = 207.771 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 4.42528676  1.51697359  7.71110418] 105.168365205\n",
      "positions (x,y,z), reward: [ 7.00340038  2.39351928  5.64491769] 97.4457613786\n",
      "positions (x,y,z), reward: [ 8.34233684  2.83092683  4.38274227] 96.649797229\n",
      "Episode =  722, score = 214.359 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.1140635   0.01795464  9.75263938] 112.268002964\n",
      "positions (x,y,z), reward: [ 2.32570862 -0.47703015  7.22213496] 111.516727782\n",
      "Episode =  723, score = 219.427 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.43162577e-02   7.10470087e-03   1.00156400e+01] 141.796920224\n",
      "positions (x,y,z), reward: [ 1.03826018 -0.83374031  5.17504838] 109.160994267\n",
      "positions (x,y,z), reward: [ 1.3914759  -1.24921342  2.52139054] 102.243260188\n",
      "Episode =  724, score = 223.734 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  6.96038319e-04  -4.35826623e-05   9.99148251e+00] 138.813439696\n",
      "positions (x,y,z), reward: [  2.58217525e-03  -8.33949310e-05   9.98338533e+00] 126.959247999\n",
      "positions (x,y,z), reward: [ 0.14826922  0.03086372  8.12337591] 118.647329519\n",
      "positions (x,y,z), reward: [ 0.12212686  0.02830906  7.98932751] 118.625925266\n",
      "positions (x,y,z), reward: [-0.36152149  0.05549538  5.06704256] 107.77622201\n",
      "positions (x,y,z), reward: [-0.49103468  0.05646388  3.09352497] 103.00016504\n",
      "positions (x,y,z), reward: [-0.54302048  0.06574569  2.44452794] 102.24949764\n",
      "positions (x,y,z), reward: [-0.64688202  0.10310773  1.26005329] 100.28418646\n",
      "Episode =  725, score = 225.994 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  4.83479830e-03  -2.52359140e-03   9.97792843e+00] 126.024076978\n",
      "positions (x,y,z), reward: [  2.29028167e-04   9.72875263e-03   9.92282059e+00] 119.459227289\n",
      "positions (x,y,z), reward: [-0.42258176 -0.07913233  9.25881902] 113.648045273\n",
      "positions (x,y,z), reward: [-0.4336071  -0.06804536  9.1923639 ] 113.21996551\n",
      "positions (x,y,z), reward: [-0.41689051 -0.06369282  8.83237447] 109.978929593\n",
      "positions (x,y,z), reward: [-0.41417782 -0.07173179  8.71577149] 109.138311583\n",
      "positions (x,y,z), reward: [-0.64244815 -0.18454622  7.20726041] 116.172388044\n",
      "positions (x,y,z), reward: [-0.70543932 -0.20805087  6.89575819] 115.422629404\n",
      "positions (x,y,z), reward: [-1.03760803 -0.35557567  5.04916396] 108.17594991\n",
      "positions (x,y,z), reward: [-1.32922712 -0.40480515  3.50831254] 103.31933975\n",
      "Episode =  726, score = 222.085 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -4.10511298e-03  -1.66858530e-03   1.00382099e+01] 145.788600653\n",
      "positions (x,y,z), reward: [ 0.01865389 -0.10221133  9.99303933] 122.518523407\n",
      "positions (x,y,z), reward: [-1.76765563 -1.95300686  2.65756744] 102.501461511\n",
      "positions (x,y,z), reward: [-1.91709793 -2.04708272  2.16402104] 101.278165778\n",
      "Episode =  727, score = 231.588 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.08789272  -0.02998655  10.03652875] 140.198024904\n",
      "positions (x,y,z), reward: [  0.06761535  -0.07449641  10.0105197 ] 123.059290739\n",
      "positions (x,y,z), reward: [-0.19419063 -0.23210293  9.20171681] 121.63953432\n",
      "Episode =  728, score = 233.756 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.78458477 -0.43587676  8.96460645] 102.732107693\n",
      "positions (x,y,z), reward: [ 2.14453019 -0.60664567  8.59547703] 99.7740617589\n",
      "positions (x,y,z), reward: [ 7.65187619 -2.2183549   1.56573694] 82.2123538507\n",
      "Episode =  729, score = 200.062 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.28362011  1.28222301  7.95481065] 117.064062627\n",
      "positions (x,y,z), reward: [ 0.53814983  1.95125343  5.68618878] 103.990105712\n",
      "positions (x,y,z), reward: [ 0.71030993  2.1894915   4.73802651] 98.208078371\n",
      "positions (x,y,z), reward: [ 0.8199822   2.36753079  3.964597  ] 95.2705097673\n",
      "positions (x,y,z), reward: [ 1.5034135   3.15701802  0.        ] 83.9009817646\n",
      "Episode =  730, score = 217.521 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.44067262e-02   4.45441283e-03   1.00080829e+01] 136.435805716\n",
      "positions (x,y,z), reward: [ 1.68745389  0.74934562  8.04868928] 112.196238542\n",
      "positions (x,y,z), reward: [ 2.35791573  0.83170323  7.31439136] 110.847247175\n",
      "positions (x,y,z), reward: [ 4.41974312  1.08217193  4.41362585] 98.6537776384\n",
      "positions (x,y,z), reward: [ 4.55208847  1.09620831  4.18938176] 98.5374524648\n",
      "positions (x,y,z), reward: [ 4.68363626  1.11149334  3.9602663 ] 98.5282632295\n",
      "positions (x,y,z), reward: [ 4.81462033  1.1281511   3.7258216 ] 98.366161384\n",
      "positions (x,y,z), reward: [ 6.38090563  1.38148551  0.65952101] 93.4361536293\n",
      "Episode =  731, score = 218.252 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.07992431 -0.01055239  9.98097812] 120.495448222\n",
      "positions (x,y,z), reward: [ 2.15099589 -0.8898105   7.77887826] 106.899817649\n",
      "positions (x,y,z), reward: [ 2.56373047 -1.13704554  6.85719114] 104.26153964\n",
      "Episode =  732, score = 208.711 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.11327307 -1.04157834  6.99564742] 104.936062042\n",
      "positions (x,y,z), reward: [-0.4054406  -1.95736219  3.56745966] 101.947775311\n",
      "positions (x,y,z), reward: [-0.4922417  -2.34949738  1.78849526] 95.6237111613\n",
      "Episode =  733, score = 219.567 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.07873927  0.09987241  9.92721609] 116.600832519\n",
      "positions (x,y,z), reward: [ 0.13278945  0.13850207  9.91981506] 115.830461947\n",
      "positions (x,y,z), reward: [ 2.58063579  0.60219312  7.97578038] 113.895652343\n",
      "Episode =  734, score = 214.218 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.97368302 -1.08154046  3.5711924 ] 105.398400917\n",
      "Episode =  735, score = 217.582 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.04667153   0.02030726  10.01223384] 124.098685093\n",
      "positions (x,y,z), reward: [ 0.81391757  0.26938722  7.51531168] 105.443330221\n",
      "positions (x,y,z), reward: [ 0.78883068  0.29097241  5.66317786] 109.102145095\n",
      "positions (x,y,z), reward: [ 0.78307179  0.29490996  5.4651921 ] 108.654899486\n",
      "positions (x,y,z), reward: [ 1.54463914  0.38115448  0.98487552] 92.3011631029\n",
      "Episode =  736, score = 223.150 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.15487893  0.48627376  9.9262225 ] 114.396055328\n",
      "positions (x,y,z), reward: [ 0.05990226  1.08073144  9.10286129] 109.659948\n",
      "positions (x,y,z), reward: [ 0.44681754  1.29636141  8.43500253] 107.6145837\n",
      "positions (x,y,z), reward: [ 1.36184378  1.08386351  1.36567079] 103.346265211\n",
      "Episode =  737, score = 225.342 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.10667146  0.22084616  9.90320273] 114.551226203\n",
      "positions (x,y,z), reward: [ 0.63024655  0.73578617  9.13660171] 118.261745256\n",
      "positions (x,y,z), reward: [ 1.32913938  1.19491086  7.53492294] 110.699898855\n",
      "positions (x,y,z), reward: [ 3.55630406  1.9097148   0.        ] 92.9117610524\n",
      "Episode =  738, score = 222.661 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.34860568  0.13843741  9.61740488] 119.855243003\n",
      "positions (x,y,z), reward: [ 0.40769195  0.54342751  7.92483056] 118.334468158\n",
      "positions (x,y,z), reward: [ 0.41142004  0.58411353  7.79975599] 117.918638603\n",
      "positions (x,y,z), reward: [ 0.48204389  0.97021003  6.42814226] 114.329749691\n",
      "positions (x,y,z), reward: [ 0.38741443  1.82114617  2.74132676] 101.771115775\n",
      "positions (x,y,z), reward: [ 0.35745794  1.99683479  1.89239241] 99.0541574884\n",
      "Episode =  739, score = 225.761 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.95430802e-02   6.46801365e-03   9.98484360e+00] 120.009253054\n",
      "positions (x,y,z), reward: [ 0.73194642  0.90135354  9.2124772 ] 107.045511585\n",
      "positions (x,y,z), reward: [ 0.92429672  1.07717499  9.00316195] 108.286651082\n",
      "positions (x,y,z), reward: [ 4.19115356  2.36780677  6.08070199] 106.162707028\n",
      "positions (x,y,z), reward: [ 4.60630324  2.54413962  5.58161335] 102.949931596\n",
      "Episode =  740, score = 214.258 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.07172599   0.01987394  10.00536617] 123.892005472\n",
      "positions (x,y,z), reward: [ 1.41076543  0.29544907  9.31771089] 108.503546722\n",
      "positions (x,y,z), reward: [ 2.44472446  0.34138152  7.70630609] 106.493228068\n",
      "positions (x,y,z), reward: [ 2.71394784  0.37133256  7.07214852] 106.395343154\n",
      "positions (x,y,z), reward: [ 5.99923595  0.47806595  0.        ] 88.1330704149\n",
      "Episode =  741, score = 208.534 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.56059391e-04   7.60544511e-04   1.00068728e+01] 150.825091443\n",
      "positions (x,y,z), reward: [ 0.87050079  0.23107362  9.85762494] 109.445971439\n",
      "positions (x,y,z), reward: [ 2.81644755  0.75153438  7.73532752] 107.455245904\n",
      "positions (x,y,z), reward: [ 4.25607997  1.46479544  5.74299504] 100.638951658\n",
      "positions (x,y,z), reward: [ 6.52919978  2.72579899  0.31307405] 92.5018756712\n",
      "positions (x,y,z), reward: [ 6.72808555  2.82064631  0.        ] 92.2519908993\n",
      "Episode =  742, score = 215.652 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.41816579  0.59484682  9.04078243] 118.029145711\n",
      "positions (x,y,z), reward: [-0.61587568  0.91645551  8.39857987] 120.646800335\n",
      "positions (x,y,z), reward: [-1.4406801   1.7221504   4.62271576] 106.10390976\n",
      "positions (x,y,z), reward: [-1.45672806  1.40474265  1.91330052] 100.688043859\n",
      "positions (x,y,z), reward: [-1.37549782  1.17694815  0.63052234] 97.8598394584\n",
      "Episode =  743, score = 228.177 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.48369937 -0.29828316  8.8801571 ] 108.715455566\n",
      "positions (x,y,z), reward: [-0.78196094 -1.31935073  5.30164469] 107.465311985\n",
      "positions (x,y,z), reward: [-0.65420203 -1.46800736  4.03206965] 105.913552265\n",
      "Episode =  744, score = 219.303 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.93378513 -0.19531345  8.66606151] 111.427507271\n",
      "positions (x,y,z), reward: [ 3.23237332 -0.62862582  6.41873222] 110.708819642\n",
      "positions (x,y,z), reward: [ 4.4707426  -1.28854799  2.67436562] 92.0493109347\n",
      "Episode =  745, score = 217.355 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.30323248  0.60689054  9.44253601] 116.944803116\n",
      "positions (x,y,z), reward: [-0.47575949  1.47844124  8.53475998] 118.86999631\n",
      "positions (x,y,z), reward: [-0.62414676  1.80950787  8.16565505] 117.67671196\n",
      "positions (x,y,z), reward: [-0.6641641   1.89874725  8.06402253] 117.51215855\n",
      "positions (x,y,z), reward: [-1.30773284  3.75405655  5.11660112] 100.985000215\n",
      "positions (x,y,z), reward: [-1.7485521   5.57817334  0.71995585] 92.558441339\n",
      "Episode =  746, score = 222.420 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.26522364e-02   4.04479975e-04   1.00062992e+01] 142.943596355\n",
      "positions (x,y,z), reward: [-0.37138883 -0.04450049  9.14959763] 121.462960702\n",
      "positions (x,y,z), reward: [-0.78874692 -0.13995078  8.03978591] 116.947551984\n",
      "positions (x,y,z), reward: [-1.16551034 -0.11879213  4.94952422] 109.400991319\n",
      "positions (x,y,z), reward: [-0.59927328  0.55752377  0.353261  ] 98.3077164045\n",
      "Episode =  747, score = 231.639 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.19819369  -0.01597356  10.07997662] 143.055442727\n",
      "positions (x,y,z), reward: [ 7.41161624 -1.75037882  1.43046605] 87.2831710743\n",
      "Episode =  748, score = 214.171 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.32517518e-03   4.28413907e-04   1.00046032e+01] 145.305058934\n",
      "positions (x,y,z), reward: [ 0.99514386  0.83368191  8.77303375] 117.271772063\n",
      "positions (x,y,z), reward: [ 2.25111625  1.23585282  7.15355945] 107.342734193\n",
      "positions (x,y,z), reward: [ 2.51036391  1.30022802  6.78583264] 103.515224004\n",
      "Episode =  749, score = 214.471 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.41703627  0.75664046  8.99436942] 122.644900966\n",
      "positions (x,y,z), reward: [ 0.45433848  0.83974591  8.77355335] 121.603907616\n",
      "positions (x,y,z), reward: [ 0.46736036  0.91838889  8.53544578] 119.855183922\n",
      "positions (x,y,z), reward: [ 0.60901937  1.03723579  7.24974619] 114.462625267\n",
      "Episode =  750, score = 227.254 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.34485205  0.02280802  9.3041311 ] 116.182946492\n",
      "positions (x,y,z), reward: [-0.31873275 -0.08570383  8.83873737] 114.773246847\n",
      "positions (x,y,z), reward: [-0.46946223 -0.54377215  7.431416  ] 117.357691132\n",
      "positions (x,y,z), reward: [-0.66002783 -0.55302977  4.82646622] 110.1960633\n",
      "Episode =  751, score = 229.415 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.15733285 -0.07054874  9.68337275] 106.655212967\n",
      "positions (x,y,z), reward: [-0.80251996 -0.69042201  7.18350624] 101.340161656\n",
      "positions (x,y,z), reward: [-1.20679992 -1.01497616  5.70539493] 108.774106595\n",
      "positions (x,y,z), reward: [-1.75990792 -1.42480522  3.78598947] 104.541943781\n",
      "Episode =  752, score = 217.600 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.08835256e-01   4.79803585e-03   9.65035213e+00] 113.001192836\n",
      "positions (x,y,z), reward: [-0.48839525  0.07222966  9.17820419] 112.362066399\n",
      "positions (x,y,z), reward: [ 1.74828662 -0.38275503  2.41873731] 100.290258955\n",
      "positions (x,y,z), reward: [ 2.56658429 -0.40874788  0.85121263] 95.8194525135\n",
      "positions (x,y,z), reward: [ 3.0289085  -0.43602833  0.        ] 96.4403720937\n",
      "Episode =  753, score = 222.479 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.02535384   0.01332276  10.02241354] 142.026782659\n",
      "positions (x,y,z), reward: [ 0.01925916  0.31098436  8.7871735 ] 114.897514121\n",
      "positions (x,y,z), reward: [ 0.36055503  0.51599622  8.13113421] 115.808058487\n",
      "positions (x,y,z), reward: [ 0.7160233   0.58462627  7.44648043] 114.764502256\n",
      "positions (x,y,z), reward: [ 0.88909526  0.61497173  6.9274945 ] 113.331347178\n",
      "positions (x,y,z), reward: [ 1.10844062  0.72726336  6.031824  ] 112.078879041\n",
      "positions (x,y,z), reward: [ 1.54029707  1.10647413  4.05196358] 107.281951748\n",
      "positions (x,y,z), reward: [ 1.58184697  1.14116639  3.85214927] 106.822521684\n",
      "Episode =  754, score = 224.635 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.28175215  0.79621891  7.13987121] 112.327465239\n",
      "Episode =  755, score = 222.445 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.16197761 -0.82282359  7.75163976] 110.26916928\n",
      "positions (x,y,z), reward: [ 3.40145488 -1.96637639  0.72727774] 94.6418307801\n",
      "Episode =  756, score = 214.303 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00124504] 146.812006678\n",
      "positions (x,y,z), reward: [-0.07810499  0.2165598   8.95745508] 120.583688012\n",
      "positions (x,y,z), reward: [ 1.36856892  1.56331387  3.92463004] 97.5698304858\n",
      "positions (x,y,z), reward: [ 1.42065991  1.60058734  3.7411956 ] 95.0975499493\n",
      "Episode =  757, score = 220.165 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00110295] 146.735162489\n",
      "positions (x,y,z), reward: [ -6.40209732e-01   4.45167752e-03   7.94382076e+00] 117.113608667\n",
      "positions (x,y,z), reward: [-1.68345854 -0.0969628   3.83466558] 106.779965327\n",
      "positions (x,y,z), reward: [-1.79373894 -0.1270549   3.33482499] 105.49384505\n",
      "positions (x,y,z), reward: [-1.95724049 -0.18370724  2.55425867] 103.434389351\n",
      "Episode =  758, score = 232.018 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.          0.         10.0010003] 146.738414393\n",
      "positions (x,y,z), reward: [ 0.34521078  0.42155378  9.93328297] 124.900775123\n",
      "positions (x,y,z), reward: [ 1.0697444   1.43338087  7.00786648] 108.89718217\n",
      "positions (x,y,z), reward: [ 2.4217674   1.83896455  2.45727337] 97.046234247\n",
      "positions (x,y,z), reward: [ 2.47980262  1.85201398  2.21762592] 96.1548095718\n",
      "positions (x,y,z), reward: [ 3.16845746  1.9721004   0.        ] 85.1177092305\n",
      "Episode =  759, score = 227.450 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.15192711  0.14011698  9.73242452] 118.160658932\n",
      "positions (x,y,z), reward: [ 4.44693344  0.32256156  5.4091299 ] 94.6141187991\n",
      "positions (x,y,z), reward: [ 7.69773234  0.40716743  1.46458431] 88.8572221119\n",
      "positions (x,y,z), reward: [ 8.6790292   0.45117737  0.16884676] 85.9471375466\n",
      "Episode =  761, score = 219.389 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.19644963  0.0796438   8.26044408] 119.990559377\n",
      "positions (x,y,z), reward: [ 0.5229171  -0.44729234  5.58750372] 111.531738154\n",
      "Episode =  762, score = 227.124 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.11622743  0.0216275   9.73592437] 116.153346915\n",
      "positions (x,y,z), reward: [-0.41534363  0.24420592  8.93629198] 120.042909635\n",
      "positions (x,y,z), reward: [-0.51028788  0.34323388  8.16517247] 112.746417656\n",
      "positions (x,y,z), reward: [-0.62250806  0.56540308  7.41735087] 113.324252358\n",
      "positions (x,y,z), reward: [-0.52022052  1.4494263   3.47739212] 104.414957775\n",
      "Episode =  763, score = 225.513 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.56685998  0.07538333  8.66406136] 120.53356795\n",
      "positions (x,y,z), reward: [ 1.85049179 -0.00810817  6.40496157] 107.511931149\n",
      "Episode =  764, score = 221.253 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  9.55223068e-03   2.06125029e-03   1.00119927e+01] 149.247751438\n",
      "positions (x,y,z), reward: [  1.15142043   0.1795972   10.03102258] 133.912484815\n",
      "positions (x,y,z), reward: [ 1.94640659  0.85530096  9.55669859] 119.805513346\n",
      "positions (x,y,z), reward: [ 3.57620849  2.31550571  7.30324808] 104.886593924\n",
      "positions (x,y,z), reward: [ 4.55916009  3.06317465  5.66777475] 99.3003321959\n",
      "positions (x,y,z), reward: [ 5.36638108  3.60554736  4.29815769] 96.8532607296\n",
      "positions (x,y,z), reward: [ 5.79650827  3.95104163  3.33297399] 96.332134047\n",
      "positions (x,y,z), reward: [ 6.99423045  4.9837157   0.        ] 83.9373277798\n",
      "Episode =  765, score = 222.493 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.16740623e-01  -9.41068595e-03   9.89748652e+00] 112.865146663\n",
      "positions (x,y,z), reward: [-0.78597097 -0.15176387  7.95257766] 110.297846762\n",
      "positions (x,y,z), reward: [-0.80419896 -0.15062581  7.50462718] 113.437857973\n",
      "positions (x,y,z), reward: [-0.79668491 -0.1245596   6.34155896] 113.448051845\n",
      "positions (x,y,z), reward: [-0.8109476  -0.04973577  4.46513094] 110.233068632\n",
      "positions (x,y,z), reward: [-0.85137537  0.07545152  2.93142481] 107.356400091\n",
      "positions (x,y,z), reward: [-0.89212461  0.24434007  0.24855232] 101.806696762\n",
      "Episode =  766, score = 219.766 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.30488247 -0.52953402  8.59867388] 116.554241553\n",
      "Episode =  767, score = 222.679 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.21262824 -0.06009185  9.08968746] 117.271560278\n",
      "positions (x,y,z), reward: [ 1.12100362 -0.07606148  7.56217247] 113.620409076\n",
      "positions (x,y,z), reward: [ 3.8682725   0.26482316  3.15690563] 100.987084983\n",
      "positions (x,y,z), reward: [ 4.29331709  0.31451973  2.28194455] 99.9628518518\n",
      "positions (x,y,z), reward: [ 4.39814273  0.32774827  2.05132743] 99.6778995881\n",
      "positions (x,y,z), reward: [ 4.60458231  0.35506225  1.57474985] 98.9494134116\n",
      "Episode =  768, score = 220.175 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.33730160e-03   9.98396484e-04   1.00270992e+01] 132.179238367\n",
      "positions (x,y,z), reward: [-0.15480149  0.17768434  9.01827102] 116.310349759\n",
      "positions (x,y,z), reward: [-0.14990107  0.5684827   6.65009633] 107.235303597\n",
      "positions (x,y,z), reward: [-0.06390362  1.02809653  3.79514635] 105.230337054\n",
      "Episode =  769, score = 227.026 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.13536549 -0.08823492  9.84230516] 126.594629437\n",
      "positions (x,y,z), reward: [ 1.09608619 -0.54733065  8.7306929 ] 113.64953899\n",
      "positions (x,y,z), reward: [ 1.26107305 -0.64490609  8.34645667] 109.580173567\n",
      "positions (x,y,z), reward: [ 1.53896965 -0.76862807  7.68226292] 102.488479563\n",
      "positions (x,y,z), reward: [ 1.60550278 -0.80249769  7.53423934] 102.346955377\n",
      "positions (x,y,z), reward: [ 1.73871321 -0.87364345  7.23458774] 102.732821207\n",
      "Episode =  770, score = 218.309 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.57693897 -0.0272457   6.85604669] 103.133649538\n",
      "positions (x,y,z), reward: [ 2.73679867 -0.09402672  4.99395097] 103.48598714\n",
      "positions (x,y,z), reward: [ 2.93642457 -0.09699568  4.63106705] 100.542785045\n",
      "positions (x,y,z), reward: [ 4.27994796 -0.11593695  2.11281985] 89.4010381731\n",
      "Episode =  771, score = 210.211 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00107385] 146.816045323\n",
      "positions (x,y,z), reward: [-0.03124892  0.07020625  9.74882811] 116.267409747\n",
      "positions (x,y,z), reward: [ 0.32361393  0.91211839  8.6291478 ] 119.506176127\n",
      "positions (x,y,z), reward: [ 0.76206499  1.21514173  8.18054702] 119.449977446\n",
      "positions (x,y,z), reward: [ 2.19182884  1.98038101  6.73665457] 112.265600993\n",
      "positions (x,y,z), reward: [ 2.29835157  2.02477547  6.60741634] 111.630448713\n",
      "positions (x,y,z), reward: [ 2.8222192   2.24216751  5.92146284] 109.048280816\n",
      "positions (x,y,z), reward: [ 3.02775819  2.33376671  5.62623058] 108.048238179\n",
      "positions (x,y,z), reward: [ 3.65936053  2.64429083  4.65122424] 102.264131899\n",
      "positions (x,y,z), reward: [ 4.61657514  3.08460932  2.96814269] 98.1871207774\n",
      "Episode =  772, score = 221.415 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.91150901 -1.92676376  5.12310671] 93.3398506545\n",
      "Episode =  773, score = 210.486 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.65469778e-02   8.26412630e-03   1.00273036e+01] 146.604722345\n",
      "positions (x,y,z), reward: [ 0.58613834  0.50931395  9.8601396 ] 120.784946985\n",
      "positions (x,y,z), reward: [ 1.50031455  1.03442494  8.06922253] 110.93662709\n",
      "positions (x,y,z), reward: [ 2.07171263  1.23374654  5.25662884] 105.076522168\n",
      "positions (x,y,z), reward: [ 2.10809516  1.23471049  5.08796739] 104.81739865\n",
      "Episode =  774, score = 225.313 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.61141064  0.35446739  8.97214786] 108.224227022\n",
      "positions (x,y,z), reward: [ 0.65778587  0.37881608  8.89946412] 108.937221414\n",
      "positions (x,y,z), reward: [ 1.3562636   0.44618745  8.15380307] 113.707026206\n",
      "positions (x,y,z), reward: [ 2.83550093  0.30780594  6.07782264] 112.897853997\n",
      "positions (x,y,z), reward: [ 3.38004484  0.36065737  4.84375305] 106.306348099\n",
      "positions (x,y,z), reward: [ 3.87202115  0.39234443  3.7573915 ] 100.570803996\n",
      "Episode =  775, score = 220.814 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.39172078 -0.499933    8.8936104 ] 112.325629318\n",
      "positions (x,y,z), reward: [ 0.59744168 -0.63061695  8.28266369] 113.114357202\n",
      "positions (x,y,z), reward: [ 0.67372886 -0.68671586  8.00922744] 108.037687963\n",
      "positions (x,y,z), reward: [ 0.976805   -1.06639301  6.75092587] 103.554565784\n",
      "positions (x,y,z), reward: [ 1.33984245 -2.03918986  3.36449337] 102.887318244\n",
      "positions (x,y,z), reward: [ 1.39140809 -2.21215564  2.6299729 ] 101.413778094\n",
      "Episode =  776, score = 218.237 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.18911583 -0.09388647  9.69288382] 113.38182162\n",
      "positions (x,y,z), reward: [ 0.3329532  -0.86703076  7.93939609] 117.981314092\n",
      "Episode =  777, score = 224.254 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.11240629   0.05435928  10.0457895 ] 128.863403848\n",
      "positions (x,y,z), reward: [ 1.05711326  0.26573405  8.89060858] 116.298582085\n",
      "positions (x,y,z), reward: [ 1.98958212 -0.00632638  2.47758796] 98.932916532\n",
      "Episode =  778, score = 229.863 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.99112041  1.37299922  7.42061194] 107.979937589\n",
      "positions (x,y,z), reward: [ 5.26040349  2.64898125  3.07306967] 93.335903969\n",
      "positions (x,y,z), reward: [ 5.80434163  2.80480462  2.2428437 ] 91.4137437947\n",
      "positions (x,y,z), reward: [ 6.37408404  2.95761661  1.35705753] 89.2033801649\n",
      "Episode =  779, score = 215.484 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.91537703e-02   2.94377132e-04   1.00145106e+01] 146.437509758\n",
      "positions (x,y,z), reward: [-0.83802579  0.41864484  9.23265934] 117.30326676\n",
      "positions (x,y,z), reward: [-1.9697285   1.57597538  6.98489305] 112.379592144\n",
      "positions (x,y,z), reward: [-4.33605343  3.47172324  1.69463738] 93.3098386374\n",
      "positions (x,y,z), reward: [-4.45139637  3.54309603  1.42230344] 92.2926395398\n",
      "Episode =  780, score = 221.891 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -7.73657271e-02  -3.62345987e-03   9.88660295e+00] 116.612539024\n",
      "positions (x,y,z), reward: [-0.82094616  0.11352429  9.00112157] 110.45836976\n",
      "Episode =  781, score = 218.783 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.67965979 -1.52127518  6.91385322] 95.9354032637\n",
      "positions (x,y,z), reward: [ 5.78658685 -2.59345981  1.87454725] 89.5702433116\n",
      "positions (x,y,z), reward: [ 6.75860698 -2.9382094   0.        ] 81.5152909288\n",
      "Episode =  782, score = 206.721 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.69315963e-01   6.41913503e-03   9.18994819e+00] 109.850188335\n",
      "positions (x,y,z), reward: [ 0.8873656  -0.05266889  5.45526456] 113.284628224\n",
      "positions (x,y,z), reward: [ 1.21880764 -0.09925051  3.63991303] 107.669807918\n",
      "Episode =  783, score = 221.151 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.24999034e-02   8.62888222e-04   1.00076040e+01] 142.455506555\n",
      "positions (x,y,z), reward: [ 1.50285249 -1.78160987  6.06681853] 103.094913496\n",
      "Episode =  784, score = 216.443 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.00956875e-03  -6.73153362e-03   9.94262662e+00] 123.241476788\n",
      "positions (x,y,z), reward: [-0.03364497 -0.02852598  9.82772922] 118.196842217\n",
      "positions (x,y,z), reward: [-0.05086679 -0.10599462  9.64218719] 114.250832654\n",
      "positions (x,y,z), reward: [-1.10410888 -1.72158589  3.72254436] 106.623117673\n",
      "Episode =  785, score = 222.201 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.01690587 -0.01264927  9.89159662] 115.856806537\n",
      "positions (x,y,z), reward: [ 0.38476405 -0.04139382  9.18076685] 111.90829705\n",
      "positions (x,y,z), reward: [ 0.78981018 -0.21257103  7.13176869] 99.2899422413\n",
      "positions (x,y,z), reward: [ 0.95716209 -0.25277504  6.50063485] 101.083108662\n",
      "positions (x,y,z), reward: [ 1.41762994 -0.33921831  3.82483289] 102.621345983\n",
      "Episode =  786, score = 211.491 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.20838119 -0.0275232   9.52856872] 114.061678689\n",
      "positions (x,y,z), reward: [ 0.34709552 -0.07331152  9.00356539] 111.257098301\n",
      "positions (x,y,z), reward: [ 0.99235497 -0.24011857  7.45770405] 105.890714961\n",
      "positions (x,y,z), reward: [ 1.59624359 -0.46409952  5.79344503] 106.400563554\n",
      "positions (x,y,z), reward: [ 1.64550407 -0.47922543  5.61888159] 106.32217518\n",
      "positions (x,y,z), reward: [ 3.08225535 -0.72630451  1.50837955] 88.2354591925\n",
      "Episode =  787, score = 215.306 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.13039412e-03  -4.19258635e-05   1.00012235e+01] 139.771284947\n",
      "positions (x,y,z), reward: [-0.43285987 -0.45155905  4.12208175] 108.876288647\n",
      "positions (x,y,z), reward: [-0.20174346 -0.70622463  2.54337082] 103.153234974\n",
      "Episode =  788, score = 228.226 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.34562547  0.01377185  9.6827713 ] 111.361639601\n",
      "positions (x,y,z), reward: [-0.60752002  0.35340463  9.07226663] 115.026789258\n",
      "positions (x,y,z), reward: [-0.52760611  0.44907994  8.89108256] 115.740606231\n",
      "positions (x,y,z), reward: [-0.33253935  0.58125266  8.60187584] 116.762943709\n",
      "positions (x,y,z), reward: [ 0.01933959  0.70221645  8.21916479] 117.893479701\n",
      "positions (x,y,z), reward: [ 0.83283813  0.76620775  7.23286415] 115.656300987\n",
      "positions (x,y,z), reward: [ 2.22790564  1.13137581  4.20606032] 101.264105866\n",
      "positions (x,y,z), reward: [ 2.37356059  1.17300999  3.79652759] 101.066990826\n",
      "positions (x,y,z), reward: [ 3.09320468  1.41803122  1.25965513] 98.0564812277\n",
      "Episode =  790, score = 206.706 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.11462696   0.01755824  10.03570961] 122.883896509\n",
      "positions (x,y,z), reward: [ 0.56273231  0.35039486  9.6240158 ] 117.751080279\n",
      "positions (x,y,z), reward: [ 3.04570168  0.88540029  8.5663363 ] 108.863686063\n",
      "positions (x,y,z), reward: [ 10.20672869   3.10039893   3.34436717] 88.0363642492\n",
      "Episode =  791, score = 203.424 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.02241752  0.15865652  9.51196323] 119.054149049\n",
      "positions (x,y,z), reward: [ -2.11436195e-03   1.90961909e-01   9.47733520e+00] 119.359944322\n",
      "positions (x,y,z), reward: [ 0.55068509  0.88884171  8.67306389] 110.559752297\n",
      "positions (x,y,z), reward: [ 0.78762786  1.06321796  8.21183496] 107.839287293\n",
      "positions (x,y,z), reward: [ 0.88318257  1.13234547  7.95914129] 107.121494194\n",
      "Episode =  792, score = 221.903 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  7.69212820e-03   4.57033307e-03   1.00127041e+01] 154.401704393\n",
      "positions (x,y,z), reward: [ 0.9696612   0.25355244  9.55990114] 117.795741268\n",
      "positions (x,y,z), reward: [ 1.77409262  0.32478671  8.98029888] 105.869957468\n",
      "positions (x,y,z), reward: [ 2.98509037  0.21664379  7.9972632 ] 110.457910897\n",
      "positions (x,y,z), reward: [ 4.00885507  0.2003183   6.48921428] 100.092049719\n",
      "positions (x,y,z), reward: [ 6.29609934 -0.17675728  1.57482089] 92.5972162979\n",
      "positions (x,y,z), reward: [ 6.46100641 -0.20531588  1.07160344] 93.6495161847\n",
      "positions (x,y,z), reward: [ 6.76770419 -0.26184221  0.02320147] 91.7241182395\n",
      "positions (x,y,z), reward: [ 6.90869798 -0.29013842  0.        ] 91.4743253812\n",
      "Episode =  793, score = 214.137 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -6.60129225e-04   3.13353383e-04   1.00058210e+01] 145.743187324\n",
      "positions (x,y,z), reward: [ 0.71649026 -0.61511794  8.39966282] 113.610315183\n",
      "Episode =  794, score = 219.892 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.94673385 -1.72567573  5.58081497] 110.539042382\n",
      "Episode =  795, score = 223.645 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.29266271  0.28625463  9.60585026] 115.482543908\n",
      "positions (x,y,z), reward: [ 1.04789841  0.44060129  8.45351974] 107.321132933\n",
      "positions (x,y,z), reward: [ 2.18243373  0.6978322   7.33044755] 112.788751442\n",
      "positions (x,y,z), reward: [ 3.28819764  0.82588288  5.87572785] 102.928252837\n",
      "positions (x,y,z), reward: [ 5.41011637  1.24799712  1.9142986 ] 97.2844551894\n",
      "positions (x,y,z), reward: [ 5.99708974  1.36990221  0.42306035] 95.6244335577\n",
      "positions (x,y,z), reward: [ 6.18252836  1.41389055  0.        ] 94.5141673506\n",
      "Episode =  796, score = 215.436 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.63078625  0.19665324  9.93823784] 123.499910254\n",
      "positions (x,y,z), reward: [ 0.8508425   0.25950019  9.90341319] 121.39247585\n",
      "positions (x,y,z), reward: [ 5.57856505  2.80733731  6.79900331] 100.495810876\n",
      "positions (x,y,z), reward: [ 9.66350564  4.2243351   1.8138671 ] 87.2625569697\n",
      "Episode =  797, score = 211.803 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.67433633  0.30760586  1.60802647] 101.748429556\n",
      "Episode =  798, score = 224.526 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.91858302 -0.10185574  6.03446499] 111.780074056\n",
      "positions (x,y,z), reward: [-2.08135017 -0.12072562  5.65962272] 111.271668131\n",
      "positions (x,y,z), reward: [-2.25293742 -0.1417191   5.27495061] 110.726880033\n",
      "Episode =  799, score = 231.404 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.02278834 -0.28887027  8.91951553] 103.167041797\n",
      "positions (x,y,z), reward: [ 1.00596584 -0.54678624  6.5223922 ] 109.805892718\n",
      "positions (x,y,z), reward: [ 1.42393656 -0.66498431  5.67944021] 105.048871628\n",
      "positions (x,y,z), reward: [ 3.33848145 -1.32371401  0.49488608] 88.4660883248\n",
      "Episode =  800, score = 209.003 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.97227406 -0.14760836  4.31085685] 100.395807775\n",
      "Episode =  801, score = 214.738 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.29168352e-03   1.81563998e-03   1.00198179e+01] 136.327575654\n",
      "positions (x,y,z), reward: [ 1.05269409 -0.28687969  9.56552394] 118.799950742\n",
      "positions (x,y,z), reward: [ 1.26548299 -0.30684421  9.48680219] 118.567553582\n",
      "Episode =  802, score = 215.007 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00070844] 145.888928205\n",
      "positions (x,y,z), reward: [ 2.76188864  0.66937205  4.39475942] 102.3833178\n",
      "positions (x,y,z), reward: [ 3.98752682  0.71780959  0.96383953] 82.5188523244\n",
      "Episode =  803, score = 220.516 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -6.37565658e-03   1.36746849e-02   9.89021544e+00] 118.33616983\n",
      "positions (x,y,z), reward: [ -1.03167176e-01   3.12619163e-03   9.73511524e+00] 114.894278098\n",
      "positions (x,y,z), reward: [ 0.36092464  0.2746928   2.42532949] 103.529430167\n",
      "positions (x,y,z), reward: [ 0.51119223  0.23933798  1.38116091] 99.2798158839\n",
      "Episode =  804, score = 221.257 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.71279984e-03  -9.78614709e-03   9.91398250e+00] 120.959078612\n",
      "positions (x,y,z), reward: [ 0.70708067 -0.47370259  8.8728322 ] 118.157684211\n",
      "positions (x,y,z), reward: [ 1.51336607 -0.6416395   8.03525039] 112.061134742\n",
      "positions (x,y,z), reward: [ 2.49951208 -0.65882013  6.10947309] 105.309695048\n",
      "positions (x,y,z), reward: [ 4.20474815 -0.65258952  0.18244789] 84.0475917065\n",
      "Episode =  805, score = 215.317 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00184154] 146.734542107\n",
      "positions (x,y,z), reward: [-1.21973679  0.73722089  7.84257513] 114.123858232\n",
      "positions (x,y,z), reward: [-1.27906852  0.78826367  7.64828033] 113.7743676\n",
      "positions (x,y,z), reward: [-2.59951697  2.11500221  1.96113427] 94.8049937843\n",
      "Episode =  806, score = 222.072 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.01960768 -0.0107308   9.98541299] 126.98923456\n",
      "positions (x,y,z), reward: [ 0.1587962  -0.15540576  9.70350332] 116.498206501\n",
      "positions (x,y,z), reward: [ 0.32778087 -1.1472819   8.16608432] 109.207794013\n",
      "positions (x,y,z), reward: [ 1.08505326 -2.59076938  5.43333548] 100.150074036\n",
      "Episode =  807, score = 211.504 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.53645629 -0.24228394  8.29229842] 110.122083442\n",
      "Episode =  808, score = 216.949 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.05157978 -0.10027487  9.9548511 ] 121.787774586\n",
      "positions (x,y,z), reward: [-0.34074937 -0.38019425  8.71255911] 112.708725799\n",
      "positions (x,y,z), reward: [-0.81594567 -1.12738297  0.71715069] 97.1077407672\n",
      "Episode =  809, score = 225.213 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.10961030e-02   3.25549367e-03   1.00095924e+01] 143.976942011\n",
      "positions (x,y,z), reward: [  0.15464938   0.04674422  10.02058489] 118.564210473\n",
      "positions (x,y,z), reward: [ 0.21057056 -0.06010522  9.84620374] 114.959248277\n",
      "positions (x,y,z), reward: [ 0.46050679  0.07221747  9.11581287] 117.632110793\n",
      "positions (x,y,z), reward: [ 0.5970908   0.08281706  8.91260505] 118.652815122\n",
      "positions (x,y,z), reward: [  1.31110497e+00  -4.62487334e-04   7.76049038e+00] 108.524762341\n",
      "positions (x,y,z), reward: [ 5.86015266 -0.37736525  0.        ] 90.5780388799\n",
      "Episode =  810, score = 219.174 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.48284522e-03   2.23930321e-04   1.00051556e+01] 145.636206058\n",
      "positions (x,y,z), reward: [ 0.22447578  0.01753994  9.83985093] 120.254137053\n",
      "positions (x,y,z), reward: [ 2.413479    0.63453024  7.46821299] 113.001532029\n",
      "positions (x,y,z), reward: [ 3.03600488  0.64227219  5.86672438] 99.6176646841\n",
      "positions (x,y,z), reward: [ 3.64391125  0.64616664  4.56201799] 97.6101114325\n",
      "Episode =  811, score = 220.722 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.12597043  0.07900173  9.96929337] 120.709751441\n",
      "positions (x,y,z), reward: [ 0.09289951 -0.06218216  9.07074824] 117.998810786\n",
      "positions (x,y,z), reward: [-0.40854008 -0.38979734  7.39376981] 117.448370653\n",
      "positions (x,y,z), reward: [-0.72179556 -0.73895444  4.87000803] 109.288397451\n",
      "positions (x,y,z), reward: [-1.31273792 -1.22761179  0.0570547 ] 97.1838884066\n",
      "Episode =  812, score = 229.375 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.05498127 -0.0163011   9.93828326] 120.186672064\n",
      "positions (x,y,z), reward: [ 0.10982912 -0.07193959  9.81791887] 115.891132648\n",
      "positions (x,y,z), reward: [ 0.42612157 -0.59935072  9.00691085] 108.867503686\n",
      "positions (x,y,z), reward: [ 0.54543665 -0.83684596  8.4442524 ] 108.851597727\n",
      "positions (x,y,z), reward: [ 1.59948025 -1.85045064  5.49064699] 102.017537562\n",
      "positions (x,y,z), reward: [ 2.80617425 -3.18447529  0.18745842] 92.3978924332\n",
      "Episode =  813, score = 216.174 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.02395984 -1.33562725  8.25217537] 119.073482655\n",
      "positions (x,y,z), reward: [-0.5476013  -2.31329966  6.40850369] 105.687827077\n",
      "positions (x,y,z), reward: [-1.09124909 -3.34542228  4.53862331] 104.745886317\n",
      "Episode =  814, score = 221.001 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.01001081  0.14077589  9.95744791] 122.447912631\n",
      "positions (x,y,z), reward: [ 0.45796682  0.64019809  9.75603734] 113.711699503\n",
      "positions (x,y,z), reward: [ 0.5276568   0.70462629  9.67852024] 113.819737158\n",
      "positions (x,y,z), reward: [ 1.70647051  2.15596719  6.23770768] 109.157986549\n",
      "positions (x,y,z), reward: [ 2.5546537   3.09391438  3.00338048] 100.972436096\n",
      "Episode =  815, score = 222.539 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.22002058 -0.79970637  8.36158207] 109.928781841\n",
      "positions (x,y,z), reward: [ 0.90817376 -1.17204858  6.96569249] 112.547779815\n",
      "positions (x,y,z), reward: [ 2.98579289 -1.96724757  3.85439214] 102.13286554\n",
      "positions (x,y,z), reward: [ 3.21156949 -2.05864035  3.45149834] 99.6629321113\n",
      "positions (x,y,z), reward: [ 4.76978475 -2.81292115  0.23630539] 91.9372397604\n",
      "Episode =  816, score = 215.199 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  7.27706774e-03   7.46951841e-02   9.85496007e+00] 117.452883777\n",
      "positions (x,y,z), reward: [ 2.20568014  0.04095798  7.0540707 ] 109.025801528\n",
      "positions (x,y,z), reward: [ 2.6718417  -0.04700213  6.20866151] 108.411465261\n",
      "positions (x,y,z), reward: [ 2.82139905 -0.06478604  5.88252415] 108.064337628\n",
      "positions (x,y,z), reward: [ 3.28081626 -0.09909464  4.77943148] 103.129340879\n",
      "positions (x,y,z), reward: [ 3.75194494 -0.15691325  3.76828811] 98.3407597255\n",
      "Episode =  817, score = 216.269 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 3.8170121   4.32997458  0.34138669] 87.6925107457\n",
      "positions (x,y,z), reward: [ 3.86002485  4.45099489  0.        ] 86.507679858\n",
      "Episode =  818, score = 217.412 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.12400491  0.16658924  9.45390123] 118.033025919\n",
      "positions (x,y,z), reward: [ 0.14264432  0.39414843  8.05426094] 113.992161587\n",
      "positions (x,y,z), reward: [ 0.74776081  0.67188672  5.98088117] 107.250038376\n",
      "positions (x,y,z), reward: [ 1.13728517  0.70068944  4.28920455] 104.907547088\n",
      "positions (x,y,z), reward: [ 1.41295624  0.73619563  2.87113867] 102.347964853\n",
      "positions (x,y,z), reward: [ 1.93238957  0.86251813  0.        ] 93.4909182268\n",
      "Episode =  819, score = 220.880 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.21014512  0.60558074  9.32600812] 115.413620517\n",
      "positions (x,y,z), reward: [ 0.48274548  0.71562905  8.9267951 ] 111.98827847\n",
      "positions (x,y,z), reward: [ 0.73099129  0.73757146  8.30156956] 106.773952974\n",
      "positions (x,y,z), reward: [ 1.18287036  0.79748567  5.93487291] 112.907023196\n",
      "Episode =  820, score = 224.055 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.0559398  -0.01316581  9.91367236] 117.204776388\n",
      "positions (x,y,z), reward: [ 1.6490362  -0.69341672  7.97634921] 109.604168826\n",
      "positions (x,y,z), reward: [ 6.21505967 -1.65777825  2.02515366] 87.0068563042\n",
      "Episode =  821, score = 204.796 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.32478766  0.60353474  7.53589004] 118.414709015\n",
      "positions (x,y,z), reward: [-0.43993239  0.47709274  5.23872556] 111.500906929\n",
      "positions (x,y,z), reward: [-0.46385015  0.40454264  4.8409948 ] 110.932481246\n",
      "positions (x,y,z), reward: [-0.5497728   0.17153561  3.59192247] 108.543640331\n",
      "positions (x,y,z), reward: [-0.65502684 -0.16069444  1.48684285] 102.327020657\n",
      "Episode =  824, score = 216.573 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.50068502e-03  -3.44350765e-03   9.96455560e+00] 125.13748936\n",
      "positions (x,y,z), reward: [ 0.06725072  0.17791767  9.72100348] 118.888385017\n",
      "positions (x,y,z), reward: [ 0.06874242  0.55708087  8.68828046] 117.311468925\n",
      "positions (x,y,z), reward: [-1.00313302  1.80484093  0.33515542] 98.0690333142\n",
      "Episode =  825, score = 226.398 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.92136236  0.25858858  8.63783515] 103.403972457\n",
      "positions (x,y,z), reward: [ 4.82997341  0.78400338  6.09845675] 88.3702266989\n",
      "positions (x,y,z), reward: [ 7.60239448  1.26147729  2.88283804] 93.4868989631\n",
      "Episode =  827, score = 219.921 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.04549126 -0.01928481  9.80188484] 106.973694158\n",
      "positions (x,y,z), reward: [ 0.20498278 -0.37444513  8.47069857] 109.328670376\n",
      "positions (x,y,z), reward: [ 0.39838027 -0.54065245  7.45532321] 115.088201101\n",
      "positions (x,y,z), reward: [ 0.50025194 -0.76294096  6.41027177] 107.698655633\n",
      "Episode =  828, score = 219.977 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -8.94161231e-03   3.85040131e-01   9.43561822e+00] 116.678116503\n",
      "positions (x,y,z), reward: [ 0.49258058  0.93434024  7.54955625] 116.343840361\n",
      "positions (x,y,z), reward: [ 0.53618986  1.09127834  6.33174887] 109.510567593\n",
      "positions (x,y,z), reward: [ 0.52705331  1.10821561  6.15577991] 108.761801203\n",
      "positions (x,y,z), reward: [ 0.10674158  1.47358455  0.99665746] 101.358582919\n",
      "Episode =  829, score = 225.051 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04391726 -0.01458894  9.90119669] 119.531656839\n",
      "positions (x,y,z), reward: [ 0.05682331 -0.04003175  9.66826985] 112.62280327\n",
      "positions (x,y,z), reward: [-0.05304044  0.01860359  8.9677009 ] 113.240219489\n",
      "positions (x,y,z), reward: [ 1.4847526  -0.51695375  4.30528126] 107.303557294\n",
      "Episode =  830, score = 221.644 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.10094022  0.80486539  8.85443763] 116.760307627\n",
      "Episode =  831, score = 226.878 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.06506993 -0.02954205  9.96146776] 123.304290874\n",
      "positions (x,y,z), reward: [-0.0757107  -0.19140821  9.2842079 ] 120.596934459\n",
      "positions (x,y,z), reward: [-0.24720498 -0.50423092  7.66517927] 111.333515732\n",
      "positions (x,y,z), reward: [-1.45435684 -1.8264142   2.44489321] 102.722354531\n",
      "Episode =  832, score = 225.830 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00138045] 146.758157319\n",
      "positions (x,y,z), reward: [ -6.68835041e-03   4.83370096e-02   1.00425392e+01] 134.142956338\n",
      "positions (x,y,z), reward: [-2.23419249  1.95716538  2.77259782] 102.344355529\n",
      "positions (x,y,z), reward: [-2.52334122  2.02424963  1.8048836 ] 99.689938256\n",
      "positions (x,y,z), reward: [-2.65213529  2.04183224  1.30448659] 98.5333473556\n",
      "Episode =  833, score = 230.098 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04315348 -0.03348769  9.76004935] 109.987671241\n",
      "positions (x,y,z), reward: [ 0.88159353  0.22581417  8.60891792] 109.658116166\n",
      "positions (x,y,z), reward: [ 1.02980463  0.23962349  8.3242992 ] 110.794682517\n",
      "Episode =  834, score = 216.415 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.03125708e-02   6.21111018e-04   1.00081837e+01] 144.038096004\n",
      "positions (x,y,z), reward: [ 0.51226916  0.02066205  9.98966392] 122.849542752\n",
      "positions (x,y,z), reward: [ 1.61211165  0.343058    9.72279791] 114.893650099\n",
      "positions (x,y,z), reward: [ 1.85372296  0.43910815  9.62665946] 112.436742846\n",
      "positions (x,y,z), reward: [ 5.41367051  2.26024568  5.42610586] 97.9616283348\n",
      "Episode =  835, score = 218.034 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.45043296 -0.41325434  9.61809807] 109.707769303\n",
      "positions (x,y,z), reward: [ 1.53242106 -2.10819338  6.36263429] 110.286894307\n",
      "Episode =  836, score = 219.343 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.21856997e-02   6.58863888e-03   1.00227196e+01] 151.97243843\n",
      "positions (x,y,z), reward: [ 0.56079871  0.18604892  9.69534637] 116.391919326\n",
      "positions (x,y,z), reward: [ 0.88121652  0.08846096  9.12555195] 113.277429138\n",
      "positions (x,y,z), reward: [ 1.01507295 -0.14389626  8.17868197] 116.668874532\n",
      "positions (x,y,z), reward: [ 1.09552997 -0.80989557  4.80093235] 104.03778845\n",
      "positions (x,y,z), reward: [ 1.20926805 -1.03315829  3.30591391] 101.905648862\n",
      "Episode =  837, score = 224.399 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.24308206 -0.56323529  6.44507913] 113.090765284\n",
      "positions (x,y,z), reward: [ 0.59936967 -0.91032473  2.18710335] 103.072258509\n",
      "positions (x,y,z), reward: [ 0.75997095 -0.97121674  1.20029937] 100.913702735\n",
      "Episode =  838, score = 223.654 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  4.51511547e-03  -1.87831195e-03   9.99180520e+00] 128.046680189\n",
      "positions (x,y,z), reward: [-1.15704166 -0.64874388  6.40591237] 113.004425917\n",
      "positions (x,y,z), reward: [-1.25843895 -1.12214677  4.71389482] 107.842306376\n",
      "positions (x,y,z), reward: [-1.27398226 -1.27806496  4.25161847] 106.738103408\n",
      "Episode =  839, score = 227.353 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.23414034 -0.28462465  9.60674505] 112.091355253\n",
      "positions (x,y,z), reward: [ 0.25690844 -0.3539797   9.52500294] 111.094454941\n",
      "positions (x,y,z), reward: [ 0.28419703 -0.57589661  9.24913901] 108.846906934\n",
      "positions (x,y,z), reward: [ 0.38409385 -1.16566732  7.61318926] 113.68507428\n",
      "positions (x,y,z), reward: [ 1.15265492 -2.18608328  3.48306105] 101.802704425\n",
      "positions (x,y,z), reward: [ 1.69113243 -2.76910781  0.64006737] 94.5034881715\n",
      "Episode =  840, score = 219.249 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.84015243e-03   2.02421928e-03   1.00159834e+01] 154.352352896\n",
      "positions (x,y,z), reward: [  7.30216842e-03   1.25136508e-02   1.00315677e+01] 151.643307355\n",
      "positions (x,y,z), reward: [ 0.89542945  0.35373482  9.24322536] 117.220224881\n",
      "positions (x,y,z), reward: [ 1.11887921  0.14480203  4.72235983] 107.080100201\n",
      "Episode =  841, score = 231.653 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.65341189 -0.12739339  9.72649505] 118.459356021\n",
      "positions (x,y,z), reward: [ 0.95258836 -0.12670895  9.62230002] 119.602548073\n",
      "positions (x,y,z), reward: [ 1.66181329 -0.03719494  9.31388363] 115.447307596\n",
      "positions (x,y,z), reward: [ 3.20805967  0.04762521  8.47320169] 107.679040889\n",
      "positions (x,y,z), reward: [ 4.32409641  0.019295    7.6046817 ] 98.2981939684\n",
      "positions (x,y,z), reward: [ 9.14954021 -0.47806996  0.42836903] 83.2091855062\n",
      "Episode =  842, score = 206.341 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.34598428e-03  -1.19778040e-04   1.00106203e+01] 133.169994764\n",
      "positions (x,y,z), reward: [ -7.01491393e-03   1.69968645e-05   1.00025984e+01] 120.640668883\n",
      "positions (x,y,z), reward: [ 0.3198473   0.16044975  9.68796195] 121.152920982\n",
      "positions (x,y,z), reward: [ 2.59486268  0.35881728  5.71676425] 107.295375828\n",
      "Episode =  844, score = 211.547 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.33072014e-02  -7.38784379e-04   9.93836176e+00] 123.864832882\n",
      "positions (x,y,z), reward: [ 1.84011182  1.24518772  6.71035207] 112.111980349\n",
      "positions (x,y,z), reward: [ 4.36095506  1.85965439  3.05468579] 97.7197458689\n",
      "positions (x,y,z), reward: [ 5.05350059  2.01421446  1.87016723] 91.9209302677\n",
      "positions (x,y,z), reward: [ 5.30110982  2.06598807  1.44595564] 89.0721587507\n",
      "Episode =  845, score = 220.568 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.18483009 -0.16141501  9.22122113] 116.031456235\n",
      "positions (x,y,z), reward: [ 2.51727982 -0.57469254  6.78465586] 106.168124985\n",
      "positions (x,y,z), reward: [ 2.94850744 -0.58616343  6.22573041] 106.972010666\n",
      "positions (x,y,z), reward: [ 3.61530375 -0.60608036  5.23618409] 94.2935803657\n",
      "positions (x,y,z), reward: [ 5.53606092 -0.67372407  2.17298331] 86.0855534431\n",
      "Episode =  846, score = 211.765 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.38194859 -0.09716736  9.3247638 ] 118.903923323\n",
      "positions (x,y,z), reward: [-0.59389298  0.02283462  8.873656  ] 112.628493762\n",
      "positions (x,y,z), reward: [ 0.50117704  1.39765237  0.12998597] 90.2889105376\n",
      "Episode =  847, score = 221.959 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.12838599 -0.55226922  6.41445849] 114.429303749\n",
      "positions (x,y,z), reward: [-0.91017811 -0.73875915  4.6553414 ] 106.15557082\n",
      "Episode =  848, score = 234.046 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.17934784  0.08972744  9.23835783] 109.575025988\n",
      "positions (x,y,z), reward: [ 2.07325536 -0.12574552  7.56721654] 103.626716737\n",
      "positions (x,y,z), reward: [ 3.36011404 -0.5217029   4.59106963] 98.0527804529\n",
      "positions (x,y,z), reward: [ 3.7956751  -0.62862892  3.55259608] 97.5461526366\n",
      "Episode =  849, score = 214.977 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.10552559  0.02797706  9.95222436] 112.26215971\n",
      "positions (x,y,z), reward: [ 0.17017123  0.40782498  9.66167238] 116.243007859\n",
      "positions (x,y,z), reward: [ 1.10014859  0.72059405  8.53591379] 111.190654314\n",
      "positions (x,y,z), reward: [ 6.09084782  2.65268211  1.17698667] 93.5636575225\n",
      "Episode =  850, score = 216.754 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  4.31779006e-02   6.18735234e-03   9.99311261e+00] 121.540767231\n",
      "positions (x,y,z), reward: [ 0.71814687  0.10887303  9.7008637 ] 110.783017543\n",
      "positions (x,y,z), reward: [ 2.32591608  0.09617038  8.0326119 ] 115.101086776\n",
      "positions (x,y,z), reward: [ 2.51163339  0.09476838  7.77059816] 113.487343675\n",
      "positions (x,y,z), reward: [ 2.89839855  0.09471116  7.19024881] 106.535251509\n",
      "positions (x,y,z), reward: [ 3.0014547   0.09662178  7.02699876] 105.004234806\n",
      "positions (x,y,z), reward: [ 4.74897862 -0.0159111   4.06444198] 100.345788525\n",
      "Episode =  851, score = 215.180 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.66748386  0.4017636   0.83270884] 95.1392828669\n",
      "positions (x,y,z), reward: [-0.59858206  0.41281154  0.26261252] 95.6623434477\n",
      "Episode =  852, score = 217.805 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.15939387e-03   1.00576536e-02   1.00168013e+01] 133.72686239\n",
      "positions (x,y,z), reward: [-0.0884368   0.17929109  9.98852293] 113.589986452\n",
      "positions (x,y,z), reward: [ 0.7460374   1.10654237  9.29187686] 119.549612572\n",
      "positions (x,y,z), reward: [ 1.57604244  1.41089716  8.57207281] 114.247795316\n",
      "positions (x,y,z), reward: [ 5.27569946  3.8962046   1.15922532] 82.1659701998\n",
      "Episode =  853, score = 218.232 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.56083083 -3.13865547  5.93581808] 110.44185511\n",
      "positions (x,y,z), reward: [-1.38697493 -5.22685239  1.8073987 ] 97.8537973005\n",
      "positions (x,y,z), reward: [-1.57264643 -5.57502559  1.00729938] 95.7482765734\n",
      "Episode =  854, score = 223.014 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.44444828e-03  -1.45035692e-03   9.94976886e+00] 122.763239218\n",
      "positions (x,y,z), reward: [ 0.71217241  0.27591123  8.52213195] 119.741326772\n",
      "positions (x,y,z), reward: [ 3.2905914   0.58503643  1.19659964] 97.4264191357\n",
      "Episode =  855, score = 223.391 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.03474543e-01   2.84268379e-03   9.95256008e+00] 117.543962981\n",
      "positions (x,y,z), reward: [ 0.02967194  0.1081411   9.67548942] 114.371600023\n",
      "positions (x,y,z), reward: [ 0.31550471  0.15645291  9.45739055] 117.870288747\n",
      "positions (x,y,z), reward: [ 0.61643935  0.09393403  8.99773036] 112.285597056\n",
      "positions (x,y,z), reward: [ 0.67610609  0.05452754  8.82099228] 112.198460373\n",
      "Episode =  856, score = 223.467 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  8.45453845e-03   1.89314246e-02   9.96919565e+00] 112.04545452\n",
      "positions (x,y,z), reward: [-0.25098092  1.31037851  5.66166924] 101.618883926\n",
      "Episode =  857, score = 217.712 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.07673105 -0.02237011  9.74863001] 111.131674435\n",
      "positions (x,y,z), reward: [ 0.65709598 -0.14263656  8.87867804] 105.89208326\n",
      "positions (x,y,z), reward: [ 1.70295199 -0.18945794  4.75023652] 98.8134515515\n",
      "positions (x,y,z), reward: [ 2.36223773 -0.25843593  1.67846174] 94.6094744422\n",
      "Episode =  858, score = 209.061 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.23584994e-02  -5.20502302e-03   9.91896866e+00] 120.825721385\n",
      "positions (x,y,z), reward: [-1.05424025  0.23101334  8.08934405] 119.048336773\n",
      "positions (x,y,z), reward: [-1.19226497  0.2736476   7.89433419] 118.393394192\n",
      "positions (x,y,z), reward: [-4.12352057  0.41959773  4.21571028] 101.96845316\n",
      "positions (x,y,z), reward: [-5.0121594   0.42735649  2.98595847] 96.850534924\n",
      "positions (x,y,z), reward: [-5.96355099  0.46400459  1.64100398] 91.3975298671\n",
      "Episode =  859, score = 221.044 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.16608402 -0.11747332  9.84748615] 121.590589714\n",
      "positions (x,y,z), reward: [-0.60041598 -0.32546996  8.56837829] 121.487475547\n",
      "positions (x,y,z), reward: [-1.18489652 -1.1512358   5.97221019] 110.228800638\n",
      "positions (x,y,z), reward: [-1.72743701 -2.22965695  3.69168438] 104.305511311\n",
      "positions (x,y,z), reward: [-2.27635498 -3.02544262  1.55831053] 98.8551790408\n",
      "Episode =  860, score = 232.261 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.0392993   0.01176241  9.98682984] 120.508861242\n",
      "positions (x,y,z), reward: [ 0.03951142 -0.01296711  9.89322495] 115.70713826\n",
      "positions (x,y,z), reward: [ 0.14662859 -0.02697767  9.82198365] 113.502700105\n",
      "positions (x,y,z), reward: [ 0.53845181 -0.14977951  9.51590802] 107.467748763\n",
      "positions (x,y,z), reward: [ 4.23826153 -1.62491622  4.40221264] 90.2605019355\n",
      "positions (x,y,z), reward: [ 5.6436135  -2.08497184  2.04101725] 84.9822639968\n",
      "positions (x,y,z), reward: [ 5.88617814 -2.18465654  1.5595835 ] 84.7444380823\n",
      "Episode =  861, score = 204.904 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00081607] 145.774387616\n",
      "positions (x,y,z), reward: [  1.04068056e-02  -5.76651033e-04   9.99411652e+00] 127.612709882\n",
      "positions (x,y,z), reward: [-0.44730016  0.17073969  9.33197374] 114.73637781\n",
      "positions (x,y,z), reward: [-0.51194017  0.25485187  9.18867786] 116.4573399\n",
      "positions (x,y,z), reward: [-0.5423837   0.2911273   9.10352106] 116.842163006\n",
      "positions (x,y,z), reward: [-1.85314543 -0.00822938  2.54335451] 105.510266293\n",
      "positions (x,y,z), reward: [-1.8797085  -0.0419435   2.32442842] 105.095646252\n",
      "positions (x,y,z), reward: [-2.06419361 -0.2420768   0.95062029] 102.415379964\n",
      "positions (x,y,z), reward: [-2.16787205 -0.34425064  0.228852  ] 101.056807904\n",
      "Episode =  862, score = 227.911 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.86645147 -0.89292912  4.06479785] 108.556930228\n",
      "positions (x,y,z), reward: [-1.97131542 -0.95734702  3.64273378] 107.417853646\n",
      "positions (x,y,z), reward: [-2.22643899 -1.10646243  2.53148627] 104.403444619\n",
      "Episode =  863, score = 228.328 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.13235018 -0.01963864  9.94767545] 126.060710038\n",
      "positions (x,y,z), reward: [ 0.13113791 -0.01009677  9.90156159] 126.267561666\n",
      "positions (x,y,z), reward: [ 0.0534688   0.16186139  9.41537148] 122.671570925\n",
      "positions (x,y,z), reward: [ 0.23621089  0.38700413  8.6538815 ] 115.595520547\n",
      "positions (x,y,z), reward: [ 0.53972053  0.56353884  7.9796062 ] 115.323753909\n",
      "Episode =  864, score = 220.682 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.2680746  -0.01450654  9.43029151] 118.689414068\n",
      "positions (x,y,z), reward: [ 0.47556287 -0.30567099  8.65259777] 117.006432404\n",
      "positions (x,y,z), reward: [-0.02179867 -1.59660038  4.29751865] 107.422275134\n",
      "Episode =  865, score = 226.460 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.01244277  0.14240039  9.79251311] 121.228075179\n",
      "positions (x,y,z), reward: [-0.06716085  0.23320224  9.62672133] 121.24577353\n",
      "positions (x,y,z), reward: [-0.52009275  0.67220804  8.20955467] 118.588486341\n",
      "positions (x,y,z), reward: [-0.95166004  0.93000251  7.08897224] 115.010217649\n",
      "positions (x,y,z), reward: [-2.07359809  1.61623566  4.02144744] 105.605890725\n",
      "Episode =  866, score = 227.220 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.23602797  0.40134031  8.11526814] 113.853732229\n",
      "positions (x,y,z), reward: [ 0.4062297   0.64265396  6.73570183] 113.544315758\n",
      "positions (x,y,z), reward: [ 0.70496993  0.97871813  4.72595925] 110.466369881\n",
      "positions (x,y,z), reward: [ 0.86076087  1.13077912  3.67644873] 108.017138377\n",
      "positions (x,y,z), reward: [ 1.11344289  1.42907764  1.36051703] 102.283405292\n",
      "Episode =  867, score = 226.083 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.61048483 -0.83013246  9.50441375] 119.247851227\n",
      "positions (x,y,z), reward: [ 0.67558233 -0.88036313  9.3796055 ] 117.564254173\n",
      "positions (x,y,z), reward: [ 0.71829687 -0.90989164  9.31690966] 116.508176394\n",
      "positions (x,y,z), reward: [ 0.95264507 -1.02809676  9.07713579] 114.980634982\n",
      "positions (x,y,z), reward: [ 1.2108131  -1.08128737  8.83422972] 115.626684895\n",
      "positions (x,y,z), reward: [ 1.27257951 -1.08211928  8.76404518] 115.704311635\n",
      "positions (x,y,z), reward: [ 4.62306815 -0.62502737  3.06426146] 94.2899023936\n",
      "positions (x,y,z), reward: [ 4.71066168 -0.60997611  2.84176965] 95.1083542855\n",
      "positions (x,y,z), reward: [ 5.31035609 -0.51502062  1.18382113] 94.8540179643\n",
      "positions (x,y,z), reward: [ 5.39416268 -0.50151378  0.93012645] 94.3361146403\n",
      "Episode =  868, score = 227.109 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.01192006 -0.01214543  9.97518389] 119.926831151\n",
      "positions (x,y,z), reward: [ 0.16663958 -0.03079835  9.90733716] 123.070132072\n",
      "positions (x,y,z), reward: [  2.33426168e-01  -5.18433165e-03   9.87696430e+00] 123.737235146\n",
      "positions (x,y,z), reward: [ 2.09658266  0.68144701  7.80291033] 112.359658542\n",
      "positions (x,y,z), reward: [ 4.39163394  1.53512275  0.98746376] 95.6258236598\n",
      "positions (x,y,z), reward: [ 4.44932727  1.55481737  0.72835039] 95.3425865067\n",
      "Episode =  869, score = 222.083 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.45016417  0.87765673  6.86218892] 110.427974394\n",
      "positions (x,y,z), reward: [ 1.42014117  1.40114932  3.34435568] 105.365465286\n",
      "Episode =  870, score = 218.277 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -9.33273593e-03   1.62322044e-02   1.00018461e+01] 130.129929123\n",
      "positions (x,y,z), reward: [-0.25179557  1.14573404  8.51076638] 121.148800965\n",
      "positions (x,y,z), reward: [-0.26453877  1.19161293  8.38489757] 120.558697001\n",
      "positions (x,y,z), reward: [-0.3225507   2.18015533  3.88190367] 99.7778707975\n",
      "positions (x,y,z), reward: [-0.11103567  2.53695981  0.86956299] 88.5971073898\n",
      "Episode =  871, score = 225.616 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.20607736 -0.01974476  9.87003997] 117.137446523\n",
      "positions (x,y,z), reward: [ 0.21326674 -0.14952567  9.19676087] 118.345771384\n",
      "Episode =  872, score = 222.050 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.20767727 -0.01512461  9.51931561] 103.6758022\n",
      "positions (x,y,z), reward: [ 0.76538928  0.05104979  8.42483433] 110.565305426\n",
      "positions (x,y,z), reward: [ 1.24034201  0.00779138  7.25114212] 101.426422381\n",
      "Episode =  873, score = 212.183 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.87172345 -0.13962724  9.38072584] 117.08214285\n",
      "positions (x,y,z), reward: [ 1.30888121 -0.11171386  9.15441463] 117.76689498\n",
      "positions (x,y,z), reward: [ 2.88528322  0.09306957  8.1604871 ] 110.245588054\n",
      "positions (x,y,z), reward: [ 3.7710237   0.18161043  7.32168494] 105.254684933\n",
      "positions (x,y,z), reward: [ 4.9728837   0.32674964  5.72569284] 103.338612981\n",
      "Episode =  874, score = 213.996 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -7.28580069e-03   9.49649490e-03   1.00072182e+01] 130.668654918\n",
      "positions (x,y,z), reward: [-0.08198967 -0.04894678  9.88291441] 113.8651975\n",
      "positions (x,y,z), reward: [-0.07690591 -0.07036149  7.62143502] 115.845841649\n",
      "Episode =  875, score = 227.822 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.32052276  0.02991382  9.7292725 ] 121.858312201\n",
      "positions (x,y,z), reward: [ 3.21989749  0.6414854   6.85561597] 98.179570742\n",
      "positions (x,y,z), reward: [ 3.46316623  0.69135021  6.56790544] 99.3480842284\n",
      "positions (x,y,z), reward: [ 4.10661862  0.82889768  5.80427256] 89.6120002722\n",
      "Episode =  876, score = 213.325 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.24644139 -0.41376999  8.98068896] 114.393047768\n",
      "positions (x,y,z), reward: [-0.28919464 -0.72837869  6.99878977] 116.376174171\n",
      "Episode =  877, score = 224.105 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.82488490e-02   2.91873318e-03   1.00047111e+01] 140.246180533\n",
      "positions (x,y,z), reward: [-0.43705992  1.02593618  8.07368933] 110.162755963\n",
      "positions (x,y,z), reward: [-0.43699796  1.10158359  7.85693707] 111.123078908\n",
      "positions (x,y,z), reward: [-0.33746343  1.30968666  7.396149  ] 113.320191629\n",
      "positions (x,y,z), reward: [ 0.98159491  3.43391601  2.06923222] 97.8758603223\n",
      "Episode =  878, score = 222.965 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.37620935  0.16572079  9.97195493] 122.838963616\n",
      "positions (x,y,z), reward: [ 2.75736097  1.13109667  8.5118239 ] 107.823547563\n",
      "positions (x,y,z), reward: [ 4.07062267  1.62803567  7.29155955] 99.3729830989\n",
      "Episode =  879, score = 214.985 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.32124716e-03   2.15705775e-01   9.74312165e+00] 119.401451674\n",
      "positions (x,y,z), reward: [-0.3792376  -0.42170718  0.64804134] 96.9856694669\n",
      "Episode =  880, score = 227.562 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.56802574 -1.52506008  7.79234371] 119.48397009\n",
      "positions (x,y,z), reward: [-1.33887273 -2.82576208  4.92487601] 107.442943627\n",
      "positions (x,y,z), reward: [-1.96022993 -4.01885314  0.92409662] 98.3814800683\n",
      "Episode =  881, score = 232.756 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.77660401 -1.75531603  7.15167281] 107.559625502\n",
      "positions (x,y,z), reward: [ 2.09134358 -2.32053523  5.98517085] 98.4330738161\n",
      "positions (x,y,z), reward: [ 2.68037308 -3.1509775   3.86629487] 92.3692096058\n",
      "positions (x,y,z), reward: [ 3.30816177 -3.80908277  1.70986643] 87.8434419145\n",
      "Episode =  882, score = 213.293 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 3.40271861  0.87211598  3.12680743] 99.6241310483\n",
      "positions (x,y,z), reward: [ 3.77460791  0.90579547  2.12369366] 96.4382822907\n",
      "Episode =  883, score = 221.900 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.54941219 -1.4238429   4.70404292] 106.494465333\n",
      "positions (x,y,z), reward: [-1.63954713 -1.50385755  4.24326407] 105.257045912\n",
      "Episode =  884, score = 229.843 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.65001554e-02   7.54234103e-03   1.00165308e+01] 138.245055158\n",
      "positions (x,y,z), reward: [-0.83675894 -0.33688038  8.95000964] 106.324529721\n",
      "Episode =  885, score = 217.778 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.1206427   0.09230995  9.73735861] 119.255459231\n",
      "positions (x,y,z), reward: [-0.24421988  0.17127471  9.49829317] 117.847990525\n",
      "positions (x,y,z), reward: [-0.26355243  0.18806374  9.41873592] 119.358458585\n",
      "positions (x,y,z), reward: [-2.84019748  0.56798105  3.23320812] 103.448518063\n",
      "positions (x,y,z), reward: [-4.19454434  0.7356412   0.        ] 92.8919377031\n",
      "Episode =  886, score = 225.330 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -9.55895881e-03   4.80576704e-03   1.00168725e+01] 146.82910489\n",
      "positions (x,y,z), reward: [ 0.38377354 -0.70659665  8.16586427] 104.45806295\n",
      "positions (x,y,z), reward: [ 0.71560493 -1.26881134  6.54780089] 103.394878014\n",
      "Episode =  887, score = 210.855 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.77418839e-03  -8.71269662e-05   1.00000429e+01] 139.734012329\n",
      "positions (x,y,z), reward: [ 0.57969504  0.52635334  6.07185678] 114.605439764\n",
      "positions (x,y,z), reward: [ 1.88348623  1.1008229   0.65257345] 97.6487836619\n",
      "Episode =  888, score = 227.499 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.27930851  0.55215332  9.26207689] 118.363224451\n",
      "positions (x,y,z), reward: [-0.19325914  0.76879683  8.93950859] 118.254452122\n",
      "positions (x,y,z), reward: [ 0.36484519  1.93878713  1.39396738] 97.6765199578\n",
      "Episode =  889, score = 224.259 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.58330114 -0.09387362  9.023363  ] 110.925231759\n",
      "positions (x,y,z), reward: [ 0.88333648  0.09612436  4.86615645] 108.573544729\n",
      "positions (x,y,z), reward: [ 0.90448829  0.08646502  4.16753155] 106.468334671\n",
      "positions (x,y,z), reward: [ 0.91161868  0.07727527  3.92945679] 105.945859394\n",
      "positions (x,y,z), reward: [ 0.930289    0.04264086  3.20175756] 104.532510918\n",
      "Episode =  890, score = 221.018 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.16428208e-03   5.02338164e-03   1.00158986e+01] 122.580661511\n",
      "positions (x,y,z), reward: [-0.22959964 -0.34678632  9.44882003] 112.165197071\n",
      "positions (x,y,z), reward: [-0.18956561 -1.05020664  6.34111919] 108.337716303\n",
      "positions (x,y,z), reward: [ 0.13022201 -1.37288017  5.08702612] 107.700467027\n",
      "Episode =  891, score = 224.117 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.2698805  -0.17819191  9.37733204] 114.514982106\n",
      "positions (x,y,z), reward: [-0.31039453 -0.0347707   2.5096436 ] 102.826577598\n",
      "Episode =  892, score = 225.633 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  5.96895991e-04   2.26361535e-02   9.92023322e+00] 122.157335079\n",
      "positions (x,y,z), reward: [-2.67514373  0.49699788  6.30994374] 110.275743431\n",
      "Episode =  893, score = 227.142 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.22684609 -0.50084741  8.31698398] 117.58189979\n",
      "positions (x,y,z), reward: [ 0.75657519 -0.67023799  7.5784745 ] 112.962581459\n",
      "positions (x,y,z), reward: [ 2.47888627 -1.20244922  5.37088687] 105.595078924\n",
      "positions (x,y,z), reward: [ 5.61116385 -1.85494841  0.21713974] 84.1524624459\n",
      "Episode =  894, score = 218.482 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.43214482 -0.17102043  9.8261156 ] 112.447523757\n",
      "positions (x,y,z), reward: [-0.79216173 -0.43025596  8.54369425] 111.888456627\n",
      "positions (x,y,z), reward: [-0.47863753 -1.118148    3.20609017] 107.042711597\n",
      "positions (x,y,z), reward: [-0.35559865 -1.35264645  0.29130867] 97.6278685231\n",
      "Episode =  895, score = 227.763 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.42208069 -0.24941608  8.56578761] 120.387814473\n",
      "positions (x,y,z), reward: [-0.81797472 -0.34603743  7.7128338 ] 117.965112515\n",
      "positions (x,y,z), reward: [-1.62412973 -0.53204553  5.91756439] 112.499735768\n",
      "Episode =  896, score = 228.473 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  8.71193316e-03  -7.33201317e-02   9.73801276e+00] 108.392387958\n",
      "positions (x,y,z), reward: [ 0.30500833 -0.58584501  8.32960517] 105.392942923\n",
      "positions (x,y,z), reward: [ 0.37124581 -0.6446266   8.04831896] 109.307327405\n",
      "positions (x,y,z), reward: [ 0.43728132 -0.70446807  7.74895882] 111.93933872\n",
      "positions (x,y,z), reward: [ 1.57529534 -1.58166674  1.73926389] 97.291821993\n",
      "Episode =  897, score = 214.756 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  7.00985161e-03  -3.78333049e-03   9.97307571e+00] 125.206782276\n",
      "positions (x,y,z), reward: [-0.13983615  0.04811426  9.8091154 ] 117.247767723\n",
      "positions (x,y,z), reward: [-0.47617302  0.11649045  9.53661062] 115.679656208\n",
      "positions (x,y,z), reward: [-2.36611725  2.28065754  0.        ] 93.5838346467\n",
      "Episode =  898, score = 223.569 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.01310095   0.06199876  10.01188643] 124.537008104\n",
      "positions (x,y,z), reward: [ 0.02532055  0.07260528  9.93657056] 124.376816657\n",
      "positions (x,y,z), reward: [-0.14102399  0.10293532  9.52236612] 120.16643275\n",
      "positions (x,y,z), reward: [-0.31176687  0.09119875  9.01539606] 113.648249506\n",
      "positions (x,y,z), reward: [-1.12858952  0.36291563  6.44943562] 114.721594031\n",
      "positions (x,y,z), reward: [-1.30527635  0.42757348  5.81413245] 113.745213778\n",
      "positions (x,y,z), reward: [-1.57547827  0.49704295  4.95070104] 111.747206986\n",
      "positions (x,y,z), reward: [-2.76628753  0.93789901  0.06219174] 97.842712126\n",
      "Episode =  899, score = 230.973 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.01475087  0.02987172  9.99452989] 121.147893362\n",
      "positions (x,y,z), reward: [-0.87619633 -0.26547872  6.46906856] 113.152240229\n",
      "positions (x,y,z), reward: [-1.07602643 -0.18085055  4.61638666] 110.684419911\n",
      "Episode =  900, score = 224.892 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -6.64002159e-02   3.70220497e-03   9.97979115e+00] 120.731936487\n",
      "positions (x,y,z), reward: [-0.1113941   0.02781498  9.84846649] 111.132012967\n",
      "positions (x,y,z), reward: [ 2.1544331  -0.13293502  2.82045983] 102.225303887\n",
      "positions (x,y,z), reward: [ 2.34424505 -0.2542252   0.        ] 96.2505083763\n",
      "Episode =  901, score = 223.799 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.10656941 -0.10436955  9.79511702] 116.818751856\n",
      "positions (x,y,z), reward: [ 0.28064026 -0.28980288  9.55175666] 113.811841985\n",
      "positions (x,y,z), reward: [ 1.56099247 -4.88228185  0.        ] 86.5268597264\n",
      "Episode =  902, score = 215.438 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.35759178 -0.28364575  8.99824711] 111.848015906\n",
      "positions (x,y,z), reward: [ 2.66058889  0.31429371  5.44678436] 106.971419888\n",
      "positions (x,y,z), reward: [ 2.89041634  0.38163855  5.10684191] 104.674726287\n",
      "Episode =  903, score = 222.027 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -9.34895048e-03  -1.56308768e-02   9.87822215e+00] 119.456120633\n",
      "positions (x,y,z), reward: [ 0.01840993 -1.33471187  7.00884271] 113.902634834\n",
      "positions (x,y,z), reward: [-0.30399849 -2.1929695   3.51984602] 104.602736794\n",
      "Episode =  904, score = 222.914 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00112619] 146.813923776\n",
      "positions (x,y,z), reward: [ 0.24658144  0.11733402  9.58023132] 119.398595588\n",
      "positions (x,y,z), reward: [ 0.58888796 -0.08452649  8.8277911 ] 119.028918799\n",
      "positions (x,y,z), reward: [ 1.8953435  -0.6540366   2.64895107] 94.0380154774\n",
      "Episode =  905, score = 222.714 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.89631972e-02   7.55249201e-04   9.99658578e+00] 134.724081138\n",
      "positions (x,y,z), reward: [-0.19856677 -0.03133663  9.81427875] 110.037231197\n",
      "positions (x,y,z), reward: [-0.65151037 -0.58179301  8.22036718] 108.411335468\n",
      "positions (x,y,z), reward: [ 0.03621689 -2.42144534  3.37224129] 103.447751345\n",
      "Episode =  906, score = 214.690 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.06802898 -0.06137521  9.90909702] 122.297991896\n",
      "positions (x,y,z), reward: [ 0.09181182 -0.16872497  8.81233235] 112.064287646\n",
      "positions (x,y,z), reward: [ 0.10787304 -0.17470503  8.72448391] 112.632420812\n",
      "Episode =  907, score = 223.769 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.03219823e-01  -4.40051804e-03   9.88760969e+00] 112.045644638\n",
      "positions (x,y,z), reward: [ 0.505741    0.17309414  9.30765743] 112.446047693\n",
      "positions (x,y,z), reward: [ 0.5402471   0.15816445  9.26005078] 112.403412606\n",
      "positions (x,y,z), reward: [ 0.94285578  0.13414508  8.44914065] 113.998397257\n",
      "positions (x,y,z), reward: [ 1.31277554  0.05753891  7.73651244] 116.536057811\n",
      "Episode =  908, score = 217.080 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.05889747  0.01315421  9.91586851] 122.903931295\n",
      "positions (x,y,z), reward: [ 0.26731202  0.09588588  9.6525412 ] 121.678554274\n",
      "positions (x,y,z), reward: [ 1.35358592 -0.01113092  8.18790769] 114.017625456\n",
      "positions (x,y,z), reward: [ 2.5602059  -0.30430766  6.62603515] 107.643591592\n",
      "positions (x,y,z), reward: [ 3.75006318 -0.68211304  4.12857649] 98.0875057065\n",
      "Episode =  909, score = 217.971 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -5.35234795e-02  -2.27957844e-03   9.94718385e+00] 120.325578656\n",
      "positions (x,y,z), reward: [-0.26587489  0.75792886  7.92332663] 108.626035323\n",
      "Episode =  910, score = 221.201 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.01687672  0.04014865  9.99583695] 120.860867313\n",
      "positions (x,y,z), reward: [ 0.04419275  0.17386847  9.90358928] 118.099534443\n",
      "Episode =  911, score = 220.510 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.10891528  0.0344299   9.75017392] 119.763630625\n",
      "positions (x,y,z), reward: [ 0.47409241  0.09888897  8.0747733 ] 111.923995779\n",
      "positions (x,y,z), reward: [ 0.70898445  0.17223808  7.21323523] 104.15559414\n",
      "Episode =  912, score = 223.331 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.36622194  1.63605377  8.07797154] 106.632458847\n",
      "positions (x,y,z), reward: [ 1.99200407  2.61663631  6.35322748] 105.320412848\n",
      "positions (x,y,z), reward: [ 2.11143566  2.73239823  6.08399577] 103.830999048\n",
      "positions (x,y,z), reward: [ 4.22388971  4.06560472  0.9081391 ] 87.2839349738\n",
      "positions (x,y,z), reward: [ 4.56296903  4.2386383   0.        ] 84.2092892417\n",
      "Episode =  913, score = 218.863 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.96808604 -2.00741671  1.96499736] 84.89610413\n",
      "Episode =  914, score = 210.039 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 4.23280886 -0.03018471  7.54779883] 106.678804791\n",
      "positions (x,y,z), reward: [ 6.50339643  0.19806745  5.07660169] 92.4097838917\n",
      "positions (x,y,z), reward: [ 7.35149527  0.32857139  3.61670025] 92.9664197908\n",
      "positions (x,y,z), reward: [ 8.27827502  0.43782254  1.96330545] 76.9215779907\n",
      "positions (x,y,z), reward: [ 9.24616069  0.6087307   0.1143379 ] 84.28339293\n",
      "Episode =  915, score = 208.239 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.10128449 -0.06416474  9.81124266] 117.809701031\n",
      "positions (x,y,z), reward: [ 0.57984745 -0.06320252  9.4448421 ] 118.270023527\n",
      "positions (x,y,z), reward: [ 0.81262723 -0.06169289  9.31462861] 113.795850101\n",
      "positions (x,y,z), reward: [ 2.30698361  0.21321022  7.82274323] 103.03154282\n",
      "positions (x,y,z), reward: [ 2.82673661  0.26195104  7.06658771] 102.776175475\n",
      "Episode =  916, score = 221.814 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-1.62757809  0.8701408   4.53013589] 109.33046245\n",
      "Episode =  917, score = 227.732 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 3.47830587  1.99745274  3.71924017] 96.7569979282\n",
      "positions (x,y,z), reward: [ 5.04273559  2.50422291  1.22036393] 90.3951990497\n",
      "Episode =  918, score = 219.452 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.42789462  0.40780768  8.93537639] 111.110277091\n",
      "positions (x,y,z), reward: [ 3.26459301  1.02417614  6.01554063] 101.895692254\n",
      "positions (x,y,z), reward: [ 4.06074124  1.44945735  3.87858012] 100.979078293\n",
      "positions (x,y,z), reward: [ 4.20082205  1.53206262  3.43726102] 100.350619284\n",
      "Episode =  919, score = 216.809 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.02684813e-02  -8.29893942e-04   9.99320991e+00] 126.326523583\n",
      "positions (x,y,z), reward: [ -7.58940313e-02  -9.19281577e-03   9.72626039e+00] 109.576779264\n",
      "positions (x,y,z), reward: [  8.87880822e-03  -4.06632572e-02   9.57177970e+00] 111.030431006\n",
      "positions (x,y,z), reward: [ 0.17237962 -0.23156162  9.28052157] 115.365231376\n",
      "positions (x,y,z), reward: [ 0.14622249 -0.7668335   8.28469766] 118.652933411\n",
      "positions (x,y,z), reward: [-0.88049311 -1.81131198  3.52316215] 105.54479491\n",
      "positions (x,y,z), reward: [-1.10751866 -2.32725641  0.71608523] 97.7133870309\n",
      "positions (x,y,z), reward: [-1.14248241 -2.48108661  0.        ] 95.6485765012\n",
      "Episode =  921, score = 221.247 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.27732151 -0.01424537  8.93027899] 121.57367164\n",
      "positions (x,y,z), reward: [-0.66466699 -0.83447283  5.94818811] 112.188862364\n",
      "Episode =  922, score = 229.560 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -2.83550601e-04   7.60442273e-04   1.00062963e+01] 150.764029046\n",
      "positions (x,y,z), reward: [ 0.03415418  0.99920216  7.87274552] 114.717386488\n",
      "Episode =  923, score = 226.667 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.14660716 -0.08755082  9.80838209] 115.437748643\n",
      "positions (x,y,z), reward: [ 1.77607233 -1.10992268  7.54014733] 104.353173107\n",
      "Episode =  924, score = 206.052 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.20488061e-02   1.57249097e-03   1.00093333e+01] 144.136969001\n",
      "positions (x,y,z), reward: [ 0.07533304 -0.81465744  9.29066439] 122.746892594\n",
      "positions (x,y,z), reward: [-0.0527514  -1.05735648  8.8888241 ] 121.416914898\n",
      "positions (x,y,z), reward: [-0.30670231 -1.45664839  8.16183183] 119.000245146\n",
      "positions (x,y,z), reward: [-1.25246341 -3.0323331   4.89380771] 108.402016624\n",
      "positions (x,y,z), reward: [-1.30446    -3.12618134  4.67903173] 107.697798613\n",
      "positions (x,y,z), reward: [-2.15764124 -4.78010804  0.56650617] 94.2133993951\n",
      "Episode =  925, score = 236.126 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.15541349  0.22185219  9.07970512] 118.430122684\n",
      "positions (x,y,z), reward: [ 2.77509888  0.32089448  7.83826202] 96.389607874\n",
      "positions (x,y,z), reward: [ 4.3832479   0.53456708  5.34132431] 102.149964422\n",
      "Episode =  926, score = 216.671 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.           0.          10.00161968] 146.709401395\n",
      "positions (x,y,z), reward: [-0.16547727  0.03817276  9.89005897] 112.280701954\n",
      "positions (x,y,z), reward: [ 1.5829541   0.64768524  7.42104953] 113.668331773\n",
      "Episode =  927, score = 219.851 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.0304368  -0.17104814  9.25900659] 108.136850643\n",
      "Episode =  928, score = 221.206 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.29303056 -0.1813457   9.59469393] 113.580747907\n",
      "positions (x,y,z), reward: [ 0.38187798 -0.3324831   9.44423033] 114.504265766\n",
      "positions (x,y,z), reward: [ 0.78430327 -1.92099634  6.2627904 ] 109.371625584\n",
      "positions (x,y,z), reward: [ 1.12621145 -3.89290032  0.30100723] 94.6250519106\n",
      "Episode =  929, score = 217.872 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.07207465 -0.06041843  9.90408514] 123.286781033\n",
      "positions (x,y,z), reward: [-1.14236526 -0.26234046  0.63699585] 96.3415247912\n",
      "Episode =  930, score = 227.974 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.47877276 -1.84202816  6.31870215] 106.239259021\n",
      "Episode =  931, score = 220.344 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.54440672 -0.91498777  7.78166407] 115.83701395\n",
      "positions (x,y,z), reward: [ 0.69504907 -1.14839051  6.98212513] 108.903695521\n",
      "positions (x,y,z), reward: [ 2.9035483  -2.26473914  0.30340719] 86.5700296485\n",
      "Episode =  932, score = 215.723 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.0642126   0.09766348  9.69041846] 118.98137881\n",
      "positions (x,y,z), reward: [-0.14117335  0.29689576  9.30728181] 118.050463285\n",
      "positions (x,y,z), reward: [-0.17308535  0.41995252  8.89003114] 118.23190443\n",
      "positions (x,y,z), reward: [-1.09421584  0.99011728  6.22062324] 111.767136281\n",
      "Episode =  933, score = 224.531 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -3.43356348e-03   4.95665644e-05   1.00036975e+01] 144.249303879\n",
      "positions (x,y,z), reward: [-0.60139537 -0.31491548  9.23481818] 112.595587079\n",
      "positions (x,y,z), reward: [-0.15332858 -0.17050821  2.19669809] 93.6755525507\n",
      "Episode =  934, score = 212.906 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  4.20542184e-03  -1.15697081e-03   9.91637471e+00] 120.826469924\n",
      "positions (x,y,z), reward: [-0.63393822 -0.08468042  9.04514724] 121.30080457\n",
      "positions (x,y,z), reward: [-1.18028964 -0.11509442  8.2877317 ] 119.459033859\n",
      "positions (x,y,z), reward: [-1.26601712 -0.10681903  8.1721759 ] 119.143545188\n",
      "positions (x,y,z), reward: [-1.82280502  0.03032095  7.2193947 ] 115.935789783\n",
      "positions (x,y,z), reward: [-1.8932196   0.07506831  6.94175904] 114.67778458\n",
      "positions (x,y,z), reward: [-1.9546629   0.42214851  5.74859752] 110.803859006\n",
      "positions (x,y,z), reward: [-2.01642315  1.79966485  2.4579561 ] 99.5973928678\n",
      "positions (x,y,z), reward: [-2.05068365  1.97563441  1.96220358] 98.2616073792\n",
      "Episode =  935, score = 227.297 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.17609922  0.11938232  9.69180521] 118.542505782\n",
      "positions (x,y,z), reward: [ 0.15962119  0.23845602  9.46622382] 116.961088088\n",
      "positions (x,y,z), reward: [ 0.1627902   0.28419418  9.37128241] 115.898242507\n",
      "positions (x,y,z), reward: [-0.32735953  0.65198397  5.10785091] 109.940970372\n",
      "positions (x,y,z), reward: [-0.35961309  0.67084598  4.89397744] 109.101958815\n",
      "Episode =  936, score = 227.880 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.34831318e-02   2.73287360e-04   1.00026683e+01] 137.201362613\n",
      "Episode =  937, score = 220.638 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.21171701  0.21052137  9.65816747] 116.501624939\n",
      "positions (x,y,z), reward: [-0.55136406  0.03679862  8.84470232] 115.089038893\n",
      "positions (x,y,z), reward: [-1.93426616 -0.3708884   5.79287226] 112.235369567\n",
      "Episode =  938, score = 228.444 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.02547201 -0.0960685   9.73833199] 120.569364412\n",
      "positions (x,y,z), reward: [-0.06320792 -0.121273    9.60001906] 120.08694783\n",
      "positions (x,y,z), reward: [-0.17495423 -0.61042806  8.07885667] 108.614168802\n",
      "positions (x,y,z), reward: [-1.37130689 -2.71354541  2.93009207] 102.661669828\n",
      "Episode =  939, score = 223.836 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.19278848 -0.12334712  7.75436549] 114.564686649\n",
      "Episode =  940, score = 233.795 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -6.72903158e-02  -7.33728962e-03   9.92613363e+00] 117.313979415\n",
      "positions (x,y,z), reward: [-0.07652557  0.05101649  8.91699281] 106.712781954\n",
      "positions (x,y,z), reward: [ 0.06226572  0.02788488  8.60849612] 109.718099224\n",
      "positions (x,y,z), reward: [  3.25436190e-01  -4.14278093e-03   8.18490654e+00] 111.305273015\n",
      "positions (x,y,z), reward: [ 1.73916275 -0.51779557  5.38232813] 108.849206014\n",
      "positions (x,y,z), reward: [ 1.79540826 -0.54652908  5.20681991] 108.643943467\n",
      "positions (x,y,z), reward: [ 2.67747596 -1.06197204  1.50410386] 97.8910448005\n",
      "Episode =  941, score = 217.594 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.18470175  0.0180866   9.50588863] 117.499666528\n",
      "positions (x,y,z), reward: [-0.86925648  0.51267597  3.87639938] 105.95959254\n",
      "positions (x,y,z), reward: [-0.85955414  0.49375611  3.45053573] 105.818749677\n",
      "positions (x,y,z), reward: [-0.84886501  0.46581276  2.78829114] 105.031090838\n",
      "Episode =  942, score = 228.112 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.01961493   0.01196228  10.02838157] 152.362918623\n",
      "positions (x,y,z), reward: [ -4.36682524e-01   6.59892577e-03   9.35543889e+00] 124.143902735\n",
      "positions (x,y,z), reward: [-2.49858047  0.19149304  6.39806161] 108.7223648\n",
      "positions (x,y,z), reward: [-4.51081196  0.617457    2.7906079 ] 95.8103070331\n",
      "positions (x,y,z), reward: [-5.80908046  0.91794659  0.04926989] 88.9524859991\n",
      "Episode =  943, score = 229.492 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.01671835 -0.01015449  9.69164897] 110.38378901\n",
      "positions (x,y,z), reward: [ 1.19394778  0.29478555  6.65581703] 108.881597111\n",
      "Episode =  944, score = 217.291 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.72235176  0.70042602  1.3602068 ] 95.8590391943\n",
      "Episode =  945, score = 226.411 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-2.1564036   1.6699363   2.68096003] 100.751917811\n",
      "positions (x,y,z), reward: [-2.22209725  1.79088657  2.10530713] 99.0840468332\n",
      "positions (x,y,z), reward: [-2.42561804  2.07562706  0.55327067] 95.9875784099\n",
      "positions (x,y,z), reward: [-2.51034621  2.21198082  0.        ] 94.3592137175\n",
      "Episode =  946, score = 225.210 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.01727886 -0.01820287  9.92527388] 118.629966241\n",
      "positions (x,y,z), reward: [ 0.94349404 -0.11686375  9.0693676 ] 111.919413202\n",
      "positions (x,y,z), reward: [ 3.47613002  0.26564808  6.8564574 ] 101.513575261\n",
      "positions (x,y,z), reward: [ 4.33782028  0.5349863   5.82380959] 102.581890016\n",
      "positions (x,y,z), reward: [ 4.54002171  0.60793612  5.52029989] 103.196170967\n",
      "positions (x,y,z), reward: [ 7.01151605  1.50173827  1.4090424 ] 95.8837007071\n",
      "Episode =  947, score = 212.834 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  4.29589680e-03   2.65776299e-03   9.90638643e+00] 119.645518826\n",
      "positions (x,y,z), reward: [-0.36865443 -0.237131    5.93577448] 112.843551211\n",
      "positions (x,y,z), reward: [ 0.85674761 -0.59955137  2.11614119] 105.721533793\n",
      "Episode =  948, score = 224.137 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.38248663  -0.06029886  10.07438246] 145.665313507\n",
      "positions (x,y,z), reward: [ 0.36636128  0.53146896  7.76145808] 114.097125091\n",
      "positions (x,y,z), reward: [-0.40912075  1.49745509  3.64359723] 104.015340963\n",
      "positions (x,y,z), reward: [-0.53188464  1.65617303  2.97823072] 102.013034819\n",
      "positions (x,y,z), reward: [-0.57590932  1.71284478  2.74807102] 101.266271535\n",
      "Episode =  949, score = 231.856 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.23089669 -0.31550901  9.30789905] 110.737152672\n",
      "positions (x,y,z), reward: [ 0.33178402 -0.75869544  8.39180585] 104.738571969\n",
      "positions (x,y,z), reward: [ 0.35832789 -0.93244231  7.98341328] 104.377617333\n",
      "positions (x,y,z), reward: [ 0.42099132 -1.04043299  7.70544308] 106.205244402\n",
      "positions (x,y,z), reward: [ 0.51568466 -1.14741427  7.41311265] 107.518309737\n",
      "positions (x,y,z), reward: [ 1.37938658 -1.79315746  5.4860071 ] 105.722579852\n",
      "Episode =  950, score = 211.026 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.36060961 -0.11734788  9.6250529 ] 112.509673939\n",
      "positions (x,y,z), reward: [-1.04707842  0.49098358  5.62010003] 111.219946399\n",
      "positions (x,y,z), reward: [-0.94382032  0.96368239  2.065673  ] 100.675355174\n",
      "Episode =  951, score = 225.387 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.28870144  0.1716424   9.89390129] 120.591968924\n",
      "positions (x,y,z), reward: [ 0.45130143  0.24952437  9.86771894] 121.307344582\n",
      "positions (x,y,z), reward: [ 2.35119358  0.6060717   8.91583306] 112.74197812\n",
      "positions (x,y,z), reward: [ 3.38011814  0.74674962  8.10263764] 108.363459486\n",
      "positions (x,y,z), reward: [ 4.32117847  0.86752345  7.16604105] 104.933925951\n",
      "positions (x,y,z), reward: [ 4.70742442  0.945645    6.71803916] 104.961088863\n",
      "Episode =  952, score = 220.848 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -4.76927612e-03   2.30538091e-03   9.97309549e+00] 126.138929366\n",
      "positions (x,y,z), reward: [  7.61237037e-03  -4.32510591e-02   9.76536120e+00] 117.455791241\n",
      "positions (x,y,z), reward: [ 0.01827234 -0.07315255  9.70447267] 116.642579045\n",
      "positions (x,y,z), reward: [ 0.02395915 -0.697926    7.45406988] 116.024883266\n",
      "positions (x,y,z), reward: [ 1.05994665 -2.0922866   1.13733353] 94.6559541142\n",
      "positions (x,y,z), reward: [ 1.23075959 -2.23046279  0.31456045] 92.8866348663\n",
      "Episode =  953, score = 223.372 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.08690306  0.06851315  9.42658985] 113.001869111\n",
      "positions (x,y,z), reward: [ 1.72412082  0.58974598  7.22901133] 112.113410447\n",
      "positions (x,y,z), reward: [ 1.97725472  0.68367046  6.82167942] 110.578579171\n",
      "positions (x,y,z), reward: [ 2.76681097  0.96826215  5.38749527] 99.1616840849\n",
      "Episode =  954, score = 219.254 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  5.47405554e-03  -1.70939228e-02   1.00271876e+01] 121.170691395\n",
      "positions (x,y,z), reward: [ 0.56289979 -0.31864541  9.61467231] 110.588683392\n",
      "positions (x,y,z), reward: [ 2.3309418  -1.30112095  2.73524409] 94.2913793363\n",
      "Episode =  955, score = 217.741 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  3.96925575e-04   1.40657662e-03   1.00054022e+01] 145.700367039\n",
      "positions (x,y,z), reward: [ 0.0556873   0.0222169   9.97497002] 118.959692641\n",
      "positions (x,y,z), reward: [ 0.46283477 -0.18070625  9.65084328] 110.232991236\n",
      "positions (x,y,z), reward: [ 0.86589318 -0.76676607  8.76533956] 102.530679039\n",
      "positions (x,y,z), reward: [ 4.68324617 -3.70680862  1.43790128] 92.7654090289\n",
      "Episode =  956, score = 207.189 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.75303264 -1.12032645  4.05969418] 106.098056789\n",
      "Episode =  957, score = 215.752 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.03112546  0.02451335  9.97717955] 115.091592624\n",
      "positions (x,y,z), reward: [-0.51636116 -0.25994649  8.68553444] 106.481310731\n",
      "positions (x,y,z), reward: [-0.54570087 -0.75886897  5.99743401] 103.115202123\n",
      "Episode =  958, score = 216.931 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.45267511  0.10371578  9.79710282] 115.972484289\n",
      "positions (x,y,z), reward: [ 1.51021473 -0.05052654  9.03573432] 121.226605203\n",
      "Episode =  959, score = 227.934 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.43374404  1.4610744   7.04896371] 115.574677008\n",
      "Episode =  960, score = 226.043 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 5.17313657  0.63283544  3.81167997] 93.0755175604\n",
      "Episode =  961, score = 216.136 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -7.02735785e-02   9.35014591e-03   9.97286104e+00] 118.1957845\n",
      "positions (x,y,z), reward: [-0.11178631 -0.01787319  9.93091955] 116.950903488\n",
      "positions (x,y,z), reward: [-0.31787047 -0.10752352  9.76080793] 114.322243639\n",
      "positions (x,y,z), reward: [-0.48254149 -0.02823302  9.19185893] 115.835989072\n",
      "positions (x,y,z), reward: [-0.43459435 -0.06564005  8.96221273] 115.767411816\n",
      "positions (x,y,z), reward: [-0.69018184  0.43387643  4.87531242] 110.152351965\n",
      "positions (x,y,z), reward: [-0.72312068  0.86204133  2.64893958] 104.62752705\n",
      "positions (x,y,z), reward: [-0.73392017  0.9134444   2.37443416] 103.852613188\n",
      "Episode =  962, score = 226.707 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -8.11748002e-03   1.21623602e-03   1.00167614e+01] 119.394095728\n",
      "positions (x,y,z), reward: [ 0.14917207 -0.0526874   9.80986074] 118.814669071\n",
      "positions (x,y,z), reward: [ 0.28484196 -0.10254392  9.61155194] 117.645710539\n",
      "positions (x,y,z), reward: [ 0.30026583 -0.12230323  9.4934417 ] 119.233733798\n",
      "positions (x,y,z), reward: [ 0.29284524 -0.13402263  9.39510618] 120.404545119\n",
      "positions (x,y,z), reward: [ 0.15008736 -0.56387247  6.90763429] 112.291130594\n",
      "positions (x,y,z), reward: [-0.18867664 -0.97448564  4.4569671 ] 106.232504205\n",
      "Episode =  963, score = 227.013 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  2.73138990e-02   3.91946373e-03   1.00083164e+01] 125.826917471\n",
      "positions (x,y,z), reward: [ 4.38838271 -0.66214995  5.42877433] 91.5100220557\n",
      "positions (x,y,z), reward: [ 4.89756116 -0.70079946  4.69322627] 95.1221972632\n",
      "Episode =  964, score = 209.294 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.09016209  0.08273809  9.79849136] 119.697505459\n",
      "positions (x,y,z), reward: [ 0.01824777  0.51974636  9.0883162 ] 119.361506507\n",
      "positions (x,y,z), reward: [-0.01510819  0.61689822  8.87273059] 119.556586921\n",
      "Episode =  965, score = 225.334 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.01072742  0.33580622  8.69404919] 113.724305656\n",
      "positions (x,y,z), reward: [ 1.0907159   0.36293242  8.00568703] 114.814663429\n",
      "positions (x,y,z), reward: [ 1.12374022  0.48415543  4.76634813] 108.138907081\n",
      "positions (x,y,z), reward: [ 0.9250184   0.75894162  0.67554311] 99.3059406841\n",
      "Episode =  966, score = 225.871 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.61991557e-03  -1.99557440e-02   9.70989656e+00] 116.01057936\n",
      "positions (x,y,z), reward: [ 0.03658276 -0.05736843  9.59236661] 112.394478393\n",
      "positions (x,y,z), reward: [-0.21564245 -1.2215497   7.28646703] 111.62487183\n",
      "positions (x,y,z), reward: [-0.25733047 -1.3652339   6.76386576] 107.455915231\n",
      "Episode =  967, score = 219.525 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -0.03375153   0.01037138  10.01054048] 133.514608913\n",
      "positions (x,y,z), reward: [ 0.15190127  0.59017302  9.96493006] 112.865311793\n",
      "positions (x,y,z), reward: [ 1.13321145  1.49920654  9.0908195 ] 107.868300761\n",
      "Episode =  968, score = 215.068 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.92928658  0.63343201  9.67445598] 117.310510903\n",
      "positions (x,y,z), reward: [ 1.12479355  0.6961902   9.57356135] 116.477606666\n",
      "positions (x,y,z), reward: [ 1.33742899  0.81218378  9.36075026] 114.657657522\n",
      "positions (x,y,z), reward: [ 2.05007398  1.14542616  8.4532549 ] 109.268060698\n",
      "positions (x,y,z), reward: [ 3.00156896  1.06916969  5.58280567] 107.731768172\n",
      "positions (x,y,z), reward: [ 3.05652652  1.07383112  5.20501574] 106.742060367\n",
      "positions (x,y,z), reward: [ 3.29635926  1.08430572  3.97760269] 95.1946244297\n",
      "positions (x,y,z), reward: [ 3.80569548  1.04917308  1.6572469 ] 96.1460842897\n",
      "Episode =  969, score = 220.541 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.02497498  0.09489583  9.79369536] 120.156569287\n",
      "positions (x,y,z), reward: [ 0.02443761  0.57199491  8.46896741] 115.264980467\n",
      "positions (x,y,z), reward: [ 0.89172312  0.68242095  5.28455906] 102.765355852\n",
      "positions (x,y,z), reward: [ 1.48825304  0.63924694  2.99255971] 93.9063866229\n",
      "Episode =  970, score = 222.185 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  0.08445051   0.05187923  10.01065896] 129.477124255\n",
      "positions (x,y,z), reward: [ 0.23091239  0.51233507  9.08442563] 114.61421809\n",
      "positions (x,y,z), reward: [ 0.69647217  0.89071762  7.40520053] 113.209792708\n",
      "positions (x,y,z), reward: [ 0.95549925  0.97937984  6.79347245] 112.451282979\n",
      "Episode =  971, score = 220.726 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04189331  0.03029015  9.89771609] 120.423179363\n",
      "positions (x,y,z), reward: [ 0.35246959  0.50106969  8.88794414] 116.82350676\n",
      "positions (x,y,z), reward: [ 0.2949511   0.62872576  8.03826446] 116.820499981\n",
      "positions (x,y,z), reward: [ 0.21805259  0.73183589  6.93460764] 115.730314905\n",
      "positions (x,y,z), reward: [ -2.82210240e-03   8.66432261e-01   4.94011728e+00] 109.880245668\n",
      "positions (x,y,z), reward: [-0.04481397  0.90972872  4.4775438 ] 107.619827913\n",
      "positions (x,y,z), reward: [-0.06177394  0.95117711  4.0045753 ] 102.757961964\n",
      "Episode =  972, score = 226.403 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.33563662 -0.10490762  9.35262012] 102.601737319\n",
      "positions (x,y,z), reward: [-0.84499939 -1.13648777  5.47737083] 105.992733958\n",
      "positions (x,y,z), reward: [-0.83350389 -1.20318808  5.03928803] 105.461524403\n",
      "positions (x,y,z), reward: [-0.82333779 -1.27563454  4.57909478] 105.570289013\n",
      "Episode =  973, score = 212.497 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.04615286 -0.17982379  9.79639424] 113.736199471\n",
      "positions (x,y,z), reward: [-0.50525985 -2.13939986  5.88346242] 108.280047708\n",
      "positions (x,y,z), reward: [-0.27083912 -2.4359897   4.88030922] 108.154260096\n",
      "positions (x,y,z), reward: [-0.20892515 -2.49880962  4.66602251] 107.967338184\n",
      "positions (x,y,z), reward: [ 1.04743551 -3.36678512  1.34430555] 97.2362018797\n",
      "Episode =  974, score = 212.139 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.10973233  0.30439468  9.67965721] 117.71675967\n",
      "positions (x,y,z), reward: [ 0.78904558  1.22950743  7.41647751] 112.903297356\n",
      "positions (x,y,z), reward: [ 1.40630453  2.05719167  5.41560706] 107.343594255\n",
      "positions (x,y,z), reward: [ 1.50687614  2.32562124  4.569617  ] 105.386780453\n",
      "Episode =  975, score = 220.284 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [-0.01947127  0.05991015  9.70314933] 109.367861352\n",
      "positions (x,y,z), reward: [ 0.32966505 -0.06703667  9.24025934] 109.144172733\n",
      "positions (x,y,z), reward: [ 0.52725883  0.02470034  8.71778984] 109.02207482\n",
      "positions (x,y,z), reward: [ 2.42997284  0.51958572  4.14205535] 103.033279115\n",
      "Episode =  976, score = 218.712 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 1.40815148  0.1997939   9.33560323] 115.690295409\n",
      "positions (x,y,z), reward: [ 1.48661541  0.19757308  9.28504343] 115.495149943\n",
      "positions (x,y,z), reward: [ 2.06407483  0.25301437  8.59115422] 115.046135383\n",
      "positions (x,y,z), reward: [ 2.13320481  0.26692013  8.46537049] 114.458777684\n",
      "positions (x,y,z), reward: [ 5.3243872   0.49381731  2.67090476] 98.9768476513\n",
      "Episode =  977, score = 213.485 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.6084592   1.20065157  0.84404237] 102.071031175\n",
      "Episode =  978, score = 219.735 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.19387743e-02   2.32391175e-03   9.90884047e+00] 121.343476472\n",
      "positions (x,y,z), reward: [-1.16677727  0.32058009  4.73890443] 110.527462605\n",
      "positions (x,y,z), reward: [-1.40986674  0.39809187  3.69044231] 107.812262287\n",
      "positions (x,y,z), reward: [-2.23059666  0.60179939  0.        ] 98.5940811655\n",
      "Episode =  979, score = 230.581 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  1.42838905e-03   1.67494981e-05   1.00044299e+01] 145.834209132\n",
      "positions (x,y,z), reward: [ 0.32271169  0.27863587  9.69405952] 121.474389002\n",
      "positions (x,y,z), reward: [ 1.22584559  1.76774245  7.24998461] 106.238101527\n",
      "Episode =  980, score = 217.121 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.226185   -2.16229584  3.71684183] 101.742569432\n",
      "Episode =  981, score = 209.326 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.48948543  0.23561719  9.88598666] 118.703403278\n",
      "positions (x,y,z), reward: [ 4.21656877  1.52400572  0.05218172] 87.4119271786\n",
      "Episode =  982, score = 213.524 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.02047232  0.08693132  9.68139101] 108.305993298\n",
      "positions (x,y,z), reward: [ 0.30473833  0.45289705  9.05197614] 109.436685278\n",
      "positions (x,y,z), reward: [ 3.73419593  0.93250747  4.09884312] 102.173124066\n",
      "Episode =  983, score = 207.975 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.25120926 -0.40170956  9.69964351] 118.317391761\n",
      "positions (x,y,z), reward: [ 0.53327337 -0.80385672  8.58182318] 113.419249568\n",
      "positions (x,y,z), reward: [ 2.28283085 -2.23802604  2.54147013] 94.2923607193\n",
      "Episode =  984, score = 220.157 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -5.71221969e-03   7.66327849e-03   1.00371688e+01] 146.234746387\n",
      "Episode =  985, score = 228.892 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04190044  0.05884268  9.81471392] 119.004213225\n",
      "positions (x,y,z), reward: [ 0.50646162  0.94585107  8.63113462] 106.218952503\n",
      "positions (x,y,z), reward: [ 0.64020616  1.57614149  7.92454235] 107.854109602\n",
      "positions (x,y,z), reward: [ 0.56633346  3.57876323  5.35462999] 99.819090984\n",
      "positions (x,y,z), reward: [ 0.83027319  5.18300535  1.13487462] 89.1602582741\n",
      "Episode =  986, score = 212.601 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 5.90947003  0.60567943  2.41288871] 95.5367667633\n",
      "Episode =  987, score = 220.104 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -8.87432298e-04  -9.25937796e-04   9.96960549e+00] 124.067931964\n",
      "positions (x,y,z), reward: [-0.49880702  0.79383736  8.689503  ] 123.319824359\n",
      "positions (x,y,z), reward: [-0.59131634  1.66455626  6.97845212] 114.541671869\n",
      "positions (x,y,z), reward: [-0.33531293  1.67409559  5.79348041] 109.335561751\n",
      "positions (x,y,z), reward: [ 0.85744353  1.12366178  1.0019136 ] 98.6662556823\n",
      "positions (x,y,z), reward: [ 1.20827156  1.02189673  0.        ] 93.3218927274\n",
      "Episode =  988, score = 227.040 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.4755731   0.49823007  9.32588868] 118.329130651\n",
      "positions (x,y,z), reward: [ 1.72709676  0.98275316  7.52651029] 109.779446092\n",
      "positions (x,y,z), reward: [ 2.34268128  1.22010917  6.49082236] 105.106261368\n",
      "positions (x,y,z), reward: [ 3.29449015  1.66023975  4.4624611 ] 103.345630068\n",
      "positions (x,y,z), reward: [ 3.38304229  1.70683718  4.23479893] 103.025112804\n",
      "positions (x,y,z), reward: [ 4.87427731  2.53086832  0.        ] 89.7185799908\n",
      "Episode =  989, score = 220.521 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -1.36835129e-02   6.92519840e-03   1.00190402e+01] 132.724310531\n",
      "positions (x,y,z), reward: [-0.13556334 -0.13023116  9.91288831] 117.567018686\n",
      "positions (x,y,z), reward: [-0.35939528 -0.27024494  9.32827416] 120.224986303\n",
      "positions (x,y,z), reward: [-0.64623843 -0.96283671  8.20143564] 112.80346331\n",
      "positions (x,y,z), reward: [-1.84920144 -2.8787577   3.62687583] 103.443670178\n",
      "positions (x,y,z), reward: [-1.89393171 -2.95942385  3.38607783] 102.902355174\n",
      "Episode =  990, score = 225.435 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -0.13452397   0.31923844  10.01155969] 116.231512824\n",
      "positions (x,y,z), reward: [-0.03785841  0.46809971  9.90920445] 120.241313007\n",
      "positions (x,y,z), reward: [ 0.16559896  0.77881595  9.51992758] 124.328167207\n",
      "positions (x,y,z), reward: [ 0.18703802  0.81820893  9.44802328] 122.506994925\n",
      "positions (x,y,z), reward: [ 0.76142336  1.095794    8.47910562] 115.771946197\n",
      "positions (x,y,z), reward: [ 2.08652544  1.41627509  6.81245902] 109.550033559\n",
      "positions (x,y,z), reward: [ 3.09572985  1.76126769  4.97190811] 102.674327766\n",
      "positions (x,y,z), reward: [ 4.02317313  2.11170065  2.70846131] 97.4454588279\n",
      "positions (x,y,z), reward: [ 4.19047293  2.17573764  2.24581691] 95.7523702918\n",
      "Episode =  991, score = 225.471 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.74921253  0.89538449  6.17770692] 106.972062295\n",
      "positions (x,y,z), reward: [ 3.50404587  1.13577149  4.54366331] 104.145365687\n",
      "Episode =  992, score = 215.622 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.03608553 -0.01472638  9.95542824] 123.520832649\n",
      "positions (x,y,z), reward: [-0.08381616 -0.07502815  9.53748819] 118.467065133\n",
      "positions (x,y,z), reward: [ 0.16962867 -0.132635    7.7709065 ] 113.107597046\n",
      "positions (x,y,z), reward: [ 0.3809526  -0.15598446  7.35892546] 112.370509153\n",
      "positions (x,y,z), reward: [ 2.49161973 -0.92156316  2.67406544] 98.5537917611\n",
      "Episode =  994, score = 218.757 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [  4.25443329e-03  -3.51472115e-03   9.96686425e+00] 125.072095059\n",
      "positions (x,y,z), reward: [ 0.83797042  0.47869964  8.68274453] 119.792944824\n",
      "positions (x,y,z), reward: [ 1.36954238  0.6829004   7.73817718] 112.118367467\n",
      "Episode =  995, score = 219.427 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 2.66360051  0.72698023  7.13205702] 109.480334022\n",
      "positions (x,y,z), reward: [ 2.86096621  0.76032221  6.83633094] 108.968002226\n",
      "positions (x,y,z), reward: [ 3.15431163  0.815396    6.37613114] 108.099614872\n",
      "positions (x,y,z), reward: [ 5.13904284  1.48258778  2.1935201 ] 97.6154980747\n",
      "Episode =  996, score = 217.242 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.04086484  0.09188706  9.75612101] 116.094221949\n",
      "positions (x,y,z), reward: [ 0.08440212  0.34923983  9.44424958] 116.8362329\n",
      "positions (x,y,z), reward: [ 1.84662909  2.17916349  2.94373426] 104.583280858\n",
      "Episode =  997, score = 226.050 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.05552388  0.23838417  9.25325616] 122.485690925\n",
      "positions (x,y,z), reward: [ 0.29372878  0.47269043  8.46037156] 113.556303346\n",
      "positions (x,y,z), reward: [ 1.02908325  0.75128818  7.21756693] 110.231662684\n",
      "positions (x,y,z), reward: [ 1.47271049  0.83714002  6.41585786] 109.124466982\n",
      "positions (x,y,z), reward: [ 2.66964788  1.12935228  4.22065674] 103.408937296\n",
      "Episode =  998, score = 218.346 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ -0.01457362   0.02211933  10.00655038] 122.129706644\n",
      "positions (x,y,z), reward: [ -7.81582166e-04  -5.75524059e-02   9.91040872e+00] 116.499355253\n",
      "positions (x,y,z), reward: [ 0.46915393 -1.64748757  7.55067701] 112.009552564\n",
      "positions (x,y,z), reward: [ 0.61485329 -1.75473928  7.25075291] 113.6885729\n",
      "positions (x,y,z), reward: [ 0.89609165 -1.98452032  6.61988695] 112.672625413\n",
      "positions (x,y,z), reward: [ 1.0304099  -2.10156518  6.27874545] 111.831724173\n",
      "positions (x,y,z), reward: [ 2.63509968 -3.59276063  0.04447981] 96.0097783103\n",
      "Episode =  999, score = 218.966 (best = 246.970), noise_scale = 3.2positions (x,y,z), reward: [ 0.14729107  0.01382902  9.80739793] 121.208938778\n",
      "positions (x,y,z), reward: [ 6.36565065 -0.01030908  5.11138746] 95.7300247135\n",
      "positions (x,y,z), reward: [ 7.49979833 -0.01822499  3.85689419] 99.2040891634\n",
      "positions (x,y,z), reward: [ 9.73688215 -0.13446926  1.0937912 ] 88.5887671482\n",
      "Episode = 1000, score = 212.132 (best = 246.970), noise_scale = 3.2"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from agents.policy_search import PolicySearch_Agent\n",
    "from task import Task\n",
    "\n",
    "num_episodes = 1000\n",
    "target_pos = np.array([0., 0., 20.])\n",
    "task = Task(target_pos=target_pos)\n",
    "agent = PolicySearch_Agent(task) \n",
    "\n",
    "for i_episode in range(1, num_episodes+1):\n",
    "    state = agent.reset_episode() # start a new episode\n",
    "    while True:\n",
    "        action = agent.act(state) \n",
    "        next_state, reward, done = task.step(action)\n",
    "        agent.step(reward, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"\\rEpisode = {:4d}, score = {:7.3f} (best = {:7.3f}), noise_scale = {}\".format(\n",
    "                i_episode, agent.score, agent.best_score, agent.noise_scale), end=\"\")  # [debug]\n",
    "            break\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This agent should perform very poorly on this task.  And that's where you come in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define the Task, Design the Agent, and Train Your Agent!\n",
    "\n",
    "Amend `task.py` to specify a task of your choosing.  If you're unsure what kind of task to specify, you may like to teach your quadcopter to takeoff, hover in place, land softly, or reach a target pose.  \n",
    "\n",
    "After specifying your task, use the sample agent in `agents/policy_search.py` as a template to define your own agent in `agents/agent.py`.  You can borrow whatever you need from the sample agent, including ideas on how you might modularize your code (using helper methods like `act()`, `learn()`, `reset_episode()`, etc.).\n",
    "\n",
    "Note that it is **highly unlikely** that the first agent and task that you specify will learn well.  You will likely have to tweak various hyperparameters and the reward function for your task until you arrive at reasonably good behavior.\n",
    "\n",
    "As you develop your agent, it's important to keep an eye on how it's performing. Use the code above as inspiration to build in a mechanism to log/save the total rewards obtained in each episode to file.  If the episode rewards are gradually increasing, this is an indication that your agent is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions (x,y,z), reward: [  0.09675985   0.02101237  19.14936931] -69.0884633791\n",
      "positions (x,y,z), reward: [  0.61915313   0.10887667  14.91092859] -71.695722954\n",
      "Episode =    1, score =   0.000 (best =    -inf), noise_scale = 0.1positions (x,y,z), reward: [  0.16765371   0.03741394  18.8871289 ] -75.2092746544\n",
      "positions (x,y,z), reward: [  0.28374278  -0.21416519  16.12319581] -89.4660011924\n",
      "positions (x,y,z), reward: [  0.30453334  -0.30685847  14.98062874] -87.8570949572\n",
      "positions (x,y,z), reward: [ 0.67865419 -0.81723431  4.48665391] -78.8078205722\n",
      "Episode =    2, score = -153.889 (best = -110.228), noise_scale = 0.1positions (x,y,z), reward: [  3.71071435e-04   6.26708361e-05   1.51203373e+01] -65.0291782796\n",
      "positions (x,y,z), reward: [  2.61614181e-03   4.97511058e-04   9.23069917e+00] -73.1805593899\n",
      "positions (x,y,z), reward: [  5.52617329e-03   1.20277151e-03   5.28019842e+00] -79.0852276791\n",
      "Episode =    3, score = -132.524 (best = -98.588), noise_scale = 0.1positions (x,y,z), reward: [  1.49646152e-19  -1.34482451e-18   1.99921516e+01] -54.3924370891\n",
      "positions (x,y,z), reward: [ -1.46151494e-10   2.38691666e-10   1.98032847e+01] -55.9727816429\n",
      "positions (x,y,z), reward: [ -3.02459894e-08   2.66448110e-08   1.89456294e+01] -58.6606486811\n",
      "positions (x,y,z), reward: [ -5.76342611e-06   2.49586685e-06   1.46663251e+01] -65.6661112742\n",
      "positions (x,y,z), reward: [ -1.94052209e-05   7.06688427e-06   1.19798540e+01] -69.354219296\n",
      "positions (x,y,z), reward: [ -2.16388947e-05   7.76023681e-06   1.16685039e+01] -69.7808480565\n",
      "positions (x,y,z), reward: [ -4.86286278e-05   1.55785176e-05   8.84122998e+00] -73.7338829777\n",
      "Episode =    4, score = -132.520 (best = -98.588), noise_scale = 0.1positions (x,y,z), reward: [  1.04892840e-08   3.54424737e-09   1.92059616e+01] -58.0194462992\n",
      "positions (x,y,z), reward: [  7.15109776e-03   2.44179070e-06   1.37074177e+01] -71.2516181831\n",
      "positions (x,y,z), reward: [  1.56774526e-01   4.95705376e-06   1.01483677e+01] -93.2073234292\n",
      "positions (x,y,z), reward: [  5.18542449e-01   9.57464393e-06   3.67296471e+00] -98.1750570942\n",
      "Episode =    5, score = -149.565 (best = -98.588), noise_scale = 0.1positions (x,y,z), reward: [ -8.13572959e-01  -8.86631969e-08   1.79731211e+01] -86.2249348866\n",
      "positions (x,y,z), reward: [ -1.64095305e+00  -1.28574666e-07   1.29308210e+01] -92.2971361159\n",
      "Episode =    6, score = -173.178 (best = -39.932), noise_scale = 0.1positions (x,y,z), reward: [ -9.65528923e-01   8.09332871e-09   1.73920053e+01] -86.6447678708\n",
      "positions (x,y,z), reward: [ -1.26046962e+00   1.38440153e-02   1.57591095e+01] -90.3140380657\n",
      "positions (x,y,z), reward: [ -1.32714223   0.04771578  15.18422943] -95.2276832644\n",
      "positions (x,y,z), reward: [ -2.12888762   0.04694609  11.16915392] -100.264208948\n",
      "positions (x,y,z), reward: [-2.74249949 -0.05587155  9.68354187] -99.3243550146\n",
      "positions (x,y,z), reward: [-2.90141278 -0.06112877  9.382203  ] -99.6289464123\n",
      "positions (x,y,z), reward: [-6.28256496 -0.42887214  1.38171017] -106.532810813\n",
      "Episode =    7, score = -180.324 (best = -39.932), noise_scale = 0.1positions (x,y,z), reward: [  0.30481899   1.11625214  17.44170507] -87.9054320105\n",
      "positions (x,y,z), reward: [  0.72093559   1.36531348  15.57178057] -90.7531157747\n",
      "positions (x,y,z), reward: [  0.99061466   1.46251631  14.63493044] -91.5318912352\n",
      "positions (x,y,z), reward: [ 3.59666281  2.10883988  7.0865556 ] -100.669105592\n",
      "positions (x,y,z), reward: [ 5.51803031  2.36046078  2.64575442] -104.212621033\n",
      "positions (x,y,z), reward: [ 7.14872545  2.58094705  0.        ] -108.307366771\n",
      "Episode =    8, score = -165.049 (best = -16.557), noise_scale = 0.1positions (x,y,z), reward: [ -8.03043599e-03   2.06713984e-01   2.02462562e+01] -27.7655217736\n",
      "positions (x,y,z), reward: [ -0.26626322   0.60687211  19.56961467] -82.136675002\n",
      "positions (x,y,z), reward: [ -4.63985755   1.12519708  13.95206326] -109.460555767\n",
      "positions (x,y,z), reward: [ -5.97739258   1.16017964  12.45807361] -101.533462988\n",
      "positions (x,y,z), reward: [ -6.70339009   1.01420159  11.37917381] -100.552026624\n",
      "positions (x,y,z), reward: [-12.06213324  -0.39306964   1.01637813] -111.306132018\n",
      "Episode =    9, score = -174.624 (best = -16.557), noise_scale = 0.1positions (x,y,z), reward: [ -5.96461220e-03   1.85522442e-01   2.02169239e+01] -26.2419883118\n",
      "positions (x,y,z), reward: [ -0.07061752   0.45053362  20.08451831] -60.438408351\n",
      "positions (x,y,z), reward: [ -0.27900333   0.73900044  19.37038686] -84.1837680865\n",
      "positions (x,y,z), reward: [ -0.84818147   0.9018665   18.31649323] -92.701073016\n",
      "positions (x,y,z), reward: [ -1.00162676   0.95317732  18.08056276] -98.2409846553\n",
      "positions (x,y,z), reward: [ -2.4639366    1.32550125  15.36756065] -93.901202264\n",
      "positions (x,y,z), reward: [ -2.66464252   1.29287222  15.04861247] -93.6768836145\n",
      "positions (x,y,z), reward: [-5.32142329  0.20072144  6.76707022] -101.452930632\n",
      "positions (x,y,z), reward: [-5.97251442 -0.0856598   3.79806054] -102.214886623\n",
      "positions (x,y,z), reward: [-6.71136541 -0.5034274   0.28099774] -104.206856232\n",
      "Episode =   10, score = -169.728 (best = -16.557), noise_scale = 0.1positions (x,y,z), reward: [ -1.93353990e-09   2.08547027e-03   2.00087600e+01] -35.0516542009\n",
      "positions (x,y,z), reward: [  8.48740374  -4.20318953  19.93332629] -95.1593046668\n",
      "positions (x,y,z), reward: [ 13.4221808   -5.27233829  19.04875401] -103.368554752\n",
      "positions (x,y,z), reward: [ 19.59842646  -6.94493455  16.67137527] -114.476355243\n",
      "positions (x,y,z), reward: [ 18.42410483 -11.52798625   3.79579798] -125.873906625\n",
      "Episode =   11, score = -178.835 (best = -16.557), noise_scale = 0.1positions (x,y,z), reward: [ -5.53586714e-03   2.35638975e-01   2.75301305e+01] 12.182282879\n",
      "positions (x,y,z), reward: [  0.05944492   0.66752244  34.3424805 ] 15.8039374192\n",
      "positions (x,y,z), reward: [  0.11106987   0.85962493  36.83963223] 66.4042275263\n",
      "positions (x,y,z), reward: [  0.69194517   2.11115237  50.17477284] 116.748069239\n",
      "positions (x,y,z), reward: [  1.05431092   2.65069597  55.17007467] 166.22574475\n",
      "positions (x,y,z), reward: [  1.45244813   3.15311738  59.66224566] 165.602303627\n",
      "positions (x,y,z), reward: [  2.26425993   3.97576014  67.05208776] 164.383797682\n",
      "positions (x,y,z), reward: [  3.49128661   4.81205145  75.71758555] 162.841919708\n",
      "positions (x,y,z), reward: [  6.35983641   5.27332361  89.93404864] 175.263748843\n",
      "positions (x,y,z), reward: [   9.80323638    4.18599687  101.33567219] 285.750189134\n",
      "positions (x,y,z), reward: [  10.46764299    3.85875454  103.11600226] 282.557704184\n",
      "positions (x,y,z), reward: [  10.93089573    3.61490829  104.29614025] 280.419522347\n",
      "positions (x,y,z), reward: [  45.10262435  -12.79301668  138.64826401] 196.528067125\n",
      "positions (x,y,z), reward: [  45.65637187  -12.99502401  138.88941476] 196.098108486\n",
      "Episode =   12, score = 303.107 (best = 303.107), noise_scale = 0.1positions (x,y,z), reward: [ -0.16871606  -1.09212221  45.29888303] 117.774231262\n",
      "positions (x,y,z), reward: [ -0.1136336   -2.46528982  56.87085359] 167.334973549\n",
      "positions (x,y,z), reward: [ -0.06556928  -2.90864819  59.66804427] 167.043383908\n",
      "positions (x,y,z), reward: [  0.12519487  -4.18244505  66.4151728 ] 165.875464061\n",
      "positions (x,y,z), reward: [   3.49131633  -16.61025461  102.15279257] 275.968204177\n",
      "positions (x,y,z), reward: [   7.95263679  -30.19434429  123.1502323 ] 240.671870855\n",
      "positions (x,y,z), reward: [   9.12964183  -33.82440888  127.40687889] 239.429466824\n",
      "Episode =   13, score = 303.043 (best = 303.107), noise_scale = 0.1positions (x,y,z), reward: [ -3.96658981e-04   8.68455386e-05   2.04945220e+01] -1.86199826628\n",
      "positions (x,y,z), reward: [ -2.44851415e-02   1.87700082e-02   2.38813382e+01] 7.87145408615\n",
      "positions (x,y,z), reward: [ -0.29044786   0.20062308  33.3959072 ] 15.6863361078\n",
      "positions (x,y,z), reward: [ -0.37985183   0.24052766  35.36180293] 16.3192969803\n",
      "positions (x,y,z), reward: [ -1.17967643   0.32165773  46.95093134] 117.837476913\n",
      "positions (x,y,z), reward: [ -4.77503895  -1.44713809  68.30738741] 164.030330028\n",
      "positions (x,y,z), reward: [-11.4724349   -6.01975812  84.00246191] 155.524914738\n",
      "positions (x,y,z), reward: [-11.78705304  -6.23541851  84.50129021] 155.542491782\n",
      "positions (x,y,z), reward: [ -28.82119911  -17.05120567  100.19860566] 248.34150292\n",
      "positions (x,y,z), reward: [ -40.88840863  -23.7035299   104.79423471] 232.075883659\n",
      "positions (x,y,z), reward: [ -49.66442461  -28.11786971  106.38110111] 225.750396679\n",
      "positions (x,y,z), reward: [ -50.25947578  -28.40590227  106.44552914] 225.403267012\n",
      "positions (x,y,z), reward: [ -69.05553734  -36.84211857  106.10264606] 192.815294282\n",
      "positions (x,y,z), reward: [ -69.66932041  -37.09643045  106.02055615] 192.729078125\n",
      "Episode =   14, score = 276.103 (best = 303.107), noise_scale = 0.1positions (x,y,z), reward: [  0.02886322   0.02915047  24.53759028] 8.88610370082\n",
      "positions (x,y,z), reward: [  0.91290765   1.02852652  45.82292234] 117.130245285\n",
      "positions (x,y,z), reward: [  1.63749461   1.65957016  54.60577158] 166.431432525\n",
      "positions (x,y,z), reward: [  2.33123829   2.14669853  61.29144106] 165.479519795\n",
      "positions (x,y,z), reward: [  3.93921901   2.94671335  73.63531638] 163.224049242\n",
      "positions (x,y,z), reward: [  7.32334307   3.80118381  92.68917664] 177.778165131\n",
      "positions (x,y,z), reward: [   9.07898028    4.05339431  100.47454391] 285.895597384\n",
      "positions (x,y,z), reward: [  11.10503193    4.24995212  108.22799956] 271.946352761\n",
      "positions (x,y,z), reward: [  12.4061833     4.32697178  112.64992157] 263.913691872\n",
      "positions (x,y,z), reward: [  18.99818218    4.17336257  130.41725308] 246.855786198\n",
      "positions (x,y,z), reward: [  24.61967095    3.50696374  141.78511728] 247.381013304\n",
      "Episode =   15, score = 313.165 (best = 313.165), noise_scale = 0.1positions (x,y,z), reward: [ -0.07978344   0.05046958  27.96176417] 12.6946818398\n",
      "positions (x,y,z), reward: [ -0.52389675   0.17929537  39.28950135] 48.6655702783\n",
      "positions (x,y,z), reward: [ -0.55255155   0.18530552  39.76411839] 46.1751163273\n",
      "positions (x,y,z), reward: [ -0.09422122   0.46433226  59.61169244] 162.636463627\n",
      "positions (x,y,z), reward: [ -0.07729472   0.44230257  63.21331427] 163.008526704\n",
      "positions (x,y,z), reward: [ -0.51075914   0.43189399  64.90671348] 160.600376212\n",
      "positions (x,y,z), reward: [ -3.22953177   0.48905502  68.44057188] 146.476536933\n",
      "positions (x,y,z), reward: [ -9.01401922   1.60530711  64.23020981] 87.181336434\n",
      "positions (x,y,z), reward: [ -8.77465745   1.82713501  62.75065571] 86.4222649868\n",
      "positions (x,y,z), reward: [  6.9965314    2.14017792  53.66516368] 135.741189718\n",
      "Episode =   16, score = 192.648 (best = 313.165), noise_scale = 0.1positions (x,y,z), reward: [ -3.16044443e+00  -5.50787627e-03   2.03692369e+01] -41.5911053596\n",
      "positions (x,y,z), reward: [ -3.82165586e+00   6.83197434e-04   2.01124424e+01] -45.3109350264\n",
      "positions (x,y,z), reward: [ -5.41036119   0.08422596  17.82305268] -72.9086602073\n",
      "positions (x,y,z), reward: [ -4.50964254   0.04407692  14.83362306] -63.1786051058\n",
      "positions (x,y,z), reward: [ -4.31243792e+00  -2.56569261e-03   1.46942557e+01] -61.4477385268\n",
      "positions (x,y,z), reward: [ -4.4675036   -0.88389665  15.40403808] -29.2736726712\n",
      "positions (x,y,z), reward: [ -9.40621535  -1.92647733  16.00621393] -67.9568199904\n",
      "positions (x,y,z), reward: [-12.46724935  -2.20413779  15.31606909] -76.3101892199\n",
      "positions (x,y,z), reward: [-19.16248948  -2.29346777  11.64461451] -94.3866450945\n",
      "positions (x,y,z), reward: [-23.54299623  -1.93667244   7.09732331] -102.505708994\n",
      "positions (x,y,z), reward: [-26.29873912  -1.43003886   2.44727644] -106.958226826\n",
      "Episode =   17, score = -115.840 (best = 313.165), noise_scale = 0.1positions (x,y,z), reward: [ -4.17057569e-01   1.39981382e-03   2.14239559e+01] -4.99415466921\n",
      "positions (x,y,z), reward: [ -8.48596276e-01  -2.69716489e-04   2.15727594e+01] -7.73536212886\n",
      "positions (x,y,z), reward: [ -2.29172262e+00  -1.76539042e-02   2.13255941e+01] -42.3410744101\n",
      "positions (x,y,z), reward: [ -2.90365245  -0.02830976  21.06562272] -49.2690834511\n",
      "positions (x,y,z), reward: [ -5.52231399  -0.0848988   19.48048007] -92.2897079364\n",
      "positions (x,y,z), reward: [ -6.44254444  -0.09988394  18.70835641] -92.6867462303\n",
      "positions (x,y,z), reward: [-11.21849908  -0.20850988  13.58918109] -103.18877896\n",
      "positions (x,y,z), reward: [-11.43663017  -0.21679247  13.32517923] -104.15760058\n",
      "positions (x,y,z), reward: [-14.18358007  -0.37217138   9.22923236] -109.783743316\n",
      "Episode =   18, score = -156.387 (best = 313.165), noise_scale = 0.1positions (x,y,z), reward: [ -3.98317300e-07  -3.59918078e-07   2.00699264e+01] -5.67112786957\n",
      "positions (x,y,z), reward: [ -9.07648823e-07   1.79043330e+00   2.09284235e+01] -39.4322817152\n",
      "Episode =   19, score = -116.102 (best = 313.165), noise_scale = 0.1positions (x,y,z), reward: [ -2.95770109e-04   2.87446729e-05   2.07700304e+01] -0.387254712812\n",
      "positions (x,y,z), reward: [ -0.03087547   0.08242043  27.54942676] 12.3531561831\n",
      "positions (x,y,z), reward: [ -0.05390827   0.16038801  30.58093183] 14.514583211\n",
      "positions (x,y,z), reward: [ -0.15655982   0.49268351  39.97323122] 67.5246689021\n",
      "positions (x,y,z), reward: [ -0.46880752   1.13503914  53.51327855] 168.064325754\n",
      "positions (x,y,z), reward: [ -0.83482041   1.66362551  62.42023978] 167.447598174\n",
      "positions (x,y,z), reward: [ -1.31661183   2.27049091  71.37553534] 166.419311201\n",
      "positions (x,y,z), reward: [ -1.90468797   2.98047376  80.90246621] 166.509024142\n",
      "positions (x,y,z), reward: [  -4.88106463    4.67893351  123.44377135] 261.102367602\n",
      "positions (x,y,z), reward: [  -5.04926185    4.60197579  125.73762964] 261.030853036\n",
      "positions (x,y,z), reward: [  -6.03203759    3.61757058  139.51467129] 261.008446561\n",
      "Episode =   20, score = 323.057 (best = 323.057), noise_scale = 0.1positions (x,y,z), reward: [ -6.09483091e-05   7.09374095e-04   2.17065388e+01] 3.08743812696\n",
      "positions (x,y,z), reward: [ -2.72434618e-03   4.05302325e-03   2.32651736e+01] 6.79098561181\n",
      "positions (x,y,z), reward: [ -0.03205053   0.07091823  28.80398324] 13.4203880487\n",
      "positions (x,y,z), reward: [ -0.75537349   3.47505224  65.52552205] 166.409497201\n",
      "positions (x,y,z), reward: [ -0.77753362   3.57131734  66.09850421] 166.307258468\n",
      "positions (x,y,z), reward: [ -1.30494674   6.03458758  78.73772592] 163.353658923\n",
      "positions (x,y,z), reward: [ -1.99027787  10.43016107  95.76423433] 181.25792593\n",
      "positions (x,y,z), reward: [ -2.02777977  10.76777821  96.88540501] 182.540077459\n",
      "positions (x,y,z), reward: [  -2.24377526   17.95839883  117.50928471] 255.932873299\n",
      "positions (x,y,z), reward: [   0.4391       25.37028898  144.68010012] 260.828668475\n",
      "Episode =   21, score = 312.895 (best = 323.057), noise_scale = 0.1positions (x,y,z), reward: [  1.71795665e-04  -1.69069169e-01   2.01264236e+01] -40.7244850779\n",
      "positions (x,y,z), reward: [  0.0491387   -0.72998163  19.84419567] -56.3129977411\n",
      "positions (x,y,z), reward: [ 3.08843992 -5.2074929   0.        ] -84.1016060566\n",
      "Episode =   22, score = -121.777 (best = 323.057), noise_scale = 0.1positions (x,y,z), reward: [  2.35294527e-06   1.67391766e-06   2.01242821e+01] -4.89734322635\n",
      "positions (x,y,z), reward: [ -7.93041059e-04   3.46761863e-01   2.33309006e+01] 1.97491355977\n",
      "positions (x,y,z), reward: [ -1.33557679   4.36144597  17.7984279 ] -75.3285348279\n",
      "positions (x,y,z), reward: [ -4.11187317  -2.9871053   13.455455  ] -68.207939983\n",
      "positions (x,y,z), reward: [ -5.04318656  -4.83550794  12.95514496] -72.8054632631\n",
      "positions (x,y,z), reward: [ -8.14468722  -9.46408574  11.01383423] -104.939817185\n",
      "positions (x,y,z), reward: [-12.55835402 -14.70409394   7.8358628 ] -116.713057367\n",
      "positions (x,y,z), reward: [-14.49564661 -16.56843849   6.44668107] -122.985390686\n",
      "Episode =   23, score = -138.813 (best = 323.057), noise_scale = 0.1positions (x,y,z), reward: [ -4.32383836e-04   1.59706240e-01   2.01302106e+01] -36.5437443033\n",
      "positions (x,y,z), reward: [ -9.95477993e-03   1.18805410e+00   1.90727003e+01] -66.6070078173\n",
      "positions (x,y,z), reward: [ -0.13324575   2.05888874  13.75464851] -79.8403680397\n",
      "positions (x,y,z), reward: [-0.55277041 -0.41289488  6.76952399] -92.6803254813\n",
      "positions (x,y,z), reward: [-1.2184189  -3.64732338  0.        ] -111.538907011\n",
      "Episode =   24, score = -143.450 (best = 323.057), noise_scale = 0.1positions (x,y,z), reward: [ -7.85541312e-06   8.65102960e-07   2.01242729e+01] -4.89789683695\n",
      "positions (x,y,z), reward: [ -7.52674632e-04   8.53430015e-02   2.10772107e+01] 0.403139304916\n",
      "positions (x,y,z), reward: [  0.09995422   6.66469346  30.17163437] 1.791710515\n",
      "positions (x,y,z), reward: [  0.71950616  15.78636033  36.60862324] 40.7651941049\n",
      "positions (x,y,z), reward: [  0.77087434  16.33197752  36.91386972] 40.0757744421\n",
      "positions (x,y,z), reward: [  2.35472991  29.18471697  42.66107476] 33.2761401243\n",
      "positions (x,y,z), reward: [  2.46778136  29.9384464   42.93403263] 33.1164860376\n",
      "positions (x,y,z), reward: [  2.83116402  32.27743771  43.7479512 ] 32.6400059076\n",
      "positions (x,y,z), reward: [  5.1102018   45.12926604  47.52380913] 80.5205317869\n",
      "positions (x,y,z), reward: [  6.21389916  50.77629085  48.90858594] 79.8053433178\n",
      "positions (x,y,z), reward: [ 14.49638443  97.20199895  56.13996869] 121.259132744\n",
      "Episode =   25, score =  84.538 (best = 323.057), noise_scale = 0.1positions (x,y,z), reward: [ -7.53869987e-03   3.75629040e-02   2.56020432e+01] 10.3453658228\n",
      "positions (x,y,z), reward: [ -0.04846877   0.19193949  33.39527603] 15.9277078764\n",
      "positions (x,y,z), reward: [ -0.04810545   0.57622776  44.75525151] 118.345729246\n",
      "positions (x,y,z), reward: [ -2.35335793e-02   7.00048753e-01   4.74692373e+01] 118.569641658\n",
      "positions (x,y,z), reward: [  0.1200538    1.13607795  55.20766709] 168.670709653\n",
      "positions (x,y,z), reward: [  0.87238229   2.49123801  71.10969023] 167.506884754\n",
      "positions (x,y,z), reward: [  2.81223534   5.01891523  89.47994301] 178.964614012\n",
      "positions (x,y,z), reward: [  4.33722649   6.8001561   98.85911526] 191.180709293\n",
      "positions (x,y,z), reward: [   7.75749535   10.75902548  115.08203259] 266.888545985\n",
      "positions (x,y,z), reward: [  22.56443019   29.47837835  171.75096348] 150.906138209\n",
      "positions (x,y,z), reward: [  28.3242811    35.63749708  191.34712763] 185.912879248\n",
      "Episode =   26, score = 308.646 (best = 323.057), noise_scale = 0.1positions (x,y,z), reward: [ -3.07558505e-06   1.18356074e-06   2.01243568e+01] -4.89508759262\n",
      "positions (x,y,z), reward: [ -1.16129167e-04   3.08516957e-04   2.12914295e+01] 1.74260611367\n",
      "positions (x,y,z), reward: [  5.43042224e-03   2.67627603e-03   2.35704208e+01] 7.36648631368\n",
      "positions (x,y,z), reward: [  4.50558901e-02   7.72040134e-03   2.75495378e+01] 12.4145744425\n",
      "positions (x,y,z), reward: [  2.12073660e-01   7.77243902e-03   3.43766847e+01] 16.3663053345\n",
      "positions (x,y,z), reward: [  2.67024721e-01   6.53183420e-03   3.58684209e+01] 16.8456925017\n",
      "positions (x,y,z), reward: [  3.30524983e-01   5.17803188e-03   3.73899505e+01] 67.2441577127\n",
      "positions (x,y,z), reward: [  5.11302732   0.23493904  75.50665346] 167.787039356\n",
      "positions (x,y,z), reward: [  8.5466048    0.44257919  89.76007278] 181.509333549\n",
      "positions (x,y,z), reward: [ 11.26428434   0.69823698  99.59516397] 195.973749071\n",
      "positions (x,y,z), reward: [  14.18137687    1.14890074  109.54348276] 282.567397892\n",
      "positions (x,y,z), reward: [  17.57550331    1.99524321  120.69329263] 268.405812354\n",
      "positions (x,y,z), reward: [  31.3542629    10.90709319  166.95841509] 159.605643081\n",
      "positions (x,y,z), reward: [  39.83643639   22.67742986  198.70507207] 216.726126427\n",
      "Episode =   27, score = 368.494 (best = 368.494), noise_scale = 0.1positions (x,y,z), reward: [  3.40134051e-03   2.03269389e-03   2.17080878e+01] 3.0924763233\n",
      "positions (x,y,z), reward: [  0.05421743   0.03411685  26.74496516] 11.595574545\n",
      "positions (x,y,z), reward: [  0.07552156   0.04744682  27.96100134] 12.7052042555\n",
      "positions (x,y,z), reward: [  0.15785958   0.09958609  31.49867157] 14.9929061311\n",
      "positions (x,y,z), reward: [  0.19914193   0.1265753   32.91539416] 15.6310329592\n",
      "positions (x,y,z), reward: [  0.24637349   0.1582313   34.3716853 ] 16.166452793\n",
      "positions (x,y,z), reward: [  0.63132548   0.43449621  43.15026595] 67.6907907985\n",
      "positions (x,y,z), reward: [  3.27968494   2.70035765  74.82048258] 164.407168214\n",
      "positions (x,y,z), reward: [  6.13524954   6.7626244   99.03160513] 188.662371579\n",
      "positions (x,y,z), reward: [   7.06622416    8.54261099  106.60165199] 278.567802014\n",
      "positions (x,y,z), reward: [  10.98117254   16.39742636  136.48913481] 250.241931593\n",
      "positions (x,y,z), reward: [  11.08036152   16.57663133  137.20235693] 250.043552641\n",
      "positions (x,y,z), reward: [  11.78905805   17.81316574  142.24311932] 248.727154442\n",
      "Episode =   28, score = 307.441 (best = 368.494), noise_scale = 0.1positions (x,y,z), reward: [  7.60660313e-03   2.11407946e-02   2.92358756e+01] 13.802463343\n",
      "positions (x,y,z), reward: [  3.01903455e-02   2.15668129e-02   3.38765830e+01] 16.3292783385\n",
      "positions (x,y,z), reward: [  4.09846551e-02   1.67020451e-02   3.53566765e+01] 16.881948432\n",
      "positions (x,y,z), reward: [   6.45480628  -14.71311264  105.68766694] 269.067766932\n",
      "positions (x,y,z), reward: [   7.99364153  -18.18837051  110.9067639 ] 254.774535783\n",
      "positions (x,y,z), reward: [  10.87398179  -24.6944691   118.50957563] 235.344318969\n",
      "positions (x,y,z), reward: [  12.92366357  -29.3001269   122.65586354] 228.490351179\n",
      "positions (x,y,z), reward: [  13.57239331  -30.75236529  123.79697359] 227.025174684\n",
      "positions (x,y,z), reward: [  14.23546853  -32.23420671  124.88863235] 225.529831108\n",
      "positions (x,y,z), reward: [  18.46641545  -41.66644275  130.36731122] 216.172826917\n",
      "Episode =   29, score = 302.503 (best = 368.494), noise_scale = 0.1positions (x,y,z), reward: [ -1.04329670e-04   7.80567509e-04   2.11018911e+01] 1.03052618586\n",
      "positions (x,y,z), reward: [ -2.11449970e-02   2.90713109e-02   2.79536543e+01] 12.7759985109\n",
      "positions (x,y,z), reward: [ -0.06552731   0.04440479  32.91036437] 15.8667555954\n",
      "positions (x,y,z), reward: [ -0.94186496  -0.75969715  58.06233125] 168.459515956\n",
      "positions (x,y,z), reward: [ -0.97500452  -0.81265845  58.6259834 ] 168.401577412\n",
      "positions (x,y,z), reward: [ -1.22008125  -1.25801789  62.58503076] 167.864630952\n",
      "positions (x,y,z), reward: [ -2.42559835  -4.90722648  79.56506954] 162.63177757\n",
      "positions (x,y,z), reward: [  -4.49945617  -15.76569533  105.18778981] 269.21297768\n",
      "positions (x,y,z), reward: [  -6.16564357  -25.32509619  120.22025615] 239.019384145\n",
      "positions (x,y,z), reward: [  -7.60843725  -32.55133894  129.18774688] 235.98858592\n",
      "positions (x,y,z), reward: [  -8.74367274  -37.69882695  134.64824149] 233.628897215\n",
      "Episode =   30, score = 307.122 (best = 368.494), noise_scale = 0.1positions (x,y,z), reward: [  3.97577273e-04   1.18121130e-04   2.09289252e+01] 0.326295439205\n",
      "positions (x,y,z), reward: [  8.25545272e-04   3.03707587e-04   2.12902277e+01] 1.73101300022\n",
      "positions (x,y,z), reward: [  3.40625386e-03   2.22904766e-03   2.24303399e+01] 5.00533400276\n",
      "positions (x,y,z), reward: [  0.06347771   0.09363152  28.80101121] 13.3497560592\n",
      "positions (x,y,z), reward: [  0.16316618   0.27261369  33.3905324 ] 15.7455292666\n",
      "positions (x,y,z), reward: [  0.35563514   0.62797764  38.93066785] 67.0353382345\n",
      "positions (x,y,z), reward: [  0.59400439   1.05549561  43.70791505] 67.3419175723\n",
      "positions (x,y,z), reward: [  2.03969095   3.34937603  59.98282686] 165.537582508\n",
      "positions (x,y,z), reward: [  2.6570202    4.24438425  64.64061118] 164.374582917\n",
      "positions (x,y,z), reward: [  3.18551109   4.98851657  68.16627866] 163.297629843\n",
      "positions (x,y,z), reward: [  3.76858513   5.7915863   71.7122041 ] 162.055932167\n",
      "positions (x,y,z), reward: [  11.07833677   15.17337299  103.86760432] 269.653656305\n",
      "positions (x,y,z), reward: [  13.83745351   18.8053902   113.90320519] 247.764927898\n",
      "positions (x,y,z), reward: [  15.57883897   21.33461717  120.30130885] 235.305511743\n",
      "positions (x,y,z), reward: [  17.53411515   24.84168155  128.3419993 ] 233.016366813\n",
      "positions (x,y,z), reward: [  18.63114298   33.79908745  145.28060877] 230.792643393\n",
      "Episode =   31, score = 301.391 (best = 368.494), noise_scale = 0.1positions (x,y,z), reward: [  2.73795482e-07   7.68578737e-07   2.00699828e+01] -5.66868887903\n",
      "positions (x,y,z), reward: [  0.3312223    0.15365119  35.86044965] 16.6208642577\n",
      "positions (x,y,z), reward: [  0.56183416   0.22701574  41.54873969] 67.6875156958\n",
      "positions (x,y,z), reward: [  0.78030136   0.2846545   46.37814722] 118.065586503\n",
      "positions (x,y,z), reward: [  1.55261536   0.40282757  62.98347263] 168.082771701\n",
      "positions (x,y,z), reward: [  2.25785346  -0.10248339  83.34616789] 173.141561047\n",
      "positions (x,y,z), reward: [  2.4977575   -0.96983036  93.05292815] 186.704934251\n",
      "positions (x,y,z), reward: [   2.63961491   -3.09552576  105.63134946] 286.33028283\n",
      "positions (x,y,z), reward: [   2.59529774   -4.22068103  110.1839909 ] 278.279228546\n",
      "positions (x,y,z), reward: [   2.10066524   -7.74768995  120.85940054] 259.865678255\n",
      "positions (x,y,z), reward: [   1.17416015  -11.19658958  128.50693487] 256.429850252\n",
      "positions (x,y,z), reward: [  -0.78746717  -16.08547742  136.82331692] 250.106604525\n",
      "positions (x,y,z), reward: [  -4.73842324  -23.13572667  145.69709636] 238.6900151\n",
      "Episode =   32, score = 321.646 (best = 368.494), noise_scale = 0.1positions (x,y,z), reward: [  5.28315524e-05  -6.35218804e-04   2.09284697e+01] 0.326574946412\n",
      "positions (x,y,z), reward: [ -0.18156546  -0.23267586  35.36008911] 16.524835732\n",
      "positions (x,y,z), reward: [ -0.23934013  -0.29267289  37.38094849] 67.0291362107\n",
      "positions (x,y,z), reward: [ -0.30520073  -0.36061888  39.44683205] 67.4029004451\n",
      "positions (x,y,z), reward: [ -0.43972131  -0.5002729   43.14610755] 67.7963533375\n",
      "positions (x,y,z), reward: [ -0.80932295  -0.89927068  51.3045322 ] 117.833678235\n",
      "positions (x,y,z), reward: [ -0.83772941  -0.93106689  51.85571517] 117.806873667\n",
      "positions (x,y,z), reward: [ -1.01740411  -1.13603477  55.17510323] 167.583670003\n",
      "positions (x,y,z), reward: [ -3.1692031   -4.09332051  84.2231775 ] 169.013320068\n",
      "positions (x,y,z), reward: [  -9.00125296  -14.48598608  125.7466789 ] 244.948818386\n",
      "positions (x,y,z), reward: [ -12.62817498  -21.8097981   144.20716226] 235.932273785\n",
      "Episode =   33, score = 311.854 (best = 368.494), noise_scale = 0.1positions (x,y,z), reward: [ -1.29464967e-08   6.53123453e-09   2.00311226e+01] -6.44419108797\n",
      "positions (x,y,z), reward: [ -0.25741619  -0.15038626  36.37324809] 66.8645848434\n",
      "positions (x,y,z), reward: [ -0.47870914  -0.23103673  41.56002664] 67.7818344964\n",
      "positions (x,y,z), reward: [ -0.53235404  -0.24918581  42.6232436 ] 67.8851906183\n",
      "positions (x,y,z), reward: [ -1.05774398  -0.42125452  51.3143387 ] 118.042967894\n",
      "positions (x,y,z), reward: [ -1.13390209  -0.44629779  52.41645527] 168.002485438\n",
      "positions (x,y,z), reward: [ -1.72068793  -0.63847794  60.18134692] 167.484786521\n",
      "positions (x,y,z), reward: [ -1.95110556  -0.71014084  62.96871192] 167.237209509\n",
      "positions (x,y,z), reward: [ -2.80737999  -0.93438161  72.4785045 ] 166.290478198\n",
      "positions (x,y,z), reward: [ -4.6275611   -1.13843362  89.92220828] 179.350802589\n",
      "positions (x,y,z), reward: [ -9.53376014e+00   4.89294252e-02   1.27303578e+02] 260.535205349\n",
      "Episode =   34, score = 323.113 (best = 368.494), noise_scale = 0.1positions (x,y,z), reward: [  7.33565552e-03   8.79479716e-03   2.26977915e+01] 5.61363390481\n",
      "positions (x,y,z), reward: [  1.53242464e-02   2.45949146e-02   2.42048371e+01] 8.40325333042\n",
      "positions (x,y,z), reward: [  0.03789368   0.1172715   28.37880294] 13.0227917047\n",
      "positions (x,y,z), reward: [  0.04302785   0.49046837  36.3652858 ] 66.7389226911\n",
      "positions (x,y,z), reward: [ -0.08867345   1.40563076  47.48609639] 117.837900063\n",
      "positions (x,y,z), reward: [ -0.9674819    4.3550805   68.67644736] 164.710437974\n",
      "positions (x,y,z), reward: [ -1.07854954   4.65500208  70.35767857] 164.273383796\n",
      "positions (x,y,z), reward: [ -3.7874235   10.39696439  95.82549551] 178.872367586\n",
      "positions (x,y,z), reward: [  -6.75488545   14.35435622  109.40427501] 263.705366415\n",
      "positions (x,y,z), reward: [  -8.18441103   15.71613894  113.69245493] 254.169218637\n",
      "positions (x,y,z), reward: [ -12.12839742   18.52361447  122.01336148] 236.464728668\n",
      "positions (x,y,z), reward: [ -24.34757359   23.7482643   135.17525375] 219.573938775\n",
      "positions (x,y,z), reward: [ -25.39291573   24.07888347  135.86417308] 218.83205699\n",
      "Episode =   35, score = 302.733 (best = 368.494), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777801] -7.22219998997\n",
      "positions (x,y,z), reward: [ -5.12988390e-08   1.15537128e-07   2.00311056e+01] -6.44504262223\n",
      "positions (x,y,z), reward: [ -2.55107421e-02   1.44391266e+00   4.26516977e+01] 67.4700209398\n",
      "Episode =   36, score = 376.191 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -8.71686371e-02  -2.34884785e-02   2.79604735e+01] 12.7155125007\n",
      "positions (x,y,z), reward: [ -1.12648556  -0.36322993  44.76558073] 117.502302644\n",
      "positions (x,y,z), reward: [ -3.4171323   -1.25738141  59.66460155] 165.226543465\n",
      "positions (x,y,z), reward: [ -3.78404837  -1.40676118  61.33945983] 164.719727144\n",
      "positions (x,y,z), reward: [ -7.78342151  -3.03998189  74.64048622] 158.461633769\n",
      "positions (x,y,z), reward: [ -9.56831588  -3.76444591  78.96880822] 155.457265628\n",
      "positions (x,y,z), reward: [ -29.62640874  -11.21835327  106.370752  ] 250.403736709\n",
      "positions (x,y,z), reward: [ -33.95806638  -12.56509468  109.65367901] 242.197523911\n",
      "positions (x,y,z), reward: [ -39.70186417  -14.17943521  113.16448932] 232.684892662\n",
      "positions (x,y,z), reward: [ -60.08237966  -18.40133042  119.95620481] 208.661062848\n",
      "Episode =   37, score = 288.086 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.46680972e-04   9.94443016e-05   2.04944961e+01] -1.86294500936\n",
      "positions (x,y,z), reward: [  0.0357201    0.03012359  25.59819948] 10.320331228\n",
      "positions (x,y,z), reward: [  0.06355496   0.05411907  27.54344989] 12.3369758799\n",
      "positions (x,y,z), reward: [  0.30104691   0.21210706  37.37965442] 67.0548597246\n",
      "positions (x,y,z), reward: [  0.83324111   0.30562942  49.67044706] 118.378144147\n",
      "positions (x,y,z), reward: [  5.37242377  -2.17976319  87.63933956] 176.1824321\n",
      "positions (x,y,z), reward: [  5.99517198  -2.57374708  90.68630544] 180.115203689\n",
      "positions (x,y,z), reward: [  7.68997728  -3.58174783  98.18222852] 189.87346277\n",
      "positions (x,y,z), reward: [  15.47781827   -6.83689455  124.99871299] 259.524538148\n",
      "positions (x,y,z), reward: [  23.39947236   -8.45794793  148.32047759] 214.458130553\n",
      "positions (x,y,z), reward: [  23.74811885   -8.50499196  149.34481502] 214.987617212\n",
      "positions (x,y,z), reward: [  33.86193778  -10.00010941  181.46067443] 117.996754177\n",
      "Episode =   38, score = 303.299 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.64690626e-04  -1.60026515e-04   2.11037438e+01] 1.04869280103\n",
      "positions (x,y,z), reward: [  6.83526208e-03  -1.43462081e-02   2.75516853e+01] 12.4482369004\n",
      "positions (x,y,z), reward: [  2.01752501e-02  -3.20484244e-02   3.05840448e+01] 14.6871535866\n",
      "positions (x,y,z), reward: [  0.23870717  -0.37402506  48.04055081] 118.749244363\n",
      "positions (x,y,z), reward: [  0.51548641  -0.76400403  56.90328136] 168.676226636\n",
      "positions (x,y,z), reward: [  1.08337933  -1.3670894   67.60551207] 167.897612234\n",
      "positions (x,y,z), reward: [  1.81232057  -1.8918426   76.73212007] 167.00112991\n",
      "positions (x,y,z), reward: [   5.45078064   -2.95207728  102.17719749] 291.17828239\n",
      "positions (x,y,z), reward: [   9.20047758   -3.04058986  118.16324071] 265.726925967\n",
      "positions (x,y,z), reward: [  12.5547468    -2.7346799   129.80780264] 262.127662238\n",
      "positions (x,y,z), reward: [  16.23861121   -2.08663391  141.65003529] 262.609147088\n",
      "Episode =   39, score = 316.078 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.41268917   9.001471    80.21594506] 162.155742267\n",
      "positions (x,y,z), reward: [  2.48946702   9.19370868  80.84196454] 162.925396791\n",
      "positions (x,y,z), reward: [  3.63773886  11.90115384  89.17170879] 172.978427639\n",
      "positions (x,y,z), reward: [   5.42052125   15.70035602  100.00965946] 286.027701234\n",
      "positions (x,y,z), reward: [   8.33157759   21.43029455  115.90405336] 261.125383844\n",
      "positions (x,y,z), reward: [   8.79180885   22.32509151  118.42284388] 258.233278215\n",
      "positions (x,y,z), reward: [  14.33594364   33.70701952  156.96278612] 188.757517324\n",
      "positions (x,y,z), reward: [  14.66221476   34.42412121  160.31325584] 193.85889695\n",
      "Episode =   40, score = 361.615 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.07610547e-05   2.46208129e-05   2.02793697e+01] -3.36125899363\n",
      "positions (x,y,z), reward: [ -2.99340699e-04   7.82941818e-04   2.14937377e+01] 2.43140026076\n",
      "positions (x,y,z), reward: [ -2.97605294e-03   6.74897141e-03   2.42082005e+01] 8.43805993893\n",
      "positions (x,y,z), reward: [ -2.92619716e-02   6.74284078e-02   3.33990150e+01] 16.0843790878\n",
      "positions (x,y,z), reward: [   0.76933591    3.46331802  123.79853964] 273.512001828\n",
      "positions (x,y,z), reward: [   3.21340447    5.59869831  141.20819132] 277.71825724\n",
      "positions (x,y,z), reward: [   6.90312337    8.93794515  161.0158802 ] 188.547530178\n",
      "positions (x,y,z), reward: [   7.43019526    9.42988305  163.57399601] 190.668195158\n",
      "Episode =   41, score = 320.687 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -9.50011283e-03  -2.18635508e-03   2.48850081e+01] 9.44124278492\n",
      "positions (x,y,z), reward: [ -2.26823086e-02  -9.00894976e-04   2.67450887e+01] 11.658207774\n",
      "positions (x,y,z), reward: [ -1.26093028e-01   6.01880473e-03   3.29168678e+01] 15.8373205324\n",
      "positions (x,y,z), reward: [ -7.52131453e-01   1.38775388e-03   4.63955584e+01] 118.443422442\n",
      "positions (x,y,z), reward: [ -9.64828355e-01  -1.27240397e-02   4.91306025e+01] 118.501273251\n",
      "positions (x,y,z), reward: [ -2.12334556  -0.19700689  59.16232429] 167.84179569\n",
      "positions (x,y,z), reward: [ -3.76617148  -0.65053572  67.65223811] 165.921863289\n",
      "positions (x,y,z), reward: [ -5.14160811  -1.10742388  72.74369074] 163.930136309\n",
      "positions (x,y,z), reward: [ -6.64236031  -1.64022563  77.22864412] 161.551898219\n",
      "positions (x,y,z), reward: [ -8.42198719  -2.28856756  81.64258515] 161.04619564\n",
      "positions (x,y,z), reward: [-10.21764516  -2.94146478  85.4216435 ] 163.625742533\n",
      "positions (x,y,z), reward: [ -32.84924428   -9.22314573  109.69936879] 243.611419244\n",
      "positions (x,y,z), reward: [ -37.43860941  -10.04828472  111.94810341] 236.69065399\n",
      "positions (x,y,z), reward: [ -46.09926504  -11.34302421  114.78530807] 225.994018592\n",
      "positions (x,y,z), reward: [ -51.98589405  -12.09859422  115.83322578] 220.24907995\n",
      "positions (x,y,z), reward: [ -64.16260566  -13.55377303  116.11371914] 185.809693933\n",
      "Episode =   42, score = 291.124 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -6.65785998e-06  -2.70313834e-06   2.01243451e+01] -4.89630242956\n",
      "positions (x,y,z), reward: [ -0.44196199   0.12587623  37.38873565] 67.0013733294\n",
      "positions (x,y,z), reward: [ -0.50046225   0.14847478  38.41713968] 67.1918073324\n",
      "positions (x,y,z), reward: [ -1.4408926    0.6079815   50.24742794] 117.611883433\n",
      "positions (x,y,z), reward: [ -2.41646768   1.2167278   58.66791454] 166.826042299\n",
      "positions (x,y,z), reward: [ -7.85846731   5.25845969  86.02776076] 171.25885205\n",
      "positions (x,y,z), reward: [ -9.43511299   6.4195634   91.49438462] 178.427206212\n",
      "positions (x,y,z), reward: [ -9.86618918   6.73130585  92.90622567] 180.296008013\n",
      "Episode =   43, score = 344.607 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.67208779e-04   6.66000874e-04   2.09295994e+01] 0.335734040396\n",
      "positions (x,y,z), reward: [ -0.40059692  -0.06980449  57.44421627] 169.446956169\n",
      "positions (x,y,z), reward: [ -8.76415966e-01  -7.44871300e-03   6.64404807e+01] 169.420834232\n",
      "positions (x,y,z), reward: [  -7.89271309    2.69130865  106.31755794] 283.040194298\n",
      "positions (x,y,z), reward: [ -10.06396689    3.38221611  112.56422102] 271.05811311\n",
      "positions (x,y,z), reward: [ -14.60369806    4.53328633  123.29742444] 254.660553097\n",
      "positions (x,y,z), reward: [ -19.85275514    5.42697263  133.56901725] 249.169607541\n",
      "positions (x,y,z), reward: [ -23.58864689    5.7969316   140.11494687] 249.235843684\n",
      "positions (x,y,z), reward: [ -30.22417162    5.91569682  150.91255525] 200.721733453\n",
      "Episode =   44, score = 316.344 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.70253789e-04   4.91799867e-04   2.07687730e+01] -0.398859586145\n",
      "positions (x,y,z), reward: [ -2.20212098e-03   5.25047086e-03   2.26945706e+01] 5.60668116343\n",
      "positions (x,y,z), reward: [ -7.23425563e-03   1.37166104e-02   2.45335949e+01] 8.91852378736\n",
      "positions (x,y,z), reward: [ -0.1075358    0.19605067  36.85965332] 67.1066055825\n",
      "positions (x,y,z), reward: [ -0.15294945   0.50464027  45.29247178] 118.429869991\n",
      "positions (x,y,z), reward: [  1.10374872e-02   1.39031379e+00   5.86240724e+01] 168.937049775\n",
      "positions (x,y,z), reward: [  1.19168375   3.96837844  79.04331358] 167.035526407\n",
      "positions (x,y,z), reward: [   5.15344098    9.51629233  103.43279717] 286.732010367\n",
      "positions (x,y,z), reward: [   5.49106638    9.91757892  104.82258233] 284.261088241\n",
      "positions (x,y,z), reward: [   5.84600154   10.33199475  106.22674937] 281.753857817\n",
      "positions (x,y,z), reward: [  11.02203983   15.84965826  122.82011696] 255.705728461\n",
      "positions (x,y,z), reward: [  12.88816092   17.71931074  127.81178708] 254.039830116\n",
      "Episode =   45, score = 298.789 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.16970797  -0.62347712  41.01744567] 67.6040768491\n",
      "positions (x,y,z), reward: [  0.08740165  -2.06925748  56.87081525] 167.742952\n",
      "positions (x,y,z), reward: [  7.32444490e-03  -2.61886709e+00   6.07868814e+01] 167.39774804\n",
      "positions (x,y,z), reward: [ -6.33794839e-03  -2.70581863e+00   6.13476399e+01] 167.325596571\n",
      "positions (x,y,z), reward: [ -0.11784584  -3.38222521  65.27906629] 166.599742098\n",
      "positions (x,y,z), reward: [ -0.4261712   -5.16382584  73.145143  ] 164.426733992\n",
      "positions (x,y,z), reward: [ -0.59319673  -6.13815353  76.49954783] 163.129817729\n",
      "positions (x,y,z), reward: [ -1.32104182 -10.72760724  87.9781159 ] 168.515461307\n",
      "positions (x,y,z), reward: [  -4.85335904  -44.07235048  122.19899364] 232.767238036\n",
      "positions (x,y,z), reward: [  -5.60815651  -53.39938757  126.88934237] 230.131391367\n",
      "positions (x,y,z), reward: [  -5.96835249  -57.92083822  128.76739033] 229.110043578\n",
      "Episode =   46, score = 303.053 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.62556752e-07   7.09673610e-08   2.00700032e+01] -5.66805841531\n",
      "positions (x,y,z), reward: [  5.52597734e-04   2.57088550e-03   2.17079955e+01] 3.09226385696\n",
      "positions (x,y,z), reward: [  2.77656075   1.5367085   64.11312171] 165.599187523\n",
      "positions (x,y,z), reward: [  2.91754861   1.60749847  65.22968541] 165.387825306\n",
      "positions (x,y,z), reward: [  7.57180426   3.4609685   95.97703516] 183.161767596\n",
      "positions (x,y,z), reward: [   9.38700368    3.96213991  110.27623738] 272.252320029\n",
      "positions (x,y,z), reward: [   9.93488703    3.96321123  124.98785333] 257.831156856\n",
      "positions (x,y,z), reward: [   9.87419654    3.91615331  126.77377313] 257.989559647\n",
      "Episode =   47, score = 317.810 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -0.87326746  -0.56952333  44.20310679] 117.416597514\n",
      "positions (x,y,z), reward: [ -0.97746277  -0.65859937  45.82058275] 117.41361285\n",
      "positions (x,y,z), reward: [ -3.4736395   -6.67799974  86.79202081] 170.630477411\n",
      "positions (x,y,z), reward: [ -3.6010745   -8.41898464  91.93276129] 176.366649746\n",
      "positions (x,y,z), reward: [ -3.63386562  -9.29929394  94.20860875] 178.766462024\n",
      "positions (x,y,z), reward: [  -3.64251166  -12.08645223  100.40497273] 283.523350808\n",
      "positions (x,y,z), reward: [  -3.35494866  -18.28602002  110.66177527] 260.232395543\n",
      "positions (x,y,z), reward: [  -1.49787601  -36.73466066  127.86808847] 237.770789828\n",
      "positions (x,y,z), reward: [  -0.98518116  -40.79881948  130.1431011 ] 236.210089397\n",
      "Episode =   48, score = 308.104 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.66354181e-02   1.08056690e-02   2.45399378e+01] 8.93369618611\n",
      "positions (x,y,z), reward: [  0.14513394   0.21267931  34.37694982] 16.2355666521\n",
      "positions (x,y,z), reward: [  0.19603729   0.33143198  37.3908266 ] 67.0580204708\n",
      "positions (x,y,z), reward: [  0.22335851   0.40360023  38.93827446] 67.3560605955\n",
      "positions (x,y,z), reward: [  0.34733408   0.82184074  45.86476953] 118.002406972\n",
      "positions (x,y,z), reward: [  0.40233126   4.41907612  75.16356838] 166.156325118\n",
      "positions (x,y,z), reward: [  0.31580481   4.85214847  77.48887357] 165.971649659\n",
      "positions (x,y,z), reward: [  0.26298746   5.07909746  78.6564652 ] 165.881367516\n",
      "positions (x,y,z), reward: [ -0.97614644   8.21238422  92.33487004] 181.547513288\n",
      "positions (x,y,z), reward: [ -16.56013799   20.5852229   133.89386088] 241.004505055\n",
      "positions (x,y,z), reward: [ -20.91471381   22.45984672  141.30007614] 240.703733325\n",
      "positions (x,y,z), reward: [ -30.97507633   26.0303906   158.95060184] 153.48298321\n",
      "Episode =   49, score = 305.053 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  10.02933139   16.17087988  134.06131532] 243.974352384\n",
      "positions (x,y,z), reward: [  10.35026734   16.89644927  137.44695986] 243.005858846\n",
      "positions (x,y,z), reward: [  10.66121751   17.60155557  140.84228046] 242.071954281\n",
      "positions (x,y,z), reward: [  10.71216652   17.71682023  141.40911647] 241.919082017\n",
      "Episode =   50, score = 311.281 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  6.11612011e-05  -3.57254884e-05   2.04943620e+01] -1.86372398031\n",
      "positions (x,y,z), reward: [  2.56425689e-02   2.37334063e-02   2.59702741e+01] 10.7870434084\n",
      "positions (x,y,z), reward: [  0.08121019   0.06434922  30.12337111] 14.3018422092\n",
      "positions (x,y,z), reward: [  0.46258042   0.15219517  42.61891834] 68.0755761188\n",
      "positions (x,y,z), reward: [  1.12593591e+00   4.12279340e-02   5.46578412e+01] 168.663355218\n",
      "positions (x,y,z), reward: [  1.20303241e+00   1.56237540e-02   5.57723795e+01] 168.671228279\n",
      "positions (x,y,z), reward: [  2.2856839   -0.53314715  68.16528801] 167.590622991\n",
      "positions (x,y,z), reward: [  3.76618839  -1.6430833   79.61476369] 165.417607545\n",
      "positions (x,y,z), reward: [  3.85620943  -1.71949046  80.19168975] 165.560372496\n",
      "positions (x,y,z), reward: [  4.64142781  -2.41807201  84.82260913] 171.193167809\n",
      "positions (x,y,z), reward: [  4.96774093  -2.72282286  86.56631722] 173.243207197\n",
      "positions (x,y,z), reward: [   9.41368083   -7.33172353  104.25785155] 278.840257036\n",
      "positions (x,y,z), reward: [  10.82561363   -8.89684924  108.47963942] 269.888818364\n",
      "positions (x,y,z), reward: [  11.93449426  -10.15076545  111.52796215] 263.250099374\n",
      "positions (x,y,z), reward: [  19.19154084  -19.15432356  128.7003075 ] 237.193943759\n",
      "positions (x,y,z), reward: [  31.2724727   -39.98511702  156.9718781 ] 155.125706794\n",
      "Episode =   51, score = 305.466 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.72844385e-05  -1.79104040e-05   2.03796166e+01] -2.60467293518\n",
      "positions (x,y,z), reward: [  0.07247479  -0.04879192  33.40145925] 16.0685094355\n",
      "positions (x,y,z), reward: [  0.10461895  -0.06489347  35.86883745] 16.9496712558\n",
      "positions (x,y,z), reward: [  0.17125253  -0.0859871   39.97987522] 67.9385028005\n",
      "positions (x,y,z), reward: [  7.24228465e-01  -7.17859045e-03   5.85607266e+01] 169.223294217\n",
      "positions (x,y,z), reward: [  1.27342753   0.12402227  69.22558675] 168.747160817\n",
      "positions (x,y,z), reward: [  1.52733895   0.15690318  73.17083169] 168.526769885\n",
      "positions (x,y,z), reward: [  1.86018856   0.16470721  77.69332267] 168.290944214\n",
      "positions (x,y,z), reward: [  1.95161411   0.15990513  78.82683498] 168.236183864\n",
      "positions (x,y,z), reward: [  2.41116653   0.09378372  83.94632769] 173.946522087\n",
      "positions (x,y,z), reward: [  3.10402154  -0.11887306  90.26121984] 183.04709791\n",
      "positions (x,y,z), reward: [   5.1027988    -1.21333969  103.18719797] 290.833007309\n",
      "positions (x,y,z), reward: [   5.96237904   -1.81252169  107.40846577] 283.470607966\n",
      "positions (x,y,z), reward: [   6.80183618   -2.442268    111.07692775] 276.908965589\n",
      "positions (x,y,z), reward: [   7.57944434   -3.05583067  114.17368633] 271.255671585\n",
      "positions (x,y,z), reward: [  12.6355036    -7.53443911  130.37524444] 255.791211911\n",
      "positions (x,y,z), reward: [  13.63593429   -8.50710284  133.12021957] 254.519061906\n",
      "positions (x,y,z), reward: [  22.61165953  -18.41879418  154.86830679] 198.750084577\n",
      "Episode =   52, score = 315.116 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -7.49747374e-04   2.79712443e-04   2.07701986e+01] -0.38551145744\n",
      "positions (x,y,z), reward: [ -1.17956973e-03   3.90365271e-04   2.09297249e+01] 0.334783583854\n",
      "positions (x,y,z), reward: [ -1.13792323e-02   1.72772287e-03   2.24327444e+01] 5.00935276479\n",
      "positions (x,y,z), reward: [ -0.59998517   0.13471072  34.85581823] 15.9883442108\n",
      "positions (x,y,z), reward: [ -1.10925762   0.25120851  39.95321318] 66.7656599099\n",
      "positions (x,y,z), reward: [ -1.23377349   0.27864228  41.00248062] 66.8169501412\n",
      "positions (x,y,z), reward: [ -4.23069822   0.81773151  57.85216404] 164.497198092\n",
      "positions (x,y,z), reward: [ -5.83846648   1.02579247  63.90891878] 162.610656603\n",
      "positions (x,y,z), reward: [ -6.33750455   1.08159399  65.55647248] 162.007197527\n",
      "positions (x,y,z), reward: [-12.88528758   1.60180169  81.13416156] 155.133962257\n",
      "positions (x,y,z), reward: [-18.82421952   1.91609556  90.10729477] 160.168968071\n",
      "positions (x,y,z), reward: [-20.35224528   1.98611003  91.98327997] 161.118247624\n",
      "positions (x,y,z), reward: [ -36.17621792    2.5833425   105.52404741] 257.449850147\n",
      "positions (x,y,z), reward: [ -39.41097605    2.68657303  107.40187182] 253.18198207\n",
      "positions (x,y,z), reward: [ -69.25726326    3.45741138  116.68114136] 227.24350197\n",
      "positions (x,y,z), reward: [ -71.1409984     3.49723569  116.88590714] 226.276545554\n",
      "Episode =   53, score = 294.319 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -5.08348548e-03   3.39439198e-03   2.35691229e+01] 7.35881615489\n",
      "positions (x,y,z), reward: [ -9.73656568e-03   3.81063024e-03   2.48834195e+01] 9.43450683747\n",
      "positions (x,y,z), reward: [ -1.66964058e-02   2.35424749e-03   2.63536054e+01] 11.2461588696\n",
      "positions (x,y,z), reward: [ -3.22076906e-02  -6.06529023e-03   2.88057567e+01] 13.4768043192\n",
      "positions (x,y,z), reward: [ -5.83346840e-02  -3.05524247e-02   3.19645424e+01] 15.4182704123\n",
      "positions (x,y,z), reward: [ -0.1769009   -0.24818095  42.6187027 ] 68.2574708544\n",
      "positions (x,y,z), reward: [ -0.28806487  -0.52564461  49.67238444] 118.672135218\n",
      "positions (x,y,z), reward: [ -0.72478878  -1.77981427  65.8558467 ] 167.642237004\n",
      "positions (x,y,z), reward: [ -1.13798015  -3.26938295  76.55816434] 165.721805124\n",
      "positions (x,y,z), reward: [ -1.16236282  -3.36459691  77.12067925] 165.593598888\n",
      "positions (x,y,z), reward: [ -1.45260684  -4.52702325  83.29376357] 168.947104195\n",
      "positions (x,y,z), reward: [ -1.76314686  -5.769469    88.87456055] 175.591325993\n",
      "positions (x,y,z), reward: [ -1.79732699  -5.90337478  89.43061714] 176.237316548\n",
      "positions (x,y,z), reward: [ -1.97789508  -6.59875933  92.20459162] 179.414891497\n",
      "positions (x,y,z), reward: [ -2.25995542  -7.6436835   96.06893651] 183.715788276\n",
      "positions (x,y,z), reward: [  -2.72821186   -9.277566    101.54551763] 284.916349605\n",
      "positions (x,y,z), reward: [  -3.52209478  -11.82619371  109.11096599] 269.774495294\n",
      "positions (x,y,z), reward: [  -4.78662459  -15.51030714  118.64522594] 249.910517655\n",
      "positions (x,y,z), reward: [  -4.94442107  -15.94715705  119.69083568] 247.676629604\n",
      "positions (x,y,z), reward: [  -8.11101525  -23.98697071  136.49671926] 238.632977588\n",
      "Episode =   54, score = 312.485 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -6.14277169e-03  -4.86958150e-04   2.26987043e+01] 5.63097418839\n",
      "positions (x,y,z), reward: [ -2.98762887e-02  -2.39524796e-03   2.52385608e+01] 9.90109863842\n",
      "positions (x,y,z), reward: [ -4.61012858e-02  -3.19342713e-03   2.63552811e+01] 11.2185165834\n",
      "positions (x,y,z), reward: [ -1.50857387e-01  -1.74687729e-03   3.10366990e+01] 14.8506560592\n",
      "positions (x,y,z), reward: [ -0.49734376   0.04211507  39.45355377] 67.5449513484\n",
      "positions (x,y,z), reward: [ -0.69144856   0.08114047  42.62232485] 67.9178942048\n",
      "positions (x,y,z), reward: [ -6.64512714   1.63641017  74.58043031] 162.623627582\n",
      "positions (x,y,z), reward: [ -36.77687284    4.9281055   122.00184277] 260.783833333\n",
      "positions (x,y,z), reward: [ -53.75777656    6.48338957  154.23498651] 243.911588918\n",
      "positions (x,y,z), reward: [ -63.30426239   14.09091594  191.05019531] 193.833772134\n",
      "Episode =   55, score = 327.064 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.24053448e-07   5.06918115e-07   2.00699680e+01] -5.66956570425\n",
      "positions (x,y,z), reward: [ -3.98899616e-02  -1.01217806e+00   4.96925851e+01] 118.477053608\n",
      "positions (x,y,z), reward: [ -4.64226371e-02  -1.06166105e+00   5.02436672e+01] 118.464885889\n",
      "positions (x,y,z), reward: [ -0.28645973  -2.416314    61.39553804] 167.377633818\n",
      "positions (x,y,z), reward: [ -0.50349752  -3.28979446  66.46078362] 166.379617025\n",
      "positions (x,y,z), reward: [ -1.15603858  -5.21501603  74.91993871] 163.778451673\n",
      "positions (x,y,z), reward: [ -1.48908848  -6.01171793  77.73210549] 162.557861571\n",
      "positions (x,y,z), reward: [ -2.07949384  -7.27529418  81.64655205] 162.930066089\n",
      "positions (x,y,z), reward: [ -6.4458571  -14.36726179  97.1418582 ] 172.051883672\n",
      "positions (x,y,z), reward: [ -17.26363182  -26.99138738  113.36326337] 232.767929802\n",
      "positions (x,y,z), reward: [ -24.81574563  -34.50922848  119.37293764] 216.41981746\n",
      "positions (x,y,z), reward: [ -26.53841016  -36.14587806  120.41204548] 214.477960535\n",
      "positions (x,y,z), reward: [ -33.80440749  -42.80757449  123.76285012] 210.450092021\n",
      "positions (x,y,z), reward: [ -34.74886506  -43.64892889  124.0911538 ] 209.95017182\n",
      "Episode =   56, score = 293.464 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.03242649   0.08648569  28.80098016] 13.387448318\n",
      "positions (x,y,z), reward: [  3.4389245    4.26118269  75.43563494] 163.861989449\n",
      "positions (x,y,z), reward: [  4.15277968   4.99549477  79.59198731] 162.65503826\n",
      "positions (x,y,z), reward: [  6.24531847   7.10885839  89.82188731] 173.773400473\n",
      "positions (x,y,z), reward: [  7.11636783   7.97929851  93.48753197] 177.829077326\n",
      "positions (x,y,z), reward: [  11.67788419   12.54660353  109.3374485 ] 266.850635015\n",
      "positions (x,y,z), reward: [  15.40360246   16.35717508  119.69424887] 246.970411367\n",
      "positions (x,y,z), reward: [  18.89261716   19.99569904  128.0946175 ] 243.509093267\n",
      "positions (x,y,z), reward: [  19.25236844   20.3744659   128.90776388] 243.63318584\n",
      "Episode =   57, score = 305.589 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.54065097e-07   1.14255516e-06   2.00699637e+01] -5.66968540393\n",
      "positions (x,y,z), reward: [  6.11181000e-06   1.63734474e-05   2.01940250e+01] -4.1292330243\n",
      "positions (x,y,z), reward: [  1.63550901e-03   7.08002522e-04   2.21778016e+01] 4.3948894546\n",
      "positions (x,y,z), reward: [  2.35557466e-02   1.41667511e-02   3.01301198e+01] 14.4262544757\n",
      "positions (x,y,z), reward: [  4.56815739e-02   3.16735019e-01   4.74962169e+01] 118.958119333\n",
      "positions (x,y,z), reward: [ -3.07355382e-02   6.37354447e-01   5.52401219e+01] 169.266586738\n",
      "positions (x,y,z), reward: [ -0.29841236   1.23950454  64.82575864] 168.882135724\n",
      "positions (x,y,z), reward: [ -1.0562991    2.37822725  76.8689872 ] 167.494150622\n",
      "positions (x,y,z), reward: [ -1.26721378   2.65270032  79.18762795] 167.110605184\n",
      "positions (x,y,z), reward: [ -2.67235813   4.32683933  90.89167752] 180.771718741\n",
      "positions (x,y,z), reward: [  -4.69501901    6.47249336  102.65214092] 286.091068299\n",
      "Episode =   58, score = 315.088 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.56821375e-07  -3.74926090e-07   2.00699365e+01] -5.67020108932\n",
      "positions (x,y,z), reward: [  1.53173633e-04  -4.75706187e-04   2.07697999e+01] -0.387102063476\n",
      "positions (x,y,z), reward: [ -1.87038860e-01   4.93591727e-03   4.42235171e+01] 118.716679132\n",
      "positions (x,y,z), reward: [ -0.42891268   0.16574982  52.43551247] 169.164188878\n",
      "positions (x,y,z), reward: [ -1.16787369   0.79498576  65.99233009] 168.732965125\n",
      "positions (x,y,z), reward: [ -3.07275406   2.88540531  86.62685974] 176.342459616\n",
      "positions (x,y,z), reward: [ -4.23579254   4.2721141   95.8651768 ] 188.514426995\n",
      "positions (x,y,z), reward: [ -10.22657803   10.27207127  127.91981734] 255.92294528\n",
      "positions (x,y,z), reward: [ -10.3997239    10.40529649  128.60921299] 255.706594485\n",
      "positions (x,y,z), reward: [ -13.0978695    12.24431008  138.47626707] 252.724845784\n",
      "positions (x,y,z), reward: [ -17.33709933   14.40827666  152.01498366] 199.790659344\n",
      "positions (x,y,z), reward: [ -18.67810248   14.93994863  156.04153906] 149.416953845\n",
      "Episode =   59, score = 311.313 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -4.99367382e-04   8.33879379e-04   2.07692807e+01] -0.39597394829\n",
      "positions (x,y,z), reward: [ -7.59141930e-04   1.24899209e-03   2.09285930e+01] 0.323285144268\n",
      "positions (x,y,z), reward: [ -0.04463654   0.0551103   25.59544194] 10.2696902289\n",
      "positions (x,y,z), reward: [ -0.62375054   0.49386815  36.85404252] 66.2719979108\n",
      "positions (x,y,z), reward: [ -3.60894517   2.24811803  55.76775318] 164.184694564\n",
      "positions (x,y,z), reward: [ -9.68136932   5.36391257  74.05619272] 155.978209088\n",
      "positions (x,y,z), reward: [-20.916842    10.12933432  95.54022431] 166.448145523\n",
      "positions (x,y,z), reward: [ -35.51753196   15.35650173  118.70809372] 249.723482164\n",
      "positions (x,y,z), reward: [ -43.16356044   18.18977985  131.56310637] 255.519512674\n",
      "positions (x,y,z), reward: [ -45.51956042   19.15537422  135.87399038] 259.015687045\n",
      "Episode =   60, score = 323.997 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -3.46121300e-08  -3.60576901e-07   2.00700063e+01] -5.66793283451\n",
      "positions (x,y,z), reward: [ -1.04940246e-04  -2.57912314e-04   2.07701689e+01] -0.386326759628\n",
      "positions (x,y,z), reward: [ -2.81674741e-03  -2.40637734e-03   2.35701410e+01] 7.36693791035\n",
      "positions (x,y,z), reward: [ -0.09422575   0.11887936  33.4002362 ] 15.9803508401\n",
      "positions (x,y,z), reward: [ -0.84468454   0.9423204   51.8839265 ] 117.832506063\n",
      "positions (x,y,z), reward: [ -4.24813113   5.9071637   92.4872488 ] 178.963886304\n",
      "positions (x,y,z), reward: [ -4.51393364   6.47245078  95.32322265] 182.327165822\n",
      "positions (x,y,z), reward: [  -4.99455373    7.56928286  100.41197221] 287.027350938\n",
      "positions (x,y,z), reward: [  -5.47752906    8.77333854  105.47840535] 277.615743069\n",
      "positions (x,y,z), reward: [  -5.90816611    9.94018191  109.96360713] 269.184353724\n",
      "positions (x,y,z), reward: [  -6.60845267   12.04457607  117.21253585] 255.298508249\n",
      "positions (x,y,z), reward: [  -9.50528056   23.28718993  145.26298977] 238.389251206\n",
      "positions (x,y,z), reward: [  -9.56688166   23.5510214   145.7804588 ] 238.278924648\n",
      "Episode =   61, score = 313.161 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.68107622e-02   7.86339391e-02   2.71366539e+01] 11.9761720514\n",
      "positions (x,y,z), reward: [  0.24699014   0.42216795  38.92327632] 67.2980643504\n",
      "positions (x,y,z), reward: [  0.26615121   0.44106875  39.44386258] 67.3805499294\n",
      "positions (x,y,z), reward: [  0.37573731   0.53989236  42.07996179] 67.6950401551\n",
      "positions (x,y,z), reward: [  0.84606818   0.86942256  50.22911346] 117.884011201\n",
      "positions (x,y,z), reward: [  1.8249426    1.33683666  61.41550215] 167.093652749\n",
      "positions (x,y,z), reward: [  2.33937042   1.51328945  65.95024636] 166.56600762\n",
      "positions (x,y,z), reward: [  2.47955404   1.5556138   67.08772117] 166.417271558\n",
      "positions (x,y,z), reward: [  5.17461423   2.12019279  84.26222645] 169.839323206\n",
      "positions (x,y,z), reward: [  11.35073983    2.88640006  109.23847052] 273.553671607\n",
      "positions (x,y,z), reward: [  12.89436926    3.00690733  114.01751134] 265.169233485\n",
      "positions (x,y,z), reward: [  18.75464403    3.19206351  129.58458524] 252.387485903\n",
      "positions (x,y,z), reward: [  29.28657114    2.13250532  153.63562244] 206.496393655\n",
      "Episode =   62, score = 314.844 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.75963855e-03  -1.69912018e-02   2.42055169e+01] 8.42698936993\n",
      "positions (x,y,z), reward: [ -3.59682526e-03  -2.65773543e-02   2.52375282e+01] 9.90142208085\n",
      "positions (x,y,z), reward: [ -0.41505567  -0.41557898  50.22687671] 118.762488532\n",
      "positions (x,y,z), reward: [ -2.10272935  -0.10650576  71.74407074] 168.684790532\n",
      "positions (x,y,z), reward: [ -2.39599615e+00  -7.50742834e-03   7.40608348e+01] 168.613861294\n",
      "positions (x,y,z), reward: [ -3.94002723   0.58598798  84.02799119] 173.154937144\n",
      "positions (x,y,z), reward: [ -5.92011187   1.42105975  93.64098123] 185.581745151\n",
      "positions (x,y,z), reward: [ -17.78774635    5.63108972  129.30060673] 253.862016182\n",
      "Episode =   63, score = 311.006 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.27442119e-02  -1.91237824e-03   2.59734551e+01] 10.8202503608\n",
      "positions (x,y,z), reward: [  3.65598774e-02  -2.50302493e-02   3.01265025e+01] 14.3905316431\n",
      "positions (x,y,z), reward: [  0.21367165  -0.1689096   41.55963332] 68.1308117034\n",
      "positions (x,y,z), reward: [  0.52196591  -0.29673645  50.78413415] 118.781880856\n",
      "positions (x,y,z), reward: [  0.76891566  -0.35020822  55.7850103 ] 168.827069998\n",
      "positions (x,y,z), reward: [  1.34087799  -0.38557908  64.24188534] 168.677074156\n",
      "positions (x,y,z), reward: [  3.82056887   0.08722851  85.63388085] 176.021979668\n",
      "positions (x,y,z), reward: [  15.07597195    4.29319079  129.66056584] 257.594894401\n",
      "Episode =   64, score = 315.027 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  4.87740258e-06   6.96824022e-04   2.06250302e+01] -1.11900972105\n",
      "positions (x,y,z), reward: [  0.10995106   0.94689384  49.1027392 ] 118.324896911\n",
      "positions (x,y,z), reward: [  0.20517569   2.4090472   74.22413957] 167.662297592\n",
      "positions (x,y,z), reward: [ -4.21022114e-02   2.80821209e+00   8.16002869e+01] 170.004332148\n",
      "positions (x,y,z), reward: [ -0.19241645   2.94587851  84.44864894] 174.042874974\n",
      "positions (x,y,z), reward: [ -1.38242864   3.3978313   98.16668129] 193.080184122\n",
      "positions (x,y,z), reward: [  -3.25912212    3.41582667  110.73168201] 277.689874294\n",
      "positions (x,y,z), reward: [  -5.70830544    2.99755315  122.05687793] 261.406131798\n",
      "positions (x,y,z), reward: [  -6.89946371    2.70136565  126.53702651] 260.278493755\n",
      "positions (x,y,z), reward: [  -7.05677562    2.65942443  127.09428247] 260.129550343\n",
      "positions (x,y,z), reward: [ -11.76493674    1.27552825  141.30378254] 255.712241325\n",
      "Episode =   65, score = 324.200 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.10147634e-04  -8.22938389e-05   2.06249983e+01] -1.11716815066\n",
      "positions (x,y,z), reward: [  2.34035863e-02   1.01359412e-02   2.45408999e+01] 8.92628227931\n",
      "positions (x,y,z), reward: [  0.18914476   0.09615568  31.49932224] 14.9714480253\n",
      "positions (x,y,z), reward: [  0.26227089   0.134667    33.39800027] 15.7821257651\n",
      "positions (x,y,z), reward: [  0.79002213   0.41192186  42.62164017] 67.500307802\n",
      "positions (x,y,z), reward: [  13.85655621    7.76109599  102.37867995] 284.635438109\n",
      "positions (x,y,z), reward: [  16.62140642    9.59734722  109.4316106 ] 272.260453501\n",
      "positions (x,y,z), reward: [  73.74042562   81.19431757  288.81342835] 994.474435781\n",
      "Episode =   66, score = 331.293 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.51803668  -0.50544243  44.76221012] 117.976401271\n",
      "positions (x,y,z), reward: [  1.22396008  -1.25156935  56.33545239] 167.463531657\n",
      "positions (x,y,z), reward: [  2.10568517  -2.40672472  66.44689564] 165.662508258\n",
      "positions (x,y,z), reward: [  2.28028633  -2.65692258  68.13794065] 165.247829896\n",
      "positions (x,y,z), reward: [  4.0244538   -5.37480072  81.64289025] 163.051594824\n",
      "positions (x,y,z), reward: [   8.94836209  -13.41212457  104.38011203] 270.932807829\n",
      "positions (x,y,z), reward: [  10.50835563  -15.84737003  109.44435287] 259.914038603\n",
      "positions (x,y,z), reward: [  11.08012062  -16.72375298  111.15939567] 256.168512816\n",
      "positions (x,y,z), reward: [  14.14300903  -21.30647313  119.44767026] 239.354913778\n",
      "positions (x,y,z), reward: [  33.50596568  -49.173983    161.66973594] 174.754200201\n",
      "Episode =   67, score = 301.385 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -3.80793249e-06   9.20568692e-06   2.01242349e+01] -4.89911893619\n",
      "positions (x,y,z), reward: [ -1.96959470e-02   2.33209207e-02   2.42035603e+01] 8.39597063671\n",
      "positions (x,y,z), reward: [ -0.05173279   0.0593353   26.74094163] 11.5636854859\n",
      "positions (x,y,z), reward: [ -0.10573939   0.12241821  29.67643802] 13.9125067056\n",
      "positions (x,y,z), reward: [ -0.40915208   0.5478448   39.96628578] 67.2298286459\n",
      "positions (x,y,z), reward: [ -1.62673725   3.88140757  70.99802529] 164.976323117\n",
      "positions (x,y,z), reward: [  -2.29533275   10.58659749  100.6537695 ] 286.273548939\n",
      "positions (x,y,z), reward: [  -2.37593281   11.95675521  105.1374521 ] 277.869011772\n",
      "positions (x,y,z), reward: [  -2.84160623   22.14785897  130.66181971] 245.329524274\n",
      "positions (x,y,z), reward: [  -2.91970405   24.27214117  134.81393984] 244.80679836\n",
      "Episode =   68, score = 314.318 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.85469758e-02   3.56130846e-02   2.96811014e+01] 14.0887454568\n",
      "positions (x,y,z), reward: [  0.03781014   0.05461131  31.49907754] 15.1716640332\n",
      "positions (x,y,z), reward: [  0.08083249   0.15031159  37.38706069] 67.3511354466\n",
      "positions (x,y,z), reward: [  0.20858445   0.41585118  46.4013577 ] 118.58663979\n",
      "positions (x,y,z), reward: [  1.35144672   2.31074917  73.3128645 ] 166.792567618\n",
      "positions (x,y,z), reward: [  3.83616094   5.73028921  97.7348788 ] 187.355157431\n",
      "positions (x,y,z), reward: [   4.68042383    6.76347744  103.39751192] 283.76620736\n",
      "positions (x,y,z), reward: [   6.85872495    9.22389386  115.28237621] 261.255596771\n",
      "positions (x,y,z), reward: [  14.4725417    16.7360524   143.17296464] 238.20234019\n",
      "Episode =   69, score = 315.687 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777679] -7.22232345591\n",
      "positions (x,y,z), reward: [  9.47440683e-02   1.90513291e-02   2.67391448e+01] 11.5452632896\n",
      "positions (x,y,z), reward: [  0.30992753   0.0756431   31.95546862] 15.0966380809\n",
      "positions (x,y,z), reward: [  0.36226712   0.08897491  32.90421888] 15.4942424462\n",
      "positions (x,y,z), reward: [  0.48212116   0.11868264  34.85313906] 16.1467779969\n",
      "positions (x,y,z), reward: [  2.91421873   0.61453026  56.37338709] 166.695883849\n",
      "positions (x,y,z), reward: [  4.15365724   0.82145955  63.2269715 ] 165.928660734\n",
      "positions (x,y,z), reward: [  6.9348126    1.21262416  75.12910687] 164.604756591\n",
      "positions (x,y,z), reward: [  7.27092795   1.25681714  76.36437845] 164.466499771\n",
      "positions (x,y,z), reward: [  38.82813916    7.99564931  161.02562141] 236.229948827\n",
      "positions (x,y,z), reward: [  43.73457816   10.07030188  175.25322495] 228.582518177\n",
      "Episode =   70, score = 352.106 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -0.04535659   0.04300563  25.9699993 ] 10.7366448163\n",
      "positions (x,y,z), reward: [ -0.17339335   0.14152205  31.0290029 ] 14.6723182302\n",
      "positions (x,y,z), reward: [ -1.14278439   0.59974511  47.45528779] 117.494435715\n",
      "positions (x,y,z), reward: [ -3.08934741   0.7328451   64.6806499 ] 166.323928121\n",
      "positions (x,y,z), reward: [ -5.67088013  -0.31906962  79.94995922] 164.301061102\n",
      "positions (x,y,z), reward: [ -10.93621306   -5.30529708  101.58161308] 280.200741246\n",
      "positions (x,y,z), reward: [ -16.44853428  -12.72764367  117.46067282] 240.783569161\n",
      "Episode =   71, score = 302.595 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.57076404e-10   3.79420610e-08   2.00311249e+01] -6.44407861068\n",
      "positions (x,y,z), reward: [  0.03329704   0.06900712  26.74613168] 11.5829985762\n",
      "positions (x,y,z), reward: [  0.45692591   0.66810583  39.97973078] 67.0865156175\n",
      "positions (x,y,z), reward: [  0.85923629   1.25734463  46.95750293] 117.247120586\n",
      "positions (x,y,z), reward: [  4.56080773  10.16658726  90.26745405] 177.042447458\n",
      "positions (x,y,z), reward: [   7.13033663   25.17349885  136.73111417] 280.101307561\n",
      "positions (x,y,z), reward: [   8.05270207   41.02685897  214.22248878] 362.068991643\n",
      "Episode =   72, score = 366.792 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.67549883e-04  -5.65456476e-04   2.07694826e+01] -0.39327814329\n",
      "positions (x,y,z), reward: [ -8.35190600e-04  -3.43936322e-03   2.17067224e+01] 3.083244381\n",
      "positions (x,y,z), reward: [  0.04505363  -0.65162017  41.01701687] 67.6918430134\n",
      "positions (x,y,z), reward: [ -1.03013559  -4.3399597   69.305134  ] 164.954403154\n",
      "positions (x,y,z), reward: [ -3.45657766  -9.10050328  82.64785802] 160.181260332\n",
      "positions (x,y,z), reward: [ -4.6849907  -11.35883288  86.842894  ] 161.818742942\n",
      "positions (x,y,z), reward: [ -5.92810191 -13.6122068   90.34205028] 162.310208947\n",
      "positions (x,y,z), reward: [ -8.83636499 -18.8412563   96.74666344] 160.737645606\n",
      "positions (x,y,z), reward: [ -21.67561971  -41.90928859  111.4952609 ] 224.137718624\n",
      "positions (x,y,z), reward: [ -27.1985225   -51.69261299  114.06246116] 215.753642287\n",
      "positions (x,y,z), reward: [ -33.05777898  -61.77266212  114.97087939] 199.679483512\n",
      "Episode =   73, score = 287.579 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.52224338e-03   3.68851184e-03   2.26984877e+01] 5.63025619844\n",
      "positions (x,y,z), reward: [ -2.16880453e-02   5.35479174e-02   2.96839428e+01] 14.0888408097\n",
      "positions (x,y,z), reward: [ -2.85062897e-02   8.67804678e-02   3.24435413e+01] 15.6431963923\n",
      "positions (x,y,z), reward: [ -0.08242643   0.4691046   49.13199841] 118.877443348\n",
      "positions (x,y,z), reward: [ -0.43814008   2.20602941  77.21488345] 167.869508959\n",
      "positions (x,y,z), reward: [  -0.89789525    8.52159018  114.73376565] 271.097119053\n",
      "positions (x,y,z), reward: [  -0.26307077   13.199965    131.25289684] 261.853639895\n",
      "positions (x,y,z), reward: [   0.65508268   16.72326503  141.66359843] 260.894067488\n",
      "positions (x,y,z), reward: [   2.16770489   20.89834063  153.17775826] 210.63776835\n",
      "Episode =   74, score = 320.005 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.48834526e-07   4.39425465e-12   2.00310691e+01] -6.446870298\n",
      "positions (x,y,z), reward: [  5.37558150e-03  -6.07717072e-03   2.29752947e+01] 6.21416751581\n",
      "positions (x,y,z), reward: [  9.05279657e-03  -1.37083581e-02   2.42037318e+01] 8.42030174662\n",
      "positions (x,y,z), reward: [  0.05660641  -0.65299984  47.47029426] 118.561927202\n",
      "positions (x,y,z), reward: [ -3.37941517e-02  -8.67731061e-01   5.24177040e+01] 168.768008159\n",
      "positions (x,y,z), reward: [ -5.07597375  -3.78441979  97.88009091] 187.774203688\n",
      "positions (x,y,z), reward: [  -7.40044724   -4.61265344  107.83891779] 275.724138732\n",
      "positions (x,y,z), reward: [ -11.41717909   -5.86483557  121.4409486 ] 251.602769428\n",
      "positions (x,y,z), reward: [ -13.27440977   -6.41644929  126.79041812] 248.916479458\n",
      "positions (x,y,z), reward: [ -17.83754374   -7.77162921  138.36069415] 242.376009973\n",
      "Episode =   75, score = 316.476 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  4.71926861e-03   1.11993170e-02   2.24330741e+01] 5.01335391385\n",
      "positions (x,y,z), reward: [  9.43484883e-03   2.08949171e-02   2.32691420e+01] 6.78635302337\n",
      "positions (x,y,z), reward: [  2.36581889e-02   4.65600005e-02   2.48865205e+01] 9.39169758497\n",
      "positions (x,y,z), reward: [  0.06330123   0.10296947  27.55085053] 12.3015176109\n",
      "positions (x,y,z), reward: [  2.55466668   1.30003788  64.1154598 ] 166.131053931\n",
      "positions (x,y,z), reward: [  4.01259587   1.80129553  75.31049459] 164.137655139\n",
      "positions (x,y,z), reward: [  5.74050043   2.29557196  86.48064936] 171.614865113\n",
      "positions (x,y,z), reward: [  6.01213835   2.36237075  88.15749928] 173.817919786\n",
      "positions (x,y,z), reward: [  6.37420127   2.44734894  90.3963123 ] 176.778851966\n",
      "positions (x,y,z), reward: [  7.25579461   2.63914108  96.01931698] 184.362871574\n",
      "positions (x,y,z), reward: [   8.80124085    3.01046087  110.39866611] 273.939057512\n",
      "positions (x,y,z), reward: [   8.41252405    3.24156801  122.27669455] 260.193437324\n",
      "positions (x,y,z), reward: [   2.55472761    3.50690034  142.63211798] 263.579807536\n",
      "Episode =   76, score = 320.221 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -6.10771777e-05   1.44543411e-04   2.03790669e+01] -2.61330813386\n",
      "positions (x,y,z), reward: [ -1.73404836e-04   4.33244541e-04   2.06244046e+01] -1.12489624938\n",
      "positions (x,y,z), reward: [ -3.98851591e-03   1.75068808e-02   2.38792918e+01] 7.884459091\n",
      "positions (x,y,z), reward: [ -0.22295797   0.33294293  41.01577394] 67.8357141356\n",
      "positions (x,y,z), reward: [ -0.54074757   0.6318929   50.75223758] 118.343127942\n",
      "positions (x,y,z), reward: [ -0.79937566   0.86050643  56.84009556] 168.133863223\n",
      "positions (x,y,z), reward: [ -0.90390285   0.95032349  59.06617861] 168.001670864\n",
      "positions (x,y,z), reward: [ -1.18949034   1.18519513  64.64957931] 167.593641297\n",
      "positions (x,y,z), reward: [ -2.04285872   1.73730769  77.55449245] 166.355036047\n",
      "positions (x,y,z), reward: [ -2.51986359   1.93954114  82.6293859 ] 169.724399083\n",
      "positions (x,y,z), reward: [  -6.86094034    2.43506404  103.62825245] 285.373148587\n",
      "positions (x,y,z), reward: [ -20.84131904    1.61344549  127.62102251] 243.510591165\n",
      "Episode =   77, score = 315.827 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  4.64213152e-05  -1.53156237e-05   2.02790031e+01] -3.36726392379\n",
      "positions (x,y,z), reward: [  2.41934798e-02   1.48381920e-03   2.42021505e+01] 8.40392255467\n",
      "positions (x,y,z), reward: [  3.19428138e-02   2.29942729e-03   2.48796571e+01] 9.40295085914\n",
      "positions (x,y,z), reward: [  6.34587382e-02   5.92051294e-03   2.71354884e+01] 11.9959958513\n",
      "positions (x,y,z), reward: [  2.00705367e-01   1.59939317e-02   3.43631673e+01] 16.3599382754\n",
      "positions (x,y,z), reward: [  4.70449597e-01  -1.58900843e-02   5.18638727e+01] 119.170415955\n",
      "positions (x,y,z), reward: [ -0.89086461  -1.78321478  80.27236591] 168.627622956\n",
      "positions (x,y,z), reward: [ -1.66681106  -2.86071633  85.46564988] 174.387295748\n",
      "positions (x,y,z), reward: [ -1.76887374  -3.00492811  86.03993403] 174.960933136\n",
      "positions (x,y,z), reward: [ -5.35782953  -8.06755072  99.32041015] 183.682105789\n",
      "positions (x,y,z), reward: [ -12.67976941  -17.5263448   112.32883788] 243.137994629\n",
      "positions (x,y,z), reward: [ -13.66951785  -18.71295488  113.49570343] 238.394536491\n",
      "positions (x,y,z), reward: [ -15.40484696  -20.74563143  115.32968406] 231.214118185\n",
      "positions (x,y,z), reward: [ -27.85117684  -33.86603137  123.20880178] 210.553943672\n",
      "Episode =   78, score = 299.823 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.44784208e-02   1.68121201e-02   2.32652830e+01] 6.76716033964\n",
      "positions (x,y,z), reward: [  0.0295624    0.03557962  24.53697049] 8.88222849324\n",
      "positions (x,y,z), reward: [  0.25091796   0.3654713   32.90649698] 15.3277306865\n",
      "positions (x,y,z), reward: [  4.00343704   7.94762695  72.43007144] 163.956471064\n",
      "positions (x,y,z), reward: [  5.48617558  10.95220783  80.97990974] 164.577947207\n",
      "positions (x,y,z), reward: [  6.99326286  14.02909679  88.91042909] 176.368464362\n",
      "positions (x,y,z), reward: [  8.56276508  17.35613008  96.98441269] 189.623657413\n",
      "positions (x,y,z), reward: [   9.52021359   19.50696217  102.01617605] 292.677278337\n",
      "positions (x,y,z), reward: [  14.14860786   32.99972513  131.57324676] 306.48984693\n",
      "positions (x,y,z), reward: [  15.36956379   38.34235453  142.74144939] 333.680205056\n",
      "positions (x,y,z), reward: [  18.39072882   64.1359599   194.38567116] 431.895404458\n",
      "Episode =   79, score = 354.362 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.85517472e-04  -9.41606252e-05   2.04944049e+01] -1.86306184512\n",
      "positions (x,y,z), reward: [  1.55301440e-02  -2.10373611e-02   2.48799055e+01] 9.39944556333\n",
      "positions (x,y,z), reward: [  1.72273920e-02  -2.49095876e-02   2.52334283e+01] 9.87274758218\n",
      "positions (x,y,z), reward: [  0.07059161  -0.2023496   32.90426827] 15.6700513708\n",
      "positions (x,y,z), reward: [  0.1701363   -0.55386748  39.9584665 ] 67.4613011434\n",
      "positions (x,y,z), reward: [  0.40298531  -1.48022419  49.6654569 ] 117.646243959\n",
      "positions (x,y,z), reward: [  0.63851196  -2.61541168  56.87792262] 166.620233496\n",
      "positions (x,y,z), reward: [  0.76397861  -3.29022086  60.22562284] 165.849370756\n",
      "positions (x,y,z), reward: [  1.15161252  -5.59061136  69.12904403] 162.925323608\n",
      "positions (x,y,z), reward: [  3.51375293 -18.68265109  97.7421958 ] 171.671139785\n",
      "positions (x,y,z), reward: [   4.2233457   -21.92203473  102.76457082] 268.620182894\n",
      "positions (x,y,z), reward: [   5.3112707   -26.51474086  109.26050285] 257.841017136\n",
      "positions (x,y,z), reward: [   5.40367863  -26.88714849  109.76172131] 257.019854767\n",
      "positions (x,y,z), reward: [   5.4974038   -27.26240168  110.26342545] 256.199381806\n",
      "positions (x,y,z), reward: [   6.50871109  -31.17606121  115.31763605] 247.993051247\n",
      "positions (x,y,z), reward: [   7.77671051  -35.83797614  120.99160255] 240.34828896\n",
      "positions (x,y,z), reward: [   7.89952206  -36.28123138  121.5147998 ] 240.291255529\n",
      "positions (x,y,z), reward: [   9.58070466  -42.35093245  128.43511393] 239.444800443\n",
      "Episode =   80, score = 302.530 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -9.28433973e-04  -2.09091910e-03   2.26970440e+01] 5.62276600542\n",
      "positions (x,y,z), reward: [ -3.90917255e-03  -1.05205756e-02   2.45374299e+01] 8.9342525817\n",
      "positions (x,y,z), reward: [ -0.04571389  -0.0883646   30.12308679] 14.3122427495\n",
      "positions (x,y,z), reward: [ -0.08311279  -0.14777355  32.43543382] 15.5161209658\n",
      "positions (x,y,z), reward: [ -0.4600956   -0.77165748  44.23068784] 117.709025952\n",
      "positions (x,y,z), reward: [ -0.9392292   -1.71411772  53.54388247] 167.039446525\n",
      "positions (x,y,z), reward: [ -1.67037892  -3.2285842   64.10299856] 164.907862269\n",
      "positions (x,y,z), reward: [ -2.73516972  -5.20687653  75.20342918] 161.731987119\n",
      "positions (x,y,z), reward: [ -2.79815822  -5.31418181  75.75684633] 161.552305283\n",
      "positions (x,y,z), reward: [ -4.21462018  -7.48044211  86.23995477] 167.171654904\n",
      "positions (x,y,z), reward: [ -4.5731777   -7.96516274  88.43903288] 169.587931126\n",
      "positions (x,y,z), reward: [ -5.46782248  -9.09013996  93.37455722] 174.868238932\n",
      "positions (x,y,z), reward: [  -8.73211999  -12.4515187   106.97267297] 267.362762277\n",
      "positions (x,y,z), reward: [ -17.8190207   -18.65097517  128.54177547] 230.636476474\n",
      "positions (x,y,z), reward: [ -25.56346366  -22.34273655  139.02007776] 224.209426765\n",
      "positions (x,y,z), reward: [ -27.22452405  -23.04333856  140.76950376] 223.506913407\n",
      "Episode =   81, score = 302.373 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.39402892e-02  -4.09778209e-03   2.38803912e+01] 7.88945273432\n",
      "positions (x,y,z), reward: [ -4.93157089e-02  -2.30923377e-02   2.67406842e+01] 11.5981782307\n",
      "positions (x,y,z), reward: [ -0.15418721  -0.09772916  31.49280798] 14.9979995363\n",
      "positions (x,y,z), reward: [ -0.28389786  -0.20488178  35.35640664] 16.4456564484\n",
      "positions (x,y,z), reward: [ -0.49180655  -0.39461542  39.96711452] 67.3111477839\n",
      "positions (x,y,z), reward: [ -1.32474439  -1.34319171  52.43059819] 167.017270881\n",
      "positions (x,y,z), reward: [ -1.86072181  -2.12162806  58.55404838] 165.953551502\n",
      "positions (x,y,z), reward: [ -2.82420608  -3.97228497  68.07658496] 163.184002571\n",
      "positions (x,y,z), reward: [ -5.32402554 -11.69852443  86.50293335] 159.945147425\n",
      "positions (x,y,z), reward: [ -5.50555867 -12.37839043  87.50491782] 160.211659567\n",
      "positions (x,y,z), reward: [ -10.54591968  -32.0533972   103.18574422] 248.776279967\n",
      "positions (x,y,z), reward: [ -19.92269207  -62.79671301  105.64684934] 190.522349413\n",
      "positions (x,y,z), reward: [ -22.92294845  -70.54066979  103.39811999] 189.262489687\n",
      "Episode =   82, score = 279.293 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.20621668e-06  -3.81401513e-07   2.00699712e+01] -5.6690979\n",
      "positions (x,y,z), reward: [ -3.84846888e-05  -3.60569834e-05   2.02791640e+01] -3.36398672015\n",
      "positions (x,y,z), reward: [ -0.12863135   0.17937074  39.45114355] 67.7813219706\n",
      "positions (x,y,z), reward: [ -0.30068996   0.50259849  48.03733033] 118.613157466\n",
      "positions (x,y,z), reward: [ -0.54128413   0.97292839  55.81003736] 168.526130345\n",
      "positions (x,y,z), reward: [ -0.71497452   1.32854458  60.31506409] 168.213089711\n",
      "positions (x,y,z), reward: [ -1.4001856    2.86833958  74.54113088] 166.331881029\n",
      "positions (x,y,z), reward: [ -2.72700265   6.10975235  93.99580277] 182.569799304\n",
      "positions (x,y,z), reward: [ -2.87079293   6.45995262  95.69832112] 184.552823391\n",
      "positions (x,y,z), reward: [  -3.99539515    9.19912326  107.47160363] 275.311562873\n",
      "positions (x,y,z), reward: [  -4.11224192    9.48685602  108.57892528] 273.183877217\n",
      "positions (x,y,z), reward: [  -4.84072007   11.31454373  115.17250635] 260.385690765\n",
      "positions (x,y,z), reward: [  -5.41083676   12.80176002  120.06474086] 250.847269722\n",
      "positions (x,y,z), reward: [  -5.86246772   14.0279153   123.84282769] 249.024034479\n",
      "positions (x,y,z), reward: [  -7.40520943   18.65896013  136.75486694] 243.042533775\n",
      "Episode =   83, score = 316.232 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  3.08535770e-03   5.25459672e-04   2.48870041e+01] 9.45698652591\n",
      "positions (x,y,z), reward: [  5.33356178e-03   1.24509935e-01   3.38897016e+01] 16.2699814438\n",
      "positions (x,y,z), reward: [  2.62324821e-03   5.08891755e-01   4.31723355e+01] 68.3105250629\n",
      "positions (x,y,z), reward: [  4.77908417e-02   2.16344837e+00   6.20363064e+01] 168.09085128\n",
      "positions (x,y,z), reward: [  6.52490028e-02   2.66675974e+00   6.60079509e+01] 167.693835923\n",
      "positions (x,y,z), reward: [ -0.16612908   6.56315277  88.24095501] 175.963870013\n",
      "positions (x,y,z), reward: [  -2.48330157   11.9063412   109.59408164] 271.19338542\n",
      "positions (x,y,z), reward: [  -9.19719149   16.24093106  129.16667186] 244.015859093\n",
      "positions (x,y,z), reward: [ -11.61809822   16.77122476  133.50693307] 240.318731369\n",
      "positions (x,y,z), reward: [ -12.27930831   16.87026502  134.57125634] 239.319395405\n",
      "Episode =   84, score = 313.949 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.52858721e-03  -1.82273927e-03   2.19360759e+01] 3.7471413681\n",
      "positions (x,y,z), reward: [ -8.05822816e-03  -7.67155843e-03   2.35685903e+01] 7.34845904703\n",
      "positions (x,y,z), reward: [ -0.23754315  -0.13777687  34.86199178] 16.3855211029\n",
      "positions (x,y,z), reward: [ -0.40001531  -0.21150617  38.9252887 ] 67.3389918525\n",
      "positions (x,y,z), reward: [ -0.84499856  -0.39840585  46.92244762] 117.955489282\n",
      "positions (x,y,z), reward: [ -0.99762718  -0.45804284  49.10645127] 117.937268929\n",
      "positions (x,y,z), reward: [ -1.82443303  -0.74062032  58.51124163] 167.284802777\n",
      "positions (x,y,z), reward: [ -2.97865571  -1.04169215  68.01251576] 165.985026044\n",
      "positions (x,y,z), reward: [ -5.28967048  -1.42637903  81.4495963 ] 165.391024665\n",
      "positions (x,y,z), reward: [ -18.3028667    -1.22314508  124.94349794] 249.612458631\n",
      "positions (x,y,z), reward: [ -21.79113094   -0.73878017  133.60698495] 248.27907449\n",
      "positions (x,y,z), reward: [ -23.40203474   -0.46916553  137.38955524] 248.551098799\n",
      "positions (x,y,z), reward: [ -24.34717079   -0.29945917  139.55254164] 248.750761741\n",
      "Episode =   85, score = 315.326 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00778305] -7.22169610444\n",
      "positions (x,y,z), reward: [  1.84534461e-05  -7.68698227e-07   2.01941183e+01] -4.12771951162\n",
      "positions (x,y,z), reward: [  1.61289738e-03  -1.17908429e-03   2.12911148e+01] 1.7375946573\n",
      "positions (x,y,z), reward: [  7.85051013e-03  -8.77285818e-03   2.26986393e+01] 5.61419713187\n",
      "positions (x,y,z), reward: [  0.47902011  -0.91437522  46.9152827 ] 117.803447411\n",
      "positions (x,y,z), reward: [  0.42819661  -1.92893951  68.69518281] 168.124026837\n",
      "positions (x,y,z), reward: [ -1.64439273  -2.28710543  94.28890884] 189.261216308\n",
      "positions (x,y,z), reward: [ -2.37131577  -2.22520442  98.47515507] 195.145018893\n",
      "positions (x,y,z), reward: [  -3.86068801   -2.05540169  105.14455376] 288.982143665\n",
      "positions (x,y,z), reward: [ -17.74180056   -0.742846    139.05035266] 263.513425932\n",
      "Episode =   86, score = 316.941 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.46216535e-04  -4.11833008e-04   2.07701391e+01] -0.385480552165\n",
      "positions (x,y,z), reward: [ -3.78121803e-03  -6.98061154e-03   2.24328075e+01] 5.01616145631\n",
      "positions (x,y,z), reward: [ -2.37791893e-02  -4.59750273e-02   2.59757437e+01] 10.7797659023\n",
      "positions (x,y,z), reward: [ -0.10696546  -0.33144066  36.37279979] 66.8313830399\n",
      "positions (x,y,z), reward: [ -0.12350524  -0.41723281  38.41756774] 67.2890505403\n",
      "positions (x,y,z), reward: [ -0.13620892  -0.48950242  39.97821529] 67.5552704628\n",
      "positions (x,y,z), reward: [ -0.3119681   -1.704732    56.31149819] 167.825966225\n",
      "positions (x,y,z), reward: [ -0.44061864  -2.52314051  63.01909649] 167.058003854\n",
      "positions (x,y,z), reward: [ -0.46718925  -2.68215158  64.14027456] 166.885427311\n",
      "positions (x,y,z), reward: [ -0.54039629  -3.10927133  66.94458321] 166.39539672\n",
      "positions (x,y,z), reward: [ -0.5723236   -3.2920719   68.06632542] 166.175743173\n",
      "positions (x,y,z), reward: [ -0.95609056  -5.50679602  79.24943179] 163.365948909\n",
      "positions (x,y,z), reward: [ -1.02086994  -5.90205373  80.91770711] 164.230401375\n",
      "positions (x,y,z), reward: [ -1.06479405  -6.17522518  82.02812288] 165.542505719\n",
      "positions (x,y,z), reward: [ -1.17688106  -6.89319905  84.7975374 ] 168.767706035\n",
      "positions (x,y,z), reward: [  -2.62022329  -19.39932435  115.13582113] 252.327147088\n",
      "positions (x,y,z), reward: [  -2.82337168  -21.52878395  118.60584278] 245.776886503\n",
      "positions (x,y,z), reward: [  -3.32153702  -27.27524663  126.69415402] 241.700682189\n",
      "positions (x,y,z), reward: [  -4.03965939  -38.59347462  138.81777994] 238.181465937\n",
      "Episode =   87, score = 310.523 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  8.28146977e-03   7.36467261e-03   2.56013246e+01] 10.3792346941\n",
      "positions (x,y,z), reward: [  1.27584027e-02   1.21519292e-02   2.67442975e+01] 11.6576660889\n",
      "positions (x,y,z), reward: [  0.06723057   0.07419796  34.86562749] 16.6219839182\n",
      "positions (x,y,z), reward: [  0.18422293   0.19786163  43.68469012] 68.4367740959\n",
      "positions (x,y,z), reward: [  0.20375729   0.21860272  44.76051904] 118.542952344\n",
      "positions (x,y,z), reward: [  0.31282425   0.33436081  49.6645628 ] 118.836928131\n",
      "positions (x,y,z), reward: [  0.35812194   0.38227556  51.31791282] 118.878913525\n",
      "positions (x,y,z), reward: [  0.95569227   1.03083632  65.35417158] 168.50161184\n",
      "positions (x,y,z), reward: [  1.32374384   1.4545909   71.08906959] 168.079392585\n",
      "positions (x,y,z), reward: [  1.40736499   1.55319874  72.24520718] 167.978167275\n",
      "positions (x,y,z), reward: [  3.03086657   3.56748145  89.41016612] 179.794747128\n",
      "positions (x,y,z), reward: [  3.10083142   3.65705847  90.01633114] 180.597187498\n",
      "positions (x,y,z), reward: [   5.23139218    6.48841873  106.24713139] 283.2078112\n",
      "Episode =   88, score = 308.113 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -3.24720859e-05  -9.49998291e-05   2.03794386e+01] -2.60837748989\n",
      "positions (x,y,z), reward: [  3.48965082e-04  -1.69396356e-03   2.17078845e+01] 3.09534479806\n",
      "positions (x,y,z), reward: [  4.28665450e-02  -1.66910730e-02   2.83809978e+01] 13.1225122842\n",
      "positions (x,y,z), reward: [  5.95135374e-02  -1.76323795e-02   2.96816404e+01] 14.0766799735\n",
      "positions (x,y,z), reward: [  7.22387731e-02  -1.76720320e-02   3.05795264e+01] 14.6440177263\n",
      "positions (x,y,z), reward: [  2.37508073e-01   3.84303624e-03   3.99742370e+01] 67.9354225259\n",
      "positions (x,y,z), reward: [  4.52040941e-01   4.50777975e-02   5.29670960e+01] 169.164819853\n",
      "positions (x,y,z), reward: [  4.78837064e-01   3.79251339e-02   7.53754501e+01] 169.658789643\n",
      "positions (x,y,z), reward: [  4.22959504e-01   2.77633454e-02   7.98847201e+01] 169.739414557\n",
      "positions (x,y,z), reward: [  2.86004798e-01   1.01895724e-02   8.72167686e+01] 180.737899628\n",
      "positions (x,y,z), reward: [  7.36224409e-02   3.69702480e-03   9.45556322e+01] 191.999939847\n",
      "positions (x,y,z), reward: [ -1.60778850e-01   2.03401030e-02   1.00208581e+02] 299.790520421\n",
      "positions (x,y,z), reward: [  -2.66968068    0.67699891  130.72140015] 266.750122256\n",
      "positions (x,y,z), reward: [  -3.57424977    1.00062986  138.57930738] 265.468633785\n",
      "Episode =   89, score = 330.448 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.01050994e-05   8.71200339e-05   2.02791370e+01] -3.3656088172\n",
      "positions (x,y,z), reward: [  0.20379952   0.04750501  31.50025535] 15.0108148047\n",
      "positions (x,y,z), reward: [  0.35139768   0.08531839  35.36558861] 16.5089696072\n",
      "positions (x,y,z), reward: [  0.56514731   0.15458987  39.97582123] 67.4652322098\n",
      "positions (x,y,z), reward: [  0.73410774   0.22037863  43.15351702] 67.7929669524\n",
      "positions (x,y,z), reward: [  2.61381744   1.29190863  69.14060862] 166.094815437\n",
      "positions (x,y,z), reward: [  4.74537261   3.5124676   97.84473513] 188.871000443\n",
      "positions (x,y,z), reward: [   4.93191445    3.98933396  102.96498972] 287.160497817\n",
      "positions (x,y,z), reward: [   1.79742325    6.39070701  138.84233848] 262.821815952\n",
      "positions (x,y,z), reward: [  -0.4667375     6.06030473  148.09518951] 214.218040493\n",
      "Episode =   90, score = 322.489 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -6.13720315e-03   5.61033136e-03   2.35692963e+01] 7.35589575009\n",
      "positions (x,y,z), reward: [  0.24882537  -0.2055612   50.25270463] 119.248014497\n",
      "positions (x,y,z), reward: [  0.43940801  -0.39863042  54.71912267] 169.266444314\n",
      "positions (x,y,z), reward: [  0.69659498  -0.66330989  59.24450722] 169.086758104\n",
      "positions (x,y,z), reward: [  1.4440877   -1.43097569  68.45793882] 168.258847926\n",
      "positions (x,y,z), reward: [  1.81473819  -1.80794314  71.97110357] 167.788361419\n",
      "positions (x,y,z), reward: [  4.3009011   -4.35124663  88.86781591] 177.69873327\n",
      "positions (x,y,z), reward: [   8.13482349   -8.39522401  106.49720179] 280.756728636\n",
      "positions (x,y,z), reward: [  20.5406095   -19.44548925  145.42992619] 270.680168194\n",
      "positions (x,y,z), reward: [  26.83717584  -23.33158611  161.56753942] 198.658201058\n",
      "Episode =   91, score = 340.789 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -8.00997711e-04  -9.08958150e-04   2.12906443e+01] 1.73682646473\n",
      "positions (x,y,z), reward: [ -3.13333831e-03  -4.22850071e-03   2.24313493e+01] 5.0094975484\n",
      "positions (x,y,z), reward: [ -0.02897367  -0.04255003  27.5439596 ] 12.3791271265\n",
      "positions (x,y,z), reward: [ -0.06736383  -0.09838083  32.43312016] 15.5693980684\n",
      "positions (x,y,z), reward: [ -0.11075959  -0.19582011  39.44547447] 67.7768407943\n",
      "positions (x,y,z), reward: [ -0.10090232  -0.29425411  45.84431751] 118.741058332\n",
      "positions (x,y,z), reward: [  0.21069605  -0.53218874  60.2802043 ] 169.472006751\n",
      "positions (x,y,z), reward: [  0.3024653   -0.56888636  62.54128153] 169.437342274\n",
      "positions (x,y,z), reward: [  0.68872651  -0.68382003  69.93045911] 169.129682581\n",
      "positions (x,y,z), reward: [  0.95243272  -0.74358866  73.92367219] 168.838665893\n",
      "positions (x,y,z), reward: [  1.20884962  -0.79521231  77.34760019] 168.520639997\n",
      "positions (x,y,z), reward: [  2.14118753  -0.97167969  87.5923027 ] 178.652346444\n",
      "positions (x,y,z), reward: [   4.41831536   -1.55335604  105.17873382] 286.711533105\n",
      "positions (x,y,z), reward: [   5.94945568   -2.11993731  113.74282246] 271.949501694\n",
      "positions (x,y,z), reward: [   9.16068071   -3.65854992  127.5226645 ] 257.903260834\n",
      "positions (x,y,z), reward: [  10.8139037    -4.60132416  133.26238326] 255.234010996\n",
      "positions (x,y,z), reward: [  11.34969982   -4.92626764  134.98032077] 254.3282678\n",
      "positions (x,y,z), reward: [  15.8641499    -7.98028876  147.4264963 ] 245.984899887\n",
      "Episode =   92, score = 323.020 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.84496590e-02   3.25256717e-03   2.45396568e+01] 8.92333848858\n",
      "positions (x,y,z), reward: [ -0.41335076  -0.0660012   35.8578404 ] 16.6117694578\n",
      "positions (x,y,z), reward: [ -0.82937629  -0.22218731  42.60916873] 67.6192151995\n",
      "positions (x,y,z), reward: [ -1.02960049  -0.31950812  45.29636653] 117.703000955\n",
      "positions (x,y,z), reward: [ -1.11594423  -0.36547536  46.38113398] 117.698151846\n",
      "positions (x,y,z), reward: [ -1.99382005  -0.94967195  55.75346844] 166.893563117\n",
      "positions (x,y,z), reward: [ -6.52708641  -9.71145217  92.14320103] 171.520476389\n",
      "positions (x,y,z), reward: [ -6.78015957 -10.8291089   94.34179847] 173.293137315\n",
      "positions (x,y,z), reward: [  -7.41211264  -14.37860335  100.31272065] 276.563563555\n",
      "positions (x,y,z), reward: [ -12.95079214  -68.56407998  134.62772009] 222.325782765\n",
      "Episode =   93, score = 301.085 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  8.84283219e-05  -1.25588108e-03   2.12905150e+01] 1.73721731905\n",
      "positions (x,y,z), reward: [ -7.64882163e-03  -2.79110946e-02   2.45386241e+01] 8.91492761631\n",
      "positions (x,y,z), reward: [ -9.43156486e-03  -3.30134530e-02   2.48825944e+01] 9.40246516544\n",
      "positions (x,y,z), reward: [ -0.03292679  -0.09732374  27.95700682] 12.6852587404\n",
      "positions (x,y,z), reward: [ -0.23784885  -0.61454613  39.96106522] 67.3078302782\n",
      "positions (x,y,z), reward: [ -0.28914097  -0.73972645  42.06996219] 67.5201312168\n",
      "positions (x,y,z), reward: [ -0.41847801  -1.05989167  46.90858867] 117.681696512\n",
      "positions (x,y,z), reward: [ -0.51201352  -1.3013329   50.18448699] 117.608434061\n",
      "positions (x,y,z), reward: [ -0.54385978  -1.38639985  51.28282588] 117.561168719\n",
      "positions (x,y,z), reward: [ -0.73288371  -1.93784171  57.92015934] 167.118422925\n",
      "positions (x,y,z), reward: [ -0.76289226  -2.0357082   59.03251092] 167.026504565\n",
      "positions (x,y,z), reward: [ -0.80649257  -2.18533792  60.7036151 ] 166.88232625\n",
      "positions (x,y,z), reward: [ -0.87447427  -2.44214333  63.49500909] 166.631687414\n",
      "positions (x,y,z), reward: [ -1.00339491  -3.10000411  70.2250972 ] 166.030729767\n",
      "positions (x,y,z), reward: [ -1.05382117  -4.3080747   80.99513439] 166.709473454\n",
      "positions (x,y,z), reward: [ -1.02559678  -4.67257035  83.86017492] 170.808799072\n",
      "positions (x,y,z), reward: [ -0.87512041  -5.64510087  90.79518723] 180.751849573\n",
      "positions (x,y,z), reward: [ -3.58180940e-02  -8.56763152e+00   1.07276845e+02] 282.042086809\n",
      "positions (x,y,z), reward: [   1.26654734  -12.18140927  122.53948276] 257.59447873\n",
      "positions (x,y,z), reward: [   2.37280057  -15.03223109  132.30898423] 252.97739515\n",
      "positions (x,y,z), reward: [   3.35508674  -17.44586219  139.60718071] 248.946469994\n",
      "positions (x,y,z), reward: [   4.1079388   -19.21996903  144.56110606] 245.966101394\n",
      "Episode =   94, score = 318.842 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.59270088e-05  -5.78167954e-06   2.01940983e+01] -4.12763320414\n",
      "positions (x,y,z), reward: [  6.69221544e-03  -6.81697339e-03   2.29765414e+01] 6.20902072611\n",
      "positions (x,y,z), reward: [  0.04618743  -0.06418461  27.54506538] 12.3458133754\n",
      "positions (x,y,z), reward: [  0.3039598   -0.48362901  38.40930859] 67.04661089\n",
      "positions (x,y,z), reward: [  2.47955029  -4.98127632  71.92930986] 162.383937283\n",
      "positions (x,y,z), reward: [  3.13845374  -6.94416982  79.14009676] 159.514731341\n",
      "positions (x,y,z), reward: [  4.20904998 -12.7149427   94.40242153] 173.558136988\n",
      "positions (x,y,z), reward: [   4.21275776  -15.91406386  100.81053477] 277.118565422\n",
      "positions (x,y,z), reward: [   4.13491808  -16.78909386  102.3953157 ] 273.805799271\n",
      "positions (x,y,z), reward: [  -8.36009153  -37.09029125  128.48279672] 230.73105497\n",
      "positions (x,y,z), reward: [  -9.70155285  -38.16217273  129.48470522] 228.577130801\n",
      "Episode =   95, score = 302.459 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -3.83495443e-06  -2.21344234e-06   2.01243321e+01] -4.89633765797\n",
      "positions (x,y,z), reward: [ -9.77471811e-04  -1.92964631e-03   2.14926669e+01] 2.42286094356\n",
      "positions (x,y,z), reward: [ -1.00906346e-02  -3.06693679e-02   2.52377386e+01] 9.88829022658\n",
      "positions (x,y,z), reward: [ -1.50834075e-02  -1.03990516e-01   2.92397197e+01] 13.7163208942\n",
      "positions (x,y,z), reward: [  1.14760405  -4.98640963  69.80202301] 163.824214322\n",
      "positions (x,y,z), reward: [  1.8561729   -8.1576316   78.65159426] 159.174762783\n",
      "positions (x,y,z), reward: [  3.07041837 -13.69219616  88.6096245 ] 163.005406024\n",
      "positions (x,y,z), reward: [  3.1492807  -14.04538707  89.10534269] 163.134048887\n",
      "positions (x,y,z), reward: [  3.57092628 -15.91087419  91.52512057] 163.455693289\n",
      "positions (x,y,z), reward: [  3.66099847 -16.30404659  91.99631852] 163.453676559\n",
      "positions (x,y,z), reward: [  5.52336885 -23.99470435  99.19287704] 163.826329298\n",
      "positions (x,y,z), reward: [  11.95398918  -45.82490956  107.79814814] 232.553960262\n",
      "positions (x,y,z), reward: [  15.20395443  -55.08092693  108.14533685] 196.760998959\n",
      "positions (x,y,z), reward: [  18.05945683  -62.46871725  107.20913822] 190.351303732\n",
      "Episode =   96, score = 282.369 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.07151094e-04   2.74313924e-04   2.07698135e+01] -0.389748244782\n",
      "positions (x,y,z), reward: [  0.03332392   0.09157726  30.12427452] 14.3197198754\n",
      "positions (x,y,z), reward: [  0.08504357   0.27567217  36.87307819] 67.0707333086\n",
      "positions (x,y,z), reward: [  0.18520068   0.7790798   48.01916617] 118.332365178\n",
      "positions (x,y,z), reward: [  0.92316926   2.66553778  72.06505308] 166.811799712\n",
      "positions (x,y,z), reward: [  1.59291535   3.79773827  81.74827556] 167.770312698\n",
      "positions (x,y,z), reward: [  1.68860314   3.94686555  82.8900476 ] 169.246105142\n",
      "positions (x,y,z), reward: [  2.79433719   5.5566717   93.75373758] 182.909891965\n",
      "positions (x,y,z), reward: [   3.94944532    7.11324167  102.35121856] 286.084961731\n",
      "positions (x,y,z), reward: [   5.59715383    9.22770417  112.092282  ] 267.623191898\n",
      "positions (x,y,z), reward: [   5.70568714    9.36422792  112.6638851 ] 266.507131596\n",
      "positions (x,y,z), reward: [   6.38390008   10.21183838  116.08681295] 259.74235131\n",
      "Episode =   97, score = 315.274 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.35770611e-02   2.68173795e-02   2.63521798e+01] 11.2210810966\n",
      "positions (x,y,z), reward: [  1.41304906e-02   3.09431958e-02   2.67415741e+01] 11.6300938546\n",
      "positions (x,y,z), reward: [ -0.04175539   0.26168944  36.36548593] 66.9818873896\n",
      "positions (x,y,z), reward: [ -6.1340891    5.21979273  79.67780194] 159.890779644\n",
      "positions (x,y,z), reward: [ -7.53790168   5.89738232  83.17954005] 162.412472033\n",
      "positions (x,y,z), reward: [-13.30476083   8.07323272  94.05878345] 169.741784556\n",
      "positions (x,y,z), reward: [-14.40091704   8.40248468  95.73428667] 170.593875387\n",
      "positions (x,y,z), reward: [ -59.27898886    9.50240719  132.4153245 ] 227.289796413\n",
      "Episode =   98, score = 301.433 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -4.12313290e-04   1.01472027e-03   2.11022277e+01] 1.03412552097\n",
      "positions (x,y,z), reward: [ -4.11086504e-04   1.75572497e-03   2.14914061e+01] 2.41462767618\n",
      "positions (x,y,z), reward: [  2.95123923e-02   4.04607006e-03   2.67394738e+01] 11.6336976638\n",
      "positions (x,y,z), reward: [  1.76309526  -0.87227627  51.41668428] 117.369799873\n",
      "positions (x,y,z), reward: [  1.99034005  -1.00496975  53.10269718] 167.185858239\n",
      "positions (x,y,z), reward: [  3.70255054  -2.05235881  63.42136582] 165.354493112\n",
      "positions (x,y,z), reward: [  4.53725676  -2.57961685  67.52271516] 164.358279409\n",
      "positions (x,y,z), reward: [  6.05098924  -3.53724543  74.08243232] 162.590271137\n",
      "positions (x,y,z), reward: [ 11.08757665  -6.59699703  91.72413736] 175.070451692\n",
      "positions (x,y,z), reward: [ 11.94978492  -7.09271578  94.40359966] 178.375331254\n",
      "positions (x,y,z), reward: [  14.27056144   -8.37298524  101.35506231] 283.09784946\n",
      "positions (x,y,z), reward: [  32.33646898  -15.33846681  155.04421864] 222.885930204\n",
      "Episode =   99, score = 295.505 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.37096315e-06   4.23729576e-06   2.01242340e+01] -4.89847320028\n",
      "positions (x,y,z), reward: [ -4.62093986e-02  -1.39833179e-03   3.38770785e+01] 16.3325617835\n",
      "positions (x,y,z), reward: [ -4.10260469e-01   2.63362593e-02   4.47700108e+01] 118.606320255\n",
      "positions (x,y,z), reward: [ -0.61645956   0.05638091  48.03991763] 118.757279287\n",
      "positions (x,y,z), reward: [ -0.88263311   0.0983677   51.35010218] 118.736987614\n",
      "positions (x,y,z), reward: [ -3.17456966   0.44817696  67.0694383 ] 166.5706818\n",
      "positions (x,y,z), reward: [ -3.54743377   0.49769595  68.7605995 ] 166.121028286\n",
      "positions (x,y,z), reward: [ -3.81192339   0.53146726  69.88695064] 165.796490722\n",
      "positions (x,y,z), reward: [ -5.86441652   0.75950576  77.16729367] 163.178068673\n",
      "positions (x,y,z), reward: [ -33.19864672    2.30166831  116.84838232] 243.223090725\n",
      "Episode =  100, score = 304.763 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.28354428e-02   9.96887827e-03   2.71377955e+01] 12.0370490848\n",
      "positions (x,y,z), reward: [ -1.25802957e-02   1.15315800e+00   5.91173117e+01] 168.777272552\n",
      "positions (x,y,z), reward: [ -3.57959711e-02   1.56159315e+00   6.47158688e+01] 168.431500843\n",
      "positions (x,y,z), reward: [ -2.77484992e-02   2.45966981e+00   7.53823915e+01] 167.617569049\n",
      "positions (x,y,z), reward: [  0.15158561   3.71962254  88.33174797] 178.808956266\n",
      "positions (x,y,z), reward: [   1.44458408    7.74160266  116.07772816] 267.355290765\n",
      "positions (x,y,z), reward: [   4.34657445   15.66118821  145.29830034] 253.426425825\n",
      "Episode =  101, score = 321.884 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.56776513  -0.38574293  53.53116996] 168.738746197\n",
      "positions (x,y,z), reward: [  0.67844091  -0.4674223   56.30689746] 168.670348628\n",
      "positions (x,y,z), reward: [  0.93228531  -0.648188    61.88744364] 168.38930616\n",
      "positions (x,y,z), reward: [  1.35165065  -0.9262081   69.73288169] 167.777610266\n",
      "positions (x,y,z), reward: [  2.29246124  -1.47933712  84.90270536] 173.704546416\n",
      "positions (x,y,z), reward: [  3.22998012  -1.98587046  99.54829415] 194.319709976\n",
      "positions (x,y,z), reward: [   4.303373     -2.51719731  121.71053665] 263.918892544\n",
      "positions (x,y,z), reward: [   4.32378115   -2.52190721  122.285685  ] 263.920831969\n",
      "positions (x,y,z), reward: [   4.45817922   -2.53596486  126.32828189] 263.991938884\n",
      "positions (x,y,z), reward: [   4.70292979   -2.42249146  135.71614999] 264.615231851\n",
      "Episode =  102, score = 325.951 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -6.59955140e-05  -4.90776263e-05   2.03790678e+01] -2.61347919327\n",
      "positions (x,y,z), reward: [ -1.12109145e-04  -1.06760495e-04   2.04942847e+01] -1.86530373668\n",
      "positions (x,y,z), reward: [ -2.13722295e-03  -4.88178481e-03   2.21757899e+01] 4.37587139721\n",
      "positions (x,y,z), reward: [  0.05836099  -0.63047349  47.46226115] 118.561343696\n",
      "positions (x,y,z), reward: [  0.08180503  -0.71097841  49.64990881] 118.638889155\n",
      "positions (x,y,z), reward: [  0.09433028  -0.75331667  50.74882203] 118.660693334\n",
      "positions (x,y,z), reward: [  0.14771935  -0.9407324   55.17106114] 168.658311871\n",
      "positions (x,y,z), reward: [  0.23408497  -1.34865579  62.42742394] 168.466017065\n",
      "positions (x,y,z), reward: [  0.30376292  -2.07337111  70.32781055] 167.978641694\n",
      "positions (x,y,z), reward: [  0.31920748  -2.98626178  76.58377944] 167.168802994\n",
      "positions (x,y,z), reward: [ -8.17536734e-02  -8.67688305e+00   9.62800260e+01] 185.024441104\n",
      "positions (x,y,z), reward: [  -3.76868881  -47.32346957  133.42979512] 228.564779002\n",
      "Episode =  103, score = 311.299 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -0.06261347  -0.21959955  36.36502378] 66.9903750929\n",
      "positions (x,y,z), reward: [  3.43522328e-02  -6.55743724e-01   6.13474205e+01] 169.43083431\n",
      "positions (x,y,z), reward: [  0.09569811  -0.67347897  64.16674725] 169.487749829\n",
      "positions (x,y,z), reward: [  0.1719626   -0.67750451  67.00048035] 169.559371698\n",
      "positions (x,y,z), reward: [  1.49945008e+00  -1.65101807e-02   8.87338508e+01] 184.361254462\n",
      "positions (x,y,z), reward: [   6.85558762    3.35414823  117.59652308] 272.412741359\n",
      "positions (x,y,z), reward: [  10.32253566    5.37036048  129.21215027] 266.906914647\n",
      "positions (x,y,z), reward: [  11.13757445    5.82713026  131.67521664] 266.52379796\n",
      "positions (x,y,z), reward: [  19.0026839     9.89432766  152.87396386] 215.114683306\n",
      "positions (x,y,z), reward: [  19.42196253   10.0932309   153.92147535] 215.183787808\n",
      "positions (x,y,z), reward: [  26.23638016   13.05336948  170.37906756] 125.187827839\n",
      "Episode =  104, score = 308.924 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -6.09862520e-09   8.58048230e-08   2.00311217e+01] -6.44423945386\n",
      "positions (x,y,z), reward: [ -1.73386143e-05   4.03616118e-05   2.02791716e+01] -3.36537215838\n",
      "positions (x,y,z), reward: [ -9.62206884e-04   7.83217305e-04   2.14925866e+01] 2.42256417563\n",
      "positions (x,y,z), reward: [ -1.58562717e-03   1.41454761e-03   2.35687130e+01] 7.35998931299\n",
      "positions (x,y,z), reward: [  9.38619976e-03  -4.60091182e-04   2.63526889e+01] 11.2513341303\n",
      "positions (x,y,z), reward: [  2.0627274   -2.25944278  67.10872011] 166.060435101\n",
      "positions (x,y,z), reward: [  3.51543208  -4.48257689  78.45963184] 162.288781763\n",
      "positions (x,y,z), reward: [  5.19389413  -7.25144016  88.00954227] 169.370106136\n",
      "positions (x,y,z), reward: [  6.81868271 -10.05957602  95.15083256] 174.882997683\n",
      "positions (x,y,z), reward: [  6.95778929 -10.30416121  95.69097112] 175.23044884\n",
      "positions (x,y,z), reward: [  24.36984728  -41.81531874  127.93758232] 215.327850495\n",
      "positions (x,y,z), reward: [  27.55111401  -47.85363632  130.63556304] 213.214315725\n",
      "Episode =  105, score = 296.949 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  3.27497122e-03  -1.04642641e-02   2.42053886e+01] 8.43120133077\n",
      "positions (x,y,z), reward: [  1.76070853e-02  -7.04969340e-02   3.48698420e+01] 16.6951215814\n",
      "positions (x,y,z), reward: [  1.0021697    0.17094715  73.82100247] 169.223176714\n",
      "positions (x,y,z), reward: [   5.1547457     5.68561072  129.02709458] 260.556698751\n",
      "positions (x,y,z), reward: [   4.94674149    7.66361766  138.44273702] 258.768932372\n",
      "positions (x,y,z), reward: [   4.83176154    8.07239547  140.20409996] 258.423835838\n",
      "positions (x,y,z), reward: [   3.9693781    10.12775105  148.36150401] 206.783836097\n",
      "Episode =  106, score = 324.934 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.30186966e-06  -1.72497529e-06   2.01243395e+01] -4.89634800314\n",
      "positions (x,y,z), reward: [  4.11962527e-05  -3.55338113e-05   2.03794711e+01] -2.60740262662\n",
      "positions (x,y,z), reward: [ -0.03846961  -0.12130586  33.3935445 ] 16.0198375559\n",
      "positions (x,y,z), reward: [ -0.05201766  -0.1557811   34.86235366] 16.558692098\n",
      "positions (x,y,z), reward: [ -0.05711102  -0.16843266  35.35947167] 16.7180815877\n",
      "positions (x,y,z), reward: [ -0.20701985  -0.51010207  44.76162271] 118.265851554\n",
      "positions (x,y,z), reward: [ -0.24420996  -0.59240013  46.38679739] 118.341390812\n",
      "positions (x,y,z), reward: [ -0.63442395  -1.49015137  58.00862287] 167.90724837\n",
      "positions (x,y,z), reward: [ -1.92644941  -4.62192878  75.51368106] 163.615800201\n",
      "positions (x,y,z), reward: [ -1.9897932   -4.7747257   76.07688084] 163.374214421\n",
      "positions (x,y,z), reward: [  -7.25110046  -16.42994024  100.47461875] 271.360308691\n",
      "positions (x,y,z), reward: [  -9.37810824  -20.57911166  105.48301117] 256.092679574\n",
      "positions (x,y,z), reward: [ -11.65158201  -24.74815179  109.61168942] 245.459277877\n",
      "positions (x,y,z), reward: [ -20.78264194  -39.42447289  119.40821741] 214.872726133\n",
      "positions (x,y,z), reward: [ -23.65150864  -43.4556716   121.17192652] 212.053442313\n",
      "Episode =  107, score = 293.473 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.41497255e-04   5.73791916e-04   2.09292858e+01] 0.332779496281\n",
      "positions (x,y,z), reward: [ -2.61501909e-04   2.91699066e-03   2.19364710e+01] 3.75410371061\n",
      "positions (x,y,z), reward: [  0.05219794   0.13180363  31.50187124] 15.0808700759\n",
      "positions (x,y,z), reward: [  0.06632671   0.15492803  32.44234733] 15.5276269813\n",
      "positions (x,y,z), reward: [  0.95186042   1.18260512  54.10675055] 167.612820406\n",
      "positions (x,y,z), reward: [  1.29763915   1.54471719  59.11921409] 167.08712536\n",
      "positions (x,y,z), reward: [  2.88181228   3.05527035  75.4325594 ] 164.370003849\n",
      "positions (x,y,z), reward: [   8.0402696     7.22067064  104.06377356] 279.580318802\n",
      "positions (x,y,z), reward: [  11.18751817    9.65833749  115.63383093] 256.55693249\n",
      "positions (x,y,z), reward: [  22.41488854   18.37890166  144.29769043] 232.18852348\n",
      "Episode =  108, score = 309.866 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  3.55944499e-02  -1.80679198e-02   2.55977740e+01] 10.3324647062\n",
      "positions (x,y,z), reward: [  0.12669798  -0.07173996  30.57323813] 14.5234681739\n",
      "positions (x,y,z), reward: [  0.13725701  -0.07871678  31.03040039] 14.7771638114\n",
      "positions (x,y,z), reward: [  0.5837585   -0.47370055  44.75143785] 117.892969739\n",
      "positions (x,y,z), reward: [  0.60603016  -0.4970154   45.29110457] 117.912426289\n",
      "positions (x,y,z), reward: [  0.84986179  -0.76744538  50.74782921] 117.889924156\n",
      "positions (x,y,z), reward: [  1.21667036  -1.22012925  57.94683129] 167.387236106\n",
      "positions (x,y,z), reward: [  3.34971916  -4.28547926  88.11754112] 174.446316908\n",
      "positions (x,y,z), reward: [   6.12505312   -9.6472504   112.5377912 ] 264.797668589\n",
      "positions (x,y,z), reward: [   9.09155418  -16.60613214  128.47036556] 241.69560001\n",
      "positions (x,y,z), reward: [   9.3270769   -17.18864286  129.48226016] 240.673860731\n",
      "positions (x,y,z), reward: [  11.64314292  -23.12824072  138.17084779] 233.300982059\n",
      "Episode =  109, score = 311.374 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.43871160e-03   1.12647514e-03   2.42036028e+01] 8.4325013992\n",
      "positions (x,y,z), reward: [ -1.38448935e-02  -5.13999338e-02   3.14955578e+01] 15.201522009\n",
      "positions (x,y,z), reward: [ -0.10300663  -0.37892844  42.09059223] 68.1336254669\n",
      "positions (x,y,z), reward: [ -0.41362945  -1.16323321  54.10893579] 168.221130444\n",
      "positions (x,y,z), reward: [ -5.22445532  -6.02507409  87.28240886] 169.358759865\n",
      "positions (x,y,z), reward: [ -19.53691118  -12.65014756  113.33421162] 242.049959094\n",
      "positions (x,y,z), reward: [ -32.25119862  -16.42680856  123.76866805] 221.505399285\n",
      "positions (x,y,z), reward: [ -44.44802651  -19.5016085   129.13477945] 211.901300249\n",
      "positions (x,y,z), reward: [ -46.32097884  -19.96284421  129.66967484] 210.426888366\n",
      "Episode =  110, score = 298.316 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.70378877e-02  -8.08796961e-03   2.48862365e+01] 9.42272479192\n",
      "positions (x,y,z), reward: [  0.47787287  -0.14066639  37.90292644] 67.0975080721\n",
      "positions (x,y,z), reward: [  1.17712982  -0.27339325  47.49553349] 117.889093988\n",
      "positions (x,y,z), reward: [  2.38492314  -0.43938846  58.60119423] 167.249705108\n",
      "positions (x,y,z), reward: [  2.68361678  -0.47582275  60.85091577] 167.00312543\n",
      "positions (x,y,z), reward: [  3.70482418  -0.58947448  67.64096352] 166.120612505\n",
      "positions (x,y,z), reward: [  6.00037091  -0.78821347  79.67487536] 164.116961564\n",
      "positions (x,y,z), reward: [  7.79472229  -0.91431798  87.24627138] 173.515851703\n",
      "positions (x,y,z), reward: [  9.75106072  -1.06663452  94.36773969] 182.760708799\n",
      "positions (x,y,z), reward: [  14.4265599    -1.73263157  108.11972132] 276.478509021\n",
      "positions (x,y,z), reward: [  23.97042919   -4.64587237  127.6540196 ] 258.076313603\n",
      "Episode =  111, score = 306.391 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.07985873e-04   2.05576423e-04   2.04947682e+01] -1.85965324473\n",
      "positions (x,y,z), reward: [ -1.79650781e-04   3.69331978e-04   2.06249923e+01] -1.11907515346\n",
      "positions (x,y,z), reward: [ -7.93445497e-04   2.11419381e-03   2.12909689e+01] 1.73576799725\n",
      "positions (x,y,z), reward: [ -0.06837509   0.29850251  35.35756373] 16.5736365791\n",
      "positions (x,y,z), reward: [ -0.56509525   1.5877342   57.43024441] 167.809258412\n",
      "positions (x,y,z), reward: [ -1.53727017   3.75217623  76.10108655] 165.276830826\n",
      "positions (x,y,z), reward: [ -2.21937571   5.28563306  85.27926928] 171.202740463\n",
      "positions (x,y,z), reward: [ -2.36661753   5.61277824  87.00785923] 173.357782631\n",
      "positions (x,y,z), reward: [  -4.89713725   10.65006593  107.99808167] 274.11589378\n",
      "positions (x,y,z), reward: [  -6.27142224   12.85060817  115.17922691] 260.27717828\n",
      "positions (x,y,z), reward: [  -8.6518693    15.96229267  124.34032374] 248.290805297\n",
      "positions (x,y,z), reward: [ -15.4719123    22.21413813  141.54144937] 239.533511765\n",
      "Episode =  112, score = 309.872 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -0.29583511   0.2952816   36.3619104 ] 66.6734320935\n",
      "positions (x,y,z), reward: [ -1.19414214   1.21730968  50.79936409] 117.344716976\n",
      "positions (x,y,z), reward: [ -2.11437108   1.96798441  58.11066331] 166.350458219\n",
      "positions (x,y,z), reward: [ -2.39823055   2.17523044  59.82203518] 166.002508258\n",
      "positions (x,y,z), reward: [ -5.02619341   3.80627676  70.85776393] 162.644945834\n",
      "positions (x,y,z), reward: [ -8.84984916   5.69033481  81.04445282] 159.509437365\n",
      "positions (x,y,z), reward: [ -9.40073504   5.93210897  82.26773388] 160.711304892\n",
      "positions (x,y,z), reward: [-15.76607847   8.35954127  94.34262223] 172.659097233\n",
      "positions (x,y,z), reward: [-17.7970617    9.02805591  97.73217131] 176.268955786\n",
      "positions (x,y,z), reward: [ -32.53190575   13.60803941  121.51690662] 258.878741842\n",
      "positions (x,y,z), reward: [ -37.25559677   15.55330362  130.24849083] 265.416340103\n",
      "positions (x,y,z), reward: [ -40.83228943   17.52854568  137.8023863 ] 271.615056123\n",
      "positions (x,y,z), reward: [ -49.23585905   26.59710469  162.22373849] 201.306072438\n",
      "positions (x,y,z), reward: [ -54.21496085   45.05348561  192.11969559] 192.274667643\n",
      "positions (x,y,z), reward: [ -55.13497834   57.58993426  206.65290242] 239.438316335\n",
      "Episode =  113, score = 315.233 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.86414175e-04   3.41088021e-05   2.04947504e+01] -1.85880544543\n",
      "positions (x,y,z), reward: [  1.80079128e-03  -1.69707574e-05   2.14926516e+01] 2.42268236291\n",
      "positions (x,y,z), reward: [  0.04968561  -0.06517688  29.24111006] 13.7295950518\n",
      "positions (x,y,z), reward: [  0.1182865   -0.19413204  35.3641299 ] 16.6291689182\n",
      "positions (x,y,z), reward: [  0.2463782   -0.50279339  49.12462831] 118.731394833\n",
      "positions (x,y,z), reward: [  0.25068544  -0.5413201   52.44348031] 169.021825051\n",
      "positions (x,y,z), reward: [  0.24960403  -0.54542001  53.00050652] 169.07448711\n",
      "positions (x,y,z), reward: [  2.42385657e-02  -4.05702569e-01   6.55624985e+01] 170.859338667\n",
      "positions (x,y,z), reward: [ -2.01352935   1.69233029  92.75563878] 192.446852103\n",
      "positions (x,y,z), reward: [  -4.01147262    4.70690931  113.92536158] 287.15998903\n",
      "positions (x,y,z), reward: [  -5.33492668    7.71095557  133.59118927] 290.036767729\n",
      "positions (x,y,z), reward: [  -5.98640225   10.55038466  154.18601096] 265.821335804\n",
      "Episode =  114, score = 351.305 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -7.11861097e-04   4.54755521e-04   2.12903034e+01] 1.73210893195\n",
      "positions (x,y,z), reward: [ -4.43123751e-03  -2.36726564e-04   2.26966825e+01] 5.61483646245\n",
      "positions (x,y,z), reward: [ -3.20455216e-02  -1.94638377e-02   2.59678078e+01] 10.7645902582\n",
      "positions (x,y,z), reward: [ -1.37909883  -1.07718688  52.94694143] 167.201276395\n",
      "positions (x,y,z), reward: [ -1.66837284  -1.25490627  55.72050977] 166.873830593\n",
      "positions (x,y,z), reward: [ -2.30530042  -1.5872607   60.74292152] 166.088882777\n",
      "positions (x,y,z), reward: [ -17.91350906   -3.9654839   105.87744699] 268.690287144\n",
      "positions (x,y,z), reward: [ -33.98663775   -5.1223455   129.34625219] 246.078893943\n",
      "positions (x,y,z), reward: [ -35.36354621   -5.24322879  131.10905462] 246.301997656\n",
      "positions (x,y,z), reward: [ -37.2499877    -5.41859761  133.49408389] 246.654865505\n",
      "positions (x,y,z), reward: [ -37.73069859   -5.46520967  134.09720553] 246.753524314\n",
      "positions (x,y,z), reward: [ -38.70311522   -5.56201256  135.3124556 ] 246.96442987\n",
      "positions (x,y,z), reward: [ -41.19849708   -5.82679286  138.40871093] 247.576327567\n",
      "Episode =  115, score = 309.125 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -5.18761806e-06  -1.94966508e-06   2.01242540e+01] -4.89775146907\n",
      "positions (x,y,z), reward: [ -9.29468758e-04  -4.96233927e-04   2.12902110e+01] 1.73277368824\n",
      "positions (x,y,z), reward: [ -2.48971070e-02  -3.02945790e-02   2.79577049e+01] 12.7725863549\n",
      "positions (x,y,z), reward: [ -0.59770319  -0.84604993  55.19700555] 168.349881387\n",
      "positions (x,y,z), reward: [ -0.68642088  -0.97842598  57.42454359] 168.222999643\n",
      "positions (x,y,z), reward: [ -0.806211    -1.16648498  60.21846953] 168.01050083\n",
      "positions (x,y,z), reward: [ -3.53496241  -6.91534309  95.04145768] 181.855035166\n",
      "positions (x,y,z), reward: [ -3.94657668  -7.76046932  97.80882822] 184.59030871\n",
      "positions (x,y,z), reward: [ -11.45963416  -19.04876049  122.3555499 ] 235.235307969\n",
      "positions (x,y,z), reward: [ -23.72476273  -30.02234265  136.25011594] 218.429594673\n",
      "Episode =  116, score = 306.166 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.02500316e-05  -1.10211718e-05   2.01939947e+01] -4.12972581532\n",
      "positions (x,y,z), reward: [  6.98945138e-05  -1.23932324e-04   2.04945345e+01] -1.86174439803\n",
      "positions (x,y,z), reward: [  8.63213738e-03  -6.54998260e-03   2.48835239e+01] 9.43942944257\n",
      "positions (x,y,z), reward: [  0.26932936  -0.1334058   37.90584446] 67.3399899447\n",
      "positions (x,y,z), reward: [  0.94895479  -0.51370149  49.18712856] 118.258460992\n",
      "positions (x,y,z), reward: [  1.87439424  -0.94716883  58.21561174] 167.847045241\n",
      "positions (x,y,z), reward: [  2.56912274  -1.22050984  63.42138825] 167.374740679\n",
      "positions (x,y,z), reward: [  3.70423498  -1.59930372  70.504946  ] 166.565615571\n",
      "positions (x,y,z), reward: [ 10.13761161  -3.10776999  98.46043259] 190.964942832\n",
      "positions (x,y,z), reward: [  23.80789168   -6.06251419  144.19166487] 281.216276336\n",
      "positions (x,y,z), reward: [  27.56564001   -6.57704663  159.17143643] 202.154722583\n",
      "Episode =  117, score = 345.447 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -8.13605265e-08   3.97283843e-08   2.00311172e+01] -6.4444649799\n",
      "positions (x,y,z), reward: [  5.44814181e-03   1.13445150e-03   2.24330261e+01] 5.02227418519\n",
      "positions (x,y,z), reward: [  9.29361777e-02  -1.35445358e-03   2.92453279e+01] 13.7605572602\n",
      "positions (x,y,z), reward: [  1.87541429   0.11211688  55.35597433] 168.433752274\n",
      "positions (x,y,z), reward: [  4.4548409   0.7006061  71.1756376] 166.970149706\n",
      "positions (x,y,z), reward: [  13.49177377    3.91645001  104.08311668] 279.828210046\n",
      "positions (x,y,z), reward: [  21.7283487     6.87656486  125.27170107] 246.134474132\n",
      "positions (x,y,z), reward: [  22.83206378    7.23133879  127.752589  ] 245.778262281\n",
      "positions (x,y,z), reward: [  23.39553055    7.40782503  128.99310449] 245.605462113\n",
      "positions (x,y,z), reward: [  23.96681508    7.58347872  130.23383959] 245.437093982\n",
      "positions (x,y,z), reward: [  28.19403737    8.7776762   138.94553527] 244.498846705\n",
      "positions (x,y,z), reward: [  31.82173811    9.6568315   145.88905537] 244.260293535\n",
      "positions (x,y,z), reward: [  37.24242363   10.73798115  155.68737348] 194.816461299\n",
      "positions (x,y,z), reward: [  38.00565413   10.86835098  157.03551998] 144.982741643\n",
      "Episode =  118, score = 310.188 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.69877637e-02   1.76837317e-02   2.38800532e+01] 7.8741675217\n",
      "positions (x,y,z), reward: [  0.10678436   0.12866024  29.23663726] 13.5924143206\n",
      "positions (x,y,z), reward: [  0.66197377   1.01920157  43.16091624] 67.1886137424\n",
      "positions (x,y,z), reward: [  0.98109655   1.63001737  48.62194768] 117.080329122\n",
      "positions (x,y,z), reward: [  2.62163851   5.22869309  68.81147053] 164.092183198\n",
      "positions (x,y,z), reward: [  3.52629817   7.34981742  77.34016576] 162.150763524\n",
      "positions (x,y,z), reward: [  5.56631058  12.19693088  93.56492866] 178.704362384\n",
      "positions (x,y,z), reward: [  6.1469216   13.5457366   97.71587753] 183.952880506\n",
      "positions (x,y,z), reward: [   7.63553276   16.85205689  107.88302015] 273.322230672\n",
      "positions (x,y,z), reward: [   8.32901378   18.29092695  112.4748884 ] 265.581844298\n",
      "positions (x,y,z), reward: [   8.80950897   19.24165076  115.62533564] 260.365786884\n",
      "positions (x,y,z), reward: [  10.20613796   21.76698279  124.72042635] 254.753870884\n",
      "positions (x,y,z), reward: [  14.97933673   26.9235911   158.91170173] 167.302311326\n",
      "Episode =  119, score = 290.331 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.7226568    1.34458272  54.64971214] 166.693451761\n",
      "positions (x,y,z), reward: [  2.49251198   2.15554813  63.03305419] 165.450900266\n",
      "positions (x,y,z), reward: [  3.83231032   3.88788763  76.04018688] 162.698610321\n",
      "positions (x,y,z), reward: [  4.79145593   5.38206392  84.59269708] 167.312201934\n",
      "positions (x,y,z), reward: [  5.0552485    5.83460751  86.88252281] 170.07920556\n",
      "positions (x,y,z), reward: [  5.45547315   6.55832067  90.32399925] 174.179864988\n",
      "positions (x,y,z), reward: [  5.92789814   7.47197586  94.34708253] 178.879796807\n",
      "positions (x,y,z), reward: [  6.06372451   7.74690242  95.49769169] 180.204883408\n",
      "positions (x,y,z), reward: [   7.86367703   11.89767444  110.46603487] 265.294409874\n",
      "positions (x,y,z), reward: [  12.79008874   24.8667208   142.70996049] 236.903156559\n",
      "positions (x,y,z), reward: [  13.57652893   26.86172205  146.5831107 ] 236.056270199\n",
      "Episode =  120, score = 309.371 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.09747383  -0.04317145  36.87797976] 67.3046649187\n",
      "positions (x,y,z), reward: [  0.23621305  -0.11600186  42.62767314] 68.3519095791\n",
      "positions (x,y,z), reward: [  0.50133635  -0.30052695  50.23644301] 118.735759387\n",
      "positions (x,y,z), reward: [  0.66291465  -0.44527402  54.10923544] 168.662901574\n",
      "positions (x,y,z), reward: [  0.83733698  -0.63127761  58.00913973] 168.460750321\n",
      "positions (x,y,z), reward: [  1.56990165  -1.86222184  74.30066728] 166.738569393\n",
      "positions (x,y,z), reward: [  1.86268589  -2.82013668  83.32109722] 170.507938911\n",
      "positions (x,y,z), reward: [  -8.81021769  -20.01314643  146.47452839] 236.801044222\n",
      "Episode =  121, score = 320.264 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -7.79705345e-03   6.72181589e-03   2.32651973e+01] 6.77868247066\n",
      "positions (x,y,z), reward: [ -0.96425532   0.16549325  43.67920747] 67.7320632829\n",
      "positions (x,y,z), reward: [ -6.32845263   0.63086062  69.64052614] 162.555676783\n",
      "positions (x,y,z), reward: [ -6.51242495   0.64526957  70.19048443] 162.321995953\n",
      "positions (x,y,z), reward: [-15.72520088   1.38232977  90.85281492] 166.481293455\n",
      "positions (x,y,z), reward: [-16.2910319    1.42854825  91.86258919] 167.251628152\n",
      "positions (x,y,z), reward: [ -40.20529842    2.95530331  122.98387209] 239.660086484\n",
      "positions (x,y,z), reward: [ -41.90001532    3.02258911  124.62327184] 239.34603934\n",
      "positions (x,y,z), reward: [ -45.39944595    3.1422141   127.84240849] 238.723918245\n",
      "positions (x,y,z), reward: [ -49.99324411    3.26425959  131.75022699] 237.938630828\n",
      "positions (x,y,z), reward: [ -50.94306248    3.2853294   132.51552469] 237.776285432\n",
      "Episode =  122, score = 302.462 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  3.59620804e-02  -2.19144993e-02   2.71407069e+01] 12.0294118869\n",
      "positions (x,y,z), reward: [  0.0569655   -0.03045545  28.80685956] 13.4410682178\n",
      "positions (x,y,z), reward: [  1.32902479   0.85755564  63.18874006] 168.304484974\n",
      "positions (x,y,z), reward: [  4.21657867   4.73613667  95.41863941] 184.987403019\n",
      "positions (x,y,z), reward: [   5.10467976    5.90949781  101.74698491] 287.068059468\n",
      "positions (x,y,z), reward: [   5.64416162    6.61087692  105.1856771 ] 280.568466144\n",
      "positions (x,y,z), reward: [   6.22264009    7.35529861  108.60960214] 273.962126825\n",
      "positions (x,y,z), reward: [   6.83895304    8.14149919  112.01251919] 267.251310825\n",
      "positions (x,y,z), reward: [   8.53764226   10.27887727  120.39066844] 250.7598531\n",
      "positions (x,y,z), reward: [   9.66573269   11.67085481  125.31741762] 247.828719444\n",
      "positions (x,y,z), reward: [  13.12360661   15.6818383   138.15203714] 239.590907853\n",
      "Episode =  123, score = 316.041 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -0.11665428  -0.06541118  27.95157679] 12.6233113081\n",
      "positions (x,y,z), reward: [ -0.55418193  -0.31870072  40.4742971 ] 67.3823657042\n",
      "positions (x,y,z), reward: [ -4.04587135  -2.68601328  84.25263854] 169.730152152\n",
      "positions (x,y,z), reward: [ -4.86452589  -3.39666914  89.86367624] 176.548971971\n",
      "positions (x,y,z), reward: [  -9.55618391   -8.40679425  113.05105118] 261.418938119\n",
      "positions (x,y,z), reward: [ -14.19256859  -14.50383053  128.7370408 ] 238.468827213\n",
      "positions (x,y,z), reward: [ -15.79903861  -16.75223805  133.20485955] 233.912854557\n",
      "positions (x,y,z), reward: [ -18.90934695  -21.21563313  140.81266056] 226.123564799\n",
      "Episode =  124, score = 309.427 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -7.02900732e-08   1.51923517e-09   2.00311261e+01] -6.44401742085\n",
      "positions (x,y,z), reward: [  3.50797942e-06   6.83725074e-07   2.01243531e+01] -4.89613816605\n",
      "positions (x,y,z), reward: [  1.99972152e-04   4.75197587e-05   2.07698221e+01] -0.38954114632\n",
      "positions (x,y,z), reward: [ -0.29426767   0.19700661  49.67198472] 118.999275519\n",
      "positions (x,y,z), reward: [ -0.83735483   0.40436817  61.35570321] 168.796458682\n",
      "positions (x,y,z), reward: [ -4.26848304   2.27790232  96.36325523] 188.465030634\n",
      "positions (x,y,z), reward: [  -6.18396982    4.09619971  111.30921293] 273.87597045\n",
      "positions (x,y,z), reward: [  -9.4872673     9.85933864  139.02815966] 253.69101643\n",
      "positions (x,y,z), reward: [ -10.23106909   11.73664945  145.89173549] 251.385205579\n",
      "Episode =  125, score = 319.448 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -9.12216173e-02  -6.53931973e-03   2.92354074e+01] 13.7354117248\n",
      "positions (x,y,z), reward: [ -6.90444121e-01   2.87532814e-02   4.52922206e+01] 118.294360107\n",
      "positions (x,y,z), reward: [ -8.13912846e-01   4.15024772e-02   4.74629838e+01] 118.389100572\n",
      "positions (x,y,z), reward: [ -2.15029375   0.25010032  63.00196368] 167.688346276\n",
      "positions (x,y,z), reward: [ -2.43600873   0.30457366  65.2520356 ] 167.409870039\n",
      "positions (x,y,z), reward: [ -5.48996597   0.96000933  81.09741139] 165.548466192\n",
      "positions (x,y,z), reward: [ -6.11015902   1.09986503  83.36542818] 168.170618759\n",
      "positions (x,y,z), reward: [ -7.51026805   1.41605548  87.89340715] 173.155931626\n",
      "positions (x,y,z), reward: [-12.03469475   2.39687086  99.09242374] 183.83920795\n",
      "positions (x,y,z), reward: [-12.30185041   2.45164786  99.64468502] 184.296502948\n",
      "positions (x,y,z), reward: [ -13.98901529    2.78805758  102.93560917] 278.061645487\n",
      "positions (x,y,z), reward: [ -16.14005275    3.192247    106.71612344] 269.331468818\n",
      "positions (x,y,z), reward: [ -34.72704925    5.69740794  129.07340205] 237.694013548\n",
      "positions (x,y,z), reward: [ -38.10695554    6.01168374  131.999866  ] 236.40111748\n",
      "positions (x,y,z), reward: [ -44.64765357    6.54636855  137.07040838] 234.045052215\n",
      "positions (x,y,z), reward: [ -47.76447675    6.77627969  139.25146789] 232.980859253\n",
      "Episode =  126, score = 309.491 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.27536641e-06  -3.51572528e-06   2.01938892e+01] -4.1311621357\n",
      "positions (x,y,z), reward: [  4.91734035e-04  -1.58692445e-03   2.26973441e+01] 5.62679325114\n",
      "positions (x,y,z), reward: [  1.33235968e-03  -3.69135409e-03   2.35678710e+01] 7.36089420957\n",
      "positions (x,y,z), reward: [  0.08292887  -0.4240843   41.02503429] 67.8940654558\n",
      "positions (x,y,z), reward: [ -0.15591379  -1.58872492  60.21343242] 168.233331674\n",
      "positions (x,y,z), reward: [ -0.21604127  -1.71960534  61.89358553] 168.088274963\n",
      "positions (x,y,z), reward: [ -1.24411161  -3.15668692  77.64958761] 165.764367505\n",
      "positions (x,y,z), reward: [ -3.24166336  -4.99673779  93.91422884] 182.515259378\n",
      "positions (x,y,z), reward: [  -6.4590112    -7.55455408  112.744031  ] 266.421999156\n",
      "positions (x,y,z), reward: [  -8.94593423   -9.56112678  125.41827986] 251.068320253\n",
      "positions (x,y,z), reward: [ -11.0141981   -11.30658409  135.36236832] 247.362445586\n",
      "positions (x,y,z), reward: [ -11.96515393  -12.13223416  139.79693474] 245.649753755\n",
      "positions (x,y,z), reward: [ -13.05882225  -13.09419884  144.79810765] 243.669685647\n",
      "Episode =  127, score = 317.212 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.30749427e-02  -8.68106838e-03   2.45372687e+01] 8.93272888686\n",
      "positions (x,y,z), reward: [ -3.07953600e-02  -2.43078778e-02   2.71390092e+01] 12.0257477211\n",
      "positions (x,y,z), reward: [ -0.1636553   -0.26765669  39.45149295] 67.6531274675\n",
      "positions (x,y,z), reward: [ -0.23118966  -0.43566368  43.69054353] 68.1820011559\n",
      "positions (x,y,z), reward: [ -0.29654141  -0.60212638  46.93823193] 118.355261546\n",
      "positions (x,y,z), reward: [ -0.39496599  -0.84796402  50.78019984] 118.363057261\n",
      "positions (x,y,z), reward: [ -1.37605144  -2.99035419  68.73642406] 165.930426963\n",
      "positions (x,y,z), reward: [ -4.04090346  -7.84288642  87.22320697] 168.352492442\n",
      "positions (x,y,z), reward: [ -10.00644076  -16.38054304  106.55810034] 260.395042004\n",
      "positions (x,y,z), reward: [ -13.54984179  -20.44278283  113.730794  ] 241.003760756\n",
      "positions (x,y,z), reward: [ -23.94615986  -29.7939245   127.27198991] 220.85104735\n",
      "positions (x,y,z), reward: [ -28.01010201  -32.87021069  130.87896246] 219.188137394\n",
      "positions (x,y,z), reward: [ -33.84064159  -37.01606493  135.05206591] 216.865360789\n",
      "Episode =  128, score = 298.782 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.06045119e-03   9.51080645e-04   2.14926873e+01] 2.42512886943\n",
      "positions (x,y,z), reward: [ -1.16749549e-03   1.44841448e-02   2.59747093e+01] 10.8302817026\n",
      "positions (x,y,z), reward: [ -2.35136008e-03   1.62953555e-02   2.63559268e+01] 11.2566580252\n",
      "positions (x,y,z), reward: [ -0.05713903   0.08103873  33.88652339] 16.2577842388\n",
      "positions (x,y,z), reward: [ -0.1992506    0.22462436  43.15767745] 68.3336057837\n",
      "positions (x,y,z), reward: [ -0.29618155   0.31098635  47.48337698] 118.667907394\n",
      "positions (x,y,z), reward: [ -0.39950329   0.39809899  51.32377311] 118.771913051\n",
      "positions (x,y,z), reward: [ -0.6142966    0.5739865   57.98008715] 168.674929368\n",
      "positions (x,y,z), reward: [ -0.63417989   0.5903155   58.53751136] 168.654369618\n",
      "positions (x,y,z), reward: [ -0.65435728   0.60692382  59.09524003] 168.632357032\n",
      "positions (x,y,z), reward: [ -0.87289823   0.78930846  64.68632381] 168.344491318\n",
      "positions (x,y,z), reward: [ -1.27349945   1.12190219  73.10423047] 167.705078619\n",
      "positions (x,y,z), reward: [ -1.46883807   1.27422126  76.47803616] 167.382560673\n",
      "positions (x,y,z), reward: [ -2.47013301   1.90351006  88.87311733] 179.152730542\n",
      "positions (x,y,z), reward: [ -3.733414     2.40255973  98.48130824] 191.868408492\n",
      "positions (x,y,z), reward: [ -3.82579679   2.43040234  99.04700551] 192.596359738\n",
      "positions (x,y,z), reward: [  -4.75999369    2.66831707  104.13564667] 286.610710266\n",
      "positions (x,y,z), reward: [  -9.23738716    3.16228482  120.93012596] 257.235223787\n",
      "positions (x,y,z), reward: [ -10.18392294    3.16879958  123.68663728] 256.133914455\n",
      "positions (x,y,z), reward: [ -11.60575698    3.12317604  127.51953299] 254.527259598\n",
      "Episode =  129, score = 320.929 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.19700392e-02   7.35645306e-03   2.35700270e+01] 7.34344041442\n",
      "positions (x,y,z), reward: [ -4.46185609e-02   1.10637859e-02   2.48849617e+01] 9.39920034061\n",
      "positions (x,y,z), reward: [ -6.98519610e-02   1.38707069e-02   2.59745875e+01] 10.7563986356\n",
      "positions (x,y,z), reward: [ -4.27262957e+00  -1.69575552e-02   5.85000197e+01] 165.405638446\n",
      "positions (x,y,z), reward: [ -1.06943571e+01  -2.10361228e-02   7.42470258e+01] 157.439789189\n",
      "positions (x,y,z), reward: [-32.01168183   0.10663756  98.43560231] 168.445300888\n",
      "positions (x,y,z), reward: [ -3.97027687e+01   5.13189259e-02   1.03732574e+02] 262.751121919\n",
      "positions (x,y,z), reward: [ -4.23692345e+01   2.14482138e-02   1.05330628e+02] 259.542124116\n",
      "positions (x,y,z), reward: [ -4.29077097e+01   1.49310793e-02   1.05640138e+02] 258.916087338\n",
      "Episode =  130, score = 294.067 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -0.06201203   0.05742812  26.35347236] 11.1447935183\n",
      "positions (x,y,z), reward: [ -0.4816487    0.53808974  38.92470278] 66.9332540689\n",
      "positions (x,y,z), reward: [ -2.29692234   3.29411327  65.82135604] 164.490795111\n",
      "positions (x,y,z), reward: [ -12.40848994   10.92909369  101.25244892] 272.158017776\n",
      "positions (x,y,z), reward: [ -18.38138047   12.99539797  108.35341912] 249.696660629\n",
      "positions (x,y,z), reward: [ -24.43593661   14.38438817  113.05438753] 235.418975821\n",
      "positions (x,y,z), reward: [ -37.83376422   15.98163001  118.70437273] 215.968530042\n",
      "positions (x,y,z), reward: [ -48.04162369   16.28665017  120.04115926] 206.459353024\n",
      "Episode =  131, score = 288.703 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.03335669   0.03487227  27.95666093] 12.7588733342\n",
      "positions (x,y,z), reward: [  0.24948316   0.22958708  42.08587813] 68.1023862096\n",
      "positions (x,y,z), reward: [  0.69880565   0.52288486  59.08124467] 168.671293524\n",
      "positions (x,y,z), reward: [  0.91721915   0.61248069  66.35868416] 168.548198443\n",
      "positions (x,y,z), reward: [  1.07753665   0.64692391  72.55160431] 168.492559001\n",
      "positions (x,y,z), reward: [  1.20467571   0.59336614  82.74712533] 172.744304349\n",
      "positions (x,y,z), reward: [  1.20421655   0.58560913  83.31573657] 173.617648716\n",
      "positions (x,y,z), reward: [  1.15070451   0.4873385   88.44485322] 181.581222415\n",
      "positions (x,y,z), reward: [  5.75254023e-01   5.91228576e-03   1.00487358e+02] 299.435791013\n",
      "positions (x,y,z), reward: [  4.80450815e-01  -6.07276539e-02   1.01637409e+02] 297.754525553\n",
      "positions (x,y,z), reward: [  2.23353344e-02  -3.64097842e-01   1.06237209e+02] 290.990417057\n",
      "positions (x,y,z), reward: [  -0.91597139   -0.92566955  113.1188874 ] 279.068470181\n",
      "Episode =  132, score = 327.385 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777847] -7.22215339473\n",
      "positions (x,y,z), reward: [  4.47361687e-07  -2.72555671e-06   2.01242814e+01] -4.89785991167\n",
      "positions (x,y,z), reward: [  2.17877347e-03   6.70137530e-04   2.21773109e+01] 4.38822600356\n",
      "positions (x,y,z), reward: [  6.01771915e-02   2.41396988e-02   2.79561857e+01] 12.7295474424\n",
      "positions (x,y,z), reward: [  0.12853906   0.05951379  31.03028318] 14.8009305177\n",
      "positions (x,y,z), reward: [  0.61780662   0.4000987   42.0878674 ] 67.6491570749\n",
      "positions (x,y,z), reward: [  1.11227      0.78445889  48.61691569] 117.771386501\n",
      "positions (x,y,z), reward: [  1.49438374   1.08474629  52.52506792] 167.558481688\n",
      "positions (x,y,z), reward: [  3.37183135   2.55064266  65.83427504] 165.852183878\n",
      "positions (x,y,z), reward: [  5.13223124   3.90086752  74.3570218 ] 164.092405684\n",
      "positions (x,y,z), reward: [  6.2351279    4.73909955  78.77080835] 162.943303118\n",
      "positions (x,y,z), reward: [  15.45867622   11.83804577  104.75308746] 277.235958927\n",
      "positions (x,y,z), reward: [ 150.          136.18736011  223.86466357] 772.271814855\n",
      "Episode =  133, score = 302.949 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -4.84052145e-04  -9.92690075e-07   2.12908524e+01] 1.74063118002\n",
      "positions (x,y,z), reward: [ -8.48222676e-03   2.09345610e-02   2.88047457e+01] 13.4828587402\n",
      "positions (x,y,z), reward: [  1.70576292e-02   8.29984243e-02   3.63648714e+01] 67.1763710296\n",
      "positions (x,y,z), reward: [  1.67865984   1.06264341  68.96835764] 168.349276184\n",
      "positions (x,y,z), reward: [  1.86656328   1.14755853  70.71889611] 168.235865071\n",
      "positions (x,y,z), reward: [  12.8259962     6.47012807  122.64155333] 266.81636995\n",
      "positions (x,y,z), reward: [  15.39156603    8.25038296  132.02686086] 268.421354537\n",
      "positions (x,y,z), reward: [  21.04931595   14.66068211  157.18887279] 180.508555943\n",
      "Episode =  134, score = 314.553 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.39152855e-03   9.16629156e-05   2.26976996e+01] 5.63075981425\n",
      "positions (x,y,z), reward: [ -5.63103826e-03  -1.50802228e-03   2.48829302e+01] 9.44477718512\n",
      "positions (x,y,z), reward: [ -6.60412182e-03  -2.05634453e-03   2.52367661e+01] 9.92255055466\n",
      "positions (x,y,z), reward: [ -1.55383751e-02  -8.21944253e-03   2.75462229e+01] 12.4421355329\n",
      "positions (x,y,z), reward: [ -0.94568166  -0.55478981  58.55663029] 168.475999311\n",
      "positions (x,y,z), reward: [ -3.10990582  -2.73147357  81.15177342] 166.21383736\n",
      "positions (x,y,z), reward: [ -4.75280207  -5.03933304  91.30120735] 177.093938709\n",
      "positions (x,y,z), reward: [ -5.09081126  -5.5389854   92.97400205] 178.627594631\n",
      "positions (x,y,z), reward: [ -5.45055982  -6.07517227  94.6377693 ] 180.062657794\n",
      "positions (x,y,z), reward: [ -5.70311015  -6.45355309  95.74110252] 180.961200008\n",
      "positions (x,y,z), reward: [ -6.52618369  -7.69283351  99.01722181] 183.356001609\n",
      "positions (x,y,z), reward: [ -10.49998426  -13.58568497  110.37435281] 256.632629011\n",
      "positions (x,y,z), reward: [ -12.60866713  -16.55597298  114.60956614] 243.637951598\n",
      "positions (x,y,z), reward: [ -20.55643413  -26.47551021  125.03726948] 219.12531158\n",
      "positions (x,y,z), reward: [ -21.29020974  -27.29588557  125.71330446] 218.645675698\n",
      "positions (x,y,z), reward: [ -31.98286039  -37.73101392  132.50163449] 212.461710716\n",
      "Episode =  135, score = 301.691 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -5.02252190e-05   1.39428394e-04   2.04943169e+01] -1.86486566556\n",
      "positions (x,y,z), reward: [ -8.92274434e-05   2.41006799e-04   2.06244273e+01] -1.12469610454\n",
      "positions (x,y,z), reward: [  3.31353500e-03   5.92798849e-02   2.71378159e+01] 12.0108545277\n",
      "positions (x,y,z), reward: [  9.62689019e-03   9.32524141e-02   2.88028261e+01] 13.4100511983\n",
      "positions (x,y,z), reward: [  1.37948324e-02   1.14254863e-01   2.96762107e+01] 14.0194166464\n",
      "positions (x,y,z), reward: [  0.03476672   0.21074347  32.91100504] 15.720049271\n",
      "positions (x,y,z), reward: [  0.05238162   0.28276458  34.86137086] 16.4304755853\n",
      "positions (x,y,z), reward: [  2.45578608   3.95453656  74.33758455] 165.48101033\n",
      "positions (x,y,z), reward: [  2.70183319   4.23336244  76.13726607] 165.154624556\n",
      "positions (x,y,z), reward: [  6.22019164   8.03884686  96.15817479] 184.613884676\n",
      "positions (x,y,z), reward: [   8.34626418   10.4308496   106.17296351] 278.106813131\n",
      "positions (x,y,z), reward: [  12.73296996   16.55928403  126.98821737] 250.850664348\n",
      "positions (x,y,z), reward: [  15.4191068    21.69325803  140.7438456 ] 249.92176002\n",
      "positions (x,y,z), reward: [  22.95590354   39.36858902  174.2385716 ] 122.720113407\n",
      "Episode =  136, score = 298.349 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.92854549e-07   2.09530243e-07   2.00699876e+01] -5.66881222432\n",
      "positions (x,y,z), reward: [  2.58437133e-03   2.80877479e-03   2.26967074e+01] 5.61306890997\n",
      "positions (x,y,z), reward: [  1.58161834e-02   8.89183926e-03   2.55964867e+01] 10.3545803644\n",
      "positions (x,y,z), reward: [  7.52748189e-02   1.20732706e-02   3.05711730e+01] 14.634510967\n",
      "positions (x,y,z), reward: [  8.31731784e-02   1.13310269e-02   3.10283503e+01] 14.8988073956\n",
      "positions (x,y,z), reward: [  1.00521473e-01   9.10392267e-03   3.19583995e+01] 15.3907228391\n",
      "positions (x,y,z), reward: [  0.34728096  -0.07260504  40.49322704] 67.8985116781\n",
      "positions (x,y,z), reward: [  0.65507995  -0.24583284  46.94216647] 118.427300205\n",
      "positions (x,y,z), reward: [  0.7190603   -0.28823975  48.0379224 ] 118.444294937\n",
      "positions (x,y,z), reward: [  0.89586445  -0.41412401  50.7971333 ] 118.407437101\n",
      "positions (x,y,z), reward: [  0.93416923  -0.44291722  51.35200984] 118.386894232\n",
      "positions (x,y,z), reward: [  1.47400948  -0.89540243  58.07160046] 167.820960628\n",
      "positions (x,y,z), reward: [  2.83451957  -2.30388256  70.01816719] 165.486359761\n",
      "positions (x,y,z), reward: [  4.1950837   -3.91997528  78.61343504] 162.505465787\n",
      "positions (x,y,z), reward: [  5.29700547  -5.30700277  84.32425354] 166.347227413\n",
      "Episode =  137, score = 303.698 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.58405323e-07  -4.62831901e-06   2.01242716e+01] -4.89759500899\n",
      "positions (x,y,z), reward: [  4.58731046e-03  -9.91804585e-03   2.35680026e+01] 7.34914790754\n",
      "positions (x,y,z), reward: [  0.08820455  -0.1555858   45.29956715] 118.788763822\n",
      "positions (x,y,z), reward: [ -0.41596261  -0.33635052  64.19477406] 169.594528352\n",
      "positions (x,y,z), reward: [ -7.70674993  -2.35277892  95.96274949] 183.178549941\n",
      "positions (x,y,z), reward: [ -21.66147107   -5.28047585  116.88361534] 243.283883538\n",
      "positions (x,y,z), reward: [ -30.81873923   -6.81543271  124.90599932] 233.286386954\n",
      "positions (x,y,z), reward: [ -39.68058022   -8.11635553  130.45285257] 228.357014498\n",
      "positions (x,y,z), reward: [ -46.41883623   -9.02993865  133.60722383] 224.771108686\n",
      "Episode =  138, score = 309.015 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.94762298e-06   5.73094337e-07   2.00699382e+01] -5.67043034852\n",
      "positions (x,y,z), reward: [ -0.47547861   0.0952837   42.61508168] 68.0841390984\n",
      "positions (x,y,z), reward: [ -0.84030203   0.10260104  54.07467829] 168.787159036\n",
      "positions (x,y,z), reward: [ -1.527412    -0.48979992  79.92204528] 168.256839747\n",
      "positions (x,y,z), reward: [ -1.67840768  -1.07124309  90.11230236] 182.759656411\n",
      "positions (x,y,z), reward: [ -1.71810107  -1.43706311  94.65124933] 189.208786595\n",
      "positions (x,y,z), reward: [  -1.74542702   -3.3456811   108.86913936] 282.017022349\n",
      "positions (x,y,z), reward: [  -1.71014279   -7.61049314  125.16969423] 260.295148007\n",
      "positions (x,y,z), reward: [  -1.68649471   -9.19655596  129.5577208 ] 258.341731808\n",
      "Episode =  139, score = 324.321 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.67705942e-02   9.05996592e-02   2.83744143e+01] 13.0457973468\n",
      "positions (x,y,z), reward: [ -0.22312126   0.55261859  43.13469914] 67.9556370582\n",
      "positions (x,y,z), reward: [ -0.76974614   1.45875616  60.73598584] 167.722157606\n",
      "positions (x,y,z), reward: [ -2.51065763   2.91174714  80.44164631] 165.504853306\n",
      "positions (x,y,z), reward: [ -4.12210235   3.78814138  89.47938476] 176.473346961\n",
      "positions (x,y,z), reward: [  -7.71513592    5.18916067  101.75133321] 283.918377151\n",
      "positions (x,y,z), reward: [ -10.0727158     5.85952901  107.17699326] 272.02644283\n",
      "positions (x,y,z), reward: [ -11.45323802    6.19313451  109.82668117] 265.843646599\n",
      "positions (x,y,z), reward: [ -32.14277473    8.93818588  132.28809948] 231.088649049\n",
      "Episode =  140, score = 309.145 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.69416155e-06   2.13646295e-07   2.01242863e+01] -4.89743192211\n",
      "positions (x,y,z), reward: [ -3.07501587e-04   8.04930156e-04   2.14923372e+01] 2.42110590074\n",
      "positions (x,y,z), reward: [  7.59095444e-03   3.23498565e-02   3.01243466e+01] 14.4018250661\n",
      "positions (x,y,z), reward: [  0.04337302   0.09172573  39.96838101] 68.0432411451\n",
      "positions (x,y,z), reward: [ -0.1358097   -0.64013367  81.09976393] 171.294498909\n",
      "positions (x,y,z), reward: [ -1.0371468   -1.62982909  94.20714962] 189.152257843\n",
      "positions (x,y,z), reward: [  -5.90165089   -4.34230966  119.58760313] 260.036988275\n",
      "positions (x,y,z), reward: [  -9.04422906   -5.55824917  129.44367227] 254.495764129\n",
      "positions (x,y,z), reward: [  -9.23610179   -5.62643551  129.98536447] 254.205973173\n",
      "positions (x,y,z), reward: [ -10.42247323   -6.03619592  133.22301693] 252.433036073\n",
      "Episode =  141, score = 323.098 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.09877192   0.05913852  28.80030258] 13.3446192308\n",
      "positions (x,y,z), reward: [  1.25341874   0.85372143  47.48253298] 117.25896518\n",
      "positions (x,y,z), reward: [  1.64259097   1.15034008  51.34150174] 116.944942569\n",
      "positions (x,y,z), reward: [  3.47617321   2.72086334  65.49098261] 164.691439176\n",
      "positions (x,y,z), reward: [  4.70326996   3.93581287  73.12733119] 163.275664822\n",
      "positions (x,y,z), reward: [  10.22323373   11.85185416  104.73560888] 282.177382076\n",
      "positions (x,y,z), reward: [  11.69615651   15.29862794  115.71955019] 267.03510993\n",
      "positions (x,y,z), reward: [  12.89909222   19.4047069   128.8340378 ] 265.997114718\n",
      "Episode =  142, score = 370.714 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.79888061e-08   7.81643908e-08   2.00311232e+01] -6.44416472402\n",
      "positions (x,y,z), reward: [  3.21182985e-05   1.53390324e-04   2.06250221e+01] -1.11751336297\n",
      "positions (x,y,z), reward: [  2.45265276e-05   2.03242566e-04   2.07699916e+01] -0.385966801154\n",
      "positions (x,y,z), reward: [ -4.00969285e-05   3.04282391e-04   2.11033062e+01] 1.0454702861\n",
      "positions (x,y,z), reward: [ -2.64077926e-03   5.52626742e-04   2.38838097e+01] 7.92327233798\n",
      "positions (x,y,z), reward: [  5.44058711e-02  -1.92697739e-02   3.84272947e+01] 67.7898860786\n",
      "positions (x,y,z), reward: [  1.13149665   0.39654583  63.84553446] 169.5287575\n",
      "positions (x,y,z), reward: [  1.27521639   0.49057223  65.5964613 ] 169.522169565\n",
      "positions (x,y,z), reward: [  6.53940441   4.66290525  99.06395661] 198.606177893\n",
      "positions (x,y,z), reward: [   8.22012844    6.05769241  105.65968709] 292.63448962\n",
      "positions (x,y,z), reward: [  12.80319402   10.2068919   121.58341376] 276.807693832\n",
      "positions (x,y,z), reward: [  18.40432622   16.93675087  141.0948025 ] 291.805372151\n",
      "positions (x,y,z), reward: [  29.53702491   55.58700916  204.27282575] 337.787513916\n",
      "Episode =  143, score = 350.460 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  3.01746730e-06   4.82749723e-07   2.01242881e+01] -4.89697111113\n",
      "positions (x,y,z), reward: [  1.50251016e-04   8.22650263e-05   2.06248698e+01] -1.11947566117\n",
      "positions (x,y,z), reward: [  1.55770870e-03   1.10116187e-03   2.19360002e+01] 3.74714125083\n",
      "positions (x,y,z), reward: [  8.10413539e-03   6.37576637e-03   2.42049691e+01] 8.42903502319\n",
      "positions (x,y,z), reward: [  0.10058591   0.18015403  35.36442091] 16.6734766329\n",
      "positions (x,y,z), reward: [  0.16450666   0.4382101   42.09210586] 68.0188507028\n",
      "positions (x,y,z), reward: [  0.19478733   0.77429796  48.04497476] 118.457112455\n",
      "positions (x,y,z), reward: [ -0.142848     3.79752563  75.66098022] 166.683425703\n",
      "positions (x,y,z), reward: [ -0.31558627   4.87660455  81.98176695] 168.619889964\n",
      "positions (x,y,z), reward: [ -0.58413056   6.51536245  90.10337192] 179.234632332\n",
      "positions (x,y,z), reward: [  -1.40884501   12.72557634  113.08699348] 267.593743368\n",
      "positions (x,y,z), reward: [  -1.54286645   14.06507215  117.18190029] 259.750930371\n",
      "positions (x,y,z), reward: [  -2.34610467   23.9019636   141.72201752] 247.997088459\n",
      "positions (x,y,z), reward: [  -2.67511344   28.26794239  150.29912902] 198.254709821\n",
      "Episode =  144, score = 317.894 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  7.16368959e-03  -4.81206553e-03   2.24294781e+01] 4.99809264744\n",
      "positions (x,y,z), reward: [  1.86555572e-02  -1.32966986e-02   2.38785948e+01] 7.87376293542\n",
      "positions (x,y,z), reward: [  0.04134497  -0.03350894  25.96863404] 10.756016492\n",
      "positions (x,y,z), reward: [  0.29997112  -0.53187555  43.67942031] 67.9853086386\n",
      "positions (x,y,z), reward: [  0.40219273  -1.17568496  56.29314216] 168.267945096\n",
      "positions (x,y,z), reward: [  0.40135908  -1.2105137   56.85037638] 168.260255374\n",
      "positions (x,y,z), reward: [  0.3748722   -1.47296834  60.76453867] 168.184702271\n",
      "positions (x,y,z), reward: [  0.10638447  -2.27089097  70.34662726] 167.926841412\n",
      "positions (x,y,z), reward: [ -0.37178389  -3.08482126  77.72312555] 166.957536309\n",
      "positions (x,y,z), reward: [ -0.57890584  -3.37992958  79.9970919 ] 166.467055217\n",
      "positions (x,y,z), reward: [ -0.7550052   -3.61653255  81.70287883] 168.608937068\n",
      "positions (x,y,z), reward: [ -1.56650916  -4.60095525  87.95023026] 176.098176503\n",
      "positions (x,y,z), reward: [  -7.00363758   -9.54906347  109.59411102] 267.85696349\n",
      "positions (x,y,z), reward: [ -12.83289086  -13.60962872  122.53713594] 240.432706735\n",
      "Episode =  145, score = 309.312 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -0.16984578   0.15322239  37.38194148] 67.2487987832\n",
      "positions (x,y,z), reward: [ -3.7532524    2.36009848  80.50978568] 164.782854728\n",
      "positions (x,y,z), reward: [ -3.95376127   2.46506667  81.63491388] 166.151066225\n",
      "positions (x,y,z), reward: [ -4.26944293   2.62784297  83.32146891] 168.177966049\n",
      "positions (x,y,z), reward: [ -5.46072522   3.21968197  88.93086832] 174.700177968\n",
      "positions (x,y,z), reward: [ -14.08275733    7.00767798  113.6955429 ] 257.138434089\n",
      "positions (x,y,z), reward: [ -20.02296527    9.26396538  124.17548167] 238.232569812\n",
      "positions (x,y,z), reward: [ -30.28808702   12.37126213  136.77128669] 232.315559676\n",
      "Episode =  146, score = 309.535 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -4.12225882e-04   6.38647575e-04   2.11032533e+01] 1.0422590951\n",
      "positions (x,y,z), reward: [  3.51686185e-02   2.29715896e-01   4.26231142e+01] 68.4303050604\n",
      "positions (x,y,z), reward: [ -7.48000090e-04   5.55742403e-01   5.07940375e+01] 119.127962385\n",
      "positions (x,y,z), reward: [ -0.11865623   1.01600581  58.08277953] 169.241822132\n",
      "positions (x,y,z), reward: [ -1.03081801   2.85644046  74.56625306] 168.765649759\n",
      "positions (x,y,z), reward: [ -3.68189624   5.67476987  90.55430325] 181.831234594\n",
      "positions (x,y,z), reward: [ -18.40631261   11.61807404  126.69330577] 259.936662445\n",
      "positions (x,y,z), reward: [ -21.33956347   12.10598179  132.74603154] 263.016966637\n",
      "positions (x,y,z), reward: [ -28.35708471   12.85016594  148.72377881] 231.160500624\n",
      "positions (x,y,z), reward: [ -31.83402494   13.1356072   158.22332473] 196.146364619\n",
      "Episode =  147, score = 338.368 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.77743424e-04  -5.28870172e-07   2.06249385e+01] -1.11880897614\n",
      "positions (x,y,z), reward: [  4.60992385e-03   3.43254281e-02   2.67438548e+01] 11.6426904424\n",
      "positions (x,y,z), reward: [ -0.04868133   0.17106921  33.88261466] 16.1677173104\n",
      "positions (x,y,z), reward: [ -0.10206795   0.28063108  37.3848537 ] 67.1929056325\n",
      "positions (x,y,z), reward: [ -1.29256814   2.22662392  64.22913169] 166.708472219\n",
      "positions (x,y,z), reward: [ -2.24734943   3.3523553   73.28683155] 164.738339058\n",
      "positions (x,y,z), reward: [ -2.71770991   3.84167476  76.68652869] 163.752075651\n",
      "positions (x,y,z), reward: [ -13.32599366   10.81972296  110.13916764] 258.248021598\n",
      "positions (x,y,z), reward: [ -18.57958487   13.33980965  118.5688946 ] 236.161671038\n",
      "positions (x,y,z), reward: [ -23.18572778   15.40824987  124.6117571 ] 229.126293344\n",
      "positions (x,y,z), reward: [ -28.2019424    17.60162212  130.28710741] 225.513163563\n",
      "Episode =  148, score = 303.303 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.64690977e-05   1.36500981e-05   2.02790186e+01] -3.36682763574\n",
      "positions (x,y,z), reward: [ -2.60639857e-03   2.37840902e-03   2.21772341e+01] 4.38590812785\n",
      "positions (x,y,z), reward: [ -3.95638679e-03   3.75038267e-03   2.26977670e+01] 5.62024176554\n",
      "positions (x,y,z), reward: [ -0.03709699   0.0442389   28.3768937 ] 13.0923109803\n",
      "positions (x,y,z), reward: [ -0.22769748   0.26073662  40.49109455] 67.7979078018\n",
      "positions (x,y,z), reward: [ -0.62865368   0.73863157  59.07601473] 168.582132597\n",
      "positions (x,y,z), reward: [ -0.71703433   1.0121463   69.20983696] 168.614532598\n",
      "positions (x,y,z), reward: [ -0.38521446   1.51898909  86.48409148] 179.1889367\n",
      "positions (x,y,z), reward: [  0.24258149   1.98710346  97.2550952 ] 196.205805131\n",
      "positions (x,y,z), reward: [   1.15061464    2.58988171  107.2597097 ] 289.402207048\n",
      "positions (x,y,z), reward: [   1.73386458    2.96989638  112.45975523] 281.599850108\n",
      "positions (x,y,z), reward: [   4.41666753    4.67939521  131.66089682] 271.823195956\n",
      "positions (x,y,z), reward: [   6.85115484    6.31180303  147.83761384] 275.880324958\n",
      "Episode =  149, score = 318.801 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.44460110e-03   2.48324337e-03   2.14915862e+01] 2.41117376068\n",
      "positions (x,y,z), reward: [  3.17088822e-02   3.33642407e-01   3.24300459e+01] 15.362544185\n",
      "positions (x,y,z), reward: [  0.08197879   1.20395713  42.61482598] 67.4384643013\n",
      "positions (x,y,z), reward: [  -1.18167277   15.99106649  100.50534747] 286.359125367\n",
      "positions (x,y,z), reward: [  -1.5387423    19.42956695  108.49929278] 272.735587062\n",
      "positions (x,y,z), reward: [  -2.30078205   36.79756327  146.69979536] 279.473963991\n",
      "positions (x,y,z), reward: [  -2.19098681   40.49539421  155.8377955 ] 241.384799064\n",
      "positions (x,y,z), reward: [  -1.95514101   44.65826526  167.07204108] 160.524795281\n",
      "positions (x,y,z), reward: [  -1.90902524   45.30326724  168.91811391] 164.203476677\n",
      "Episode =  150, score = 312.153 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.71846923e-04  -2.49593950e-05   2.04949609e+01] -1.85651746629\n",
      "positions (x,y,z), reward: [ -3.06938912e-02  -1.46991025e-02   2.63568663e+01] 11.2304310575\n",
      "positions (x,y,z), reward: [ -0.04532602  -0.04150841  31.50286603] 15.1838084432\n",
      "positions (x,y,z), reward: [ -3.04319597e-02  -6.85158255e-02   3.48723113e+01] 16.6804312498\n",
      "positions (x,y,z), reward: [  2.07790586  -2.08701578  70.75580425] 166.840500193\n",
      "positions (x,y,z), reward: [  3.40326813  -3.59115942  80.07934051] 164.344277726\n",
      "positions (x,y,z), reward: [  6.57099361  -7.54614681  95.84610011] 180.704002602\n",
      "positions (x,y,z), reward: [  22.46974024  -31.37853218  133.88767107] 221.77278555\n",
      "positions (x,y,z), reward: [  27.51898021  -39.49648683  139.50008008] 217.192718726\n",
      "Episode =  151, score = 304.155 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.67774033e-05   1.31084414e-04   2.03793511e+01] -2.61072867603\n",
      "positions (x,y,z), reward: [ -0.04727135   0.30005505  37.88260859] 67.3508267442\n",
      "positions (x,y,z), reward: [ -0.04869374   0.33424214  38.91568098] 67.5684732013\n",
      "positions (x,y,z), reward: [ -2.25484520e-02   7.58390674e-01   4.96461987e+01] 118.66325519\n",
      "positions (x,y,z), reward: [ -4.89369334e-03   8.56871300e-01   5.18480650e+01] 118.733844448\n",
      "positions (x,y,z), reward: [  0.83198999   2.32872351  79.377826  ] 167.312103095\n",
      "positions (x,y,z), reward: [  1.17331346   2.73221009  84.52537928] 173.605686744\n",
      "positions (x,y,z), reward: [  1.83198562   3.46554546  92.05801814] 184.016373304\n",
      "positions (x,y,z), reward: [  2.35382598   4.0239644   96.76432435] 190.363432268\n",
      "positions (x,y,z), reward: [   5.17699178    6.86126429  114.36124157] 269.519868577\n",
      "positions (x,y,z), reward: [  11.86262827   12.60646376  139.79288406] 252.331641994\n",
      "positions (x,y,z), reward: [  12.54011447   13.11886276  141.89821972] 251.709886358\n",
      "positions (x,y,z), reward: [  15.26013005   15.08892635  149.97729789] 199.957221493\n",
      "Episode =  152, score = 315.728 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -9.66280490e-07  -1.81504833e-07   2.01242647e+01] -4.89761072351\n",
      "positions (x,y,z), reward: [  5.34701134e-06   3.87787391e-05   2.04946611e+01] -1.85841147522\n",
      "positions (x,y,z), reward: [  4.87894567e-04   9.92040265e-03   2.29773494e+01] 6.21988354048\n",
      "positions (x,y,z), reward: [  0.44879055   1.48541933  46.40775105] 117.30635692\n",
      "positions (x,y,z), reward: [  0.96587236   2.59682092  55.24349649] 166.320191498\n",
      "positions (x,y,z), reward: [  1.66106668   3.8902949   63.64742778] 164.543551546\n",
      "positions (x,y,z), reward: [  2.00014391   4.47096461  67.02179715] 163.667671611\n",
      "positions (x,y,z), reward: [  2.37713692   5.08578323  70.40183316] 162.726803983\n",
      "positions (x,y,z), reward: [  3.09780408   6.18105901  76.05387802] 161.05706111\n",
      "positions (x,y,z), reward: [  3.76764147   7.11286625  80.6047069 ] 160.58184652\n",
      "positions (x,y,z), reward: [  6.55227209  10.20930117  95.22054536] 178.158054981\n",
      "positions (x,y,z), reward: [  11.49934067   13.56216703  113.46799846] 259.716786039\n",
      "positions (x,y,z), reward: [  26.60279621   12.95698595  147.45168121] 245.624669605\n",
      "positions (x,y,z), reward: [  27.51180021   12.59634887  148.91460393] 195.924735175\n",
      "Episode =  153, score = 301.926 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -5.45502135e-07   2.31513761e-05   2.01939261e+01] -4.13145727397\n",
      "positions (x,y,z), reward: [  4.95262205e-05   3.41609197e-04   2.09283813e+01] 0.322421303558\n",
      "positions (x,y,z), reward: [  0.27046551   0.31331592  40.48650017] 67.7184764329\n",
      "positions (x,y,z), reward: [  0.47848583   0.52413896  45.83820514] 118.142665849\n",
      "positions (x,y,z), reward: [  3.34101764   3.04943724  76.80880792] 164.206383377\n",
      "positions (x,y,z), reward: [  4.90822931   4.38136175  86.5235947 ] 171.004147503\n",
      "positions (x,y,z), reward: [  5.22068666   4.646793    88.2328769 ] 172.947434215\n",
      "positions (x,y,z), reward: [  7.19660402   6.32851724  97.85663981] 183.3798366\n",
      "positions (x,y,z), reward: [   9.23968615    8.07090441  106.22729445] 273.003905841\n",
      "positions (x,y,z), reward: [  10.60347042    9.23436099  111.17452338] 262.706661095\n",
      "positions (x,y,z), reward: [  12.93877735   11.22322475  118.7369978 ] 246.43105285\n",
      "positions (x,y,z), reward: [  13.8383603    11.98699475  121.39505132] 242.634320467\n",
      "positions (x,y,z), reward: [  15.35075218   13.26695774  125.59595265] 239.425382028\n",
      "positions (x,y,z), reward: [  21.07980895   18.08929643  139.24983147] 228.493657556\n",
      "positions (x,y,z), reward: [  21.99943571   18.87018904  141.21056623] 227.563147913\n",
      "positions (x,y,z), reward: [  23.40528358   20.07562135  144.1318683 ] 226.26083313\n",
      "Episode =  154, score = 308.940 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.67062106e-08   2.14291337e-11   2.00311258e+01] -6.44403321145\n",
      "positions (x,y,z), reward: [ -1.23406172e-03  -9.13282304e-03   2.75464368e+01] 12.4509249971\n",
      "positions (x,y,z), reward: [ -6.18714118e-02   3.38632033e-02   3.68741375e+01] 67.3337755912\n",
      "positions (x,y,z), reward: [ -1.00566144   0.47524974  56.9218778 ] 168.549500578\n",
      "positions (x,y,z), reward: [ -1.3753996    0.64569107  60.85702794] 168.152216707\n",
      "positions (x,y,z), reward: [ -1.4339936    0.67264633  61.42068355] 168.082251563\n",
      "positions (x,y,z), reward: [ -4.94387123   2.26036479  82.95984575] 167.608396891\n",
      "positions (x,y,z), reward: [ -5.94253847   2.68998761  86.93113826] 172.101058102\n",
      "positions (x,y,z), reward: [ -12.76227807    5.19016239  104.78203742] 273.888344912\n",
      "positions (x,y,z), reward: [ -16.80564235    6.37021221  111.65102681] 257.092777859\n",
      "positions (x,y,z), reward: [ -26.68250309    8.6510474   123.73463054] 235.780674034\n",
      "positions (x,y,z), reward: [ -30.86316959    9.41805338  127.6518628 ] 233.650676843\n",
      "positions (x,y,z), reward: [ -36.37008887   10.27852951  132.09811306] 231.044154589\n",
      "positions (x,y,z), reward: [ -43.37993106   11.15137301  136.84487788] 228.014644817\n",
      "Episode =  155, score = 307.374 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.00613987e-03   4.25043374e-04   2.09294395e+01] 0.334786465052\n",
      "positions (x,y,z), reward: [  2.03004310e-02   6.99023746e-03   2.35707286e+01] 7.35045023377\n",
      "positions (x,y,z), reward: [  0.59145477   0.3349687   40.50390988] 67.3723604805\n",
      "positions (x,y,z), reward: [  1.30123407   0.91444866  51.34040085] 117.46641427\n",
      "positions (x,y,z), reward: [  1.82061196   1.40218489  57.47974905] 166.880145879\n",
      "positions (x,y,z), reward: [  2.98612085   2.65695646  68.85009805] 165.104814059\n",
      "positions (x,y,z), reward: [  4.35109819   4.47721278  80.51429185] 163.573676137\n",
      "positions (x,y,z), reward: [  5.80415812   7.33683857  93.94401706] 181.489230039\n",
      "positions (x,y,z), reward: [  6.19892629   8.51150064  98.46641845] 187.901807123\n",
      "positions (x,y,z), reward: [  6.25135783   8.69283935  99.12703189] 188.859495556\n",
      "Episode =  156, score = 347.837 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.11920243e-06  -2.07152161e-07   2.01243947e+01] -4.89530453475\n",
      "positions (x,y,z), reward: [ -0.03164224   0.05654012  28.80850069] 13.4399907792\n",
      "positions (x,y,z), reward: [ -0.17931229   0.2704188   37.9037779 ] 67.2676694273\n",
      "positions (x,y,z), reward: [ -0.20399936   0.3042081   38.93765884] 67.4635376231\n",
      "positions (x,y,z), reward: [ -0.2747784    0.39783958  41.56261145] 67.8311498703\n",
      "positions (x,y,z), reward: [ -0.35988453   0.5042948   44.23462131] 118.051553797\n",
      "positions (x,y,z), reward: [ -0.96039599   1.11632743  56.32215386] 167.766565208\n",
      "positions (x,y,z), reward: [ -1.43293168   1.50671509  62.4671825 ] 167.057634675\n",
      "positions (x,y,z), reward: [ -1.92056874   1.86957815  67.51287878] 166.264012944\n",
      "positions (x,y,z), reward: [ -4.30354237   3.35538569  83.79225638] 168.041800502\n",
      "positions (x,y,z), reward: [ -4.41347899   3.41667311  84.35251652] 168.702166855\n",
      "positions (x,y,z), reward: [ -4.99735678   3.73457154  87.15103918] 171.948499676\n",
      "positions (x,y,z), reward: [ -5.24774504   3.86726105  88.26898137] 173.219375096\n",
      "positions (x,y,z), reward: [ -5.3767402    3.93482758  88.82759477] 173.848210706\n",
      "positions (x,y,z), reward: [ -35.34248646   14.39181537  138.99820959] 227.494738066\n",
      "Episode =  157, score = 306.933 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -7.30473421e-07  -3.89974630e-06   2.01243205e+01] -4.89610915066\n",
      "positions (x,y,z), reward: [ -2.03597282  -2.29549684  62.98040101] 165.580857539\n",
      "positions (x,y,z), reward: [ -4.10669734  -4.33518048  78.0685396 ] 161.458527616\n",
      "positions (x,y,z), reward: [ -9.35386486  -7.63215304  96.80009902] 177.105624831\n",
      "positions (x,y,z), reward: [ -28.91458614  -15.62515727  127.23906183] 227.040847198\n",
      "positions (x,y,z), reward: [ -35.68754437  -18.12042315  133.49961635] 222.298759603\n",
      "Episode =  158, score = 300.858 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  5.23761565e-03  -1.74408601e-03   2.21772227e+01] 4.38599537062\n",
      "positions (x,y,z), reward: [  2.29344247e-02  -7.61080420e-03   2.42049746e+01] 8.4125813135\n",
      "positions (x,y,z), reward: [  0.17505342  -0.06696105  31.49672523] 15.0168294467\n",
      "positions (x,y,z), reward: [  0.54161165  -0.22720682  41.54888744] 67.7063607839\n",
      "positions (x,y,z), reward: [  0.6371594   -0.27155831  43.68068266] 67.8993765545\n",
      "positions (x,y,z), reward: [  0.87573285  -0.38822844  48.55716434] 118.065819192\n",
      "positions (x,y,z), reward: [  1.05097431  -0.48247126  51.8512509 ] 118.022926462\n",
      "positions (x,y,z), reward: [  1.3674854   -0.68241251  57.39087566] 167.767457386\n",
      "positions (x,y,z), reward: [  2.46137035  -1.89808393  74.78831119] 165.891131698\n",
      "positions (x,y,z), reward: [  2.74737583  -2.49286462  79.88324213] 165.109985813\n",
      "positions (x,y,z), reward: [   2.81532868   -6.55615949  100.42110735] 290.508074413\n",
      "positions (x,y,z), reward: [  -3.20438443  -18.20981053  126.37934767] 244.714058693\n",
      "positions (x,y,z), reward: [  -5.96235114  -22.11185138  131.44391557] 237.826856995\n",
      "positions (x,y,z), reward: [  -7.68568509  -24.42504823  133.9725927 ] 234.605318418\n",
      "positions (x,y,z), reward: [ -13.34912528  -31.60542624  140.06125391] 223.993879524\n",
      "positions (x,y,z), reward: [ -14.08578003  -32.50201767  140.66305072] 222.625683809\n",
      "Episode =  159, score = 313.046 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -3.05143396e-09   1.71350189e-07   2.00311074e+01] -6.44495438364\n",
      "positions (x,y,z), reward: [ -9.72753556e-07  -4.61089217e-06   2.01242980e+01] -4.8970328029\n",
      "positions (x,y,z), reward: [ -6.39185389e-04  -3.75065908e-03   2.19360720e+01] 3.75017960775\n",
      "positions (x,y,z), reward: [ -6.93007869e-03  -2.66822663e-02   2.48842700e+01] 9.42156601189\n",
      "positions (x,y,z), reward: [ -1.57636678e-02  -5.90575625e-02   2.71422563e+01] 12.0069828653\n",
      "positions (x,y,z), reward: [ -0.0632099   -0.28721714  35.36443672] 16.595196454\n",
      "positions (x,y,z), reward: [ -0.14199941  -0.87679956  45.8498154 ] 118.097732024\n",
      "positions (x,y,z), reward: [ -0.19301831  -1.35944143  51.32699767] 118.055775258\n",
      "positions (x,y,z), reward: [ -0.20333689  -1.47482257  52.43293449] 168.000882793\n",
      "positions (x,y,z), reward: [ -0.22805347  -1.79432652  55.20905339] 167.804647654\n",
      "positions (x,y,z), reward: [ -0.23725763  -1.9354268   56.32335684] 167.703861457\n",
      "positions (x,y,z), reward: [ -0.26457386  -2.49639071  60.23726112] 167.254701245\n",
      "positions (x,y,z), reward: [ -0.2755105   -2.86908943  62.48135961] 166.924076991\n",
      "positions (x,y,z), reward: [ -0.22660629  -5.81272     74.8437787 ] 163.932294235\n",
      "positions (x,y,z), reward: [  6.05656074e-02  -9.74844728e+00   8.47769358e+01] 166.383349679\n",
      "positions (x,y,z), reward: [  0.5984892  -14.59826797  93.18222737] 171.945296127\n",
      "positions (x,y,z), reward: [  0.68727626 -15.29515211  94.19218419] 172.415565987\n",
      "positions (x,y,z), reward: [  0.7811519  -16.01220323  95.19158956] 172.833265471\n",
      "positions (x,y,z), reward: [  0.98456998 -17.50700709  97.15680519] 173.504437702\n",
      "positions (x,y,z), reward: [   4.85499578  -39.38247238  114.39352918] 239.138465738\n",
      "positions (x,y,z), reward: [  10.12724647  -63.80374674  119.91945049] 213.575388335\n",
      "Episode =  160, score = 298.407 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.95784612e-09   2.97556005e-07   2.00310992e+01] -6.44536713585\n",
      "positions (x,y,z), reward: [ -1.66262508e-07   3.00616035e-06   2.00699448e+01] -5.67010311627\n",
      "positions (x,y,z), reward: [ -3.54863023e-06   3.85908080e-05   2.01939956e+01] -4.12929842756\n",
      "positions (x,y,z), reward: [ -1.86573725e-04   6.70922775e-03   2.24322373e+01] 5.01918989668\n",
      "positions (x,y,z), reward: [  7.21765754e-04   1.16332435e-02   2.32680370e+01] 6.79915397734\n",
      "positions (x,y,z), reward: [  1.93832617e-03   1.61984774e-02   2.38828517e+01] 7.90149963874\n",
      "positions (x,y,z), reward: [  0.07762498   0.15129505  31.5001276 ] 15.032676272\n",
      "positions (x,y,z), reward: [  0.57318973   0.78800983  45.31443849] 117.707481347\n",
      "positions (x,y,z), reward: [  0.81403552   1.09543495  49.68283935] 117.594910116\n",
      "positions (x,y,z), reward: [  0.91501122   1.22572598  51.33689413] 117.485481416\n",
      "positions (x,y,z), reward: [  1.97546983   2.64132177  65.29932765] 165.487965527\n",
      "positions (x,y,z), reward: [  3.79082679   5.67018688  84.12362977] 168.049254804\n",
      "positions (x,y,z), reward: [  4.33751484   7.15942759  90.69453758] 176.987770798\n",
      "positions (x,y,z), reward: [  4.46049547   7.62415342  92.53349977] 179.538760407\n",
      "positions (x,y,z), reward: [   4.78053896   10.82700166  103.47300753] 284.901100954\n",
      "positions (x,y,z), reward: [   4.58106074   12.96845802  109.73723505] 275.794885988\n",
      "positions (x,y,z), reward: [   2.68341363   19.29946827  126.45579117] 264.756358706\n",
      "positions (x,y,z), reward: [   1.88335712   21.0793238   131.09628043] 268.284175625\n",
      "positions (x,y,z), reward: [   0.72688882   23.35993228  137.18376899] 274.79552498\n",
      "Episode =  161, score = 326.477 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -3.23824462e-06  -1.75259149e-05   2.02790995e+01] -3.36583515974\n",
      "positions (x,y,z), reward: [ -9.71757293e-05  -1.07117621e-04   2.06248468e+01] -1.11971314804\n",
      "positions (x,y,z), reward: [ -3.71239835e-02  -3.10646696e-03   2.52381290e+01] 9.89108945525\n",
      "positions (x,y,z), reward: [ -1.64496346e-01  -6.77598632e-03   2.96807173e+01] 13.9711102687\n",
      "positions (x,y,z), reward: [ -3.86627896e-01  -1.72818101e-02   3.38816606e+01] 15.9695204598\n",
      "positions (x,y,z), reward: [ -0.80113836  -0.04285875  38.92833135] 67.1061248234\n",
      "positions (x,y,z), reward: [ -1.2899433   -0.07680926  43.14994219] 67.3812654911\n",
      "positions (x,y,z), reward: [ -1.68130994  -0.10565845  45.84443958] 117.314985666\n",
      "positions (x,y,z), reward: [ -2.25492094  -0.14929802  49.11803002] 117.006745107\n",
      "positions (x,y,z), reward: [ -2.36284785  -0.15760111  49.66691726] 116.929727743\n",
      "positions (x,y,z), reward: [ -2.9609034   -0.20381535  52.4211332 ] 166.427121765\n",
      "positions (x,y,z), reward: [ -5.63542824  -0.40959698  61.25237565] 163.364722864\n",
      "positions (x,y,z), reward: [-14.85923884  -1.07228396  77.940533  ] 150.295902022\n",
      "positions (x,y,z), reward: [-17.50178185  -1.2548582   81.26225079] 148.337986026\n",
      "positions (x,y,z), reward: [-22.49474193  -1.5938442   86.5987877 ] 151.504235924\n",
      "positions (x,y,z), reward: [-25.21106911  -1.77292152  89.07691293] 153.90682445\n",
      "positions (x,y,z), reward: [-41.59779563  -2.66149924  99.30489815] 160.680480449\n",
      "positions (x,y,z), reward: [ -55.99825793   -2.94960533  103.29809965] 248.776270517\n",
      "positions (x,y,z), reward: [ -77.77170833   -1.84824437  102.22930898] 212.337810035\n",
      "positions (x,y,z), reward: [ -80.50645219   -1.52893523  101.48126304] 211.968884627\n",
      "positions (x,y,z), reward: [ -83.89221916   -1.0618798   100.34080894] 211.851876485\n",
      "Episode =  162, score = 275.949 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -9.77274679e-07   1.67569955e-06   2.01243346e+01] -4.89551634017\n",
      "positions (x,y,z), reward: [ -4.88019309e-05   1.49452915e-04   2.06252784e+01] -1.11449167954\n",
      "positions (x,y,z), reward: [ -2.02331252e-01  -3.02552082e-02   3.63827256e+01] 67.0693249696\n",
      "positions (x,y,z), reward: [ -0.38820978  -0.07638376  41.04773153] 67.9752943332\n",
      "positions (x,y,z), reward: [ -0.59690248  -0.11696729  44.79309632] 118.311473443\n",
      "positions (x,y,z), reward: [ -4.37409932e+00  -7.70737099e-03   7.32534783e+01] 165.870087744\n",
      "positions (x,y,z), reward: [ -9.70161566   0.66928449  90.04475359] 174.072255531\n",
      "positions (x,y,z), reward: [-12.86943582   1.05210303  96.501506  ] 179.151497935\n",
      "positions (x,y,z), reward: [ -20.21556321    1.78736846  106.94435911] 262.820696513\n",
      "positions (x,y,z), reward: [ -43.69761834    3.13990864  121.61188318] 227.445094507\n",
      "positions (x,y,z), reward: [ -46.28862505    3.23007818  122.22874105] 225.549876693\n",
      "positions (x,y,z), reward: [ -46.94501078    3.2512787   122.36015102] 225.066149683\n",
      "positions (x,y,z), reward: [ -60.5781536     3.53084308  122.96765221] 189.120211313\n",
      "Episode =  163, score = 302.161 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  5.95790638e-04   6.73864634e-03   2.38790450e+01] 7.89068503695\n",
      "positions (x,y,z), reward: [  2.96108917e-03   1.63116429e-02   2.63484780e+01] 11.2279085932\n",
      "positions (x,y,z), reward: [  0.04651699   0.04042452  34.85637093] 16.6816664379\n",
      "positions (x,y,z), reward: [  2.51449103e-01   3.58511254e-02   5.13115961e+01] 119.291126682\n",
      "positions (x,y,z), reward: [  0.49717398   0.09952079  68.61540251] 169.509246545\n",
      "positions (x,y,z), reward: [  0.58933975   0.20334582  78.74946277] 169.392501637\n",
      "positions (x,y,z), reward: [ -7.63928624e-02   5.60298213e-01   1.02020997e+02] 297.019583767\n",
      "positions (x,y,z), reward: [  -0.45055631    0.6175835   105.46866259] 291.483539712\n",
      "positions (x,y,z), reward: [  -1.92109193    0.76206269  114.09711553] 276.863129523\n",
      "positions (x,y,z), reward: [ -13.83621916    1.33311543  140.71756623] 251.270548377\n",
      "Episode =  164, score = 326.611 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.08104356e-03   5.05028453e-03   2.48842196e+01] 9.45069049455\n",
      "positions (x,y,z), reward: [ -4.06578593e-03   6.36530583e-03   2.56015827e+01] 10.390072129\n",
      "positions (x,y,z), reward: [ -5.23868096e-01   1.90759567e-02   4.26374867e+01] 68.190069751\n",
      "positions (x,y,z), reward: [ -6.38552686e-01   9.55176251e-03   4.42495268e+01] 118.335528601\n",
      "positions (x,y,z), reward: [-14.01712419  -5.82918931  94.80694301] 170.014926827\n",
      "positions (x,y,z), reward: [ -18.22664887   -8.50877044  102.80256861] 265.349775767\n",
      "positions (x,y,z), reward: [ -25.70074794  -13.66550146  114.35317125] 238.658277284\n",
      "positions (x,y,z), reward: [ -26.992913    -14.6001006   116.08465222] 234.699980416\n",
      "positions (x,y,z), reward: [ -37.91107019  -22.89557495  128.24017934] 219.6039798\n",
      "positions (x,y,z), reward: [ -44.56937569  -28.22952323  133.80061947] 217.049266085\n",
      "Episode =  165, score = 295.668 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.41871876e-01   2.78157883e-02   2.92341896e+01] 13.5442355672\n",
      "positions (x,y,z), reward: [  1.26356866   0.21304792  41.00298019] 66.8861783775\n",
      "positions (x,y,z), reward: [  1.79684655   0.34072785  45.27795305] 116.886729988\n",
      "positions (x,y,z), reward: [  6.59087584   2.04316709  69.95818022] 162.213230732\n",
      "positions (x,y,z), reward: [ 17.39266454   6.73240826  99.81167111] 178.798871304\n",
      "positions (x,y,z), reward: [  24.70619344    9.63862579  114.82371146] 254.755199198\n",
      "positions (x,y,z), reward: [  26.49269617   10.34105719  118.35100041] 250.075119272\n",
      "positions (x,y,z), reward: [  30.26733372   11.87541843  125.87182466] 249.592601342\n",
      "Episode =  166, score = 294.839 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -3.00370121e-04  -1.34990749e-04   2.11028666e+01] 1.03954168892\n",
      "positions (x,y,z), reward: [ -5.59331181e-02   3.16129274e-03   2.79553225e+01] 12.7559126332\n",
      "positions (x,y,z), reward: [ -2.51467591e-01  -2.93204849e-03   3.63568268e+01] 66.9985594679\n",
      "positions (x,y,z), reward: [ -5.30575847e-01   1.05947434e-02   4.42088503e+01] 118.343469768\n",
      "positions (x,y,z), reward: [ -7.30869779e-01   3.33957515e-02   4.90969914e+01] 118.618702788\n",
      "positions (x,y,z), reward: [ -0.9155189    0.05753191  53.50310479] 168.698375987\n",
      "positions (x,y,z), reward: [ -1.20010057   0.08539735  60.74400908] 168.7206104\n",
      "positions (x,y,z), reward: [ -1.6649582   -0.31331599  82.35658142] 172.414184785\n",
      "positions (x,y,z), reward: [ -1.66641217  -0.42958624  84.66935414] 175.86438418\n",
      "positions (x,y,z), reward: [ -1.4039584   -1.6068888   98.71812591] 196.635043695\n",
      "positions (x,y,z), reward: [  -1.02984644   -2.70453696  106.44245473] 288.413310103\n",
      "positions (x,y,z), reward: [   1.06024342   -8.31798575  128.35395279] 261.669828116\n",
      "positions (x,y,z), reward: [   1.13711264   -8.52364593  128.93448798] 261.341532064\n",
      "positions (x,y,z), reward: [   2.23039245  -11.45363421  136.39435461] 256.685701351\n",
      "Episode =  167, score = 324.025 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.14681895e-02   4.86501810e-03   2.35708403e+01] 7.35957898587\n",
      "positions (x,y,z), reward: [ -3.06295754e-02   6.79672214e-03   2.59754511e+01] 10.8034251825\n",
      "positions (x,y,z), reward: [ -7.95959525e-02  -1.08104392e-02   3.01290574e+01] 14.3613203339\n",
      "positions (x,y,z), reward: [ -1.90875507  -2.26920277  73.67426908] 165.931698798\n",
      "positions (x,y,z), reward: [ -2.65822994  -3.0183561   80.98185218] 165.878005669\n",
      "positions (x,y,z), reward: [ -3.96781243  -4.32944093  91.06113733] 178.185376994\n",
      "positions (x,y,z), reward: [ -4.45987101  -4.85060425  94.4031971 ] 182.099991041\n",
      "positions (x,y,z), reward: [ -4.88693693  -5.32056457  97.18025272] 185.295313319\n",
      "positions (x,y,z), reward: [  -5.50786606   -6.03674491  101.05584806] 286.501093155\n",
      "positions (x,y,z), reward: [  -6.0590715    -6.70873961  104.36639022] 280.225699416\n",
      "positions (x,y,z), reward: [  -7.80035214   -9.08629885  114.23352047] 261.024758953\n",
      "positions (x,y,z), reward: [ -11.02795793  -14.77823067  130.9661934 ] 242.903164988\n",
      "positions (x,y,z), reward: [ -12.53816563  -18.24456301  138.41688311] 237.708363687\n",
      "positions (x,y,z), reward: [ -14.07331082  -22.40368248  145.78547323] 234.025511382\n",
      "Episode =  168, score = 312.799 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  4.54282810e-03  -1.03040307e-03   2.24312960e+01] 5.01459480689\n",
      "positions (x,y,z), reward: [  2.01183822e-02  -1.19860196e-03   2.45389541e+01] 8.93564423914\n",
      "positions (x,y,z), reward: [  3.19305665e-02  -7.13227600e-04   2.56001525e+01] 10.360785596\n",
      "positions (x,y,z), reward: [  1.30242698e-01   7.47401029e-03   3.10349089e+01] 14.8664870163\n",
      "positions (x,y,z), reward: [  7.04247737e-01   1.94622937e-02   4.58483887e+01] 118.40060651\n",
      "positions (x,y,z), reward: [  7.66109764e-01   1.83033532e-02   4.69359703e+01] 118.46298125\n",
      "positions (x,y,z), reward: [  1.30156381e+00   9.44952657e-03   5.46629721e+01] 168.576009646\n",
      "positions (x,y,z), reward: [  3.77994154e+00   6.47999347e-02   7.57157783e+01] 167.10106668\n",
      "positions (x,y,z), reward: [  6.10951347   0.18452022  88.50860646] 177.532356355\n",
      "positions (x,y,z), reward: [  8.32067983   0.35614468  98.32158688] 189.406011371\n",
      "positions (x,y,z), reward: [  13.2470677     0.98720697  115.76905229] 261.998210337\n",
      "positions (x,y,z), reward: [  16.13596175    1.60481044  124.76738091] 252.748153308\n",
      "positions (x,y,z), reward: [  17.39501334    1.98646468  128.79522961] 251.669709811\n",
      "positions (x,y,z), reward: [  17.57156573    2.04802309  129.37749471] 251.526272035\n",
      "positions (x,y,z), reward: [  18.43479725    2.38547478  132.31905352] 250.847465535\n",
      "positions (x,y,z), reward: [  21.48640974    4.58691726  146.03131093] 250.281537544\n",
      "Episode =  169, score = 318.185 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  8.35567114e-03  -1.86273809e-03   2.32690874e+01] 6.80258660083\n",
      "positions (x,y,z), reward: [  1.02345341e-02  -2.70298404e-03   2.35709800e+01] 7.36231375215\n",
      "positions (x,y,z), reward: [  0.06254398  -0.0457677   28.38240913] 13.0701026178\n",
      "positions (x,y,z), reward: [  0.17579666  -0.21805127  34.86761777] 16.3698744768\n",
      "positions (x,y,z), reward: [  0.19541153  -0.25885706  35.86535682] 16.6565668586\n",
      "positions (x,y,z), reward: [  0.37040485  -0.7878957   44.2340061 ] 117.789648448\n",
      "positions (x,y,z), reward: [  0.41896458  -0.98673284  46.40133081] 117.812782161\n",
      "positions (x,y,z), reward: [  1.21793218  -6.84690936  74.16503664] 161.420647548\n",
      "positions (x,y,z), reward: [  1.28018151  -7.44884599  75.81026146] 160.617975645\n",
      "positions (x,y,z), reward: [  1.41281769  -8.74632822  79.07357607] 158.866504605\n",
      "positions (x,y,z), reward: [  2.22287292 -16.48225331  93.63557373] 168.51845801\n",
      "positions (x,y,z), reward: [  2.61048364 -19.91908604  98.48254985] 170.863973661\n",
      "positions (x,y,z), reward: [  2.65253802 -20.28192036  98.95483314] 171.331719876\n",
      "positions (x,y,z), reward: [   3.01138125  -23.30831907  102.64548181] 267.579115433\n",
      "positions (x,y,z), reward: [   3.20596318  -24.903399    104.42926998] 264.174550961\n",
      "positions (x,y,z), reward: [   3.62507834  -28.25418379  107.86323541] 257.454730607\n",
      "positions (x,y,z), reward: [   4.5705952   -35.56780142  114.13590572] 244.477628336\n",
      "positions (x,y,z), reward: [   4.76066554  -37.02442369  115.21554808] 242.13568478\n",
      "positions (x,y,z), reward: [   5.08335885  -39.50860879  116.94311947] 238.313824354\n",
      "positions (x,y,z), reward: [   5.41064948  -42.06193515  118.57875499] 234.601411829\n",
      "positions (x,y,z), reward: [   6.19164492  -48.46836164  122.11543349] 229.36210114\n",
      "Episode =  170, score = 298.759 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  8.02219293e-07  -4.14476772e-06   2.01243760e+01] -4.89513995869\n",
      "positions (x,y,z), reward: [  8.97243543e-05  -2.13542491e-04   2.06250877e+01] -1.11954661277\n",
      "positions (x,y,z), reward: [  1.50683288e-02  -1.13202408e-02   2.48836358e+01] 9.42601796821\n",
      "positions (x,y,z), reward: [  0.03672916  -0.03280023  27.95954953] 12.7578691553\n",
      "positions (x,y,z), reward: [  0.04370725  -0.04152366  28.80663759] 13.4325919014\n",
      "positions (x,y,z), reward: [  0.06857169  -0.07894858  31.49805872] 15.1140623393\n",
      "positions (x,y,z), reward: [  0.18165094  -0.31233479  39.9762035 ] 67.7087097986\n",
      "positions (x,y,z), reward: [  0.19099722  -0.33308641  40.50137592] 67.7856167137\n",
      "positions (x,y,z), reward: [  0.42378947  -0.82215074  49.68172022] 118.276941499\n",
      "positions (x,y,z), reward: [  0.59305644  -1.14504523  54.11080496] 168.078575088\n",
      "positions (x,y,z), reward: [  0.69398174  -1.32974174  56.34068472] 167.900203491\n",
      "positions (x,y,z), reward: [  0.72099116  -1.37843751  56.89944033] 167.848332876\n",
      "positions (x,y,z), reward: [  11.30750339  -30.41092808  117.47012323] 230.591653237\n",
      "Episode =  171, score = 298.965 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -4.68891189e-04   1.32085918e-03   2.11031830e+01] 1.04165776147\n",
      "positions (x,y,z), reward: [ -0.5968868    0.33605495  37.88955672] 66.7487909976\n",
      "positions (x,y,z), reward: [ -0.90500966   0.46413807  41.54397882] 67.1008673719\n",
      "positions (x,y,z), reward: [ -1.11987479   0.54603707  43.67612931] 67.1457345067\n",
      "positions (x,y,z), reward: [ -1.30148627   0.61180561  45.29175036] 117.112173398\n",
      "positions (x,y,z), reward: [ -4.08256003   1.4451931   60.743364  ] 164.309136138\n",
      "positions (x,y,z), reward: [-12.34370772   3.20128518  80.36591139] 152.933778942\n",
      "positions (x,y,z), reward: [ -39.47153762    4.33099935  104.85768056] 259.564697325\n",
      "positions (x,y,z), reward: [ -49.33862567    3.67368426  110.86099827] 250.382614603\n",
      "positions (x,y,z), reward: [ -60.69438641    2.68333114  117.31505697] 240.748336252\n",
      "positions (x,y,z), reward: [ -65.11072272    2.29557501  119.71818407] 237.002566507\n",
      "Episode =  172, score = 295.203 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.05776576e-06  -4.21508322e-06   2.01242900e+01] -4.89701576431\n",
      "positions (x,y,z), reward: [ -1.93762699e-04  -6.10458645e-04   2.07695490e+01] -0.393375616707\n",
      "positions (x,y,z), reward: [ -0.1628994   -0.37741303  33.38649075] 15.6141424992\n",
      "positions (x,y,z), reward: [ -0.18502228  -0.43801739  34.3608786 ] 15.9292435228\n",
      "positions (x,y,z), reward: [ -0.44443489  -1.21858412  43.13220881] 67.0650816872\n",
      "positions (x,y,z), reward: [ -0.46437494  -1.28150732  43.66768895] 67.0611410025\n",
      "positions (x,y,z), reward: [ -0.84160517  -2.50981867  51.84498972] 116.221091425\n",
      "positions (x,y,z), reward: [ -1.25606714  -3.95642797  58.49056119] 164.517162084\n",
      "positions (x,y,z), reward: [ -4.72164802 -22.44037599  90.56026168] 153.739590796\n",
      "positions (x,y,z), reward: [ -4.78842591 -22.90529348  90.97049748] 154.053695276\n",
      "positions (x,y,z), reward: [ -5.26079098 -26.29964295  93.7066621 ] 155.962459162\n",
      "positions (x,y,z), reward: [ -10.87000599  -73.83402505  105.45855593] 202.716616223\n",
      "Episode =  173, score = 278.089 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  5.62252340e-04   4.69543218e-04   2.07694677e+01] -0.393395989069\n",
      "positions (x,y,z), reward: [  9.50343783e-04   7.30170983e-04   2.09288319e+01] 0.325706699594\n",
      "positions (x,y,z), reward: [  0.20690126   0.06460344  28.79998837] 13.2296022778\n",
      "positions (x,y,z), reward: [  1.69528872   0.23898774  45.82935696] 117.17632041\n",
      "positions (x,y,z), reward: [  2.87453567   0.28600508  54.08595238] 166.696337693\n",
      "positions (x,y,z), reward: [  3.24723832   0.29128512  56.32065457] 166.462441653\n",
      "positions (x,y,z), reward: [  4.75762719   0.27750919  64.2234373 ] 165.39211174\n",
      "positions (x,y,z), reward: [  9.95665910e+00   1.89463125e-02   8.39669903e+01] 167.816752436\n",
      "positions (x,y,z), reward: [  21.50839095   -0.47966551  113.54747506] 267.415576231\n",
      "positions (x,y,z), reward: [  28.74238112   -0.34890936  128.69037517] 266.138851566\n",
      "positions (x,y,z), reward: [  30.09581171   -0.26343796  131.41950595] 268.237537807\n",
      "positions (x,y,z), reward: [  36.92953597    0.51965713  145.02162024] 281.000712315\n",
      "Episode =  174, score = 317.244 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.53600636e-05   1.94579755e-05   2.03791318e+01] -2.6138492236\n",
      "positions (x,y,z), reward: [  7.63323510e-04   3.19056721e-04   2.14909911e+01] 2.41259318891\n",
      "positions (x,y,z), reward: [  0.14768984   0.22832877  39.44963097] 67.7044024572\n",
      "positions (x,y,z), reward: [  0.64226174   0.96620204  65.2264568 ] 168.394571672\n",
      "positions (x,y,z), reward: [  1.247358     1.84730865  89.96159529] 182.042393627\n",
      "positions (x,y,z), reward: [   1.49907474    3.58009858  113.25585457] 275.775021461\n",
      "positions (x,y,z), reward: [   1.47581602    4.11380613  117.8716376 ] 268.560775067\n",
      "positions (x,y,z), reward: [   1.39383995    4.81553922  123.11320482] 265.072449313\n",
      "Episode =  175, score = 325.963 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -5.94891647e-04  -2.91892868e-03   2.14939673e+01] 2.43029897183\n",
      "positions (x,y,z), reward: [ -2.50624377e-02  -7.87374314e-02   2.71475198e+01] 11.9846200956\n",
      "positions (x,y,z), reward: [ -0.21317655  -0.51325332  37.90579383] 66.9769230451\n",
      "positions (x,y,z), reward: [ -0.24360231  -0.57267822  38.93917229] 67.1403792572\n",
      "positions (x,y,z), reward: [ -0.55039638  -1.09468405  46.397161  ] 117.521719706\n",
      "positions (x,y,z), reward: [ -1.21481053  -2.02616125  55.76606825] 166.595779114\n",
      "positions (x,y,z), reward: [ -1.31804249  -2.1631734   56.88061947] 166.40033542\n",
      "positions (x,y,z), reward: [ -1.48345154  -2.38160697  58.55539375] 166.06974083\n",
      "positions (x,y,z), reward: [ -1.66163625  -2.61632216  60.23286798] 165.694829202\n",
      "positions (x,y,z), reward: [ -2.91526747  -4.28459005  69.74701796] 162.714579093\n",
      "positions (x,y,z), reward: [ -9.02129078 -13.23060782  97.78971224] 172.067189151\n",
      "positions (x,y,z), reward: [ -13.07979718  -19.86227133  110.68623192] 246.954550092\n",
      "positions (x,y,z), reward: [ -17.47698278  -27.58693335  122.17616799] 226.489147814\n",
      "positions (x,y,z), reward: [ -19.17670408  -30.68489843  126.05974835] 224.001580255\n",
      "positions (x,y,z), reward: [ -21.33807071  -34.68812016  130.60938585] 222.176780557\n",
      "Episode =  176, score = 295.745 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -9.19904840e-03   6.18598729e-04   2.24320855e+01] 5.01189200389\n",
      "positions (x,y,z), reward: [ -4.24993014  -1.39724945  62.37291038] 164.22569356\n",
      "positions (x,y,z), reward: [ -4.89089361  -1.71103587  65.16277193] 163.285062283\n",
      "positions (x,y,z), reward: [ -8.68723777  -3.92590023  77.33683106] 156.524106903\n",
      "positions (x,y,z), reward: [ -8.90306298  -4.06700324  77.87926298] 156.087662283\n",
      "positions (x,y,z), reward: [ -9.57521008  -4.51541503  79.49633129] 154.697785155\n",
      "positions (x,y,z), reward: [-10.04417366  -4.83597945  80.56477613] 154.54907772\n",
      "positions (x,y,z), reward: [-12.09115412  -6.30092253  84.7419822 ] 156.245611918\n",
      "positions (x,y,z), reward: [-24.25052538 -16.14315688  99.93569304] 152.553550018\n",
      "positions (x,y,z), reward: [ -33.8667704   -24.11667708  105.44437533] 233.091660339\n",
      "positions (x,y,z), reward: [ -52.2849771   -37.51088867  107.80964239] 192.492726589\n",
      "Episode =  177, score = 275.833 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.14131253e-02  -1.19854822e-04   2.42055780e+01] 8.42489452097\n",
      "positions (x,y,z), reward: [ -1.24333493e-01  -1.29336178e-02   2.96801492e+01] 14.0096630712\n",
      "positions (x,y,z), reward: [ -1.48654228e-01  -1.71744022e-02   3.05777566e+01] 14.5601976586\n",
      "positions (x,y,z), reward: [ -0.43829703  -0.07038254  38.40879834] 67.3135745717\n",
      "positions (x,y,z), reward: [ -1.32842606  -0.15160426  54.61514999] 168.232101608\n",
      "positions (x,y,z), reward: [ -2.85547453  -0.15478522  81.5659547 ] 169.633003225\n",
      "positions (x,y,z), reward: [  -3.96938077   -1.04956807  103.69339248] 289.774555796\n",
      "positions (x,y,z), reward: [  -4.74250768   -2.24805393  116.68135171] 268.120216528\n",
      "positions (x,y,z), reward: [  -4.97883784   -2.63587251  120.05417406] 262.465446391\n",
      "positions (x,y,z), reward: [  -6.00084231   -4.29202465  132.36368339] 259.580833367\n",
      "Episode =  178, score = 324.834 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.73984308e-02   1.28760242e-03   2.59756731e+01] 10.833483991\n",
      "positions (x,y,z), reward: [  5.75834966e-02   1.19879721e-03   2.96858538e+01] 14.1126803885\n",
      "positions (x,y,z), reward: [  1.27305556e-01  -3.13665155e-03   3.34060443e+01] 16.0746574446\n",
      "positions (x,y,z), reward: [  6.66490745e-01  -4.12706575e-02   4.85823417e+01] 118.649035359\n",
      "positions (x,y,z), reward: [  7.69725162e-01  -4.28361654e-02   5.07776372e+01] 118.705917026\n",
      "positions (x,y,z), reward: [  8.23063095e-01  -4.27859145e-02   5.18798154e+01] 118.721218302\n",
      "positions (x,y,z), reward: [  2.17261692   0.14148113  81.59094655] 170.327124641\n",
      "positions (x,y,z), reward: [   3.37207567   -1.52112989  112.85870212] 276.218988441\n",
      "positions (x,y,z), reward: [   3.63900138   -2.0929527   117.39600194] 268.485591674\n",
      "positions (x,y,z), reward: [   3.90432985   -2.64584041  121.35347487] 263.668911732\n",
      "positions (x,y,z), reward: [   4.33723509   -3.50404192  126.98417722] 262.246089546\n",
      "positions (x,y,z), reward: [   4.68094294   -4.14142794  130.91259162] 261.20864811\n",
      "positions (x,y,z), reward: [   5.3638714    -5.28255521  137.64358842] 259.44220762\n",
      "Episode =  179, score = 326.015 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.41707296e-04  -1.10294404e-04   2.04946173e+01] -1.86194564031\n",
      "positions (x,y,z), reward: [ -1.11475855e-01  -2.41727808e-02   2.79547064e+01] 12.6686600367\n",
      "positions (x,y,z), reward: [ -0.32225591  -0.04340887  32.90471257] 15.5700388155\n",
      "positions (x,y,z), reward: [ -3.17503584   0.32136507  56.85482027] 166.409966431\n",
      "positions (x,y,z), reward: [ -4.47117767   0.62390951  63.02024419] 165.025721452\n",
      "positions (x,y,z), reward: [ -7.84756285   1.56681005  75.47102288] 161.044743125\n",
      "positions (x,y,z), reward: [ -9.92496058   2.21665128  81.74952003] 161.088416668\n",
      "positions (x,y,z), reward: [-15.07102974   3.92641896  94.94483645] 174.131049885\n",
      "positions (x,y,z), reward: [ -18.1468289     4.97435635  101.8283476 ] 274.775953484\n",
      "positions (x,y,z), reward: [ -19.22574187    5.34355196  104.11820123] 269.856413433\n",
      "positions (x,y,z), reward: [ -20.05148817    5.62658197  105.83350262] 266.193010869\n",
      "positions (x,y,z), reward: [ -34.96765537   10.76251255  132.52903683] 237.697363686\n",
      "Episode =  180, score = 305.793 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.10905222e-02   1.45396878e-02   2.35673617e+01] 7.33667518555\n",
      "positions (x,y,z), reward: [  0.08063759   0.22777663  34.36882065] 16.2752552977\n",
      "positions (x,y,z), reward: [  0.15735588   1.4124421   55.74561462] 168.230684798\n",
      "positions (x,y,z), reward: [  0.11938149   1.87894592  61.32310693] 167.954957998\n",
      "positions (x,y,z), reward: [ -0.3095603    3.83223319  80.38149239] 166.484623599\n",
      "positions (x,y,z), reward: [ -0.39060595   4.08426717  82.62598046] 169.52143101\n",
      "positions (x,y,z), reward: [ -0.54553939   4.52903693  86.55481492] 174.825199478\n",
      "positions (x,y,z), reward: [  -1.99054982    7.98543041  118.07602339] 263.135671282\n",
      "positions (x,y,z), reward: [  -2.62747322    9.96254068  135.57420944] 257.596614873\n",
      "positions (x,y,z), reward: [  -2.84719183   11.11973923  144.0272968 ] 256.200603287\n",
      "Episode =  181, score = 322.842 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  0.20144789   0.41745992  41.03946108] 67.8330910263\n",
      "positions (x,y,z), reward: [  0.280519     0.51701462  43.17119387] 68.0258961635\n",
      "positions (x,y,z), reward: [  0.32535286   0.57125602  44.24754982] 118.088517514\n",
      "positions (x,y,z), reward: [  1.63326924   1.9005655   62.11993431] 167.214625903\n",
      "positions (x,y,z), reward: [  3.89888558   3.90600374  77.55685286] 165.007925785\n",
      "positions (x,y,z), reward: [  7.20627617   6.69215535  91.67098661] 179.0053805\n",
      "positions (x,y,z), reward: [  12.13790295   10.74781937  107.05841761] 275.227247664\n",
      "positions (x,y,z), reward: [  13.218729     11.62120272  110.02425921] 269.564332245\n",
      "positions (x,y,z), reward: [  13.77951546   12.07223277  111.52997099] 266.687949499\n",
      "positions (x,y,z), reward: [  14.64550739   12.7660189   113.81896875] 262.320441446\n",
      "positions (x,y,z), reward: [  15.84526674   13.72217359  116.93202353] 256.404621333\n",
      "positions (x,y,z), reward: [  28.51704973   23.82408077  148.79178879] 206.456080418\n",
      "positions (x,y,z), reward: [  35.0517403    29.45524103  165.8327375 ] 120.692588356\n",
      "positions (x,y,z), reward: [  39.57404551   33.54074155  177.84500599] 134.397094559\n",
      "Episode =  182, score = 291.726 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -2.94375959e-03   4.56384242e-04   2.19364938e+01] 3.74846305789\n",
      "positions (x,y,z), reward: [ -6.55468052e-02  -3.63370928e-03   2.71415793e+01] 12.00821819\n",
      "positions (x,y,z), reward: [ -1.69241974  -0.14167671  55.74133717] 167.999632266\n",
      "positions (x,y,z), reward: [ -3.32261787  -0.63629628  67.55260804] 166.377397446\n",
      "positions (x,y,z), reward: [ -4.67336918  -1.2313506   73.80164573] 164.475416028\n",
      "positions (x,y,z), reward: [-14.38780333  -6.30514199  94.81149054] 167.50883299\n",
      "positions (x,y,z), reward: [ -19.81733154   -8.82851767  100.62961483] 262.973660868\n",
      "positions (x,y,z), reward: [ -21.2384816    -9.42199236  101.83898981] 259.493317165\n",
      "positions (x,y,z), reward: [ -45.0952293   -15.00716791  112.75681173] 226.006220193\n",
      "positions (x,y,z), reward: [ -67.18675713  -12.20818218  116.49222215] 219.691478676\n",
      "Episode =  183, score = 294.098 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.09204526e-06   1.40252078e-07   2.01939526e+01] -4.13127223862\n",
      "positions (x,y,z), reward: [ -8.19713005e-05  -5.19118716e-05   2.09285296e+01] 0.325366883619\n",
      "positions (x,y,z), reward: [ -7.85731980e-03  -2.84834379e-02   2.92337084e+01] 13.7972711867\n",
      "positions (x,y,z), reward: [ -8.18953151e-03  -3.63208357e-02   3.01193481e+01] 14.3967342737\n",
      "positions (x,y,z), reward: [ -7.96881275e-03  -5.04573398e-02   3.14907923e+01] 15.1976435243\n",
      "positions (x,y,z), reward: [  0.06538706  -0.27181625  43.68388008] 68.5091571771\n",
      "positions (x,y,z), reward: [  0.54479793  -0.8666152   61.35563833] 168.65705491\n",
      "positions (x,y,z), reward: [  1.10570896  -1.37805489  72.04880597] 167.681788856\n",
      "positions (x,y,z), reward: [  1.14057117  -1.40858673  72.61211745] 167.61526188\n",
      "positions (x,y,z), reward: [  2.32896958  -2.4837464   88.91881395] 178.625856238\n",
      "positions (x,y,z), reward: [   4.45616605   -5.11244603  115.84622013] 266.742780623\n",
      "positions (x,y,z), reward: [   5.69322419   -8.02932949  138.35791409] 256.489351059\n",
      "Episode =  184, score = 323.240 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -1.14192681e-05  -2.64609999e-05   2.02790419e+01] -3.36587080574\n",
      "positions (x,y,z), reward: [ -8.87526815e-03  -6.76067557e-03   2.32666764e+01] 6.78732895887\n",
      "positions (x,y,z), reward: [ -0.47049287  -0.14210921  39.96374719] 67.558854708\n",
      "positions (x,y,z), reward: [ -1.55622416  -0.46790372  57.38397902] 167.777653774\n",
      "positions (x,y,z), reward: [ -2.1362772   -0.71700292  64.63547211] 167.102873493\n",
      "positions (x,y,z), reward: [ -2.99272372  -1.1711726   74.15368652] 165.849773754\n",
      "positions (x,y,z), reward: [  -7.07255916   -4.65056147  109.38572669] 274.041265442\n",
      "positions (x,y,z), reward: [  -7.38302152   -5.02261159  111.61233542] 269.989064246\n",
      "Episode =  185, score = 315.970 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [ -5.63978286e-09   2.84398606e-10   2.00311256e+01] -6.44404210643\n",
      "positions (x,y,z), reward: [ -2.24175816e-05   1.09666914e-04   2.14927117e+01] 2.42291386555\n",
      "positions (x,y,z), reward: [  1.07165997e-03   1.82628507e-04   2.35688074e+01] 7.36392677711\n",
      "positions (x,y,z), reward: [  2.65886496e-03   4.20040783e-04   2.48829653e+01] 9.44364869979\n",
      "positions (x,y,z), reward: [  2.62175193e-02  -5.47366840e-03   3.19642844e+01] 15.4801109114\n",
      "positions (x,y,z), reward: [  0.08517728  -0.04901113  39.45140319] 67.9534042194\n",
      "positions (x,y,z), reward: [  0.20682851  -0.17085308  48.57119587] 118.989238033\n",
      "positions (x,y,z), reward: [  0.30324536  -0.28857191  54.08335078] 169.127918441\n",
      "positions (x,y,z), reward: [  0.43683008  -0.50505802  61.32702254] 169.029226327\n",
      "positions (x,y,z), reward: [  0.59466743  -0.98422277  71.99706946] 168.594880365\n",
      "positions (x,y,z), reward: [  0.61713564  -1.87191318  83.86671647] 173.640826007\n",
      "positions (x,y,z), reward: [  -2.61764291  -12.43059502  129.69267414] 253.815994173\n",
      "positions (x,y,z), reward: [  -5.2634251   -17.65917561  140.69224261] 244.458665673\n",
      "Episode =  186, score = 321.740 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  1.51107208e-03   4.40127152e-02   2.67491814e+01] 11.643821642\n",
      "positions (x,y,z), reward: [  1.85163051e-02   1.24370829e-01   3.01331429e+01] 14.3083085858\n",
      "positions (x,y,z), reward: [  0.03847977   0.20959231  32.44603621] 15.501545949\n",
      "positions (x,y,z), reward: [  0.05982741   0.30101043  34.38129084] 16.2359210827\n",
      "positions (x,y,z), reward: [  0.0659007    0.32734397  34.87524252] 16.3931859161\n",
      "positions (x,y,z), reward: [  0.20576956   1.01099244  43.72864399] 67.8084015803\n",
      "positions (x,y,z), reward: [ -1.77220028e-02   5.60283436e+00   7.03524614e+01] 167.291888731\n",
      "positions (x,y,z), reward: [ -0.29988477   6.38597374  73.46828472] 166.678048799\n",
      "positions (x,y,z), reward: [ -1.19123901   8.10421545  79.8296559 ] 164.899644251\n",
      "positions (x,y,z), reward: [ -1.42976672   8.46830632  81.12112558] 166.130089175\n",
      "positions (x,y,z), reward: [ -5.61055043  12.69157854  95.70940786] 181.277771191\n",
      "positions (x,y,z), reward: [ -27.49728027   19.97654654  136.93053932] 256.748903168\n",
      "positions (x,y,z), reward: [ -37.63938418   21.53392483  160.04109813] 188.24861598\n",
      "positions (x,y,z), reward: [ -39.46594741   22.00331799  165.50683482] 148.250464221\n",
      "positions (x,y,z), reward: [ -53.70644822   62.0722424   300.        ] 1473.15343938\n",
      "Episode =  187, score = 353.787 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  4.02005711e-03   2.06549672e-03   2.59683111e+01] 10.8174413709\n",
      "positions (x,y,z), reward: [  8.40412564e-03   5.47465009e-03   2.71355989e+01] 12.049830363\n",
      "positions (x,y,z), reward: [  0.05031886   0.06486484  33.38780902] 16.0575208978\n",
      "positions (x,y,z), reward: [  0.18986349   0.47772302  45.30762144] 118.448914652\n",
      "positions (x,y,z), reward: [  0.23044158   0.63291311  48.0354519 ] 118.563464001\n",
      "positions (x,y,z), reward: [   0.21498948    6.92541353  100.89428038] 292.110701819\n",
      "positions (x,y,z), reward: [ -10.70485774   11.54869246  141.39925804] 246.311918678\n",
      "Episode =  188, score = 319.651 (best = 376.191), noise_scale = 0.1positions (x,y,z), reward: [  2.44782336e-04  -2.30126172e-04   2.04944035e+01] -1.86418614771\n",
      "positions (x,y,z), reward: [  2.31028017e-02  -4.18115025e-02   2.67426051e+01] 11.6180977512\n",
      "positions (x,y,z), reward: [ -4.89275134e-01  -3.73696386e-03   5.19368278e+01] 119.361572995\n",
      "positions (x,y,z), reward: [  -8.29163661    5.63952662  100.59856961] 297.135805885\n",
      "positions (x,y,z), reward: [  -9.66690786    6.73173636  105.5715715 ] 290.250759573\n",
      "positions (x,y,z), reward: [  -9.91091304    6.92867146  106.43779666] 289.092547002\n",
      "positions (x,y,z), reward: [ -21.18169534   18.00152686  149.018856  ] 252.874648154\n",
      "positions (x,y,z), reward: [ -22.53550597   19.84553788  155.36261261] 265.298483983\n",
      "positions (x,y,z), reward: [ -23.00509001   20.53362569  157.68306356] 220.882078142\n",
      "positions (x,y,z), reward: [ -28.91188368   32.89447757  195.95225988] 299.188638338\n",
      "Episode =  189, score = 405.554 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -1.3204813    1.09552534  82.49908257] 174.044970188\n",
      "positions (x,y,z), reward: [ -1.36063174   1.15381292  83.11461895] 174.979201345\n",
      "positions (x,y,z), reward: [ -1.57185017   1.47070789  86.227136  ] 179.721739102\n",
      "positions (x,y,z), reward: [ -1.70677227   1.6822311   88.12529413] 182.632204859\n",
      "positions (x,y,z), reward: [  -5.47658399    9.87694632  135.77243584] 283.304836144\n",
      "positions (x,y,z), reward: [  -6.71144022   12.94944857  154.44761801] 252.291969855\n",
      "positions (x,y,z), reward: [  -7.00094859   13.7140655   159.49023003] 209.678930046\n",
      "positions (x,y,z), reward: [  -8.04741528   16.8714885   181.44949058] 186.042763532\n",
      "positions (x,y,z), reward: [  -9.36823972   23.85617439  229.84212914] 414.72539309\n",
      "Episode =  190, score = 357.559 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -3.10263637e-08   1.69276988e-07   2.00311027e+01] -6.44519066815\n",
      "positions (x,y,z), reward: [ -5.71434608e-03   6.35484937e-03   2.24316054e+01] 5.01139038593\n",
      "positions (x,y,z), reward: [ -1.12434297e-02   1.17917029e-02   2.32673209e+01] 6.78786657101\n",
      "positions (x,y,z), reward: [ -0.03724528   0.03586232  25.60159262] 10.3255755292\n",
      "positions (x,y,z), reward: [ -0.98530071   0.5394574   43.69060183] 67.3222530595\n",
      "positions (x,y,z), reward: [ -3.34309078   1.2670958   58.54931233] 165.238206324\n",
      "positions (x,y,z), reward: [ -3.60524795   1.33226219  59.66374657] 164.914137126\n",
      "positions (x,y,z), reward: [ -4.32747572   1.50087996  62.44872062] 163.987587748\n",
      "positions (x,y,z), reward: [ -6.4980116    1.93379488  69.09060894] 161.005789151\n",
      "positions (x,y,z), reward: [-12.33683396   2.79325981  80.78937657] 153.472212211\n",
      "positions (x,y,z), reward: [ -50.94378594    5.76903831  108.35119   ] 242.473911408\n",
      "positions (x,y,z), reward: [ -63.9870579     6.35245898  111.02195776] 233.075349087\n",
      "Episode =  191, score = 290.050 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  9.63060725e-05  -1.28028494e-04   2.03793469e+01] -2.60866071536\n",
      "positions (x,y,z), reward: [  3.57859075e-04  -4.14132551e-04   2.06249090e+01] -1.11911465006\n",
      "positions (x,y,z), reward: [  0.17642597  -0.07380972  28.80522065] 13.2585238357\n",
      "positions (x,y,z), reward: [  0.6888969   -0.24262821  37.37723307] 66.6198547082\n",
      "positions (x,y,z), reward: [ 13.51227215  -2.62515294  97.20207494] 183.480531538\n",
      "positions (x,y,z), reward: [  20.63896905   -2.72549555  114.79113275] 260.42518543\n",
      "positions (x,y,z), reward: [  30.07526548   -2.47130058  134.26365523] 256.286537883\n",
      "positions (x,y,z), reward: [  32.51471013   -2.36452727  138.75019959] 257.66332258\n",
      "positions (x,y,z), reward: [  39.53374677   -1.98891109  150.78384713] 212.549122482\n",
      "Episode =  192, score = 305.770 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -1.62932213e-04   5.92486782e-04   2.21772638e+01] 4.39154589846\n",
      "positions (x,y,z), reward: [ -0.10845066  -0.09083136  32.91345113] 15.7633342866\n",
      "positions (x,y,z), reward: [ -1.60638249  -1.18514761  55.25997936] 167.243965883\n",
      "positions (x,y,z), reward: [-13.42465816  -6.93744856  86.86623855] 156.52954141\n",
      "positions (x,y,z), reward: [-17.45892061  -8.50012779  92.08847898] 156.997509806\n",
      "positions (x,y,z), reward: [ -26.15932053  -11.47257229  100.46370319] 258.701972733\n",
      "positions (x,y,z), reward: [ -66.91114527  -20.34062752  113.96705604] 211.6224033\n",
      "positions (x,y,z), reward: [ -68.86136907  -20.69059096  113.98108497] 194.898629947\n",
      "Episode =  193, score = 284.699 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  5.09581126e-03   1.71647064e-03   2.32659945e+01] 6.79436291889\n",
      "positions (x,y,z), reward: [  0.20000178  -0.10772359  39.97020144] 67.873328708\n",
      "positions (x,y,z), reward: [  0.35787343  -0.19716689  52.41644109] 169.101310978\n",
      "positions (x,y,z), reward: [  0.30274198  -0.17534686  63.04607749] 169.783895091\n",
      "positions (x,y,z), reward: [ -3.91727752e-01   5.77041542e-02   7.50473534e+01] 170.390875419\n",
      "positions (x,y,z), reward: [ -0.71994524   0.15447261  77.93703391] 170.059670461\n",
      "positions (x,y,z), reward: [  -7.32971971    1.60830829  102.04876077] 287.646476734\n",
      "positions (x,y,z), reward: [  -8.11824176    1.74499312  103.6998109 ] 283.937357279\n",
      "positions (x,y,z), reward: [ -20.03038331    3.32105289  120.09853746] 240.310969104\n",
      "positions (x,y,z), reward: [ -22.34638544    3.55731819  122.20408637] 238.90467101\n",
      "positions (x,y,z), reward: [ -32.13143936    4.42254331  129.08857856] 233.282419797\n",
      "positions (x,y,z), reward: [ -37.78778169    4.84716831  131.97393578] 230.294053414\n",
      "Episode =  194, score = 313.490 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -5.99115167e-03  -3.15602049e-03   2.19352229e+01] 3.73281070566\n",
      "positions (x,y,z), reward: [ -2.33521679  -1.89356458  59.01151786] 165.516665114\n",
      "positions (x,y,z), reward: [ -2.52215619  -2.05071219  60.67709398] 165.197777061\n",
      "positions (x,y,z), reward: [ -4.11600989  -3.29986951  72.35593931] 162.39315589\n",
      "positions (x,y,z), reward: [ -6.32240143  -4.73196273  83.46126126] 163.803336737\n",
      "positions (x,y,z), reward: [ -7.47595252  -5.36118738  87.87809901] 168.503263856\n",
      "positions (x,y,z), reward: [ -13.9374471    -7.99082709  104.59231963] 269.283907597\n",
      "positions (x,y,z), reward: [ -16.49653483   -8.79478243  109.22566205] 258.199505081\n",
      "positions (x,y,z), reward: [ -19.07194536   -9.52203701  113.21226626] 248.035927895\n",
      "positions (x,y,z), reward: [ -23.11602262  -10.54104094  118.42727087] 236.673336198\n",
      "positions (x,y,z), reward: [ -28.22907233  -11.67595618  123.64750221] 230.825188952\n",
      "positions (x,y,z), reward: [ -29.15456635  -11.86696615  124.45899049] 230.172214323\n",
      "positions (x,y,z), reward: [ -43.65513498  -14.44437767  133.22529803] 219.306025588\n",
      "Episode =  195, score = 299.855 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -6.37151692e-05   2.64014058e-05   2.02790367e+01] -3.36652460837\n",
      "positions (x,y,z), reward: [ -1.11487399e-02   2.95407781e-03   2.24326719e+01] 5.01512601887\n",
      "positions (x,y,z), reward: [ -4.99856379e-02   8.90823683e-03   2.52393375e+01] 9.87419577712\n",
      "positions (x,y,z), reward: [ -7.95292230e-02   1.23827538e-02   2.67454996e+01] 11.5877636979\n",
      "positions (x,y,z), reward: [ -1.73700484e-01   2.60923480e-02   3.05788357e+01] 14.5233459456\n",
      "positions (x,y,z), reward: [ -0.42906886   0.10605075  38.40998835] 67.2901159096\n",
      "positions (x,y,z), reward: [ -0.85121639   0.3538512   48.0212372 ] 118.133697754\n",
      "positions (x,y,z), reward: [ -1.48201524   0.92165401  59.67644017] 167.673262983\n",
      "positions (x,y,z), reward: [ -1.67957143   1.15230106  63.05606228] 167.410603289\n",
      "positions (x,y,z), reward: [ -2.6529376    2.78149894  79.15591445] 165.957855953\n",
      "positions (x,y,z), reward: [ -3.32127662   4.78293987  91.79067411] 182.422224851\n",
      "positions (x,y,z), reward: [ -3.45281536   5.37503317  94.89608421] 186.779062052\n",
      "positions (x,y,z), reward: [  -3.73562284    7.28565342  103.84301042] 287.931721047\n",
      "positions (x,y,z), reward: [  -3.75017591    7.43698391  104.49878   ] 286.909735378\n",
      "positions (x,y,z), reward: [  -3.4796349    14.60081168  131.47503719] 265.674300574\n",
      "positions (x,y,z), reward: [  -2.88619841   17.65850529  142.24304233] 270.012135883\n",
      "positions (x,y,z), reward: [   1.05625662   29.21391143  183.96916175] 160.270373657\n",
      "Episode =  196, score = 309.758 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  3.60935517e-03   9.86634450e-04   2.24323972e+01] 5.01669450094\n",
      "positions (x,y,z), reward: [  1.16853674e-01  -1.84173006e-02   3.05781067e+01] 14.593851855\n",
      "positions (x,y,z), reward: [  1.27377566e-01  -2.13246488e-02   3.10354056e+01] 14.8512500026\n",
      "positions (x,y,z), reward: [  0.4933828   -0.14535398  42.0806621 ] 67.9285362241\n",
      "positions (x,y,z), reward: [  0.74305045  -0.22942691  47.46843816] 118.274880327\n",
      "positions (x,y,z), reward: [  0.91767926  -0.28275555  50.75459251] 118.306876224\n",
      "positions (x,y,z), reward: [  2.68471883  -0.52031239  74.21562668] 166.971984762\n",
      "positions (x,y,z), reward: [   7.29898779    0.58398975  107.27115945] 281.966071173\n",
      "positions (x,y,z), reward: [  10.7765212     2.05932485  123.3022149 ] 257.560987549\n",
      "positions (x,y,z), reward: [  11.49861969    2.39067182  126.13634168] 256.389522954\n",
      "positions (x,y,z), reward: [  13.04596185    3.11721103  131.76664056] 253.849655727\n",
      "Episode =  197, score = 320.507 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -1.06737299e-02   5.48209520e-02   2.63506038e+01] 11.1979598563\n",
      "positions (x,y,z), reward: [ -0.03248459   0.12353716  30.12211658] 14.2907099103\n",
      "positions (x,y,z), reward: [ -0.09637919   0.40740315  41.02233777] 67.8946525799\n",
      "positions (x,y,z), reward: [ -0.09895446   0.43869652  42.08211676] 68.0469371923\n",
      "positions (x,y,z), reward: [ -0.10034468   0.51826016  44.76114876] 118.35780447\n",
      "positions (x,y,z), reward: [  5.23647484e-03   8.20362811e-01   5.63236635e+01] 169.124544248\n",
      "positions (x,y,z), reward: [  0.62894375   0.78183995  74.43413499] 169.114574309\n",
      "positions (x,y,z), reward: [  1.22608372   0.20513612  84.71632985] 176.208705854\n",
      "positions (x,y,z), reward: [  1.58385961  -0.28751017  89.85574416] 183.443930822\n",
      "positions (x,y,z), reward: [  1.8429838   -0.70195498  93.27728405] 187.859045122\n",
      "positions (x,y,z), reward: [   3.15085648   -3.32298784  107.98081038] 281.525894186\n",
      "positions (x,y,z), reward: [   7.60521941  -13.31056618  140.45132645] 247.272459115\n",
      "positions (x,y,z), reward: [   7.79869063  -13.72040098  141.49779986] 246.614575487\n",
      "Episode =  198, score = 322.938 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -3.43343515e-03  -1.29868629e-02   2.24303660e+01] 4.99313197467\n",
      "positions (x,y,z), reward: [ -1.22575451e-02  -3.77926424e-02   2.38790920e+01] 7.84556149606\n",
      "positions (x,y,z), reward: [ -0.06237387  -0.1778117   27.95075435] 12.5503454993\n",
      "positions (x,y,z), reward: [ -0.10033337  -0.29132125  30.11330548] 14.0093927504\n",
      "positions (x,y,z), reward: [ -0.43739647  -1.64838249  44.70198576] 116.746101794\n",
      "positions (x,y,z), reward: [ -0.53755183  -2.14547883  48.48497604] 116.50209851\n",
      "positions (x,y,z), reward: [ -1.04163403  -4.65050268  63.876399  ] 163.920753608\n",
      "positions (x,y,z), reward: [ -1.23313107  -5.49304557  68.29508573] 162.889874979\n",
      "positions (x,y,z), reward: [ -1.51632833  -6.61939552  73.81608434] 161.45323793\n",
      "positions (x,y,z), reward: [ -2.23980897  -8.96353455  84.28928859] 164.765974542\n",
      "positions (x,y,z), reward: [ -2.43167202  -9.48727665  86.49219885] 167.353794786\n",
      "positions (x,y,z), reward: [  -4.25264421  -13.26588298  101.36670408] 279.958126853\n",
      "positions (x,y,z), reward: [  -5.81384022  -15.54987182  109.60588425] 263.598235505\n",
      "positions (x,y,z), reward: [  -7.60321447  -17.64114156  116.69121049] 248.818184044\n",
      "positions (x,y,z), reward: [ -15.78617773  -24.35736975  136.64144783] 231.223461043\n",
      "Episode =  199, score = 304.065 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -0.91023225  -0.46157487  49.1575757 ] 118.155008989\n",
      "positions (x,y,z), reward: [ -1.05845797  -0.53813285  50.81356719] 118.063939185\n",
      "positions (x,y,z), reward: [ -1.22352672  -0.62137     52.4769448 ] 167.928511933\n",
      "positions (x,y,z), reward: [ -1.75365646  -0.87935455  56.94080506] 167.364763587\n",
      "positions (x,y,z), reward: [ -2.83029737  -1.38280989  63.68415483] 165.934419907\n",
      "positions (x,y,z), reward: [ -4.90663035  -2.32912351  72.68040098] 162.753750116\n",
      "positions (x,y,z), reward: [ -7.437184    -3.48389542  80.45144247] 159.184275025\n",
      "positions (x,y,z), reward: [ -8.96990286  -4.20580533  84.2634198 ] 162.203151209\n",
      "positions (x,y,z), reward: [-15.97597444  -7.84986791  97.1594149 ] 168.166561597\n",
      "positions (x,y,z), reward: [-17.31471099  -8.60252327  99.07609993] 168.338802178\n",
      "positions (x,y,z), reward: [ -19.4279437    -9.81624556  101.85537663] 262.624931638\n",
      "positions (x,y,z), reward: [ -34.3674646   -18.93465702  115.66408337] 224.927979909\n",
      "positions (x,y,z), reward: [ -37.65166039  -21.00915252  117.70333587] 219.181641319\n",
      "positions (x,y,z), reward: [ -39.57537201  -22.2293161   118.76556737] 216.635550582\n",
      "positions (x,y,z), reward: [ -40.54960403  -22.84811411  119.2679772 ] 215.398409608\n",
      "positions (x,y,z), reward: [ -47.07446229  -26.99105131  122.0534727 ] 211.053523491\n",
      "positions (x,y,z), reward: [ -55.52915887  -32.28104963  124.29700065] 206.903653861\n",
      "Episode =  200, score = 291.363 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  2.28609246e-07  -2.80430924e-07   2.00700089e+01] -5.6677299556\n",
      "positions (x,y,z), reward: [  0.14859393   0.28562369  50.782353  ] 119.164364981\n",
      "positions (x,y,z), reward: [  0.12319016   0.33518272  52.99684   ] 169.296232379\n",
      "positions (x,y,z), reward: [ -0.06533207   0.52393983  60.26377059] 169.517554308\n",
      "positions (x,y,z), reward: [ -0.53392252   0.77261367  68.73116504] 169.001713931\n",
      "positions (x,y,z), reward: [ -3.76440703   1.13655536  94.23645868] 186.66532527\n",
      "positions (x,y,z), reward: [  -6.16036891    0.85028196  106.01442302] 283.822117184\n",
      "positions (x,y,z), reward: [  -7.21131132    0.66429232  110.45865982] 276.132751096\n",
      "positions (x,y,z), reward: [ -9.68215198e+00   1.19002814e-01   1.19818596e+02] 259.839104848\n",
      "positions (x,y,z), reward: [ -1.03068180e+01  -4.29377050e-02   1.22005443e+02] 258.952122055\n",
      "positions (x,y,z), reward: [ -16.41023475   -2.22248802  140.9740416 ] 250.327659472\n",
      "Episode =  201, score = 322.542 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -2.66366166e-04  -1.20019919e-03   2.11036003e+01] 1.04480257112\n",
      "positions (x,y,z), reward: [ -0.05592551  -0.18845133  33.40086052] 15.9454299655\n",
      "positions (x,y,z), reward: [ -0.06725676  -0.5679832   47.4831275 ] 118.648678442\n",
      "positions (x,y,z), reward: [  0.15402257  -0.95616413  59.69469265] 169.010656486\n",
      "positions (x,y,z), reward: [  0.68670287  -1.43462948  71.59862098] 168.39075636\n",
      "positions (x,y,z), reward: [  1.33846854  -1.92316096  80.75294334] 168.574833595\n",
      "positions (x,y,z), reward: [  2.83883995  -2.84723987  94.71161415] 188.027068803\n",
      "positions (x,y,z), reward: [  11.40484521   -5.46440633  134.84982256] 265.342830103\n",
      "Episode =  202, score = 314.106 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  4.34260127e-03  -1.24373977e-02   2.29778319e+01] 6.21860645683\n",
      "positions (x,y,z), reward: [  9.74315370e-03  -1.05500732e-01   2.88103444e+01] 13.4077217098\n",
      "positions (x,y,z), reward: [  1.94326618e-03  -1.88518304e-01   3.24422308e+01] 15.5531407414\n",
      "positions (x,y,z), reward: [ -2.35894739e-02  -3.49909474e-01   3.84147245e+01] 67.4501997828\n",
      "positions (x,y,z), reward: [  0.09252637  -2.71537068  81.55789794] 169.882979823\n",
      "positions (x,y,z), reward: [  0.25848378  -3.27133318  86.68212898] 177.063681291\n",
      "positions (x,y,z), reward: [  0.30555305  -3.41494839  87.82652646] 178.644548494\n",
      "positions (x,y,z), reward: [  1.10507399  -5.59054206  99.9668303 ] 194.347189763\n",
      "positions (x,y,z), reward: [   1.33651185   -6.18423571  102.29618342] 290.144402941\n",
      "positions (x,y,z), reward: [   3.33475383  -11.07502354  115.5824181 ] 262.581756309\n",
      "positions (x,y,z), reward: [   6.2867638   -17.98032411  127.10498653] 244.012590683\n",
      "positions (x,y,z), reward: [   7.67640132  -21.22173699  131.22419593] 239.496098465\n",
      "positions (x,y,z), reward: [  11.66343797  -30.75069678  140.647914  ] 232.135466452\n",
      "Episode =  203, score = 315.052 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  3.68152911e-07  -2.95621662e-07   2.00699900e+01] -5.66912636788\n",
      "positions (x,y,z), reward: [  0.11885448  -0.14320449  29.6783684 ] 13.8714653044\n",
      "positions (x,y,z), reward: [  0.43400924  -0.66003319  38.9246917 ] 66.8653181476\n",
      "positions (x,y,z), reward: [  1.08733878  -1.8803613   49.1389738 ] 116.577479599\n",
      "positions (x,y,z), reward: [  1.13429817  -1.97302573  49.69066028] 116.48674848\n",
      "positions (x,y,z), reward: [  3.87691014  -7.88293891  69.08547858] 157.232172777\n",
      "positions (x,y,z), reward: [  7.53659012 -16.12552705  82.30474884] 145.187228725\n",
      "positions (x,y,z), reward: [  8.57752566 -18.48008379  85.04235879] 144.691901052\n",
      "positions (x,y,z), reward: [ 10.06930943 -21.864508    88.45160617] 144.962505124\n",
      "positions (x,y,z), reward: [ 10.26380933 -22.30697533  88.85662015] 145.128581476\n",
      "positions (x,y,z), reward: [ 11.46676287 -25.05265116  91.17934141] 145.839658279\n",
      "positions (x,y,z), reward: [ 16.324683   -36.47996005  97.86237651] 143.943790607\n",
      "positions (x,y,z), reward: [ 16.55718823 -37.04932875  98.08865801] 143.686088928\n",
      "positions (x,y,z), reward: [ 18.89646455 -42.96776852  99.93657253] 140.269299282\n",
      "positions (x,y,z), reward: [  22.93101647  -54.56387858  101.17736292] 203.624739175\n",
      "positions (x,y,z), reward: [ 27.05589804 -71.97191461  97.877079  ] 90.1374229104\n",
      "positions (x,y,z), reward: [ 27.26322498 -73.38404821  97.35204186] 88.4109455682\n",
      "positions (x,y,z), reward: [ 27.53105736 -75.49799111  96.49485364] 85.7491726989\n",
      "Episode =  204, score = 232.485 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  2.35105804e-02   7.04598385e-03   2.79554846e+01] 12.7869707244\n",
      "positions (x,y,z), reward: [  2.65253069e-02   8.99509438e-03   2.92355590e+01] 13.79627003\n",
      "positions (x,y,z), reward: [  2.55294548e-02   2.66434180e-02   3.43667736e+01] 16.5331998506\n",
      "positions (x,y,z), reward: [  1.76655434e-02   4.00730863e-02   3.63623378e+01] 67.2218410651\n",
      "positions (x,y,z), reward: [ -0.32184504   0.37266481  53.00272373] 169.098027053\n",
      "positions (x,y,z), reward: [ -1.78363917   1.17005295  69.92671036] 167.530295452\n",
      "positions (x,y,z), reward: [ -2.79243189   1.54767355  75.62997716] 166.162515414\n",
      "positions (x,y,z), reward: [ -16.59940395    4.5351303   105.48592859] 267.080558822\n",
      "positions (x,y,z), reward: [ -17.81117194    4.7090355   106.9391845 ] 263.048696476\n",
      "positions (x,y,z), reward: [ -20.81572882    5.09576311  110.21487314] 254.361067087\n",
      "positions (x,y,z), reward: [ -32.24499448    6.08778508  119.61349573] 234.315849173\n",
      "positions (x,y,z), reward: [ -40.75506028    6.45906326  124.38951353] 229.484730656\n",
      "Episode =  205, score = 304.914 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -3.23714488e-06   4.62566273e-06   2.01242700e+01] -4.89828084849\n",
      "positions (x,y,z), reward: [  3.61375107e-03  -9.48715400e-04   2.29746499e+01] 6.21279193089\n",
      "positions (x,y,z), reward: [  0.5312998   -0.22757734  40.48896494] 67.5430293873\n",
      "positions (x,y,z), reward: [  1.41822148  -0.53023468  52.42941767] 167.780316489\n",
      "positions (x,y,z), reward: [  2.24982647  -0.68730216  60.26555995] 167.278078194\n",
      "positions (x,y,z), reward: [  4.145128    -0.74731128  73.37316353] 165.797452335\n",
      "positions (x,y,z), reward: [  4.34269677  -0.73878475  74.52101651] 165.62041075\n",
      "positions (x,y,z), reward: [  7.51246118  -0.41331989  89.97923899] 177.491799307\n",
      "positions (x,y,z), reward: [  9.37518712  -0.11602388  97.33949299] 186.671091892\n",
      "positions (x,y,z), reward: [  11.28853998    0.24314898  104.05524869] 282.186959909\n",
      "positions (x,y,z), reward: [  22.77369746    3.0845597   134.08766668] 244.661152045\n",
      "Episode =  206, score = 315.920 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  0.05780784  -0.03625416  27.95744645] 12.7291025707\n",
      "positions (x,y,z), reward: [  0.22454399  -0.29270046  37.89541231] 67.1972065679\n",
      "positions (x,y,z), reward: [  0.30070621  -0.46579307  41.55410863] 67.7386174175\n",
      "positions (x,y,z), reward: [  0.82253376  -2.46481963  64.65316404] 166.629836874\n",
      "positions (x,y,z), reward: [  1.07102     -4.69058018  80.8553176 ] 165.421456372\n",
      "positions (x,y,z), reward: [   1.24290716   -8.42792423  102.57491185] 286.270946765\n",
      "positions (x,y,z), reward: [   1.86325243  -16.04161276  136.24087404] 251.34530527\n",
      "positions (x,y,z), reward: [   1.99028603  -17.16295271  140.0482285 ] 249.98036522\n",
      "Episode =  207, score = 318.070 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -2.28053914e-02  -4.85744047e-02   2.96786483e+01] 14.0729537572\n",
      "positions (x,y,z), reward: [ -0.13254338  -0.69712     51.3226104 ] 118.79344889\n",
      "positions (x,y,z), reward: [ -0.15446047  -1.07762615  56.88449784] 168.72944376\n",
      "positions (x,y,z), reward: [  -4.55946665  -24.82319233  108.77484435] 253.114231653\n",
      "positions (x,y,z), reward: [  -6.50906806  -32.26502732  113.44493657] 239.684210978\n",
      "positions (x,y,z), reward: [ -14.28589121  -55.78117205  118.73872059] 182.607981438\n",
      "Episode =  208, score = 296.153 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  0.          0.         20.0077774] -7.22226017115\n",
      "positions (x,y,z), reward: [ -2.02182243e-08   4.26339487e-08   2.00311032e+01] -6.44516150043\n",
      "positions (x,y,z), reward: [  3.19365139e-04   3.16181541e-04   2.07695597e+01] -0.390142972622\n",
      "positions (x,y,z), reward: [  3.99632798e-03   8.10359573e-03   2.35692058e+01] 7.36229899589\n",
      "positions (x,y,z), reward: [ -0.07496396   0.18729738  34.37961347] 16.3421819066\n",
      "positions (x,y,z), reward: [ -0.22983662   0.41585952  39.99057954] 67.6111491126\n",
      "positions (x,y,z), reward: [ -0.43690135   0.70081732  44.79979738] 117.978808223\n",
      "positions (x,y,z), reward: [ -0.68941935   1.0351422   49.18420726] 117.928173868\n",
      "positions (x,y,z), reward: [ -0.92549541   1.33736132  52.52132964] 167.684959421\n",
      "positions (x,y,z), reward: [ -1.10731313   1.56342164  54.76395594] 167.435606855\n",
      "positions (x,y,z), reward: [ -2.38135507   2.99049138  66.11825066] 165.202397196\n",
      "positions (x,y,z), reward: [ -3.19382958   3.79393275  71.26703072] 163.625807253\n",
      "positions (x,y,z), reward: [ -5.18967405   5.57570867  80.97002879] 161.089422168\n",
      "positions (x,y,z), reward: [ -19.02326698   15.12006311  115.38740837] 239.239659197\n",
      "positions (x,y,z), reward: [ -20.94291624   16.21234759  118.28339991] 232.146002616\n",
      "positions (x,y,z), reward: [ -24.05465726   17.89688681  122.46446009] 226.742225576\n",
      "positions (x,y,z), reward: [ -32.85751981   22.18121386  131.70314297] 221.193145735\n",
      "Episode =  209, score = 298.784 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -4.85737227e-01  -3.59129819e-02   4.64037986e+01] 118.704239668\n",
      "positions (x,y,z), reward: [ -1.38080268  -0.17854823  57.48295083] 168.467644771\n",
      "positions (x,y,z), reward: [ -2.01341638  -0.30053982  62.54267776] 167.855006755\n",
      "positions (x,y,z), reward: [ -5.05506324  -0.92927128  77.7536907 ] 164.028958441\n",
      "positions (x,y,z), reward: [ -6.9324993   -1.28789292  83.88292113] 167.262439443\n",
      "positions (x,y,z), reward: [-11.00163261  -1.95732766  93.66016108] 176.068514414\n",
      "positions (x,y,z), reward: [ -14.71371169   -2.47461697  100.41209286] 279.551675587\n",
      "positions (x,y,z), reward: [ -29.42641476   -4.07897134  119.10421935] 240.739976764\n",
      "positions (x,y,z), reward: [ -35.56019896   -4.63246914  124.96607618] 237.779667646\n",
      "positions (x,y,z), reward: [ -41.23623835   -5.0954878   129.77584446] 236.574314203\n",
      "positions (x,y,z), reward: [ -44.74441446   -5.35713979  132.50453944] 235.932624181\n",
      "Episode =  210, score = 307.253 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  2.65715004e-03   4.12844129e-03   2.35691145e+01] 7.36772140542\n",
      "positions (x,y,z), reward: [  8.94255128e-03   1.68693990e-02   2.56015962e+01] 10.3758606666\n",
      "positions (x,y,z), reward: [  0.04530123   0.12278333  32.44335958] 15.5929800527\n",
      "positions (x,y,z), reward: [ -0.63743705   1.14373836  55.86945161] 168.437653078\n",
      "positions (x,y,z), reward: [ -1.57145913   1.67601582  62.7004773 ] 167.373724184\n",
      "positions (x,y,z), reward: [ -1.90315395   1.83093644  64.42057325] 166.936265819\n",
      "positions (x,y,z), reward: [ -4.5236295    2.79424194  73.58557283] 163.094443025\n",
      "positions (x,y,z), reward: [ -5.67556597   3.13150008  76.41516797] 161.318412053\n",
      "positions (x,y,z), reward: [ -8.18415025   3.75331367  81.41614255] 159.541235243\n",
      "positions (x,y,z), reward: [-12.40449753   4.54246599  87.8161345 ] 162.647216013\n",
      "positions (x,y,z), reward: [-16.6500611    5.08619167  92.84265935] 163.864472027\n",
      "positions (x,y,z), reward: [ -27.38303194    5.6089381   102.31521802] 263.601967319\n",
      "positions (x,y,z), reward: [ -50.2640441     3.59690703  114.82725242] 238.910027181\n",
      "positions (x,y,z), reward: [ -56.27539146    2.46271145  116.92555635] 234.694074412\n",
      "positions (x,y,z), reward: [ -60.33185304    1.56835816  118.1015162 ] 232.318981291\n",
      "positions (x,y,z), reward: [ -61.69028087    1.24613823  118.45312267] 231.607133992\n",
      "Episode =  211, score = 298.843 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  1.49371165e-02  -6.64660186e-04   2.45398439e+01] 8.94151127226\n",
      "positions (x,y,z), reward: [  7.38711634e-02  -1.89805503e-02   3.29152199e+01] 15.8719194437\n",
      "positions (x,y,z), reward: [  0.20843329  -0.10716517  45.29886356] 118.709777068\n",
      "positions (x,y,z), reward: [  0.27428147  -0.1349018   49.11070287] 118.995969989\n",
      "positions (x,y,z), reward: [  1.27425467  -0.13110538  75.39573777] 168.819354745\n",
      "positions (x,y,z), reward: [  1.85944234e+00  -7.69783624e-02   8.38700251e+01] 174.131093385\n",
      "positions (x,y,z), reward: [  3.48507299e+00   2.79364096e-02   1.00282897e+02] 296.41990835\n",
      "positions (x,y,z), reward: [  4.40005105e+00   6.21545914e-02   1.07101145e+02] 285.346642487\n",
      "positions (x,y,z), reward: [  5.89399782e+00   7.36694125e-02   1.16230914e+02] 270.280425894\n",
      "Episode =  212, score = 325.804 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -2.05585776e-03   1.36072273e-03   2.24317502e+01] 5.0187813476\n",
      "positions (x,y,z), reward: [ -1.39947805e-02   1.59602290e-02   2.59736008e+01] 10.8129640992\n",
      "positions (x,y,z), reward: [ -0.05442491   0.08771182  31.96692542] 15.3685744007\n",
      "positions (x,y,z), reward: [ -0.05869969   0.09599097  32.43951456] 15.5916268755\n",
      "positions (x,y,z), reward: [ -0.40033399   0.72665416  49.68888817] 118.448325299\n",
      "positions (x,y,z), reward: [ -0.47886909   0.86477242  51.90300867] 118.424549175\n",
      "positions (x,y,z), reward: [ -0.61551467   1.10244098  55.25065514] 168.295613984\n",
      "positions (x,y,z), reward: [ -1.63830232   2.95715609  72.87122425] 166.159561048\n",
      "positions (x,y,z), reward: [ -1.71786884   3.11625975  74.02252922] 165.968536434\n",
      "positions (x,y,z), reward: [ -3.40548794   7.4228775   97.00046034] 186.959448059\n",
      "positions (x,y,z), reward: [  -3.66740462    8.3131072   100.65534419] 289.660215118\n",
      "positions (x,y,z), reward: [  -4.46486985   11.76540484  113.16582425] 268.005680412\n",
      "positions (x,y,z), reward: [  -5.10505777   16.43905923  127.68060615] 254.528546323\n",
      "positions (x,y,z), reward: [  -5.61388881   24.06885219  149.80346226] 203.792608834\n",
      "Episode =  213, score = 312.147 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -3.70598273e-02  -2.41944665e-02   2.75471197e+01] 12.401520054\n",
      "positions (x,y,z), reward: [ -0.06434977  -0.0965954   35.86618937] 16.9607322858\n",
      "positions (x,y,z), reward: [ -0.06352391  -0.10545104  36.87739623] 67.2646908015\n",
      "positions (x,y,z), reward: [ -0.06162284  -0.1141879   37.9004704 ] 67.5393169737\n",
      "positions (x,y,z), reward: [  0.15323486  -0.17287053  55.76820538] 169.53013097\n",
      "positions (x,y,z), reward: [  0.21664689  -0.15559871  58.55978752] 169.597949739\n",
      "positions (x,y,z), reward: [  4.83946759e-01  -1.30485247e-02   6.81182518e+01] 169.730483003\n",
      "positions (x,y,z), reward: [  1.33340796   1.25595132  94.28712143] 189.574793902\n",
      "positions (x,y,z), reward: [  1.39119288   1.49887947  97.16588979] 193.695068201\n",
      "positions (x,y,z), reward: [  -2.9091744     9.43892671  143.82901707] 262.910410704\n",
      "Episode =  214, score = 326.551 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  1.85033352e-05  -1.76014409e-05   2.02792000e+01] -3.36337846193\n",
      "positions (x,y,z), reward: [  2.74545652e-04  -4.20371692e-04   2.09295737e+01] 0.333558119786\n",
      "positions (x,y,z), reward: [  0.15655279  -0.25499291  34.37242795] 16.1729291361\n",
      "positions (x,y,z), reward: [  1.03963679  -1.55502711  54.09460255] 167.19581228\n",
      "positions (x,y,z), reward: [  1.62426418  -2.28373077  61.36506211] 166.192841753\n",
      "positions (x,y,z), reward: [  1.67613655  -2.34497773  61.92726352] 166.096078164\n",
      "positions (x,y,z), reward: [  5.8801424   -6.39815389  91.33733091] 175.060346161\n",
      "positions (x,y,z), reward: [   8.29074673   -8.30901986  102.1259776 ] 280.662995513\n",
      "positions (x,y,z), reward: [  10.42962587   -9.86246978  110.10027693] 265.049873846\n",
      "positions (x,y,z), reward: [  10.92915187  -10.21034852  111.80987354] 261.63700418\n",
      "positions (x,y,z), reward: [  13.84368209  -12.15447008  120.92192076] 244.456861451\n",
      "positions (x,y,z), reward: [  21.79891543  -16.99444103  140.88321727] 233.608438142\n",
      "positions (x,y,z), reward: [  22.8497123   -17.60362991  143.17217352] 233.014533993\n",
      "positions (x,y,z), reward: [  23.65620651  -18.06819501  144.88981506] 232.565823777\n",
      "Episode =  215, score = 307.590 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  2.21971255e-02  -3.34650983e-02   2.63557187e+01] 11.2130811667\n",
      "positions (x,y,z), reward: [  0.0269428   -0.03815721  26.74525297] 11.6163636794\n",
      "positions (x,y,z), reward: [  0.45061222  -0.55482448  41.02725171] 67.3999141786\n",
      "positions (x,y,z), reward: [  1.02402796  -1.43199251  51.32730934] 117.140769372\n",
      "positions (x,y,z), reward: [  1.33525409  -1.97631757  55.76220841] 166.503014299\n",
      "positions (x,y,z), reward: [  2.52841435  -4.44492303  69.16474876] 162.916774375\n",
      "positions (x,y,z), reward: [  5.32502427 -12.15957835  88.69488145] 163.046812936\n",
      "positions (x,y,z), reward: [  5.63460907 -13.12607004  90.21106721] 163.555691408\n",
      "positions (x,y,z), reward: [   9.68884251  -26.56201207  103.39312906] 253.729324352\n",
      "positions (x,y,z), reward: [   9.84734566  -27.09247117  103.72007706] 252.717450487\n",
      "positions (x,y,z), reward: [  12.8472074   -36.82494535  108.09034374] 236.358364562\n",
      "Episode =  216, score = 281.856 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  1.30251117e-03   4.17375180e-04   2.12908392e+01] 1.73749671015\n",
      "positions (x,y,z), reward: [  3.12425301e-02   7.98163272e-03   2.48835736e+01] 9.40941830025\n",
      "positions (x,y,z), reward: [  0.36251988   0.10192319  34.86215158] 16.2932553434\n",
      "positions (x,y,z), reward: [  0.60607886   0.17556876  38.92671395] 67.1862128689\n",
      "positions (x,y,z), reward: [  1.16544623   0.360008    45.85270121] 117.655294532\n",
      "positions (x,y,z), reward: [  1.80143296   0.59442857  51.90215167] 117.365638593\n",
      "positions (x,y,z), reward: [  2.7501512    0.97915772  59.17839476] 166.436487308\n",
      "positions (x,y,z), reward: [  2.83221345   1.01393862  59.74197599] 166.341820096\n",
      "positions (x,y,z), reward: [  3.26255792   1.19952429  62.56612136] 165.825367928\n",
      "positions (x,y,z), reward: [  3.35269383   1.239025    63.13209483] 165.713574019\n",
      "positions (x,y,z), reward: [  4.22690306   1.6316806   68.23996856] 164.577788061\n",
      "positions (x,y,z), reward: [  4.65279415   1.82833971  70.51666915] 163.994893104\n",
      "positions (x,y,z), reward: [  4.87451956   1.93192334  71.65603468] 163.682682111\n",
      "positions (x,y,z), reward: [  6.45940079   2.69279066  79.06559317] 161.32616468\n",
      "positions (x,y,z), reward: [  8.75624682   3.8437747   88.14861606] 169.869238582\n",
      "positions (x,y,z), reward: [  12.53489092    5.8114968   100.42557106] 280.5105721\n",
      "positions (x,y,z), reward: [  13.49409656    6.32146176  103.16518163] 274.731381432\n",
      "positions (x,y,z), reward: [  14.69668437    6.96614882  106.42606618] 267.748519476\n",
      "positions (x,y,z), reward: [  19.87248191    9.79999932  118.65424219] 240.453394587\n",
      "positions (x,y,z), reward: [  32.85874262   17.05854621  140.73004699] 228.763111377\n",
      "positions (x,y,z), reward: [  34.2596606    17.83506031  142.62412467] 227.6891719\n",
      "Episode =  217, score = 304.938 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -3.71001693e-03  -1.20405378e-03   2.21773774e+01] 4.38729448668\n",
      "positions (x,y,z), reward: [ -2.57603144e-02  -1.12109813e-02   2.71404303e+01] 12.0454925003\n",
      "positions (x,y,z), reward: [ -3.70038974e-02  -2.05841778e-02   2.92398297e+01] 13.7892238563\n",
      "positions (x,y,z), reward: [ -0.04990374  -0.03489861  31.49817409] 15.1834340815\n",
      "positions (x,y,z), reward: [ -0.44046012  -0.75799963  59.65734534] 168.753326028\n",
      "positions (x,y,z), reward: [ -1.10679648  -2.37986785  79.36635911] 166.824055055\n",
      "positions (x,y,z), reward: [  -3.35849778   -7.64183949  103.58990167] 283.294669537\n",
      "positions (x,y,z), reward: [  -4.44336995   -9.68882472  109.63107753] 270.631780392\n",
      "positions (x,y,z), reward: [  -7.78999984  -14.83444485  121.83365767] 245.058963909\n",
      "positions (x,y,z), reward: [  -8.16130502  -15.33715359  122.85785503] 244.007144761\n",
      "positions (x,y,z), reward: [  -8.94668842  -16.37010122  124.88405933] 241.804729006\n",
      "positions (x,y,z), reward: [ -16.50943415  -25.00166512  138.3799197 ] 226.428191176\n",
      "Episode =  218, score = 311.774 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  1.42088163e-03   1.81728243e-03   2.12904010e+01] 1.73242077199\n",
      "positions (x,y,z), reward: [  1.48991231e-02   2.00873441e-02   2.42037408e+01] 8.40293223774\n",
      "positions (x,y,z), reward: [  0.36419063   4.96064707  77.72182064] 169.763246666\n",
      "positions (x,y,z), reward: [  0.38449555   5.25859915  79.05419308] 169.865709021\n",
      "positions (x,y,z), reward: [   1.13109391   11.68165345  101.96320548] 301.256716418\n",
      "positions (x,y,z), reward: [   1.32643487   12.94808093  105.68066975] 297.163341753\n",
      "positions (x,y,z), reward: [   1.68592643   15.15746529  111.75907192] 291.083878622\n",
      "positions (x,y,z), reward: [   2.31341129   18.89331903  121.13513932] 285.16743363\n",
      "positions (x,y,z), reward: [   3.63912951   27.37081201  139.8140009 ] 314.111931666\n",
      "Episode =  219, score = 383.167 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  2.51633285e-03   2.40455882e-03   2.21771900e+01] 4.38854482442\n",
      "positions (x,y,z), reward: [  3.85449284e-03   3.81498973e-03   2.26978809e+01] 5.62520690298\n",
      "positions (x,y,z), reward: [  0.09724321   0.06425988  35.86326096] 16.9498287599\n",
      "positions (x,y,z), reward: [  0.11579517   0.07158887  37.38397383] 67.3799765068\n",
      "positions (x,y,z), reward: [  1.18979862   0.50215301  65.38087841] 168.805780835\n",
      "positions (x,y,z), reward: [  5.48435947   3.19705017  98.30137713] 191.179781246\n",
      "positions (x,y,z), reward: [   9.02812145    5.57859752  113.95598367] 268.924977688\n",
      "positions (x,y,z), reward: [   9.53503605    5.91805574  115.9150061 ] 265.50247196\n",
      "positions (x,y,z), reward: [  20.31303564   13.0421315   155.85746415] 206.718004208\n",
      "Episode =  220, score = 311.001 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -1.50217287e-04  -5.29956921e-04   2.11032232e+01] 1.04367332782\n",
      "positions (x,y,z), reward: [ -6.53412793e-03  -7.46614046e-03   2.42064404e+01] 8.43285500163\n",
      "positions (x,y,z), reward: [ -8.16689665e-03  -8.86284351e-03   2.45405136e+01] 8.94223256976\n",
      "positions (x,y,z), reward: [ -0.0944302   -0.06784027  31.03572355] 14.8321847672\n",
      "positions (x,y,z), reward: [ -0.13003512  -0.08955859  32.43825421] 15.5166336873\n",
      "positions (x,y,z), reward: [ -0.41084035  -0.25806318  39.45139614] 67.4207561848\n",
      "positions (x,y,z), reward: [ -0.86660102  -0.53910029  46.39529535] 117.793854848\n",
      "positions (x,y,z), reward: [ -1.61156397  -1.00744875  54.10524267] 167.170134393\n",
      "positions (x,y,z), reward: [ -3.32859883  -2.08548758  65.83941297] 164.562607465\n",
      "positions (x,y,z), reward: [ -3.63878006  -2.27982413  67.51761213] 164.038906663\n",
      "positions (x,y,z), reward: [ -4.67488893  -2.92769878  72.54097344] 162.237757829\n",
      "positions (x,y,z), reward: [ -5.18769586  -3.24767421  74.76509123] 161.322999606\n",
      "positions (x,y,z), reward: [ -8.57056337  -5.37298462  86.83203005] 165.323594629\n",
      "positions (x,y,z), reward: [ -9.4649866   -5.94567619  89.52286504] 167.667115132\n",
      "positions (x,y,z), reward: [-10.59441522  -6.67748952  92.7206238 ] 170.306740162\n",
      "positions (x,y,z), reward: [ -27.57605208  -18.79130504  128.62112891] 228.917652318\n",
      "positions (x,y,z), reward: [ -35.24095108  -24.6895083   141.8953564 ] 232.66090369\n",
      "Episode =  221, score = 300.231 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -8.52941797e-09   8.81176715e-09   2.00310976e+01] -6.44543863328\n",
      "positions (x,y,z), reward: [ -2.27031516e-03  -2.67470339e-03   2.17064562e+01] 3.0813608398\n",
      "positions (x,y,z), reward: [ -0.0986298   -0.15884049  29.23035046] 13.5543582076\n",
      "positions (x,y,z), reward: [ -0.26593306  -0.43727141  34.84809285] 16.0271636118\n",
      "positions (x,y,z), reward: [ -0.38860577  -0.63907581  37.87478968] 66.637015785\n",
      "positions (x,y,z), reward: [ -4.87683112  -9.2791763   81.57642709] 157.109881165\n",
      "positions (x,y,z), reward: [ -4.97632316  -9.48626868  82.11407358] 157.558582843\n",
      "positions (x,y,z), reward: [ -15.2840913   -30.10885738  111.08650373] 237.181241079\n",
      "positions (x,y,z), reward: [ -26.47693444  -48.37922738  118.99730349] 208.7096058\n",
      "Episode =  222, score = 285.842 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -0.03152937  -0.09681296  27.9623538 ] 12.6968129291\n",
      "positions (x,y,z), reward: [ -0.04456943  -0.1405214   29.24308885] 13.6486364028\n",
      "positions (x,y,z), reward: [ -0.20903599  -0.83980137  38.9319183 ] 66.9100754753\n",
      "positions (x,y,z), reward: [ -0.95295491  -5.5341869   58.99622443] 162.736059735\n",
      "positions (x,y,z), reward: [ -1.07282983  -6.42073303  61.16642572] 161.509248149\n",
      "positions (x,y,z), reward: [ -1.20088483  -7.39199265  63.3162266 ] 160.121890037\n",
      "positions (x,y,z), reward: [ -1.26804478  -7.90976343  64.38180696] 159.36856205\n",
      "positions (x,y,z), reward: [ -2.01358055 -13.8865585   74.06697691] 150.317590985\n",
      "positions (x,y,z), reward: [ -4.05711407 -30.62402186  89.98331246] 150.330353568\n",
      "positions (x,y,z), reward: [  -6.50410084  -51.37613777  100.3949679 ] 254.816758452\n",
      "positions (x,y,z), reward: [  -6.57076607  -51.96002543  100.59132056] 254.250612195\n",
      "positions (x,y,z), reward: [  -6.97298839  -55.50083029  101.68312292] 250.970616077\n",
      "positions (x,y,z), reward: [  -7.72480239  -62.16726123  103.29565654] 245.497007269\n",
      "positions (x,y,z), reward: [  -7.93540311  -64.02859617  103.64740187] 244.129886599\n",
      "positions (x,y,z), reward: [  -8.98635371  -73.023466    104.79454339] 238.466673363\n",
      "positions (x,y,z), reward: [  -9.23420378  -75.03567452  104.93632015] 237.405177441\n",
      "Episode =  223, score = 271.080 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -3.99416497e-03  -2.56991523e-02   2.67404730e+01] 11.6413761071\n",
      "positions (x,y,z), reward: [ -1.54546168e-02  -9.23748670e-02   3.05733984e+01] 14.6177781782\n",
      "positions (x,y,z), reward: [ -0.25486357  -0.99607331  51.31131099] 118.335154992\n",
      "positions (x,y,z), reward: [ -1.22395388  -2.20397934  69.19726246] 166.724017984\n",
      "positions (x,y,z), reward: [ -1.42859853  -2.38738342  71.45060405] 166.358625733\n",
      "positions (x,y,z), reward: [ -3.65678555  -3.84259537  86.69623424] 172.76110742\n",
      "positions (x,y,z), reward: [ -4.16856395  -4.09113435  88.95312893] 175.341818989\n",
      "positions (x,y,z), reward: [  -8.35370869   -5.61420312  101.17694659] 283.314772824\n",
      "positions (x,y,z), reward: [ -27.44317436   -9.58742134  123.30165351] 230.120450045\n",
      "positions (x,y,z), reward: [ -40.56475133  -11.39967277  130.06015943] 222.185212362\n",
      "Episode =  224, score = 305.521 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -0.04509566   0.03040467  28.80546472] 13.4504749875\n",
      "positions (x,y,z), reward: [ -0.18456966   0.1186756   39.97902964] 67.9035986505\n",
      "positions (x,y,z), reward: [ -0.26583899   0.31001113  54.10943365] 169.272560981\n",
      "positions (x,y,z), reward: [ -0.14967401   0.49427819  61.99672299] 169.855471345\n",
      "positions (x,y,z), reward: [ -0.10090994   0.5463974   63.71236515] 170.021708609\n",
      "positions (x,y,z), reward: [ -0.08245832   0.56504325  64.28656809] 170.081258573\n",
      "positions (x,y,z), reward: [  2.75084025   2.86267162  93.95523979] 190.855467738\n",
      "positions (x,y,z), reward: [   4.64903926    4.36309462  104.28311078] 291.872464321\n",
      "positions (x,y,z), reward: [   4.79303519    4.47617629  104.99060647] 290.675421423\n",
      "positions (x,y,z), reward: [   5.23773229    4.82453795  107.12791437] 287.050970092\n",
      "positions (x,y,z), reward: [  14.58771708   11.20768152  143.23499402] 263.174977953\n",
      "positions (x,y,z), reward: [  24.95091535   14.35814881  179.02658424] 138.87250954\n",
      "Episode =  225, score = 305.423 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  2.51638145e-02  -7.12930314e-03   2.42067912e+01] 8.41321963885\n",
      "positions (x,y,z), reward: [  6.61900287e-02  -2.28309492e-02   2.71425365e+01] 11.9896353257\n",
      "positions (x,y,z), reward: [  0.11172661  -0.04167555  29.68127075] 13.995960758\n",
      "positions (x,y,z), reward: [  0.13916707  -0.05382969  31.0362134 ] 14.8049785975\n",
      "positions (x,y,z), reward: [  0.46284074  -0.30771043  44.22557371] 118.150340953\n",
      "positions (x,y,z), reward: [  0.64353342  -1.61726591  62.01252162] 168.16162802\n",
      "positions (x,y,z), reward: [  0.63263693  -1.69181511  62.58142241] 168.125088477\n",
      "positions (x,y,z), reward: [ -1.91075798  -7.98091908  87.53833833] 170.942997759\n",
      "positions (x,y,z), reward: [  -9.17867218  -21.22960483  112.35919286] 247.179883219\n",
      "Episode =  226, score = 302.418 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  6.05537453e-04  -2.33686960e-03   2.17075489e+01] 3.08936614368\n",
      "positions (x,y,z), reward: [ -0.08459579  -0.24420675  45.29996338] 118.720562311\n",
      "positions (x,y,z), reward: [ -2.80853371  -0.35911758  92.8528132 ] 186.313047659\n",
      "positions (x,y,z), reward: [ -2.87361976  -0.36813923  93.41691869] 187.087840242\n",
      "positions (x,y,z), reward: [ -3.52242179  -0.47135476  98.49555475] 193.965882659\n",
      "positions (x,y,z), reward: [  -6.78259409   -1.11215197  115.90881373] 268.06728861\n",
      "positions (x,y,z), reward: [ -15.47349687   -2.6943644   143.06573642] 250.205499218\n",
      "Episode =  227, score = 323.720 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -1.04809168e-07   1.70224081e-09   2.00310952e+01] -6.44556298608\n",
      "positions (x,y,z), reward: [  3.78026850e-07  -1.06414038e-07   2.00699365e+01] -5.67031971672\n",
      "positions (x,y,z), reward: [  0.18927586   0.08193959  32.91733067] 15.7035923559\n",
      "positions (x,y,z), reward: [  0.27990807   0.13033802  35.36656372] 16.5479495164\n",
      "positions (x,y,z), reward: [  0.54866089   0.27886203  40.51308792] 67.5661144516\n",
      "positions (x,y,z), reward: [  5.54376174   3.06737441  72.63470859] 165.775762404\n",
      "positions (x,y,z), reward: [  6.6059559    3.69008692  76.57504421] 164.982412235\n",
      "positions (x,y,z), reward: [  6.98659972   3.91703477  77.91262035] 164.684627634\n",
      "positions (x,y,z), reward: [ 11.72174314   6.97536421  92.79619538] 180.043324625\n",
      "positions (x,y,z), reward: [  15.76507593   10.12492582  104.68932678] 281.229534008\n",
      "positions (x,y,z), reward: [  26.4398088    23.08218711  140.67166428] 279.117059516\n",
      "positions (x,y,z), reward: [  31.0725113    31.87907512  161.90032573] 225.661516165\n",
      "Episode =  228, score = 374.266 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  8.94628240e-04   4.63904707e-04   2.21764983e+01] 4.38409863749\n",
      "positions (x,y,z), reward: [  0.18078356   0.04792621  36.35957164] 67.0384730562\n",
      "positions (x,y,z), reward: [  5.27200305e-01  -3.63016277e-03   4.58439509e+01] 118.625780854\n",
      "positions (x,y,z), reward: [  0.8641483   -0.152189    51.89430777] 118.781045036\n",
      "positions (x,y,z), reward: [  0.90054001  -0.17226975  52.45087495] 168.773542993\n",
      "positions (x,y,z), reward: [  1.86915825  -0.90554167  63.75461454] 167.810202004\n",
      "positions (x,y,z), reward: [  2.4037138   -1.43411272  68.34367322] 166.909963525\n",
      "positions (x,y,z), reward: [  3.97235126  -3.30939659  78.7003047 ] 163.390369457\n",
      "positions (x,y,z), reward: [  4.9687521   -4.65902444  83.84122385] 166.547642711\n",
      "positions (x,y,z), reward: [  6.26061066  -6.50882964  89.48229012] 171.410203448\n",
      "positions (x,y,z), reward: [  14.0135759   -18.49435908  111.5595682 ] 246.245185213\n",
      "positions (x,y,z), reward: [  14.7206207   -19.62305026  112.99441313] 241.880782822\n",
      "positions (x,y,z), reward: [  21.18703632  -30.13102746  123.63248218] 222.549339909\n",
      "positions (x,y,z), reward: [  24.71089989  -36.00402346  127.99202589] 221.040893037\n",
      "positions (x,y,z), reward: [  31.68225758  -47.80196609  134.39765986] 218.464041055\n",
      "Episode =  229, score = 299.362 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -0.11433754  -0.05112436  28.79984447] 13.3352146647\n",
      "positions (x,y,z), reward: [ -0.73368295  -0.16710634  41.01290818] 67.498436931\n",
      "positions (x,y,z), reward: [ -3.84927067   0.20668594  63.65662042] 166.251265141\n",
      "positions (x,y,z), reward: [-11.79133998   1.98551586  88.43078711] 168.332540832\n",
      "positions (x,y,z), reward: [-13.26140615   2.3228496   91.70734072] 171.118286225\n",
      "positions (x,y,z), reward: [ -21.16476728    4.1695816   106.43912461] 263.576294115\n",
      "Episode =  230, score = 304.577 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  4.37120618e-05   2.50336056e-05   2.02789844e+01] -3.36707325535\n",
      "positions (x,y,z), reward: [  1.70302905e-03   8.43353581e-04   2.12907443e+01] 1.73977234118\n",
      "positions (x,y,z), reward: [  1.69209421e-02   1.32173784e-02   2.45404536e+01] 8.93080230857\n",
      "positions (x,y,z), reward: [  0.20225599   0.5162641   46.9345658 ] 118.527612422\n",
      "positions (x,y,z), reward: [  0.26910526   2.52645254  72.77103491] 167.883643541\n",
      "positions (x,y,z), reward: [  0.30792101   3.95818543  83.17570585] 171.633318679\n",
      "positions (x,y,z), reward: [   0.12791361    9.91434257  111.18555756] 275.448836397\n",
      "positions (x,y,z), reward: [  -0.33634885   12.65228305  120.87425959] 259.256785695\n",
      "positions (x,y,z), reward: [  -1.65544811   16.94032989  134.09874215] 253.178077853\n",
      "positions (x,y,z), reward: [  -3.69417717   21.10340031  145.25720894] 247.13577262\n",
      "positions (x,y,z), reward: [  -4.71940531   22.73542928  149.25860239] 195.581628408\n",
      "positions (x,y,z), reward: [  -5.55874021   23.93100459  152.06775485] 194.300611516\n",
      "Episode =  231, score = 318.927 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -1.14161472e-03   5.50320883e-04   2.11026117e+01] 1.03805304101\n",
      "positions (x,y,z), reward: [ -0.09850727  -0.43879492  42.62574986] 68.1810262111\n",
      "positions (x,y,z), reward: [ -0.10464223  -0.73011671  46.95037184] 118.457520757\n",
      "positions (x,y,z), reward: [ -0.17316755  -2.90677965  63.10999796] 167.092183995\n",
      "positions (x,y,z), reward: [ -0.37387679  -5.10741489  71.55496128] 164.524042409\n",
      "positions (x,y,z), reward: [ -12.97974199  -59.28514457  111.58688526] 223.006600606\n",
      "positions (x,y,z), reward: [ -14.57028974  -65.05723901  111.62340277] 193.051018512\n",
      "positions (x,y,z), reward: [ -15.10930685  -66.98190141  111.54458694] 191.888369608\n",
      "positions (x,y,z), reward: [ -16.19882359  -70.82639915  111.25550798] 189.790833207\n",
      "Episode =  232, score = 290.643 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  2.74902697e-04   2.95756439e-03   2.19348029e+01] 3.74019848216\n",
      "positions (x,y,z), reward: [  3.93947475e-03   1.82483216e-02   2.52332995e+01] 9.89367083924\n",
      "positions (x,y,z), reward: [  4.17976975e-03   2.28723532e-01   4.10157188e+01] 68.1681110184\n",
      "positions (x,y,z), reward: [ -9.06315912e-03   3.87955957e-01   4.63810647e+01] 118.790033148\n",
      "positions (x,y,z), reward: [ -2.22771932e-02   5.14187321e-01   4.96634576e+01] 118.966320701\n",
      "positions (x,y,z), reward: [ -2.02039005   4.66048321  94.68282321] 185.466384564\n",
      "positions (x,y,z), reward: [ -2.15370898   4.81484333  95.80746231] 186.850152627\n",
      "positions (x,y,z), reward: [ -2.22262953   4.89274939  96.36953813] 187.537938708\n",
      "positions (x,y,z), reward: [  -7.092873      9.08832517  122.42565595] 253.047830848\n",
      "positions (x,y,z), reward: [  -8.61775116   10.21024862  128.39195646] 250.185597149\n",
      "positions (x,y,z), reward: [ -11.87706818   12.47477052  139.66113975] 244.308019375\n",
      "Episode =  233, score = 318.338 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -1.53909541e-05   8.00320440e-06   2.02789697e+01] -3.36706362525\n",
      "positions (x,y,z), reward: [ -3.52536613e-04   5.55151911e-05   2.12903510e+01] 1.73680908156\n",
      "positions (x,y,z), reward: [  1.93341697e-02   3.69887780e-02   3.43741911e+01] 16.5402346383\n",
      "positions (x,y,z), reward: [  0.08485438   0.11513209  41.03181237] 68.2176343228\n",
      "positions (x,y,z), reward: [  0.2531925    0.28058897  49.13593206] 118.954059248\n",
      "positions (x,y,z), reward: [  1.55359786   1.18180676  70.68872289] 168.570527954\n",
      "positions (x,y,z), reward: [  1.6719251    1.25522899  71.86388416] 168.509158328\n",
      "positions (x,y,z), reward: [  4.55735853   2.96372723  91.65039913] 184.800080296\n",
      "positions (x,y,z), reward: [  15.27804856   10.90511926  132.1510722 ] 264.235129707\n",
      "positions (x,y,z), reward: [  26.441899     23.31457061  164.65359954] 129.949589489\n",
      "positions (x,y,z), reward: [  34.88714835   35.93571595  187.26838084] 148.295073175\n",
      "Episode =  234, score = 307.383 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -3.10206716e-06  -4.31033225e-05   2.02789136e+01] -3.3699996411\n",
      "positions (x,y,z), reward: [ -4.26585220e-06  -1.82602109e-04   2.04942608e+01] -1.86678142112\n",
      "positions (x,y,z), reward: [  1.88629940e-03  -2.19108010e-02   2.38780447e+01] 7.87895776265\n",
      "positions (x,y,z), reward: [  0.12987235  -0.2996822   33.87647581] 15.9586390388\n",
      "positions (x,y,z), reward: [  0.66164886  -1.21417425  45.86306419] 117.347688877\n",
      "positions (x,y,z), reward: [  1.07213505  -1.96329157  51.37075669] 116.747478941\n",
      "positions (x,y,z), reward: [  2.45891268  -4.81763994  63.68191378] 162.613711011\n",
      "positions (x,y,z), reward: [  3.63773816  -7.47818932  70.85350214] 158.04378677\n",
      "positions (x,y,z), reward: [  4.05820081  -8.45671255  73.01324812] 156.296541348\n",
      "positions (x,y,z), reward: [  4.27867158  -8.97447656  74.08208274] 155.362558513\n",
      "positions (x,y,z), reward: [  7.44665098 -16.6435971   86.12546977] 150.345396261\n",
      "positions (x,y,z), reward: [  8.22521478 -18.57084309  88.40536309] 150.135709643\n",
      "positions (x,y,z), reward: [ 13.51149178 -31.80938196  99.50367584] 153.233785539\n",
      "positions (x,y,z), reward: [  21.6704762   -51.67883335  106.47560731] 226.139909908\n",
      "positions (x,y,z), reward: [  23.81861263  -56.58989316  106.85781596] 222.610064568\n",
      "positions (x,y,z), reward: [  25.77841819  -60.92855984  106.80568326] 194.125501419\n",
      "Episode =  235, score = 272.154 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [ -0.15927963  -0.11061132  31.4935731 ] 14.97528902\n",
      "positions (x,y,z), reward: [ -0.65613459  -0.55135389  42.60597337] 67.4362640619\n",
      "positions (x,y,z), reward: [ -0.87096486  -0.72109209  45.8306945 ] 117.480710807\n",
      "positions (x,y,z), reward: [ -1.03820489  -0.84166252  48.00610901] 117.416508713\n",
      "positions (x,y,z), reward: [ -1.87763999  -1.32319328  56.28733131] 166.635578842\n",
      "positions (x,y,z), reward: [ -7.0654424   -2.68488781  80.9068697 ] 161.402837827\n",
      "positions (x,y,z), reward: [ -28.48424402   -3.94335461  124.52011749] 243.240616398\n",
      "positions (x,y,z), reward: [ -30.17696692   -3.91464367  127.04904856] 243.475807486\n",
      "positions (x,y,z), reward: [ -34.1197139    -3.73808305  132.72624002] 244.568060662\n",
      "positions (x,y,z), reward: [ -37.2130908    -3.4740041   137.02115918] 245.947079157\n",
      "positions (x,y,z), reward: [ -38.43106455   -3.33691462  138.68259059] 246.608183786\n",
      "Episode =  236, score = 308.431 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  8.19334361e-06   1.24826732e-05   2.01940958e+01] -4.12784418644\n",
      "positions (x,y,z), reward: [  0.10148538   0.1917895   34.37719326] 16.2937728314\n",
      "positions (x,y,z), reward: [  0.16466701   0.2901277   37.38998675] 67.1226782333\n",
      "positions (x,y,z), reward: [  0.29831886   0.48166593  42.09292892] 67.8191944391\n",
      "positions (x,y,z), reward: [  0.39403591   0.61077506  44.77361285] 117.99084055\n",
      "positions (x,y,z), reward: [   9.17941006    9.82556173  106.10060244] 275.393460964\n",
      "positions (x,y,z), reward: [  14.7858513    14.69271782  123.01770834] 246.441590383\n",
      "positions (x,y,z), reward: [  20.62582336   18.99138345  137.39723933] 241.602724356\n",
      "positions (x,y,z), reward: [  20.95989598   19.21598576  138.17287017] 241.731097364\n",
      "Episode =  237, score = 301.062 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  8.99030676e-06  -8.30943897e-06   2.01939612e+01] -4.13066768522\n",
      "positions (x,y,z), reward: [  3.15843949e-04  -1.44560494e-04   2.07694611e+01] -0.390763569212\n",
      "positions (x,y,z), reward: [  1.60109383e-02  -1.07733591e-02   2.45385901e+01] 8.93022069516\n",
      "positions (x,y,z), reward: [  0.04745557  -0.05097266  28.37892266] 13.083160614\n",
      "positions (x,y,z), reward: [  0.11522453  -0.18803706  34.86539115] 16.4666146213\n",
      "positions (x,y,z), reward: [  0.31773572  -1.17964511  56.85422901] 168.319697737\n",
      "positions (x,y,z), reward: [  0.34045263  -1.60866256  63.55263769] 168.034050932\n",
      "positions (x,y,z), reward: [  0.31577714  -2.09126618  70.28208551] 167.681675052\n",
      "positions (x,y,z), reward: [  0.28912347  -2.26386126  72.53100466] 167.57435525\n",
      "positions (x,y,z), reward: [  0.22298367  -2.53403851  75.91080988] 167.439070103\n",
      "positions (x,y,z), reward: [  6.97201009e-02  -2.91686358e+00   8.04307674e+01] 167.954018698\n",
      "positions (x,y,z), reward: [ -0.26104235  -3.4344695   86.10176337] 175.861607064\n",
      "positions (x,y,z), reward: [ -1.47088393  -4.52624388  96.91754126] 189.851151029\n",
      "positions (x,y,z), reward: [  -3.25282447   -5.51223056  106.01143756] 282.536110943\n",
      "positions (x,y,z), reward: [  -6.50195717   -6.69372551  116.70195901] 261.641855883\n",
      "positions (x,y,z), reward: [  -9.03106477   -7.37574258  122.79902626] 253.096189631\n",
      "positions (x,y,z), reward: [ -21.15641775   -9.92641001  142.43550039] 237.420312888\n",
      "Episode =  238, score = 317.596 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  0.31259642   0.49852616  44.77003544] 118.164345402\n",
      "positions (x,y,z), reward: [  0.6788271    1.46214897  62.47875099] 168.023066353\n",
      "positions (x,y,z), reward: [  0.69551623   1.63859112  64.73715711] 167.948823408\n",
      "positions (x,y,z), reward: [ -0.51004366   4.58422057  88.14875074] 179.744382669\n",
      "positions (x,y,z), reward: [ -0.59220461   4.69266527  88.76224673] 180.561904162\n",
      "positions (x,y,z), reward: [  -3.41716046    7.56760568  102.81341908] 290.213463908\n",
      "positions (x,y,z), reward: [  -4.58475944    8.50943005  106.88976025] 283.092143452\n",
      "positions (x,y,z), reward: [ -10.23668271   12.20538858  122.55317405] 260.471388354\n",
      "positions (x,y,z), reward: [ -15.91725703   15.20942414  136.16221162] 261.823401883\n",
      "positions (x,y,z), reward: [ -17.23541537   15.87433416  139.31083095] 262.902347062\n",
      "Episode =  239, score = 314.406 (best = 405.554), noise_scale = 0.1positions (x,y,z), reward: [  0.45099302  -0.35461249  44.7919368 ] 118.289058582\n",
      "positions (x,y,z), reward: [  0.73782433  -0.60973466  49.73280769] 118.417175537\n",
      "positions (x,y,z), reward: [  2.62880195  -2.45665306  67.00011327] 166.688277602\n",
      "positions (x,y,z), reward: [  6.08863526  -6.17796919  83.67688743] 167.421088707\n",
      "positions (x,y,z), reward: [ 10.37825304 -11.08056476  97.162456  ] 181.904514176\n",
      "positions (x,y,z), reward: [  12.41360436  -13.4540988   102.28640254] 280.348318268\n",
      "positions (x,y,z), reward: [  14.09847811  -15.42687074  106.14602664] 272.836521811\n",
      "positions (x,y,z), reward: [  18.25079079  -20.26189589  114.59569361] 257.251547564\n",
      "positions (x,y,z), reward: [ 111.61486014 -103.75834633  230.84522241] 976.954227073\n",
      "Episode =  240, score = 444.213 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  6.29342887e-03   1.19183248e-04   2.21770814e+01] 4.38583374509\n",
      "positions (x,y,z), reward: [  3.88312939e-02   7.28992272e-04   2.48828727e+01] 9.41213254859\n",
      "positions (x,y,z), reward: [  1.17340920e-01  -1.88438776e-03   2.83787786e+01] 13.0590904823\n",
      "positions (x,y,z), reward: [  3.70622214e-01  -3.32812281e-02   3.53599191e+01] 16.5258911295\n",
      "positions (x,y,z), reward: [  0.59701991  -0.07580624  39.96682295] 67.4920019619\n",
      "positions (x,y,z), reward: [  0.65472917  -0.08768866  41.01757498] 67.6270831772\n",
      "positions (x,y,z), reward: [  0.74624641  -0.10712717  42.60800513] 67.7848517918\n",
      "positions (x,y,z), reward: [  0.98243838  -0.15945521  46.37286265] 117.972355253\n",
      "positions (x,y,z), reward: [  1.05563803  -0.17596814  47.45957443] 117.987433193\n",
      "positions (x,y,z), reward: [  2.24132795  -0.40473433  61.83347958] 167.272402153\n",
      "positions (x,y,z), reward: [  7.96395085e+00   7.97320802e-02   9.69108128e+01] 189.440216758\n",
      "positions (x,y,z), reward: [  13.03581569    1.42698778  114.15283991] 267.689509704\n",
      "Episode =  241, score = 314.458 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.48130144  -0.18864235  42.6224825 ] 68.0016188452\n",
      "positions (x,y,z), reward: [ -0.59583483  -0.21942725  45.30910349] 118.227179337\n",
      "positions (x,y,z), reward: [ -1.25040424  -0.3602241   56.3126502 ] 168.224494561\n",
      "positions (x,y,z), reward: [ -2.9411658   -0.65699276  72.56109404] 166.490900522\n",
      "positions (x,y,z), reward: [ -3.34000813  -0.7271574   75.36975959] 166.013358957\n",
      "positions (x,y,z), reward: [ -8.09938299  -1.74375358  98.79457618] 187.924172921\n",
      "positions (x,y,z), reward: [ -15.24698538   -3.61616006  119.90293246] 249.644672284\n",
      "positions (x,y,z), reward: [ -17.69413518   -4.22367884  125.12453378] 245.895931813\n",
      "Episode =  242, score = 313.728 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.1742918    0.31575128  38.93976907] 67.4860897742\n",
      "positions (x,y,z), reward: [ -0.24037463   0.53023323  44.23725076] 118.146057203\n",
      "positions (x,y,z), reward: [ -0.2525166    0.57987158  45.31666875] 118.219609658\n",
      "positions (x,y,z), reward: [ -0.35868219   1.37844755  59.10355229] 168.157822129\n",
      "positions (x,y,z), reward: [ -0.37843203   1.70317891  63.57430644] 167.897633244\n",
      "positions (x,y,z), reward: [ -0.38884933   1.87905142  65.81394079] 167.737814031\n",
      "positions (x,y,z), reward: [ -0.41360943   2.20958503  69.73800511] 167.42334764\n",
      "positions (x,y,z), reward: [ -0.42327471   2.30947452  70.8601683 ] 167.324363292\n",
      "positions (x,y,z), reward: [ -0.44075313   2.4639206   72.5441574 ] 167.167597213\n",
      "positions (x,y,z), reward: [ -0.62064857   3.38221365  81.53881804] 168.441828266\n",
      "positions (x,y,z), reward: [ -0.73783572   3.76815766  84.91617263] 173.01716396\n",
      "positions (x,y,z), reward: [ -0.76048485   3.83471144  85.47916383] 173.772886508\n",
      "positions (x,y,z), reward: [ -0.86041227   4.10729853  87.73114205] 176.778001789\n",
      "positions (x,y,z), reward: [  -2.72112601    7.23034242  109.07584992] 276.398415839\n",
      "positions (x,y,z), reward: [  -4.36002064    9.06744977  119.09389   ] 257.595577\n",
      "positions (x,y,z), reward: [ -10.26525501   13.92071657  140.82436107] 244.356581741\n",
      "positions (x,y,z), reward: [ -11.48622079   14.71855433  143.99440835] 242.075191673\n",
      "Episode =  243, score = 318.813 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.02955944e-02  -3.36329185e-02   2.52351170e+01] 9.86823374158\n",
      "positions (x,y,z), reward: [ -0.30338621  -0.83300837  39.97021985] 67.0734689583\n",
      "positions (x,y,z), reward: [ -0.46688972  -1.25551189  43.69009318] 67.1501103531\n",
      "positions (x,y,z), reward: [ -2.56508928  -5.51732548  62.98025487] 161.489380475\n",
      "positions (x,y,z), reward: [ -2.67009376  -5.69994624  63.53151242] 161.165535394\n",
      "positions (x,y,z), reward: [ -3.76346445  -7.50056564  68.45074489] 157.800654202\n",
      "positions (x,y,z), reward: [ -8.38684449 -13.83492385  81.42709191] 146.461289425\n",
      "positions (x,y,z), reward: [ -9.36736154 -15.00167325  83.36921836] 146.669043123\n",
      "positions (x,y,z), reward: [-12.43514662 -18.38182087  88.46175295] 146.117227907\n",
      "positions (x,y,z), reward: [-13.05247974 -19.02001426  89.34484893] 145.837370824\n",
      "positions (x,y,z), reward: [-19.04122232 -24.65483855  96.24539295] 145.911907458\n",
      "positions (x,y,z), reward: [-19.43438865 -24.99471314  96.61517793] 145.862808098\n",
      "positions (x,y,z), reward: [ -32.64849392  -34.8672602   105.41729458] 235.757018144\n",
      "positions (x,y,z), reward: [ -45.75964672  -42.50794198  109.81724856] 223.738448684\n",
      "positions (x,y,z), reward: [ -58.43005168  -48.34303519  111.5392163 ] 216.36446363\n",
      "positions (x,y,z), reward: [ -62.24339468  -49.79839923  111.65460484] 204.735216202\n",
      "Episode =  244, score = 275.117 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.66242264e-03   1.20510840e-03   2.14931124e+01] 2.42522096134\n",
      "positions (x,y,z), reward: [  2.19985769e-01   3.12113236e-02   3.19656768e+01] 15.2463597897\n",
      "positions (x,y,z), reward: [  0.60200715   0.10884522  39.44826716] 67.3636860741\n",
      "positions (x,y,z), reward: [  1.20832041   0.29045368  47.4804233 ] 117.820225274\n",
      "positions (x,y,z), reward: [  2.58166222   0.86766686  60.26849254] 166.701727938\n",
      "positions (x,y,z), reward: [  5.77603806   2.73354765  80.29519949] 163.16363868\n",
      "positions (x,y,z), reward: [  7.95980434   4.22966307  90.39841862] 175.643023524\n",
      "positions (x,y,z), reward: [  8.10373339   4.33123951  91.00386434] 176.371620566\n",
      "positions (x,y,z), reward: [  10.48407152    6.02552085  100.2539618 ] 286.507919742\n",
      "positions (x,y,z), reward: [  11.74490085    6.91775412  104.69247844] 278.310612778\n",
      "positions (x,y,z), reward: [  16.62297595   10.18024008  119.99039032] 249.928738657\n",
      "positions (x,y,z), reward: [  19.63715037   11.97360067  128.56517547] 247.226149937\n",
      "positions (x,y,z), reward: [  28.45404828   15.79586222  153.0932306 ] 202.45702761\n",
      "Episode =  245, score = 301.110 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.758393     0.0660097   60.21596628] 169.156641684\n",
      "positions (x,y,z), reward: [ -1.72150268e+00   6.15623977e-02   7.37574237e+01] 168.612384734\n",
      "positions (x,y,z), reward: [ -2.04908203e+00   3.93658005e-02   7.65992936e+01] 168.343139946\n",
      "positions (x,y,z), reward: [ -4.32446302  -0.14515305  89.66286882] 180.29716848\n",
      "positions (x,y,z), reward: [ -5.77199561  -0.26400377  95.29455947] 186.922006045\n",
      "positions (x,y,z), reward: [  -7.55242205   -0.40394117  100.86318505] 290.380599224\n",
      "positions (x,y,z), reward: [  -7.75075755   -0.41897519  101.41546756] 289.291111858\n",
      "positions (x,y,z), reward: [ -11.47378059   -0.67846188  110.09007526] 271.239325177\n",
      "positions (x,y,z), reward: [ -17.31975432   -1.01710274  119.81195993] 248.409471284\n",
      "positions (x,y,z), reward: [ -25.72703176   -1.41025033  129.39536876] 241.508880342\n",
      "positions (x,y,z), reward: [ -27.56280048   -1.48561901  131.03651174] 240.591551467\n",
      "positions (x,y,z), reward: [ -31.96627514   -1.65479875  134.46613809] 238.285317491\n",
      "Episode =  246, score = 315.750 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.45948373e-04  -7.51878758e-05   2.04944362e+01] -1.86290819701\n",
      "positions (x,y,z), reward: [ -0.09733597  -0.04251544  28.37438817] 13.0283005241\n",
      "positions (x,y,z), reward: [ -0.83222488  -0.21580992  44.74197229] 117.88998016\n",
      "positions (x,y,z), reward: [ -0.90172863  -0.2231975   45.82221084] 117.942424847\n",
      "positions (x,y,z), reward: [ -1.29220563  -0.23968158  51.29003071] 118.038518582\n",
      "positions (x,y,z), reward: [ -2.3877968   -0.09244037  63.03374292] 167.835709529\n",
      "positions (x,y,z), reward: [ -6.60066568   1.60603108  89.3639906 ] 178.407025673\n",
      "positions (x,y,z), reward: [ -7.50323711   2.09690147  93.69523299] 184.263478935\n",
      "positions (x,y,z), reward: [ -8.61665042   2.76370758  98.79963648] 191.346977862\n",
      "positions (x,y,z), reward: [ -15.29950253    9.13452885  129.03562877] 266.496549366\n",
      "positions (x,y,z), reward: [ -21.38611305   25.4634665   177.4837679 ] 183.612577398\n",
      "Episode =  247, score = 366.065 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777782] -7.22221909869\n",
      "positions (x,y,z), reward: [ -1.76072681e-08   1.75141719e-07   2.00311049e+01] -6.44508115475\n",
      "positions (x,y,z), reward: [ -9.28458024e-04  -1.46018763e-03   2.12911246e+01] 1.73960870963\n",
      "positions (x,y,z), reward: [ -0.2562243   -0.49974198  38.92643679] 67.2063495157\n",
      "positions (x,y,z), reward: [ -0.83812541  -2.05140339  54.63695088] 166.829055972\n",
      "positions (x,y,z), reward: [ -2.76200862  -7.90514543  81.79362285] 161.37311029\n",
      "positions (x,y,z), reward: [  -5.52967467  -15.6578135   101.5202063 ] 274.264229484\n",
      "positions (x,y,z), reward: [  -6.34402093  -17.78621583  105.59477381] 264.657045204\n",
      "positions (x,y,z), reward: [ -10.51473128  -28.14750425  120.78153259] 233.436995824\n",
      "positions (x,y,z), reward: [ -18.86779652  -45.73564837  135.62981349] 217.503237187\n",
      "Episode =  248, score = 299.426 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.16845942e-02  -1.37484318e-02   2.55989883e+01] 10.3450558603\n",
      "positions (x,y,z), reward: [  3.49611140e-02  -1.53829629e-02   2.59712610e+01] 10.7864322417\n",
      "positions (x,y,z), reward: [  2.16634445e-01  -3.98363650e-02   4.63856559e+01] 118.900709978\n",
      "positions (x,y,z), reward: [   5.36950034   -1.62175225  105.24906487] 291.028731526\n",
      "positions (x,y,z), reward: [   5.50731163   -1.71821014  105.92818006] 289.891742153\n",
      "positions (x,y,z), reward: [  12.46327364   -8.85702245  137.44684442] 263.495219707\n",
      "positions (x,y,z), reward: [  14.90595573  -13.10646937  151.41000671] 215.203828674\n",
      "positions (x,y,z), reward: [  17.16028623  -19.9910383   171.90362279] 127.507959583\n",
      "Episode =  249, score = 308.968 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.75371405e-03  -4.05606775e-04   2.12911377e+01] 1.73958646948\n",
      "positions (x,y,z), reward: [ -1.74602111e-02  -5.99801574e-03   2.42062933e+01] 8.42306215153\n",
      "positions (x,y,z), reward: [ -0.0772646   -0.03964609  29.24264014] 13.7329001367\n",
      "positions (x,y,z), reward: [ -0.98155299  -0.81002329  49.15297201] 117.743587793\n",
      "positions (x,y,z), reward: [ -1.18319072  -0.98726355  51.36390182] 117.548148746\n",
      "positions (x,y,z), reward: [ -2.98797791  -2.55595532  64.25586204] 164.597111653\n",
      "positions (x,y,z), reward: [ -4.63109425  -3.95217883  71.55227989] 161.317584667\n",
      "positions (x,y,z), reward: [ -7.69587219  -6.46456669  80.89615787] 156.068687097\n",
      "positions (x,y,z), reward: [-12.0162018   -9.7757368   89.72973206] 159.68556292\n",
      "positions (x,y,z), reward: [-12.31317633  -9.99322166  90.22613543] 159.765916749\n",
      "positions (x,y,z), reward: [-18.11623105 -14.00123459  98.14868868] 158.792903378\n",
      "positions (x,y,z), reward: [ -34.91160113  -23.53211903  110.76647115] 228.853096885\n",
      "positions (x,y,z), reward: [ -43.40516734  -27.4171002   114.10501113] 220.080680124\n",
      "positions (x,y,z), reward: [ -48.2009423  -29.3698624  115.4375095] 216.226003081\n",
      "Episode =  250, score = 285.340 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.11662256e-04  -2.29109046e-04   2.11030164e+01] 1.04161515657\n",
      "positions (x,y,z), reward: [  4.19298468e-04  -2.75899654e-04   2.12908411e+01] 1.7394110486\n",
      "positions (x,y,z), reward: [  8.35527214e-02  -7.36706670e-03   2.92435926e+01] 13.7583949572\n",
      "positions (x,y,z), reward: [  2.00452587e-01  -3.04276580e-02   3.38878624e+01] 16.1699839196\n",
      "positions (x,y,z), reward: [  1.0566087   -0.41303887  51.87877207] 118.131154095\n",
      "positions (x,y,z), reward: [  1.62994421  -0.88465644  60.78019719] 167.472018115\n",
      "positions (x,y,z), reward: [  3.02128087  -3.54135227  81.66648717] 166.244249408\n",
      "positions (x,y,z), reward: [  3.55387551  -5.67501808  90.12536444] 175.966920706\n",
      "positions (x,y,z), reward: [  4.10497115  -8.90160284  98.9757612 ] 184.650288489\n",
      "positions (x,y,z), reward: [   4.66472016  -13.65528277  107.9653904 ] 267.222520495\n",
      "positions (x,y,z), reward: [   5.06498838  -18.33125907  114.34447456] 250.553437905\n",
      "positions (x,y,z), reward: [   5.09447534  -18.72811338  114.81213573] 249.246428149\n",
      "positions (x,y,z), reward: [   5.72076785  -30.22357774  125.19285617] 234.229022242\n",
      "positions (x,y,z), reward: [   5.82999586  -33.94678693  127.58358017] 232.324065152\n",
      "positions (x,y,z), reward: [   5.8838336   -37.30274836  129.42552795] 230.614831587\n",
      "positions (x,y,z), reward: [   5.89171804  -38.45408984  129.99461907] 230.031882226\n",
      "Episode =  251, score = 307.788 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.25679775e-07   1.05268967e-10   2.00310902e+01] -6.44581083284\n",
      "positions (x,y,z), reward: [ -1.60571058e-03  -5.72372109e-04   2.14918734e+01] 2.41937349178\n",
      "positions (x,y,z), reward: [ -3.23279014e-03  -1.69527542e-03   2.21768854e+01] 4.38730432564\n",
      "positions (x,y,z), reward: [ -3.29314872  -1.777516    68.0389948 ] 164.942402003\n",
      "positions (x,y,z), reward: [ -6.2624487   -4.71343732  87.01963258] 169.304604403\n",
      "positions (x,y,z), reward: [ -6.35685853  -4.82938749  87.57464922] 169.919520235\n",
      "positions (x,y,z), reward: [ -14.45260028  -19.01146169  134.32515593] 240.272954855\n",
      "Episode =  252, score = 306.810 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.15567235e-02   2.07411463e-02   2.63509364e+01] 11.2251228985\n",
      "positions (x,y,z), reward: [ -0.05398377   0.10618853  31.96030103] 15.3426093648\n",
      "positions (x,y,z), reward: [ -0.42042041   0.47655351  44.76063012] 118.093875796\n",
      "positions (x,y,z), reward: [ -0.47346692   0.51199014  45.84306359] 118.13883124\n",
      "positions (x,y,z), reward: [ -2.88523479   1.07305425  68.716307  ] 166.349395422\n",
      "positions (x,y,z), reward: [ -3.89747165   1.07957542  73.81277045] 165.318483439\n",
      "positions (x,y,z), reward: [ -6.53163206   0.85082227  83.94976712] 168.498906784\n",
      "positions (x,y,z), reward: [ -1.07976390e+01   1.63412381e-02   9.60704649e+01] 182.337936698\n",
      "positions (x,y,z), reward: [ -1.12375487e+01  -9.19142404e-02   9.71501734e+01] 183.334432533\n",
      "positions (x,y,z), reward: [-11.68551952  -0.20522882  98.22551551] 184.275396908\n",
      "positions (x,y,z), reward: [ -13.31503518   -0.63954485  101.9528357 ] 281.530289378\n",
      "positions (x,y,z), reward: [ -13.79780966   -0.77384055  103.00695899] 279.209314318\n",
      "positions (x,y,z), reward: [ -23.77132642   -3.83006874  121.08685343] 242.03619851\n",
      "positions (x,y,z), reward: [ -29.65204224   -5.703365    129.45395029] 238.933622937\n",
      "Episode =  253, score = 310.003 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.00782447e-04   2.25574797e-05   2.04941462e+01] -1.86634057327\n",
      "positions (x,y,z), reward: [ -5.30147987e-04   1.01463262e-05   2.07690055e+01] -0.396291303941\n",
      "positions (x,y,z), reward: [ -2.89571182e-02  -9.86303386e-03   2.59677125e+01] 10.7895032528\n",
      "positions (x,y,z), reward: [ -6.55654725e-02  -1.78945651e-02   2.92337408e+01] 13.7533779139\n",
      "positions (x,y,z), reward: [ -2.91505176e-01  -2.59243047e-02   3.99655134e+01] 67.867286897\n",
      "positions (x,y,z), reward: [ -0.64404298   0.11049342  51.8709718 ] 118.938038268\n",
      "positions (x,y,z), reward: [ -0.84343901   2.51231654  83.11936981] 175.522339023\n",
      "positions (x,y,z), reward: [   2.84547814    8.48595451  113.73426194] 282.491238126\n",
      "positions (x,y,z), reward: [   5.17370914   10.75854285  123.6265347 ] 273.862844143\n",
      "positions (x,y,z), reward: [  25.93003834   18.89943202  206.73518848] 253.180095991\n",
      "Episode =  254, score = 342.172 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.16072354  -0.04754552  33.39690395] 15.9671981608\n",
      "positions (x,y,z), reward: [  0.92990172   0.11031714  50.21168138] 118.429304048\n",
      "positions (x,y,z), reward: [  1.03187965   0.13387904  51.86294519] 118.403633199\n",
      "positions (x,y,z), reward: [  3.64441858e+00  -8.21141272e-02   8.61060533e+01] 175.871440278\n",
      "positions (x,y,z), reward: [  3.6910853   -0.11743792  86.67498277] 176.652212591\n",
      "positions (x,y,z), reward: [  3.83134584  -0.23412799  88.3828842 ] 178.983881531\n",
      "positions (x,y,z), reward: [  4.20662575  -0.63164104  92.94488905] 185.119061438\n",
      "positions (x,y,z), reward: [  4.25359485  -0.69102102  93.51583293] 185.875921304\n",
      "positions (x,y,z), reward: [  4.67639594  -1.33463412  98.65804928] 192.544729685\n",
      "positions (x,y,z), reward: [   5.82455482   -4.21032288  112.30890869] 271.672901586\n",
      "positions (x,y,z), reward: [   5.9236579    -4.54037315  113.43449968] 269.481760033\n",
      "positions (x,y,z), reward: [   5.97348526   -4.71116686  113.99614947] 268.378939844\n",
      "positions (x,y,z), reward: [   6.58521041   -7.07087238  120.66108882] 255.771432943\n",
      "positions (x,y,z), reward: [   7.22021841  -10.01119215  127.13909035] 251.270883908\n",
      "positions (x,y,z), reward: [   7.99424604  -14.14043317  134.37012224] 244.95782485\n",
      "positions (x,y,z), reward: [   8.05121505  -14.46291796  134.87089365] 244.466555659\n",
      "Episode =  255, score = 318.117 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -7.44600768e-04   3.59251379e-04   2.09291564e+01] 0.330000771072\n",
      "positions (x,y,z), reward: [ -1.10448163e-03   5.00361574e-04   2.11028747e+01] 1.03890344836\n",
      "positions (x,y,z), reward: [ -6.27956340e-03   1.70668615e-03   2.24314445e+01] 5.01070707573\n",
      "positions (x,y,z), reward: [ -0.21750595  -0.04820598  44.76693275] 118.71414934\n",
      "positions (x,y,z), reward: [ -0.2236046   -0.19405441  60.21638074] 169.541187288\n",
      "positions (x,y,z), reward: [  0.22000082  -1.4717545   88.98847615] 182.194935182\n",
      "positions (x,y,z), reward: [   0.69830286   -4.01481864  105.46580536] 287.397946503\n",
      "positions (x,y,z), reward: [   0.73624536   -4.27334085  106.59767531] 285.368911488\n",
      "Episode =  256, score = 322.926 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  6.06402797e-03   1.74980857e-03   2.24298311e+01] 5.00404676951\n",
      "positions (x,y,z), reward: [  2.79075774e-02   8.64507744e-03   2.52339083e+01] 9.88880595445\n",
      "positions (x,y,z), reward: [  1.29319414e-01   2.24003243e-02   3.19618451e+01] 15.3607979043\n",
      "positions (x,y,z), reward: [  0.38135128  -0.05968471  43.68717888] 68.3953425017\n",
      "positions (x,y,z), reward: [  0.55400224  -0.24261319  52.42560341] 168.866708363\n",
      "positions (x,y,z), reward: [  0.85805132  -1.22639691  74.81808887] 168.041651026\n",
      "positions (x,y,z), reward: [  1.4174662   -2.86910435  97.89235282] 192.743533589\n",
      "positions (x,y,z), reward: [   1.69489601   -3.39940529  105.24018025] 287.387603897\n",
      "positions (x,y,z), reward: [   1.78988487   -3.55471805  107.51073437] 283.805604764\n",
      "positions (x,y,z), reward: [   2.24911677   -4.17771646  117.83645328] 267.845995645\n",
      "positions (x,y,z), reward: [   2.49365244   -4.44828278  123.70169085] 264.704368431\n",
      "positions (x,y,z), reward: [   2.71882871   -4.67768521  130.93131221] 265.223529903\n",
      "positions (x,y,z), reward: [   2.75961181   -4.82139748  142.90177641] 266.841164068\n",
      "positions (x,y,z), reward: [   2.69897502   -4.82222958  145.5127538 ] 267.327079988\n",
      "positions (x,y,z), reward: [   2.60970693   -4.81516086  148.15857293] 217.867989645\n",
      "Episode =  257, score = 325.799 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.38047434e-05   6.83461946e-05   2.03792784e+01] -2.60877756296\n",
      "positions (x,y,z), reward: [  1.06052617e-01   2.18033396e-02   3.48669326e+01] 16.6522422452\n",
      "positions (x,y,z), reward: [  2.43145199e-01   2.96895811e-02   3.99799229e+01] 67.9550743321\n",
      "positions (x,y,z), reward: [  2.61380331e-01   3.04877491e-02   4.05056663e+01] 68.0462899703\n",
      "positions (x,y,z), reward: [  0.91813497   0.06610477  52.49071747] 168.937497791\n",
      "positions (x,y,z), reward: [  2.90850623   0.310448    70.77704178] 167.979724512\n",
      "positions (x,y,z), reward: [  2.99379974   0.32483025  71.36158206] 167.925080302\n",
      "positions (x,y,z), reward: [  4.47576833   0.61493843  80.25426754] 167.378991665\n",
      "positions (x,y,z), reward: [  8.40264082   1.69325264  97.23767939] 191.0212674\n",
      "positions (x,y,z), reward: [  15.30110467    4.34578645  116.94403655] 267.649409434\n",
      "positions (x,y,z), reward: [  31.18853066   12.03232404  145.72481878] 273.042877977\n",
      "positions (x,y,z), reward: [  32.97678351   12.97851125  148.30923533] 225.165377015\n",
      "positions (x,y,z), reward: [  51.85302438   23.54422637  171.5526939 ] 160.334006524\n",
      "positions (x,y,z), reward: [ 150.          123.50999071  300.        ] 2681.87373039\n",
      "Episode =  258, score = 349.590 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.27555336e-06   2.29412691e-06   2.01242412e+01] -4.89870055924\n",
      "positions (x,y,z), reward: [ -1.01997301e-02   5.77811967e-02   3.05732516e+01] 14.6615769745\n",
      "positions (x,y,z), reward: [ -1.21975802e-02   9.44993630e-02   3.43674363e+01] 16.475135062\n",
      "positions (x,y,z), reward: [ -2.45833378e-02   2.66723777e-01   4.36839846e+01] 68.5448298241\n",
      "positions (x,y,z), reward: [ -3.00401384e-02   3.11491945e-01   4.53007148e+01] 118.707059775\n",
      "positions (x,y,z), reward: [ -3.44760363e-02   3.44171176e-01   4.63852079e+01] 118.794856488\n",
      "positions (x,y,z), reward: [ -0.08498233   0.63896209  54.08656755] 169.04209617\n",
      "positions (x,y,z), reward: [ -0.15500849   0.98863272  60.7851821 ] 168.884457981\n",
      "positions (x,y,z), reward: [ -0.21377195   1.27460751  65.27833113] 168.639291627\n",
      "positions (x,y,z), reward: [ -0.23801631   1.39330164  66.96682572] 168.522373956\n",
      "positions (x,y,z), reward: [ -0.2990174    1.69566831  70.91185071] 168.206462005\n",
      "positions (x,y,z), reward: [ -0.32694647   1.83661426  72.60452037] 168.055744303\n",
      "positions (x,y,z), reward: [ -0.3754674    2.08752232  75.42787289] 167.781731115\n",
      "positions (x,y,z), reward: [ -0.59521755   3.46640799  87.8917922 ] 178.213066951\n",
      "positions (x,y,z), reward: [ -0.67662527   4.27221915  93.59699789] 186.065746119\n",
      "positions (x,y,z), reward: [ -0.69570375   4.53986065  95.31644123] 188.426783012\n",
      "positions (x,y,z), reward: [ -0.70139151   4.6319038   95.89053356] 189.214958304\n",
      "positions (x,y,z), reward: [ -0.7204664    5.01473967  98.19206765] 192.371294577\n",
      "positions (x,y,z), reward: [  -0.70380663    7.31585197  109.8532458 ] 278.731824783\n",
      "positions (x,y,z), reward: [  -0.42889965   10.52388813  122.4837121 ] 261.715733733\n",
      "positions (x,y,z), reward: [ -2.78838551e-02   1.37641928e+01   1.33128641e+02] 260.242593297\n",
      "Episode =  259, score = 321.112 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -9.66400117e-03  -7.47220059e-04   2.38805452e+01] 7.90036414207\n",
      "positions (x,y,z), reward: [ -1.84295710e-02  -3.23150553e-03   2.52358043e+01] 9.90573348302\n",
      "positions (x,y,z), reward: [ -0.38328928  -0.25270197  40.50001952] 67.6884234623\n",
      "positions (x,y,z), reward: [ -0.4072617   -0.27065941  41.02759353] 67.7509556777\n",
      "positions (x,y,z), reward: [ -0.48535673  -0.32932042  42.62209315] 67.8958518222\n",
      "positions (x,y,z), reward: [ -1.21138451  -0.87432669  53.00150378] 167.647473789\n",
      "positions (x,y,z), reward: [ -1.31226525  -0.94910865  54.11192976] 167.52472515\n",
      "positions (x,y,z), reward: [ -1.95280787  -1.41796622  60.24661591] 166.580249745\n",
      "positions (x,y,z), reward: [ -2.08477894  -1.51349996  61.36489367] 166.363407467\n",
      "positions (x,y,z), reward: [ -2.22151482  -1.61215981  62.48351783] 166.13458372\n",
      "positions (x,y,z), reward: [ -2.29167454  -1.66266648  63.04291324] 166.016042017\n",
      "positions (x,y,z), reward: [ -3.94762192  -2.85018675  74.21917202] 163.070215898\n",
      "positions (x,y,z), reward: [ -5.95041987  -4.34991127  84.7579711 ] 166.409476199\n",
      "positions (x,y,z), reward: [ -6.06621682  -4.44085396  85.30927837] 167.010720143\n",
      "positions (x,y,z), reward: [ -14.62779164  -13.88478363  118.08607987] 241.936158115\n",
      "positions (x,y,z), reward: [ -15.64472834  -15.48765567  121.12280124] 235.860873643\n",
      "positions (x,y,z), reward: [ -16.8826988   -17.56646561  124.56623906] 231.701906322\n",
      "positions (x,y,z), reward: [ -22.43423294  -28.07014831  136.82706036] 221.289209256\n",
      "Episode =  260, score = 302.720 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -8.24245223e-08   3.17063689e-08   2.00310939e+01] -6.44562918901\n",
      "positions (x,y,z), reward: [ -5.86522879e-06  -2.53752493e-06   2.01242265e+01] -4.89924873758\n",
      "positions (x,y,z), reward: [ -2.71381042e-03   9.07799394e-04   2.26976427e+01] 5.62825080766\n",
      "positions (x,y,z), reward: [  0.2763613    0.24543847  43.15181457] 68.2406784745\n",
      "positions (x,y,z), reward: [  0.29286475   0.25382544  43.68785107] 68.2934597029\n",
      "positions (x,y,z), reward: [  0.34553613   0.2789014   45.3046968 ] 118.424418967\n",
      "positions (x,y,z), reward: [  0.48735661   0.33625717  49.11956488] 118.602280304\n",
      "positions (x,y,z), reward: [  0.91728568   0.45462778  57.98483131] 168.542277783\n",
      "positions (x,y,z), reward: [  1.04907254   0.48107069  60.22088925] 168.453555707\n",
      "positions (x,y,z), reward: [  1.77968212   0.59651157  70.33707177] 167.81817807\n",
      "positions (x,y,z), reward: [  3.06217001   0.80756217  82.81237935] 170.906845971\n",
      "positions (x,y,z), reward: [  3.20608335   0.83555724  83.95588902] 172.500255738\n",
      "positions (x,y,z), reward: [   6.05964026    1.546905    101.37612004] 291.748197955\n",
      "positions (x,y,z), reward: [   7.05662566    1.84743277  106.09406719] 283.49766467\n",
      "positions (x,y,z), reward: [   9.3491073     2.60347785  115.55973257] 266.26416931\n",
      "positions (x,y,z), reward: [   9.50523723    2.65755714  116.15077504] 265.156988457\n",
      "positions (x,y,z), reward: [  11.14934731    3.24249975  122.04719012] 257.016420426\n",
      "positions (x,y,z), reward: [  12.95020562    3.91012959  127.9128594 ] 254.381388761\n",
      "positions (x,y,z), reward: [  13.13931084    3.98159666  128.49754789] 254.102884347\n",
      "positions (x,y,z), reward: [  19.88848649    6.6460775   146.41905702] 243.985006707\n",
      "Episode =  261, score = 318.664 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.47784560e-06   7.80782617e-07   2.01242987e+01] -4.89712922921\n",
      "positions (x,y,z), reward: [  4.71881220e-03  -2.91104004e-03   2.29781453e+01] 6.22615562483\n",
      "positions (x,y,z), reward: [  0.44123774  -0.43339303  38.41784446] 66.9765049815\n",
      "positions (x,y,z), reward: [  1.1627641   -1.22239178  48.60224941] 117.1269255\n",
      "positions (x,y,z), reward: [  1.54379709  -1.65141565  52.48009988] 166.664174435\n",
      "positions (x,y,z), reward: [  4.4005158   -5.08684402  71.67494767] 160.759929896\n",
      "positions (x,y,z), reward: [  5.43933294  -6.40128565  76.74105288] 158.179262508\n",
      "positions (x,y,z), reward: [  6.19555289  -7.37219282  80.09114181] 156.374969409\n",
      "positions (x,y,z), reward: [  8.76181616 -10.71645102  89.95488145] 164.394975746\n",
      "positions (x,y,z), reward: [ 10.20330781 -12.59954773  94.75696997] 167.734743682\n",
      "positions (x,y,z), reward: [ 10.70572962 -13.25267665  96.33546867] 168.754652069\n",
      "positions (x,y,z), reward: [ 11.56692949 -14.36611322  98.94024914] 170.356533627\n",
      "positions (x,y,z), reward: [  12.82269921  -15.97258834  102.53073682] 264.817010761\n",
      "positions (x,y,z), reward: [  13.37916451  -16.6770181   104.04949411] 261.078885978\n",
      "positions (x,y,z), reward: [  15.92487722  -19.83595161  110.50087571] 244.928763097\n",
      "positions (x,y,z), reward: [  17.17902519  -21.35489507  113.41858319] 238.879797257\n",
      "positions (x,y,z), reward: [  21.99671048  -27.05291439  123.54050179] 226.321690505\n",
      "positions (x,y,z), reward: [  27.12544461  -33.23881739  133.63729364] 228.493681614\n",
      "Episode =  262, score = 295.820 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.11077768   0.10128887  31.49788281] 15.0579439099\n",
      "positions (x,y,z), reward: [ -0.15815586   0.14405993  33.88336759] 16.0940634727\n",
      "positions (x,y,z), reward: [ -3.40649811   3.53010062  79.68333441] 165.373749674\n",
      "positions (x,y,z), reward: [ -6.82446133   6.34187317  95.72778452] 183.703339864\n",
      "positions (x,y,z), reward: [ -7.54155055   6.8288656   98.23515118] 186.37551407\n",
      "positions (x,y,z), reward: [  -9.37045376    7.95586529  103.90987131] 280.457298992\n",
      "positions (x,y,z), reward: [ -23.18229594   13.23819722  133.21044616] 242.843310144\n",
      "positions (x,y,z), reward: [ -25.99612051   13.83161904  138.04664163] 243.216753566\n",
      "positions (x,y,z), reward: [ -28.10357164   14.18997016  141.59500187] 243.753410094\n",
      "positions (x,y,z), reward: [ -32.09347238   14.6755116   148.24992608] 195.457240715\n",
      "positions (x,y,z), reward: [ -40.80116274   14.89691697  163.2417134 ] 153.29326896\n",
      "Episode =  263, score = 305.775 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777712] -7.22228887652\n",
      "positions (x,y,z), reward: [  3.47335418e-06  -2.96747973e-07   2.01242862e+01] -4.89710126101\n",
      "positions (x,y,z), reward: [  1.45644848  -1.87994018  62.98413211] 166.723134849\n",
      "positions (x,y,z), reward: [  3.22152121  -2.90573266  80.08540205] 165.076732765\n",
      "positions (x,y,z), reward: [  4.09635087  -3.17157234  85.95336758] 173.263881767\n",
      "positions (x,y,z), reward: [  5.04225981  -3.35878359  91.3305162 ] 180.735823571\n",
      "positions (x,y,z), reward: [  11.4478073    -3.3903688   116.10652866] 266.802279811\n",
      "positions (x,y,z), reward: [  12.60906046   -3.27583125  119.52315549] 261.3530644\n",
      "positions (x,y,z), reward: [  23.7670496    -1.20950667  146.2574454 ] 264.063009757\n",
      "positions (x,y,z), reward: [  24.1764988    -1.10225765  147.12722503] 264.587033604\n",
      "Episode =  264, score = 309.982 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -7.19965996e-06  -6.06472276e-06   2.01940257e+01] -4.12847578439\n",
      "positions (x,y,z), reward: [ -2.69795126e-03  -5.46790792e-03   2.26987567e+01] 5.62693323368\n",
      "positions (x,y,z), reward: [ -6.39168517e-03  -1.44856208e-02   2.42061551e+01] 8.42518891232\n",
      "positions (x,y,z), reward: [ -0.04608344  -0.11409673  31.96748067] 15.3523916382\n",
      "positions (x,y,z), reward: [ -0.06410704  -0.15481674  33.88497021] 16.1749832078\n",
      "positions (x,y,z), reward: [ -0.16756175  -0.36454234  40.5044947 ] 67.7882225198\n",
      "positions (x,y,z), reward: [ -0.24655031  -0.51260937  43.69802093] 68.1138675903\n",
      "positions (x,y,z), reward: [ -0.45722561  -0.88831044  49.69007792] 118.188169444\n",
      "positions (x,y,z), reward: [ -1.22494464  -2.1296348   62.50316511] 166.668901226\n",
      "positions (x,y,z), reward: [ -2.16968455  -3.51784957  72.59102368] 164.297423173\n",
      "positions (x,y,z), reward: [ -3.30123183  -5.10574108  81.52230518] 163.686299448\n",
      "positions (x,y,z), reward: [ -5.16022133  -7.67306833  92.56433515] 175.360248728\n",
      "positions (x,y,z), reward: [ -5.26658721  -7.82065949  93.11101515] 175.895336487\n",
      "positions (x,y,z), reward: [ -5.48330148  -8.12176408  94.20249322] 176.950851525\n",
      "positions (x,y,z), reward: [  -9.7976576   -14.14227187  111.21578803] 256.959342875\n",
      "positions (x,y,z), reward: [ -14.26821695  -20.09528686  122.61161575] 231.332129675\n",
      "positions (x,y,z), reward: [ -18.28276883  -25.14132699  129.82188175] 225.066883595\n",
      "Episode =  265, score = 302.722 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.04653727  -0.08056626  30.11810857] 14.3036201882\n",
      "positions (x,y,z), reward: [  0.0753575   -0.14620169  32.90554246] 15.7301960657\n",
      "positions (x,y,z), reward: [  0.14928541  -0.38484425  38.91969934] 67.4334379944\n",
      "positions (x,y,z), reward: [  0.20232225  -0.61459752  42.61051583] 67.8920902751\n",
      "positions (x,y,z), reward: [  0.44418657  -1.94401789  54.66952201] 167.478129758\n",
      "positions (x,y,z), reward: [  0.47556549  -2.11925706  55.78533717] 167.319275106\n",
      "positions (x,y,z), reward: [  0.90221751  -4.30847278  66.4344312 ] 164.823057521\n",
      "positions (x,y,z), reward: [  2.27534315 -10.13040733  83.60255579] 162.104290032\n",
      "positions (x,y,z), reward: [  2.46141347 -10.85711878  85.22407706] 163.455701682\n",
      "positions (x,y,z), reward: [  2.7933255  -12.13338571  87.90266471] 165.551727504\n",
      "positions (x,y,z), reward: [  3.07817131 -13.21174026  90.02176477] 167.089775217\n",
      "positions (x,y,z), reward: [   6.3039725   -24.76281135  107.43048919] 257.677525578\n",
      "positions (x,y,z), reward: [   6.76338519  -26.33966033  109.2613867 ] 253.965468589\n",
      "Episode =  266, score = 297.468 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.78038551e-04   9.28058091e-04   2.17060720e+01] 3.08397365894\n",
      "positions (x,y,z), reward: [ -2.13884841e-04   3.72193341e-03   2.26958709e+01] 5.61755776225\n",
      "positions (x,y,z), reward: [ -0.03025134   0.06400921  28.37392364] 13.0787883935\n",
      "positions (x,y,z), reward: [ -0.15322464   0.25883227  35.85633618] 16.6982978565\n",
      "positions (x,y,z), reward: [ -1.4409086    2.35552005  64.2003113 ] 166.487764845\n",
      "positions (x,y,z), reward: [ -1.71659296   2.85360527  68.1705576 ] 165.856791338\n",
      "positions (x,y,z), reward: [ -1.88599415   3.1657841   70.44811426] 165.455315115\n",
      "positions (x,y,z), reward: [ -3.35933693   5.96315981  86.5528756 ] 171.476841513\n",
      "positions (x,y,z), reward: [ -4.19777818   7.5140823   93.53038633] 179.763988741\n",
      "positions (x,y,z), reward: [  -8.0109212    14.00246121  116.08108143] 256.125809359\n",
      "positions (x,y,z), reward: [ -11.67060778   19.72050844  132.00875649] 241.462356475\n",
      "positions (x,y,z), reward: [ -15.13573418   24.72153497  144.94405148] 237.593892395\n",
      "positions (x,y,z), reward: [ -17.3075693    27.67412581  152.32172106] 185.47408638\n",
      "Episode =  267, score = 308.225 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -9.91055656e-10   2.91334891e-10   2.00310965e+01] -6.44549550451\n",
      "positions (x,y,z), reward: [  1.26641261e-04   5.10872378e-04   2.09288716e+01] 0.330021306139\n",
      "positions (x,y,z), reward: [ -6.44764640e-03   2.68166654e-01   3.33911819e+01] 15.8979645849\n",
      "positions (x,y,z), reward: [ -0.05446118   0.48529165  37.89024247] 67.1611899622\n",
      "positions (x,y,z), reward: [ -0.1297059    0.74406895  42.07868147] 67.7201848277\n",
      "positions (x,y,z), reward: [ -0.17961088   0.8977967   44.22000513] 117.847521323\n",
      "positions (x,y,z), reward: [ -0.46153582   1.68413804  52.98734164] 167.622577852\n",
      "positions (x,y,z), reward: [ -0.52899006   1.86359101  54.6566799 ] 167.478767458\n",
      "positions (x,y,z), reward: [ -1.46207008   4.47087221  72.72926375] 164.633138489\n",
      "positions (x,y,z), reward: [  -1.96093046   16.38838348  113.75081869] 268.530357951\n",
      "Episode =  268, score = 305.977 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.07174316e-03   1.90161004e-03   2.19359967e+01] 3.74931326207\n",
      "positions (x,y,z), reward: [  1.39503140e-03   2.41784459e-03   2.21774649e+01] 4.39059529296\n",
      "positions (x,y,z), reward: [  0.55592761   0.2998289   44.79715255] 118.246635616\n",
      "positions (x,y,z), reward: [  0.65792754   0.33668856  46.43019566] 118.327159103\n",
      "positions (x,y,z), reward: [  3.14367849   0.80177293  69.13703074] 167.366085374\n",
      "positions (x,y,z), reward: [  4.91883555   0.82597306  79.19434676] 166.00458807\n",
      "positions (x,y,z), reward: [  6.02792012   0.73170505  84.55094963] 171.799156289\n",
      "positions (x,y,z), reward: [  9.40905582e+00  -8.30977427e-02   9.81204878e+01] 188.846089861\n",
      "positions (x,y,z), reward: [  10.80948637   -0.66433431  102.76202692] 285.193691717\n",
      "positions (x,y,z), reward: [  15.97778537   -3.96925024  116.14658687] 254.389929292\n",
      "positions (x,y,z), reward: [  25.15630539  -12.81571264  131.40709129] 229.955489272\n",
      "positions (x,y,z), reward: [  28.38286473  -16.58456673  135.35282531] 224.063357596\n",
      "positions (x,y,z), reward: [  32.33909096  -21.73575618  139.5072705 ] 217.889723898\n",
      "Episode =  269, score = 310.137 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.16882834e-04  -3.26182128e-04   2.04943360e+01] -1.8656264383\n",
      "positions (x,y,z), reward: [  0.04097987  -0.0520739   26.73651819] 11.573761654\n",
      "positions (x,y,z), reward: [  0.3694024   -0.31566145  42.07570519] 67.901628456\n",
      "positions (x,y,z), reward: [  0.98480744  -0.63917951  56.28623011] 168.162218078\n",
      "positions (x,y,z), reward: [  1.10419885  -0.69370254  58.51204372] 168.058134151\n",
      "positions (x,y,z), reward: [  1.32650215  -0.79163155  62.41825361] 167.822148628\n",
      "positions (x,y,z), reward: [  1.35954034  -0.80588572  62.97715538] 167.783813653\n",
      "positions (x,y,z), reward: [   3.36292704   -1.69387267  101.36117349] 293.61471529\n",
      "positions (x,y,z), reward: [   3.12582794   -1.6926889   113.5076168 ] 276.014759554\n",
      "positions (x,y,z), reward: [   2.88490249   -1.65082271  117.00476867] 271.13421631\n",
      "positions (x,y,z), reward: [   0.80456335   -1.27760713  131.04124711] 269.095056973\n",
      "positions (x,y,z), reward: [  -1.22764384   -0.93956619  138.58427358] 268.612391289\n",
      "Episode =  270, score = 327.166 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.07207562e-02   2.73471712e-02   2.52398583e+01] 9.89798606287\n",
      "positions (x,y,z), reward: [  0.10033171   0.23316427  39.45394576] 67.7407600025\n",
      "positions (x,y,z), reward: [  0.12312239   0.30870401  43.68961515] 68.3880806252\n",
      "positions (x,y,z), reward: [  0.14167007   0.44496755  51.31561115] 118.971397585\n",
      "positions (x,y,z), reward: [  0.14148414   0.46399994  52.41932202] 169.019774741\n",
      "positions (x,y,z), reward: [  0.09429199   0.60276487  61.88551804] 169.318129519\n",
      "positions (x,y,z), reward: [  1.06076791e-02   6.47378534e-01   6.75033568e+01] 169.495744491\n",
      "positions (x,y,z), reward: [ -0.34958782   0.61901228  79.35853314] 169.298209846\n",
      "positions (x,y,z), reward: [ -0.81776382   0.54838297  87.84657076] 180.725401015\n",
      "positions (x,y,z), reward: [ -1.51492904   0.51416717  95.79591614] 192.124183472\n",
      "positions (x,y,z), reward: [  -4.22129273    0.72730684  111.82780324] 278.030172496\n",
      "positions (x,y,z), reward: [ -14.10067836    2.06473363  138.17218207] 252.61976735\n",
      "positions (x,y,z), reward: [ -14.64688808    2.1426785   139.24083609] 251.857530489\n",
      "positions (x,y,z), reward: [ -16.62259362    2.42838422  142.9370108 ] 249.103569633\n",
      "positions (x,y,z), reward: [ -19.30081204    2.82783778  147.58978768] 245.418147775\n",
      "Episode =  271, score = 324.769 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.07473119e-02  -7.30922027e-02   2.67447773e+01] 11.5987257801\n",
      "positions (x,y,z), reward: [  0.038725    -0.30865381  33.88346654] 16.0355772934\n",
      "positions (x,y,z), reward: [  5.66144625e-03  -1.91631532e+00   5.62804317e+01] 167.853000212\n",
      "positions (x,y,z), reward: [ -0.90054865  -4.46508404  75.37897732] 164.943338914\n",
      "positions (x,y,z), reward: [ -1.69253928  -5.67553351  81.61092052] 165.34394206\n",
      "positions (x,y,z), reward: [ -3.25386734  -7.58708708  89.49538113] 173.330833062\n",
      "positions (x,y,z), reward: [ -6.54310304 -10.96639009  99.89439382] 180.939578058\n",
      "positions (x,y,z), reward: [ -10.50591705  -14.55255576  108.11719927] 259.392504891\n",
      "positions (x,y,z), reward: [ -12.29069958  -16.05906456  111.01765369] 250.802367754\n",
      "positions (x,y,z), reward: [ -18.98723908  -21.30256337  119.36172466] 224.054422853\n",
      "Episode =  272, score = 298.644 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -7.70185948e-03  -7.88864187e-04   2.21778892e+01] 4.38735269916\n",
      "positions (x,y,z), reward: [ -0.50000205  -0.25619212  36.36702762] 66.5093099478\n",
      "positions (x,y,z), reward: [ -0.60230056  -0.32313515  37.89660788] 66.7765152414\n",
      "positions (x,y,z), reward: [ -0.71706741  -0.40031648  39.45048416] 66.9586529282\n",
      "positions (x,y,z), reward: [ -1.62923075  -1.06066142  48.57422967] 116.699415998\n",
      "positions (x,y,z), reward: [ -6.75665201  -5.84055252  73.45244543] 156.481230382\n",
      "positions (x,y,z), reward: [ -8.92105842  -8.22780754  79.84447424] 150.95837184\n",
      "positions (x,y,z), reward: [-17.22077333 -17.56622443  96.19590417] 153.145337158\n",
      "Episode =  273, score = 280.574 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.39597863e-07   6.69003739e-07   2.00699899e+01] -5.668508163\n",
      "positions (x,y,z), reward: [  1.03246106e-03   1.09032704e-03   2.12914436e+01] 1.74227776573\n",
      "positions (x,y,z), reward: [ -0.21403193   0.10062597  45.86085751] 118.789878227\n",
      "positions (x,y,z), reward: [ -0.32913647   0.15460675  54.09724376] 169.239289501\n",
      "positions (x,y,z), reward: [ -0.49499998   0.36033195  72.00701945] 169.271749576\n",
      "positions (x,y,z), reward: [ -0.5210905    0.52770598  83.83383734] 174.890284538\n",
      "positions (x,y,z), reward: [  -0.29456739    0.51259465  103.0862759 ] 295.051774723\n",
      "positions (x,y,z), reward: [   1.02963495   -0.89734219  127.30381603] 269.439489695\n",
      "positions (x,y,z), reward: [   1.57064143   -1.497825    132.63024237] 268.757483546\n",
      "Episode =  274, score = 329.590 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  6.08322817e-03  -4.44734079e-05   2.19360464e+01] 3.74367099816\n",
      "positions (x,y,z), reward: [  1.53157574e-02  -4.73360043e-04   2.29766190e+01] 6.20807562703\n",
      "positions (x,y,z), reward: [  6.71814299e-02  -3.03610423e-03   2.59712859e+01] 10.75495888\n",
      "positions (x,y,z), reward: [  7.65684743e-02  -3.50138162e-03   2.63521098e+01] 11.1737427142\n",
      "positions (x,y,z), reward: [  4.23898280e-01  -2.24241888e-02   3.43629979e+01] 16.1108936644\n",
      "positions (x,y,z), reward: [  1.91077068e+00   9.92973326e-03   4.91748943e+01] 117.888915327\n",
      "positions (x,y,z), reward: [  3.64469636   0.19703038  59.42485984] 167.271904996\n",
      "positions (x,y,z), reward: [  4.25197399   0.28664608  62.35653285] 166.966852603\n",
      "positions (x,y,z), reward: [  4.51164192   0.32803248  63.54046087] 166.832643873\n",
      "positions (x,y,z), reward: [  5.49972114   0.50033228  67.73892834] 166.298662042\n",
      "positions (x,y,z), reward: [  8.44635693   1.12732101  78.34343241] 164.593203475\n",
      "positions (x,y,z), reward: [  17.20749143    3.83820136  102.43344413] 287.393969338\n",
      "positions (x,y,z), reward: [  24.37929864    7.14084808  119.43891187] 266.374431686\n",
      "positions (x,y,z), reward: [  26.60038319    8.43648392  124.72263759] 268.71412039\n",
      "positions (x,y,z), reward: [  49.69368581   33.97829797  186.31954912] 220.685762094\n",
      "positions (x,y,z), reward: [  63.09679253   59.51330754  226.03183122] 482.786986707\n",
      "positions (x,y,z), reward: [ 103.99656024  150.          300.        ] 3186.0771669\n",
      "Episode =  275, score = 361.556 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  6.77728016e-03  -1.14835452e-03   2.29755589e+01] 6.21019231798\n",
      "positions (x,y,z), reward: [  8.40411643e-03  -1.12971120e-03   2.32657151e+01] 6.78715590587\n",
      "positions (x,y,z), reward: [  5.97527450e-02   1.50611035e-02   2.79550560e+01] 12.7394875319\n",
      "positions (x,y,z), reward: [  0.69035916   0.6913516   48.56523762] 118.010979307\n",
      "positions (x,y,z), reward: [  14.62156614   20.59609145  139.36725086] 234.367662667\n",
      "positions (x,y,z), reward: [  15.13216703   21.5948447   141.51807311] 233.645457695\n",
      "Episode =  276, score = 310.456 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  9.42936919e-03   1.73934018e-03   2.56027675e+01] 10.3879648212\n",
      "positions (x,y,z), reward: [ -0.16675427  -0.16206069  43.16506975] 68.4490347962\n",
      "positions (x,y,z), reward: [ -1.45293375  -1.01043558  70.30534837] 167.589881672\n",
      "positions (x,y,z), reward: [ -1.92953937  -1.24492226  76.48099251] 166.910273848\n",
      "positions (x,y,z), reward: [ -3.39110218  -1.74541686  90.54226871] 180.838746344\n",
      "positions (x,y,z), reward: [ -4.35170965  -1.9445618   97.30510722] 189.850339592\n",
      "positions (x,y,z), reward: [  -5.12070575   -2.05580206  101.81565727] 290.281666267\n",
      "positions (x,y,z), reward: [  -7.18144458   -2.23398531  111.37456971] 273.521569533\n",
      "positions (x,y,z), reward: [  -8.07239134   -2.28020575  114.72786051] 267.430594426\n",
      "Episode =  277, score = 320.152 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  5.37838501e-03  -2.14770629e-02   3.24364633e+01] 15.7213883604\n",
      "positions (x,y,z), reward: [  1.38328066e-02  -3.53624257e-02   3.99720851e+01] 68.1366003812\n",
      "positions (x,y,z), reward: [  5.24032753e-02  -3.19193697e-02   4.53032662e+01] 118.969743743\n",
      "positions (x,y,z), reward: [  0.71551403   0.14265956  64.32448623] 169.977157892\n",
      "positions (x,y,z), reward: [  0.87469822   0.18482455  66.64212208] 170.030583373\n",
      "positions (x,y,z), reward: [  1.20848166   0.26895177  70.75268462] 170.154950887\n",
      "positions (x,y,z), reward: [  1.62200514   0.36534981  74.94927718] 170.335817905\n",
      "positions (x,y,z), reward: [  2.12736164   0.4749197   79.25458439] 170.584447324\n",
      "positions (x,y,z), reward: [  3.03335718   0.66367223  85.64559194] 179.544428958\n",
      "positions (x,y,z), reward: [  3.24339065   0.70776358  86.96444566] 181.641795332\n",
      "positions (x,y,z), reward: [  3.57794275   0.77916848  88.97192102] 184.850044138\n",
      "positions (x,y,z), reward: [   6.00356434    1.37507666  101.19462272] 301.413334837\n",
      "positions (x,y,z), reward: [  28.63598927   14.15750036  167.6567128 ] 181.100267503\n",
      "Episode =  278, score = 357.005 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.29651181  -1.45254524  68.00989923] 168.27855969\n",
      "positions (x,y,z), reward: [  0.4426228   -2.18607145  82.63593896] 171.579299399\n",
      "Episode =  279, score = 325.055 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.07030848  -0.20247655  33.40554989] 15.9223120931\n",
      "positions (x,y,z), reward: [ -0.08679591  -0.24007151  34.38153117] 16.2664636995\n",
      "positions (x,y,z), reward: [ -1.97290682  -4.58521789  70.24955962] 163.22305192\n",
      "positions (x,y,z), reward: [ -2.24747802  -5.33347974  73.57899994] 162.120500056\n",
      "positions (x,y,z), reward: [ -2.48120481  -6.00963586  76.3459246 ] 161.139077998\n",
      "positions (x,y,z), reward: [ -3.87109152 -11.20415114  92.77133783] 173.169452045\n",
      "positions (x,y,z), reward: [ -4.12796109 -12.50288393  96.01578757] 176.372373366\n",
      "positions (x,y,z), reward: [ -4.25188225 -13.18765975  97.63317296] 177.937167181\n",
      "positions (x,y,z), reward: [  -4.60414682  -15.38568528  102.46595569] 275.073562632\n",
      "positions (x,y,z), reward: [  -4.71504229  -16.16640182  104.07000817] 271.71581138\n",
      "positions (x,y,z), reward: [  -5.9644381   -28.36968419  124.36218139] 240.937232845\n",
      "positions (x,y,z), reward: [  -6.20939183  -31.27431017  128.29194794] 239.985789686\n",
      "Episode =  280, score = 305.869 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.04367585e-02   4.15749495e-02   3.05762791e+01] 14.6777068173\n",
      "positions (x,y,z), reward: [ -0.07282035   0.28933945  44.2251049 ] 118.547506997\n",
      "positions (x,y,z), reward: [ -0.82658511   1.63577628  69.89340676] 168.161654561\n",
      "positions (x,y,z), reward: [ -13.14782675    8.59744249  114.99234765] 257.038895352\n",
      "positions (x,y,z), reward: [ -22.44881915   11.67222417  130.5559331 ] 238.677374824\n",
      "positions (x,y,z), reward: [ -29.51167588   13.35141987  140.11339337] 236.544164822\n",
      "positions (x,y,z), reward: [ -32.21174082   13.86678647  143.45535221] 235.939874411\n",
      "positions (x,y,z), reward: [ -33.13450533   14.02804063  144.56741768] 235.76333715\n",
      "Episode =  281, score = 311.712 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777368] -7.22263270988\n",
      "positions (x,y,z), reward: [  1.01102305e-04  -4.04105623e-04   2.07693138e+01] -0.393642835284\n",
      "positions (x,y,z), reward: [  1.67664706e-02  -7.90638595e-02   2.92378571e+01] 13.7472779841\n",
      "positions (x,y,z), reward: [  0.11551811  -0.19956341  37.38246195] 67.2594065693\n",
      "positions (x,y,z), reward: [  0.17422734  -0.24020138  39.97310876] 67.7944850004\n",
      "positions (x,y,z), reward: [  0.34635561  -0.33031107  45.31112887] 118.418796379\n",
      "positions (x,y,z), reward: [  0.39038501  -0.35011319  46.39774682] 118.488093299\n",
      "positions (x,y,z), reward: [  1.34707949  -0.72744354  61.44084366] 168.236770258\n",
      "positions (x,y,z), reward: [  1.55136506  -0.81008307  63.70995583] 168.048787657\n",
      "positions (x,y,z), reward: [  2.55629715  -1.25449658  72.86614052] 167.013112886\n",
      "positions (x,y,z), reward: [  4.43891233  -2.2578803   85.13918736] 172.674140122\n",
      "positions (x,y,z), reward: [  5.7498214   -3.06814917  91.73195156] 181.050402223\n",
      "positions (x,y,z), reward: [  6.43358828  -3.52375538  94.7749857 ] 184.782095906\n",
      "positions (x,y,z), reward: [  10.15090027   -6.32871875  108.55419077] 274.757063558\n",
      "positions (x,y,z), reward: [  20.67228266  -17.49681885  139.28411651] 241.690271295\n",
      "positions (x,y,z), reward: [  26.93597769  -28.96333443  159.61228205] 147.37669909\n",
      "Episode =  282, score = 305.224 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.76490618e-03   1.11846087e-02   2.48818771e+01] 9.42873981044\n",
      "positions (x,y,z), reward: [ -2.63277557e-02   3.47828941e-02   3.14935965e+01] 15.1945686552\n",
      "positions (x,y,z), reward: [ -1.36960471   0.29597137  66.41071432] 168.461020338\n",
      "positions (x,y,z), reward: [ -1.78788805   0.36668337  70.91451173] 168.008907734\n",
      "positions (x,y,z), reward: [ -4.45824287   0.78672364  89.49734633] 179.101158654\n",
      "positions (x,y,z), reward: [ -6.81862537   1.13612149  99.56749359] 191.184295174\n",
      "positions (x,y,z), reward: [ -13.0820709     1.84937905  117.53154156] 257.320982062\n",
      "positions (x,y,z), reward: [ -13.76942651    1.90611439  119.12063376] 254.058907526\n",
      "positions (x,y,z), reward: [ -17.75514469    2.13899682  127.4559847 ] 247.775362193\n",
      "positions (x,y,z), reward: [ -20.51506764    2.20597252  132.53932241] 244.950140861\n",
      "positions (x,y,z), reward: [ -26.95383403    2.11078451  142.86047787] 243.856023872\n",
      "Episode =  283, score = 317.859 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.1071621   -0.05291483  29.67923842] 13.9858493463\n",
      "positions (x,y,z), reward: [ -0.34376861  -0.17136356  40.49561281] 67.7813148304\n",
      "positions (x,y,z), reward: [ -0.35585171  -0.17742587  41.02257686] 67.8643408192\n",
      "positions (x,y,z), reward: [ -0.64925793  -0.34898361  60.23971002] 169.111649268\n",
      "positions (x,y,z), reward: [ -0.65342108  -0.35139567  62.49254311] 169.200129156\n",
      "positions (x,y,z), reward: [ -0.63644188  -0.33050973  67.58639027] 169.41262383\n",
      "positions (x,y,z), reward: [ -0.59953583  -0.28471729  71.56757448] 169.603154235\n",
      "positions (x,y,z), reward: [ -0.59271986  -0.27582543  72.13750325] 169.632841371\n",
      "positions (x,y,z), reward: [ -0.12857993   0.53997663  93.38676185] 190.244526446\n",
      "positions (x,y,z), reward: [   1.34286092    3.82968613  125.93597513] 264.988228367\n",
      "positions (x,y,z), reward: [   1.8994487     5.21502849  134.90802419] 262.808777847\n",
      "Episode =  284, score = 328.853 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.32954409e-03   6.07451021e-03   2.48825794e+01] 9.44223832181\n",
      "positions (x,y,z), reward: [  6.04041814e-05   1.54522907e-02   2.67423076e+01] 11.6630397197\n",
      "positions (x,y,z), reward: [ -1.32718719e-03   2.07263281e-02   2.75452161e+01] 12.4361566565\n",
      "positions (x,y,z), reward: [ -8.41459030e-03   3.83526246e-02   2.96785298e+01] 14.1026660661\n",
      "positions (x,y,z), reward: [ -1.0911601    0.54838127  60.77325368] 168.347543154\n",
      "positions (x,y,z), reward: [ -3.80345561   1.37589323  82.82233878] 169.60950494\n",
      "positions (x,y,z), reward: [ -4.74390957   1.68791508  87.40066554] 175.326661309\n",
      "positions (x,y,z), reward: [ -13.11942888    4.379685    112.30374771] 265.561057148\n",
      "positions (x,y,z), reward: [ -26.04907379    8.10027056  136.75766162] 248.05202065\n",
      "positions (x,y,z), reward: [ -28.90755586    8.81792484  141.65301788] 249.023407717\n",
      "positions (x,y,z), reward: [ -29.32884703    8.91989664  142.37269373] 249.198787169\n",
      "Episode =  285, score = 313.128 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.21042106e-04   4.99709933e-05   2.04945929e+01] -1.8619697025\n",
      "positions (x,y,z), reward: [  6.96906625e-04   2.76057423e-04   2.11027022e+01] 1.03790523334\n",
      "positions (x,y,z), reward: [  1.74811065e-03   6.55446153e-04   2.17071678e+01] 3.0896673904\n",
      "positions (x,y,z), reward: [  2.42454632e-02   3.57001603e-03   2.59714476e+01] 10.8063606946\n",
      "positions (x,y,z), reward: [  1.50860014e-01  -3.81187491e-03   3.38789596e+01] 16.2272448256\n",
      "positions (x,y,z), reward: [  1.62762044e-01  -4.64676050e-03   3.43685657e+01] 16.4092992662\n",
      "positions (x,y,z), reward: [  4.40131703e-01  -1.89509224e-02   4.26131858e+01] 68.214755975\n",
      "positions (x,y,z), reward: [  7.32436905e-01  -2.93760387e-02   4.85678646e+01] 118.62927397\n",
      "positions (x,y,z), reward: [  2.09214856e+00  -3.21553203e-02   6.63942822e+01] 167.9719242\n",
      "positions (x,y,z), reward: [  3.57676195   0.14041141  79.9009827 ] 166.463222342\n",
      "positions (x,y,z), reward: [   1.24651974    4.3631968   129.10981087] 264.98288893\n",
      "positions (x,y,z), reward: [  -3.98322377    5.77641917  138.3553103 ] 257.677630622\n",
      "Episode =  286, score = 323.888 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -7.03237372e-05  -2.17108929e-06   2.02791049e+01] -3.36620043463\n",
      "positions (x,y,z), reward: [ -8.12433711e-03   3.62844940e-03   2.24313060e+01] 5.00559349185\n",
      "positions (x,y,z), reward: [ -0.08963279   0.06372651  27.95692852] 12.6617034452\n",
      "positions (x,y,z), reward: [ -0.21564156   0.17135116  32.43277379] 15.341345953\n",
      "positions (x,y,z), reward: [ -0.32459641   0.27032288  35.35546198] 16.3292190788\n",
      "positions (x,y,z), reward: [ -0.48414123   0.42016057  38.91981079] 67.0310297344\n",
      "positions (x,y,z), reward: [ -1.71217963   1.59277663  56.81539597] 166.450517883\n",
      "positions (x,y,z), reward: [ -3.37007158   2.94875861  70.76093304] 163.621386799\n",
      "positions (x,y,z), reward: [ -7.30032692   5.08000175  88.58782401] 170.105720275\n",
      "positions (x,y,z), reward: [-11.19935065   6.46828793  98.92731907] 179.397260627\n",
      "positions (x,y,z), reward: [ -11.94410113    6.69574269  100.52150355] 279.031429135\n",
      "positions (x,y,z), reward: [ -12.20045547    6.77211643  101.04987894] 277.828090993\n",
      "positions (x,y,z), reward: [ -13.82365647    7.23627598  104.18523331] 270.521584755\n",
      "positions (x,y,z), reward: [ -25.25990539    9.95578964  120.02106656] 233.850107114\n",
      "positions (x,y,z), reward: [ -29.96866666   10.90791184  124.62845252] 231.123623935\n",
      "Episode =  287, score = 301.437 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.06566440e-05  -4.19316972e-05   2.03794606e+01] -2.60787764959\n",
      "positions (x,y,z), reward: [  0.03891282   0.17318351  33.4054878 ] 15.9953936657\n",
      "positions (x,y,z), reward: [  0.04419037   0.58188961  42.10834971] 68.0269666056\n",
      "positions (x,y,z), reward: [  3.11989322e-02   9.69136729e-01   4.75222218e+01] 118.427537397\n",
      "positions (x,y,z), reward: [ -0.45277484   4.61550608  74.32731592] 166.336685823\n",
      "positions (x,y,z), reward: [ -0.56154152   5.08220563  76.68696478] 165.931797108\n",
      "positions (x,y,z), reward: [ -0.92017065   6.37300753  82.65161082] 168.756223444\n",
      "positions (x,y,z), reward: [  -5.76963974   14.76019734  112.29557411] 265.891013376\n",
      "positions (x,y,z), reward: [  -6.54927934   15.58436792  114.93124995] 260.474378999\n",
      "positions (x,y,z), reward: [ -14.4483078    21.21722063  134.18074334] 240.623125617\n",
      "positions (x,y,z), reward: [ -15.13692966   21.5566861   135.50253339] 239.875964989\n",
      "positions (x,y,z), reward: [ -15.84212426   21.88704512  136.82181588] 239.104177027\n",
      "positions (x,y,z), reward: [ -19.98980808   23.52541508  144.01853299] 234.447325006\n",
      "positions (x,y,z), reward: [ -28.91355187   25.72041493  157.39369933] 133.318191702\n",
      "Episode =  288, score = 304.952 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.27021243e-03   9.67957397e-03   2.29777248e+01] 6.21957375636\n",
      "positions (x,y,z), reward: [  3.92999467e-03   1.41136601e-02   2.35700001e+01] 7.355227617\n",
      "positions (x,y,z), reward: [  0.09083032   0.25979519  34.376876  ] 16.2410482213\n",
      "positions (x,y,z), reward: [  0.14121541   0.46850382  38.93829311] 67.3772089357\n",
      "positions (x,y,z), reward: [  0.17150323   0.61988803  41.56589219] 67.7478365946\n",
      "positions (x,y,z), reward: [  0.23624978   1.00431336  46.95824838] 118.081049769\n",
      "positions (x,y,z), reward: [  0.29966108   1.44729226  51.92003313] 118.02860412\n",
      "positions (x,y,z), reward: [  0.47769534   2.85514533  63.7244902 ] 167.019732753\n",
      "positions (x,y,z), reward: [  0.59358622   3.81154975  69.97876567] 166.080760432\n",
      "positions (x,y,z), reward: [  0.75897101   5.1424485   77.39112271] 164.605571938\n",
      "positions (x,y,z), reward: [  0.92950903   6.43986868  83.65304606] 168.511145281\n",
      "positions (x,y,z), reward: [  0.94649177   6.56561333  84.2209192 ] 169.205406392\n",
      "positions (x,y,z), reward: [   1.59262474   11.48125434  102.74206492] 282.499426882\n",
      "positions (x,y,z), reward: [   1.63185029   11.83001104  103.84854881] 280.401147566\n",
      "positions (x,y,z), reward: [   1.68925126   12.36482343  105.50444667] 277.247582986\n",
      "positions (x,y,z), reward: [   2.10231517   21.42694459  128.10149053] 245.993166754\n",
      "Episode =  289, score = 314.513 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.86364422e-02  -2.14636511e-02   2.52332311e+01] 9.87585953538\n",
      "positions (x,y,z), reward: [  0.02703398  -0.03174876  26.34900994] 11.1962254937\n",
      "positions (x,y,z), reward: [  2.69097813e-04  -2.48257962e+00   6.97639128e+01] 167.672591021\n",
      "positions (x,y,z), reward: [ -1.90958654e-02  -2.63387532e+00   7.08904685e+01] 167.512094374\n",
      "positions (x,y,z), reward: [ -0.07418728  -3.04437916  73.70823818] 167.061953412\n",
      "positions (x,y,z), reward: [ -0.14039205  -3.50495917  76.52702242] 166.537769771\n",
      "positions (x,y,z), reward: [  -2.49064384  -13.81710357  107.40020946] 270.569709488\n",
      "positions (x,y,z), reward: [  -3.09085956  -15.94012313  110.98602457] 261.708380746\n",
      "positions (x,y,z), reward: [  -4.08532223  -19.31550553  115.90607909] 248.671081498\n",
      "positions (x,y,z), reward: [  -7.43226052  -29.91950561  127.26103299] 234.045514209\n",
      "positions (x,y,z), reward: [  -8.97440139  -34.63761175  130.95445541] 230.45057552\n",
      "positions (x,y,z), reward: [ -12.01253827  -43.86516345  136.52429829] 223.458212331\n",
      "Episode =  290, score = 308.619 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.55927076e-04  -2.40001880e-04   2.07698653e+01] -0.388262087944\n",
      "positions (x,y,z), reward: [  0.17335363  -0.09741355  31.96544327] 15.2360179738\n",
      "positions (x,y,z), reward: [  0.72266656  -0.27670609  43.69089455] 67.8581298029\n",
      "positions (x,y,z), reward: [  1.79522119  -0.50887713  56.3471601 ] 167.66228826\n",
      "positions (x,y,z), reward: [  3.84630399  -0.96987748  72.09384602] 165.311631075\n",
      "positions (x,y,z), reward: [  4.57338948  -1.1939985   76.5919975 ] 164.324890388\n",
      "positions (x,y,z), reward: [  5.15889534  -1.40818168  79.96133083] 163.488996882\n",
      "positions (x,y,z), reward: [  5.67223378  -1.62244929  82.76553151] 166.874476578\n",
      "positions (x,y,z), reward: [  6.65021585  -2.10317454  87.80392885] 172.907887513\n",
      "positions (x,y,z), reward: [  8.53177662  -3.32995118  96.73397303] 183.084409857\n",
      "positions (x,y,z), reward: [  8.65431961  -3.42506815  97.29084519] 183.692904\n",
      "positions (x,y,z), reward: [  11.19638643   -5.86560017  108.36919528] 269.872466967\n",
      "positions (x,y,z), reward: [  15.28770898  -11.85095481  124.49131127] 240.872138232\n",
      "positions (x,y,z), reward: [  17.28799303  -15.76447988  131.61183182] 233.717742347\n",
      "positions (x,y,z), reward: [  18.45644752  -18.34381625  135.50525088] 229.057773812\n",
      "Episode =  291, score = 308.534 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.15373140e-03  -5.61230529e-03   2.48836457e+01] 9.44440521792\n",
      "positions (x,y,z), reward: [  2.66945467e-03  -6.97751649e-03   2.59730131e+01] 10.8281386569\n",
      "positions (x,y,z), reward: [ -0.04245406  -0.04366888  37.38760257] 67.4928268048\n",
      "positions (x,y,z), reward: [ -0.41964786  -0.5356631   60.22525617] 169.033538061\n",
      "positions (x,y,z), reward: [ -0.43124265  -0.56090832  60.78523261] 169.013667898\n",
      "positions (x,y,z), reward: [ -0.64143301  -1.22790374  71.47390643] 168.353770408\n",
      "positions (x,y,z), reward: [ -0.79080947  -2.15269389  80.52379349] 168.16377453\n",
      "positions (x,y,z), reward: [ -0.79895319  -2.22497268  81.09035728] 168.937342673\n",
      "positions (x,y,z), reward: [ -0.80691335  -2.29921431  81.65700188] 169.70900861\n",
      "positions (x,y,z), reward: [ -0.91666682  -4.92664233  95.82017568] 188.115394106\n",
      "positions (x,y,z), reward: [  -0.90099225   -6.13113271  100.32365399] 292.528037236\n",
      "positions (x,y,z), reward: [  -0.88755522   -6.63199373  102.0038486 ] 289.428957286\n",
      "positions (x,y,z), reward: [  -0.83980747   -7.90752741  105.90003089] 282.090053097\n",
      "positions (x,y,z), reward: [  -0.76965362   -9.33642047  109.75350275] 274.607123998\n",
      "positions (x,y,z), reward: [  -0.69288789  -10.68699472  113.01438014] 268.087590451\n",
      "positions (x,y,z), reward: [  -0.53486332  -13.2040583   118.3442613 ] 257.022307646\n",
      "positions (x,y,z), reward: [  2.81325566e-02  -2.20703790e+01   1.32336281e+02] 245.474024571\n",
      "positions (x,y,z), reward: [   0.2011032   -25.4945722   136.46961044] 244.202879308\n",
      "positions (x,y,z), reward: [   0.32305012  -28.75947081  139.97425356] 243.069259095\n",
      "Episode =  292, score = 318.607 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.12089929  -3.06689017  56.82338363] 166.543629776\n",
      "positions (x,y,z), reward: [  0.12720393 -14.12907751  87.31192812] 164.368315737\n",
      "positions (x,y,z), reward: [   3.6042373   -52.12215569  122.97943894] 233.093990729\n",
      "positions (x,y,z), reward: [   4.06488865  -56.61295185  125.23230813] 231.383750339\n",
      "Episode =  293, score = 300.270 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.57735432e-03  -2.17086982e-03   2.48820397e+01] 9.44649512015\n",
      "positions (x,y,z), reward: [ -0.08024657   0.1098016   36.8752617 ] 67.2465597501\n",
      "positions (x,y,z), reward: [ -0.28583455   0.57912129  49.70507836] 118.808532015\n",
      "positions (x,y,z), reward: [ -0.56839053   1.40711946  60.44848229] 168.907839437\n",
      "positions (x,y,z), reward: [ -1.41139822   3.7737705   77.39447141] 168.839285999\n",
      "positions (x,y,z), reward: [ -2.22691758   5.64843601  86.70555192] 178.768301402\n",
      "positions (x,y,z), reward: [ -2.9586682    7.1042158   93.11240862] 188.259304772\n",
      "positions (x,y,z), reward: [  -6.00003863   11.88587361  113.48877341] 279.976371902\n",
      "Episode =  294, score = 381.395 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.79953249e-08  -4.29363963e-08   2.00699437e+01] -5.67031686448\n",
      "positions (x,y,z), reward: [ -4.20678312e-05  -1.00864472e-04   2.09288396e+01] 0.328520857272\n",
      "positions (x,y,z), reward: [ -7.43756465e-05  -1.13289609e-04   2.14917952e+01] 2.41966376405\n",
      "positions (x,y,z), reward: [  9.45980032e-03   1.40653651e-02   2.67419461e+01] 11.6571732722\n",
      "positions (x,y,z), reward: [  1.21966316  -0.24408346  57.51310678] 168.718517202\n",
      "positions (x,y,z), reward: [  1.56467449  -0.46138312  61.47175035] 168.326362008\n",
      "positions (x,y,z), reward: [  1.89983847  -0.70506303  64.87967512] 167.829776443\n",
      "positions (x,y,z), reward: [  3.04764823  -1.71900589  74.55583274] 165.662464852\n",
      "positions (x,y,z), reward: [  4.77217837  -3.62172283  85.86153622] 170.423861654\n",
      "positions (x,y,z), reward: [  6.98978798  -6.49885839  97.47946017] 181.985997743\n",
      "positions (x,y,z), reward: [  7.45698213  -7.14875783  99.65302696] 183.95567015\n",
      "positions (x,y,z), reward: [   8.30695686   -8.36377378  103.42218287] 276.954661534\n",
      "positions (x,y,z), reward: [  13.90834499  -17.20776619  123.98467439] 235.425534985\n",
      "positions (x,y,z), reward: [  14.37842429  -18.00218605  125.45138891] 233.967222788\n",
      "positions (x,y,z), reward: [  16.3297163   -21.35009264  131.1984138 ] 229.20233528\n",
      "positions (x,y,z), reward: [  20.43101546  -28.46121919  141.64967744] 223.910256813\n",
      "Episode =  295, score = 306.980 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.50046615e-03   8.74735299e-03   2.29764576e+01] 6.21814427904\n",
      "positions (x,y,z), reward: [ -0.26664701   0.5736399   44.21702104] 118.051112201\n",
      "positions (x,y,z), reward: [ -0.36830065   0.69634325  47.46751346] 118.197157491\n",
      "positions (x,y,z), reward: [ -1.46109163   1.22781856  66.40500463] 167.527443044\n",
      "positions (x,y,z), reward: [ -2.11774116   1.25981873  73.19092846] 166.941990582\n",
      "positions (x,y,z), reward: [ -4.71838338   0.64683527  91.32681591] 181.901110761\n",
      "positions (x,y,z), reward: [ -10.02719508   -1.8485351   113.06704784] 267.802171522\n",
      "positions (x,y,z), reward: [ -13.34450021   -3.65102561  122.75152614] 251.498230255\n",
      "positions (x,y,z), reward: [ -18.35662829   -6.47527729  134.67250014] 242.479325938\n",
      "Episode =  296, score = 316.883 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -4.07747981e-10   5.29038089e-09   2.00310902e+01] -6.44580759273\n",
      "positions (x,y,z), reward: [ -4.79596362e-06   1.23498203e-05   2.02788888e+01] -3.36930360373\n",
      "positions (x,y,z), reward: [ -3.14463868e-03   4.47578142e-03   2.38799091e+01] 7.90372227631\n",
      "positions (x,y,z), reward: [ -7.75873536e-03   1.25082640e-02   2.67409945e+01] 11.6584141779\n",
      "positions (x,y,z), reward: [ -1.16011618e-02   1.85025156e-02   2.83767580e+01] 13.1467869713\n",
      "positions (x,y,z), reward: [ -2.66836675e-02   3.58666319e-02   3.19621476e+01] 15.4405089549\n",
      "positions (x,y,z), reward: [ -0.65259538   0.38351326  52.45514275] 168.814301415\n",
      "positions (x,y,z), reward: [ -0.9322198    0.5130883   55.81565707] 168.685459167\n",
      "positions (x,y,z), reward: [ -1.10416048   0.58921721  57.50812599] 168.565883896\n",
      "positions (x,y,z), reward: [ -6.42493743   2.3477248   79.94464273] 162.102612535\n",
      "positions (x,y,z), reward: [-10.46730779   3.30742252  88.5716055 ] 169.677096709\n",
      "positions (x,y,z), reward: [-12.4148255    3.69453015  91.99677157] 172.360049366\n",
      "positions (x,y,z), reward: [-16.06193034   4.30924477  97.68271391] 176.55309699\n",
      "positions (x,y,z), reward: [ -18.06679768    4.59312137  100.52772298] 277.034888848\n",
      "positions (x,y,z), reward: [ -44.62213803    6.39955082  133.37520986] 255.446572357\n",
      "positions (x,y,z), reward: [ -61.9717577     9.78332049  161.77644632] 172.034085489\n",
      "Episode =  297, score = 303.662 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777759] -7.22224229626\n",
      "positions (x,y,z), reward: [  9.17257323e-05   2.55747743e-04   2.06248347e+01] -1.11958169031\n",
      "positions (x,y,z), reward: [  1.68017789e-04   3.94231445e-04   2.07697608e+01] -0.388850151705\n",
      "positions (x,y,z), reward: [  2.46104610e-02   3.01597655e-02   2.55969686e+01] 10.3218235774\n",
      "positions (x,y,z), reward: [  0.04928314   0.05902825  27.54156972] 12.3412678465\n",
      "positions (x,y,z), reward: [  0.42393277   0.4390097   39.96670906] 67.3321910245\n",
      "positions (x,y,z), reward: [  0.49867141   0.50922851  41.54793613] 67.4941893389\n",
      "positions (x,y,z), reward: [  0.52517885   0.53390002  42.07893601] 67.5352956462\n",
      "positions (x,y,z), reward: [  0.80113432   0.78432485  46.92924552] 117.660901147\n",
      "positions (x,y,z), reward: [  1.57386327   1.43716128  56.88497037] 166.954629778\n",
      "positions (x,y,z), reward: [  2.61008236   2.23818386  66.45458626] 165.43794339\n",
      "positions (x,y,z), reward: [  2.90120546   2.45233858  68.71966844] 164.982935539\n",
      "positions (x,y,z), reward: [  3.37374151   2.79112854  72.12431961] 164.237591018\n",
      "positions (x,y,z), reward: [  3.54109372   2.90855749  73.2609485 ] 163.974032211\n",
      "positions (x,y,z), reward: [  5.39445515   4.11310867  84.10421032] 167.315736226\n",
      "positions (x,y,z), reward: [  6.58363102   4.7797288   89.85982273] 174.316840577\n",
      "positions (x,y,z), reward: [  7.1060196    5.04370769  92.17556032] 177.107215539\n",
      "positions (x,y,z), reward: [  7.79897055   5.36643484  95.08211543] 180.586140504\n",
      "positions (x,y,z), reward: [  10.6976853     6.38433747  105.66311573] 276.072249433\n",
      "positions (x,y,z), reward: [  15.74171046    6.99967694  120.04633013] 249.422867489\n",
      "positions (x,y,z), reward: [  16.48162394    6.98445634  121.85674356] 248.697389506\n",
      "positions (x,y,z), reward: [  18.30934144    6.84863292  126.07574789] 246.911313741\n",
      "positions (x,y,z), reward: [  22.09343813    6.17953946  133.8336183 ] 245.320348366\n",
      "positions (x,y,z), reward: [  24.68225536    5.47217095  138.50729414] 245.38979137\n",
      "positions (x,y,z), reward: [  27.11296662    4.65812918  142.4983622 ] 245.435563208\n",
      "positions (x,y,z), reward: [  28.57255493    4.10920217  144.72581009] 245.446023454\n",
      "Episode =  298, score = 311.549 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  7.79897829e-03  -1.30826492e-03   2.29745182e+01] 6.21049782425\n",
      "positions (x,y,z), reward: [  0.53709682   0.53475826  45.32080996] 118.036902089\n",
      "positions (x,y,z), reward: [  0.60393785   0.62682493  46.95300915] 118.062233901\n",
      "positions (x,y,z), reward: [  0.77487598   0.871246    50.79821441] 117.968593994\n",
      "positions (x,y,z), reward: [  1.87378009   2.56841538  69.77165889] 165.531127394\n",
      "positions (x,y,z), reward: [  2.19147456   3.05780891  74.24640351] 164.709130451\n",
      "positions (x,y,z), reward: [   4.75116194    6.12080289  109.39724422] 276.093791071\n",
      "positions (x,y,z), reward: [   5.00188773    6.08420034  121.10265191] 260.337247264\n",
      "positions (x,y,z), reward: [   2.88816663    3.89571843  144.62846963] 264.279846875\n",
      "Episode =  299, score = 321.365 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.56675603e-05  -1.03019572e-04   2.04941199e+01] -1.86803643414\n",
      "positions (x,y,z), reward: [  4.50823463e-05  -7.52407794e-04   2.11015864e+01] 1.02794081806\n",
      "positions (x,y,z), reward: [ -1.39342475e-02  -5.51833069e-02   2.87925837e+01] 13.4192560734\n",
      "positions (x,y,z), reward: [ -2.06781322e-02  -8.23470176e-02   3.10185500e+01] 14.8749431167\n",
      "positions (x,y,z), reward: [ -0.04003347  -0.17279054  36.85305979] 67.1950270582\n",
      "positions (x,y,z), reward: [ -0.04800397  -0.23148626  39.95031158] 67.8953155905\n",
      "positions (x,y,z), reward: [ -0.04783886  -0.37583562  46.36264237] 118.734495351\n",
      "positions (x,y,z), reward: [  3.22942937e-02  -6.44204390e-01   5.62851529e+01] 169.189793241\n",
      "positions (x,y,z), reward: [  0.33331629  -0.96918718  68.08881346] 169.008459521\n",
      "positions (x,y,z), reward: [  0.52656045  -1.08379994  72.63042814] 168.84486867\n",
      "positions (x,y,z), reward: [  2.17834566  -1.46473393  93.96129798] 188.506148558\n",
      "positions (x,y,z), reward: [  1.12354948e+01  -2.91603053e-02   1.40208170e+02] 260.54442686\n",
      "Episode =  300, score = 324.563 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.89227266e-05   4.77842250e-07   2.03796649e+01] -2.60477053981\n",
      "positions (x,y,z), reward: [ -1.28887891e-02   1.39408508e-03   2.42082331e+01] 8.43657883097\n",
      "positions (x,y,z), reward: [ -5.55891020e-02   7.74843467e-03   2.79628208e+01] 12.7613380592\n",
      "positions (x,y,z), reward: [ -9.48939830e-02   1.53644950e-02   3.01290604e+01] 14.3322205238\n",
      "positions (x,y,z), reward: [ -0.83122461   0.24313101  46.93786378] 118.161249735\n",
      "positions (x,y,z), reward: [ -1.25470267   0.39819786  52.43029103] 167.993236443\n",
      "positions (x,y,z), reward: [ -1.60704856   0.53191683  56.31304977] 167.668785715\n",
      "positions (x,y,z), reward: [ -2.248572     0.78090316  62.44592306] 166.896435678\n",
      "positions (x,y,z), reward: [ -7.20079304   2.89069357  91.56295191] 177.223291221\n",
      "positions (x,y,z), reward: [ -15.19130592    6.19522584  114.19149276] 256.309364019\n",
      "positions (x,y,z), reward: [ -17.09915258    6.91287514  117.95030618] 247.757710902\n",
      "positions (x,y,z), reward: [ -21.11454208    8.34327534  124.82134171] 239.795030044\n",
      "positions (x,y,z), reward: [ -23.89520842    9.27431671  128.97701553] 238.520262578\n",
      "Episode =  301, score = 309.423 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777862] -7.22213792284\n",
      "positions (x,y,z), reward: [ -2.69219424e-08   4.31228971e-09   2.00311081e+01] -6.44491677856\n",
      "positions (x,y,z), reward: [ -1.44133249e-03  -1.18746376e-03   2.14921799e+01] 2.4181079745\n",
      "positions (x,y,z), reward: [ -1.93283561e-03  -1.64556565e-03   2.17073064e+01] 3.08815355944\n",
      "positions (x,y,z), reward: [ -0.05644171  -0.03729865  28.38050372] 13.0977277051\n",
      "positions (x,y,z), reward: [ -0.11203574  -0.06085994  31.50032408] 15.0992201307\n",
      "positions (x,y,z), reward: [ -0.89403823  -0.29829589  50.77252189] 118.33927026\n",
      "positions (x,y,z), reward: [ -2.51694461  -0.5738539   68.61569166] 166.947477787\n",
      "positions (x,y,z), reward: [ -2.65353687  -0.58851622  69.73734566] 166.799110919\n",
      "positions (x,y,z), reward: [ -4.40746831  -0.6911249   81.52263241] 167.270227374\n",
      "positions (x,y,z), reward: [ -4.82456493  -0.69384057  83.77093282] 170.245269501\n",
      "positions (x,y,z), reward: [ -5.51473458  -0.68299468  87.14724014] 174.67072721\n",
      "positions (x,y,z), reward: [ -8.33722338  -0.50370558  97.87126067] 188.214761801\n",
      "positions (x,y,z), reward: [ -21.22550709    0.79194422  124.92722465] 247.543364401\n",
      "positions (x,y,z), reward: [ -36.59242813    1.65478088  143.16591692] 243.04790915\n",
      "positions (x,y,z), reward: [ -38.04343864    1.68354084  144.51832   ] 242.67013967\n",
      "Episode =  302, score = 316.194 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.32026546  -0.46131888  34.86262449] 15.9627510957\n",
      "positions (x,y,z), reward: [-12.54019478 -25.92004009  89.43414445] 141.32270275\n",
      "positions (x,y,z), reward: [-15.44986324 -32.37315035  93.59888137] 141.192311161\n",
      "positions (x,y,z), reward: [-18.31127364 -38.85327897  96.60958583] 139.407948597\n",
      "positions (x,y,z), reward: [-18.80295253 -39.97587998  97.0303816 ] 138.962457559\n",
      "positions (x,y,z), reward: [-19.05030809 -40.54132445  97.23199278] 138.724177656\n",
      "positions (x,y,z), reward: [-21.32139819 -45.74481369  98.78093754] 137.431185634\n",
      "positions (x,y,z), reward: [-22.61833952 -48.71618737  99.43263658] 136.901711744\n",
      "positions (x,y,z), reward: [ -24.74913179  -53.57485982  100.15836477] 235.046645697\n",
      "positions (x,y,z), reward: [ -30.73767573  -66.82644726  100.09634643] 202.050170938\n",
      "positions (x,y,z), reward: [-34.82655297 -75.27291931  98.45930504] 94.7803906253\n",
      "Episode =  303, score = 228.904 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.21951047  -0.088819    31.03155006] 14.6745831485\n",
      "positions (x,y,z), reward: [ -0.34099226  -0.15253454  33.39194788] 15.6745414816\n",
      "positions (x,y,z), reward: [ -0.46768676  -0.21967843  35.35750612] 16.2463384379\n",
      "positions (x,y,z), reward: [ -5.11778392  -2.18005729  61.2528848 ] 162.212940372\n",
      "positions (x,y,z), reward: [ -6.22799698  -2.58348549  64.54405981] 160.50314985\n",
      "positions (x,y,z), reward: [ -7.70087312  -3.10328266  68.3464554 ] 158.167001956\n",
      "positions (x,y,z), reward: [ -9.88839613  -3.85189467  73.14924329] 154.599200514\n",
      "positions (x,y,z), reward: [-16.41800755  -5.94328121  83.75890137] 149.190137285\n",
      "positions (x,y,z), reward: [-19.47719494  -6.84737672  87.48395702] 149.485312119\n",
      "positions (x,y,z), reward: [-29.57318966  -9.4639044   96.42108632] 154.890910739\n",
      "positions (x,y,z), reward: [ -43.21628203  -11.96826631  103.28425463] 245.657337471\n",
      "positions (x,y,z), reward: [ -50.22150822  -12.74194728  105.20154245] 238.279916361\n",
      "positions (x,y,z), reward: [ -69.9309332   -13.05331942  106.31750137] 200.725851645\n",
      "Episode =  304, score = 274.648 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  5.38420671e-05  -1.35240094e-04   2.04946663e+01] -1.8613163181\n",
      "positions (x,y,z), reward: [  4.23265849e-03  -5.96519615e-03   2.29766693e+01] 6.21685312241\n",
      "positions (x,y,z), reward: [  0.26242112  -0.18598527  37.38565389] 67.1222520898\n",
      "positions (x,y,z), reward: [  0.65733483  -0.44286969  45.85588106] 118.060920098\n",
      "positions (x,y,z), reward: [  1.75095689  -1.21592262  59.21224264] 167.445890051\n",
      "positions (x,y,z), reward: [  2.94549412  -2.1726879   68.42841814] 166.041891447\n",
      "positions (x,y,z), reward: [  15.3590541   -16.15425099  113.68216547] 247.841258435\n",
      "positions (x,y,z), reward: [  28.59715378  -36.76766685  139.91911366] 223.176678326\n",
      "Episode =  305, score = 302.954 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.44704780e-06  -2.55858579e-06   2.01242307e+01] -4.89951219182\n",
      "positions (x,y,z), reward: [  3.65197863e-04  -9.90123970e-05   2.06243524e+01] -1.12529386285\n",
      "positions (x,y,z), reward: [  2.45485898e-03   2.14645126e-04   2.14914283e+01] 2.41641511698\n",
      "positions (x,y,z), reward: [  1.13956638e-02   7.86549295e-03   2.32657388e+01] 6.78496070694\n",
      "positions (x,y,z), reward: [  0.54723416   1.07347599  45.29305825] 117.406680585\n",
      "positions (x,y,z), reward: [  0.75833272   1.46236926  49.65417261] 117.234882248\n",
      "positions (x,y,z), reward: [  0.88021334   1.67931861  51.85707187] 117.050296039\n",
      "positions (x,y,z), reward: [  2.95766295   4.83040323  75.3729325 ] 162.428519534\n",
      "positions (x,y,z), reward: [  6.50854897   8.83003571  96.90617742] 180.527427176\n",
      "positions (x,y,z), reward: [   8.34227907   10.3717092   104.92446294] 274.678812051\n",
      "positions (x,y,z), reward: [  10.54127337   11.79047161  113.02574704] 259.193223366\n",
      "positions (x,y,z), reward: [  10.88799301   11.97694666  114.18898914] 256.944199839\n",
      "positions (x,y,z), reward: [  11.42382203   12.2474716   115.93571974] 253.550332142\n",
      "positions (x,y,z), reward: [  17.08058648   14.109085    131.59976097] 239.41953455\n",
      "positions (x,y,z), reward: [  21.0840245    14.69902714  140.60194812] 234.883660993\n",
      "positions (x,y,z), reward: [  24.37618518   14.90878399  147.10730381] 233.703262858\n",
      "Episode =  306, score = 307.434 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.15296587   0.13912445  29.23842071] 13.5381469495\n",
      "positions (x,y,z), reward: [ -1.04326271   0.99397281  44.76052104] 116.982465088\n",
      "positions (x,y,z), reward: [ -1.38405878   1.34208416  48.57934012] 116.776214759\n",
      "positions (x,y,z), reward: [ -6.8840101    6.95650076  80.78217032] 160.64800951\n",
      "positions (x,y,z), reward: [ -8.01305741   8.05621791  85.20468366] 165.596459418\n",
      "positions (x,y,z), reward: [ -8.6972293    8.71177182  87.76557868] 168.400123144\n",
      "positions (x,y,z), reward: [ -18.25346549   16.70247705  118.82148488] 246.81863007\n",
      "positions (x,y,z), reward: [ -25.68959365   21.32344592  141.90933246] 251.600392372\n",
      "positions (x,y,z), reward: [ -31.18838922   23.96893574  161.58771188] 170.942070525\n",
      "positions (x,y,z), reward: [ -33.69011182   24.9534138   172.2332717 ] 136.26309031\n",
      "positions (x,y,z), reward: [ -35.57400141   25.56361972  181.44068472] 132.911025166\n",
      "Episode =  307, score = 291.972 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.84636937e-07  -1.63928822e-07   2.00699503e+01] -5.67003749144\n",
      "positions (x,y,z), reward: [  2.38661573e-04  -2.62964595e-05   2.04945114e+01] -1.86224776931\n",
      "positions (x,y,z), reward: [  0.08528253  -0.04161681  29.67788883] 14.0241052394\n",
      "positions (x,y,z), reward: [  0.09211271  -0.04645314  30.12387862] 14.3085803921\n",
      "positions (x,y,z), reward: [  1.3358436   -0.26493747  59.14865982] 168.619907731\n",
      "positions (x,y,z), reward: [  1.79125215  -0.21589979  64.2609291 ] 168.566806218\n",
      "positions (x,y,z), reward: [  3.65310527   0.15726091  78.84276825] 168.056080823\n",
      "positions (x,y,z), reward: [  5.53457018   0.63710451  89.21668247] 180.879862922\n",
      "positions (x,y,z), reward: [  11.28243363    1.9615159   112.26376897] 278.316012344\n",
      "positions (x,y,z), reward: [  12.21380561    2.10720594  115.36036751] 274.10314138\n",
      "positions (x,y,z), reward: [  25.67349936    1.57090486  153.13688561] 245.791481165\n",
      "positions (x,y,z), reward: [  85.16005341  -35.84022656  292.41044507] 1251.32192022\n",
      "Episode =  308, score = 356.899 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.85309078e-04  -5.45027980e-04   2.17063772e+01] 3.08719010226\n",
      "positions (x,y,z), reward: [  8.82515158e-04  -8.76818925e-04   2.21760256e+01] 4.38481054361\n",
      "positions (x,y,z), reward: [  6.01355789e-02  -1.16387845e-02   2.96742277e+01] 14.0687974815\n",
      "positions (x,y,z), reward: [  0.99767692  -0.88680068  58.56101981] 168.181803563\n",
      "positions (x,y,z), reward: [  2.21187743  -3.46682433  76.11731021] 164.687829092\n",
      "positions (x,y,z), reward: [  3.07799609  -5.52398186  84.03724669] 167.625260754\n",
      "positions (x,y,z), reward: [  3.61001564  -6.77918821  87.97225812] 171.593892823\n",
      "positions (x,y,z), reward: [  11.71971976  -25.47781319  120.23122375] 232.774449207\n",
      "positions (x,y,z), reward: [  14.31202177  -31.52011034  126.19130519] 227.67556457\n",
      "Episode =  309, score = 302.759 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -8.38593411e-07   1.28155343e-06   2.00699526e+01] -5.66962966043\n",
      "positions (x,y,z), reward: [ -1.78021483e-04   2.75540426e-04   2.06249410e+01] -1.11762604683\n",
      "positions (x,y,z), reward: [-11.87537598   7.9088025   91.00909296] 171.196185245\n",
      "positions (x,y,z), reward: [-12.12763877   8.05223792  91.65954482] 171.878250949\n",
      "positions (x,y,z), reward: [ -16.00020019   10.1024514   101.0128851 ] 278.745982751\n",
      "positions (x,y,z), reward: [ -20.52077645   12.17455547  111.02800186] 260.725571807\n",
      "positions (x,y,z), reward: [ -35.96203698   17.35792737  145.89830068] 268.616702369\n",
      "Episode =  310, score = 336.212 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.36533887e-05  -9.14991930e-05   2.03789789e+01] -2.61495345667\n",
      "positions (x,y,z), reward: [  1.64386807e-02  -3.30549980e-02   2.59675939e+01] 10.7796442449\n",
      "positions (x,y,z), reward: [  0.03511419  -0.07224681  29.67353616] 14.0400764574\n",
      "positions (x,y,z), reward: [  0.05252475  -0.12397212  33.87586592] 16.2138726345\n",
      "positions (x,y,z), reward: [ -0.27239289  -0.67456376  56.88742797] 168.967191666\n",
      "positions (x,y,z), reward: [ -1.34208324  -1.78268837  78.78276609] 167.077226725\n",
      "positions (x,y,z), reward: [ -1.39737119  -1.8467915   79.91207743] 167.000406531\n",
      "positions (x,y,z), reward: [ -1.80328995  -2.40617472  90.20652494] 182.1763476\n",
      "positions (x,y,z), reward: [ -1.8340909   -2.46470536  91.37300248] 183.988149472\n",
      "positions (x,y,z), reward: [  -1.62926667   -3.2081008   111.9749536 ] 283.153583171\n",
      "positions (x,y,z), reward: [  -0.99227747   -3.31322888  121.97114968] 275.356063238\n",
      "positions (x,y,z), reward: [ -6.09624634e-02  -3.22946892e+00   1.32385814e+02] 281.493373371\n",
      "positions (x,y,z), reward: [   0.3796435    -3.14051128  136.7938271 ] 283.920395248\n",
      "Episode =  311, score = 320.411 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777746] -7.22225471221\n",
      "positions (x,y,z), reward: [  3.87047443e-07   8.88306579e-09   2.00699507e+01] -5.67013093405\n",
      "positions (x,y,z), reward: [  7.46629191e-05   1.80551147e-05   2.03792206e+01] -2.61152851564\n",
      "positions (x,y,z), reward: [  3.49796429e-04   1.81831345e-04   2.07694687e+01] -0.393035322907\n",
      "positions (x,y,z), reward: [  9.69575105e-04   7.82314781e-04   2.12901757e+01] 1.73231630969\n",
      "positions (x,y,z), reward: [ -0.07937234   0.68890735  48.01381651] 118.53219889\n",
      "positions (x,y,z), reward: [ -0.21713488   1.39385601  61.85840518] 168.322867357\n",
      "positions (x,y,z), reward: [ -0.19286917   3.23679184  87.72133246] 178.3983028\n",
      "positions (x,y,z), reward: [   1.10697659    6.95692349  119.83141797] 262.200915651\n",
      "positions (x,y,z), reward: [   1.81930801    8.93295087  131.02740657] 259.21552282\n",
      "positions (x,y,z), reward: [   1.85587427    9.04439085  131.58677507] 259.065905938\n",
      "Episode =  312, score = 324.585 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00778004] -7.22199866564\n",
      "positions (x,y,z), reward: [ -1.87353963e-05  -2.33962363e-05   2.01940533e+01] -4.12882442635\n",
      "positions (x,y,z), reward: [ -1.61572130e-02  -1.90045856e-02   2.35691357e+01] 7.33443617685\n",
      "positions (x,y,z), reward: [ -0.04868001  -0.04957829  25.97302523] 10.7370526913\n",
      "positions (x,y,z), reward: [ -0.53929974  -0.31458521  38.40564366] 66.9612770782\n",
      "positions (x,y,z), reward: [ -0.98138938  -0.46414947  44.21498978] 117.446449729\n",
      "positions (x,y,z), reward: [ -1.18780177  -0.51974301  46.37757476] 117.448409919\n",
      "positions (x,y,z), reward: [ -3.28055582  -0.86355513  60.75299059] 165.744040209\n",
      "positions (x,y,z), reward: [ -3.84721953  -0.92625658  63.54139329] 165.099873098\n",
      "positions (x,y,z), reward: [ -5.99526985  -1.12193931  72.42758112] 162.501606342\n",
      "positions (x,y,z), reward: [-13.14046996  -1.5925827   94.07649074] 174.907344775\n",
      "positions (x,y,z), reward: [-13.75886222  -1.63024733  95.66594684] 176.566327035\n",
      "positions (x,y,z), reward: [-15.02793521  -1.70769377  98.8326245 ] 179.834630042\n",
      "positions (x,y,z), reward: [ -16.56330921   -1.80170281  102.5065331 ] 276.038191781\n",
      "positions (x,y,z), reward: [ -34.1781691    -2.93547928  135.96633023] 243.237537151\n",
      "Episode =  313, score = 307.708 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.09308089  -0.04144761  37.38156273] 67.4363040383\n",
      "positions (x,y,z), reward: [ -0.13927032  -0.05471     39.97106767] 67.9987048494\n",
      "positions (x,y,z), reward: [ -0.16144016  -0.06089813  41.02303292] 68.1782595394\n",
      "positions (x,y,z), reward: [ -0.17337797  -0.0641958   41.55203064] 68.2591680924\n",
      "positions (x,y,z), reward: [ -0.41082484  -0.12614601  49.11900675] 118.903543262\n",
      "positions (x,y,z), reward: [ -2.51037784  -0.41146502  73.7455028 ] 167.299407817\n",
      "positions (x,y,z), reward: [ -2.6713982   -0.4190234   74.87460351] 167.137314017\n",
      "positions (x,y,z), reward: [ -2.83962126  -0.42540243  76.00391905] 166.966981149\n",
      "positions (x,y,z), reward: [ -3.198521    -0.43433539  78.262876  ] 166.602422625\n",
      "positions (x,y,z), reward: [ -4.23542249  -0.43101173  83.90932525] 171.412021055\n",
      "positions (x,y,z), reward: [ -5.48421629  -0.38540556  89.5451815 ] 178.575753862\n",
      "positions (x,y,z), reward: [ -6.49002667  -0.32614855  93.47579278] 183.411051942\n",
      "positions (x,y,z), reward: [ -7.77501068  -0.23024806  97.94389278] 188.73690996\n",
      "positions (x,y,z), reward: [ -9.97667466e+00  -2.92778677e-02   1.04579391e+02] 282.575213318\n",
      "positions (x,y,z), reward: [ -20.46251751    1.2675832   126.92322792] 246.352420841\n",
      "positions (x,y,z), reward: [ -20.77014898    1.31037555  127.43519553] 246.256218132\n",
      "positions (x,y,z), reward: [ -24.69143253    1.86405014  133.49187487] 245.016112071\n",
      "positions (x,y,z), reward: [ -25.03772134    1.91331752  133.98900399] 244.905484075\n",
      "positions (x,y,z), reward: [ -27.91923992    2.32241945  137.92130618] 243.993332182\n",
      "positions (x,y,z), reward: [ -30.21319915    2.64451988  140.8172218 ] 243.285291544\n",
      "Episode =  314, score = 317.062 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.29410057e-07  -2.82617811e-07   2.00699815e+01] -5.66908281789\n",
      "positions (x,y,z), reward: [ -6.37523331e-03  -2.89351259e-03   2.38818806e+01] 7.90668635965\n",
      "positions (x,y,z), reward: [ -7.49401771e-03  -3.78610814e-03   2.42054976e+01] 8.43399724905\n",
      "positions (x,y,z), reward: [ -2.00264442e-02  -1.53928278e-02   2.67438200e+01] 11.6486027969\n",
      "positions (x,y,z), reward: [ -0.76043016  -0.82972338  53.00849372] 168.187719186\n",
      "positions (x,y,z), reward: [ -0.86586479  -0.94972532  54.67833001] 168.059393882\n",
      "positions (x,y,z), reward: [ -1.29240101  -1.44041817  60.27897836] 167.370426001\n",
      "positions (x,y,z), reward: [ -1.90698858  -2.16366539  66.47581758] 166.129996898\n",
      "positions (x,y,z), reward: [ -2.93250092  -3.40522     74.36682622] 163.785786688\n",
      "positions (x,y,z), reward: [ -3.65790192  -4.2936843   78.85698884] 162.034145035\n",
      "positions (x,y,z), reward: [ -6.54431428  -7.83081672  92.10435422] 172.860339619\n",
      "positions (x,y,z), reward: [ -7.93882908  -9.50791826  96.933387  ] 176.503167682\n",
      "positions (x,y,z), reward: [ -10.51132751  -12.49452582  104.22729611] 268.144030973\n",
      "positions (x,y,z), reward: [ -16.71052466  -19.13268237  116.81243291] 233.694623778\n",
      "positions (x,y,z), reward: [ -25.41978109  -27.51212242  128.52534438] 220.957122983\n",
      "positions (x,y,z), reward: [ -26.11101134  -28.14982342  129.27779323] 220.665136857\n",
      "positions (x,y,z), reward: [ -29.31448473  -31.07352563  132.51853301] 219.340488421\n",
      "Episode =  315, score = 299.133 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.11372866  -0.06986269  32.43252763] 15.5591941813\n",
      "positions (x,y,z), reward: [ -0.19728696  -0.20509363  38.92485089] 67.559549952\n",
      "positions (x,y,z), reward: [ -0.31967329  -0.92812933  55.74188028] 168.540275512\n",
      "positions (x,y,z), reward: [ -0.32348844  -1.15991832  59.6414047 ] 168.425869415\n",
      "positions (x,y,z), reward: [ -0.31023381  -1.52016165  65.23510435] 168.186950885\n",
      "positions (x,y,z), reward: [  6.39133228e-02  -3.10671759e+00   8.71981778e+01] 177.950112155\n",
      "positions (x,y,z), reward: [   3.98391851   -6.56290221  132.19708111] 259.865593179\n",
      "positions (x,y,z), reward: [   4.40794325   -6.76408612  135.03849622] 259.240630273\n",
      "Episode =  316, score = 324.253 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.80902561e-07   9.00927152e-08   2.00699791e+01] -5.6694382805\n",
      "positions (x,y,z), reward: [  3.12141380e-06   5.37205814e-07   2.01243105e+01] -4.89744033722\n",
      "positions (x,y,z), reward: [  0.10183837   0.11757067  29.67564565] 13.9150612007\n",
      "positions (x,y,z), reward: [  0.28949842   0.34404824  35.35631485] 16.3094221936\n",
      "positions (x,y,z), reward: [  0.31106769   0.37022348  35.85692539] 16.4327548535\n",
      "positions (x,y,z), reward: [  0.97375974   1.17642647  46.93395063] 117.076521193\n",
      "positions (x,y,z), reward: [  1.36491107   1.65499228  51.86797529] 116.540573641\n",
      "positions (x,y,z), reward: [  4.6145925    6.47330783  83.10537088] 163.783637918\n",
      "positions (x,y,z), reward: [  5.78373927   9.63428154  95.66522547] 179.028614589\n",
      "positions (x,y,z), reward: [   6.98531779   17.81547909  118.63467804] 251.226771748\n",
      "positions (x,y,z), reward: [   7.21194569   27.0226067   138.79115065] 253.495129852\n",
      "positions (x,y,z), reward: [   7.18798024   28.55366226  141.95320656] 255.185257915\n",
      "positions (x,y,z), reward: [   6.8979829    36.5451462   158.45066904] 168.147821944\n",
      "Episode =  317, score = 306.350 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.14739427e-02  -1.23829741e-02   2.56010959e+01] 10.3578919913\n",
      "positions (x,y,z), reward: [ -0.21053534  -0.17586534  37.38549371] 67.1826785794\n",
      "positions (x,y,z), reward: [ -0.44540644  -0.49384391  46.39169979] 118.238003297\n",
      "positions (x,y,z), reward: [ -0.81575414  -1.493996    59.68716426] 167.7478771\n",
      "positions (x,y,z), reward: [ -0.9787045   -2.28159686  65.87905376] 166.941967465\n",
      "positions (x,y,z), reward: [ -1.09384159  -3.02263673  70.39458703] 166.105485068\n",
      "positions (x,y,z), reward: [ -1.19362739  -3.80656016  74.34457912] 165.186999044\n",
      "positions (x,y,z), reward: [ -1.80936212 -12.22288636  97.43368291] 180.211395199\n",
      "positions (x,y,z), reward: [  -2.39752613  -28.18216578  116.41511634] 244.564718592\n",
      "positions (x,y,z), reward: [  -2.66376505  -39.37409066  124.08745254] 234.569796863\n",
      "positions (x,y,z), reward: [  -2.73417819  -43.21498827  126.11943384] 233.052364533\n",
      "positions (x,y,z), reward: [  -2.78998345  -46.59785003  127.69878167] 231.740335949\n",
      "positions (x,y,z), reward: [  -2.89217699  -53.58042683  130.40323005] 229.10997671\n",
      "Episode =  318, score = 307.066 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.74459434e-05  -3.74118312e-06   2.01941953e+01] -4.12538505224\n",
      "positions (x,y,z), reward: [  4.45335822e-05  -9.94830267e-06   2.02793247e+01] -3.36178811506\n",
      "positions (x,y,z), reward: [  4.78901771e-03  -3.92935090e-03   2.24328445e+01] 5.01389876962\n",
      "positions (x,y,z), reward: [  0.36077866  -1.47625874  47.4743109 ] 117.436462985\n",
      "positions (x,y,z), reward: [  0.5548888   -3.31530543  58.53881591] 166.029676924\n",
      "positions (x,y,z), reward: [  0.5806675   -4.55317956  63.56915344] 164.800589788\n",
      "positions (x,y,z), reward: [  0.42705242  -6.9513128   70.80989868] 162.259923081\n",
      "positions (x,y,z), reward: [ -20.56951704  -43.58604518  106.67082477] 230.524539513\n",
      "positions (x,y,z), reward: [ -32.1675152   -53.50210854  109.28934172] 221.6667262\n",
      "Episode =  319, score = 284.585 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  6.45206794e-03  -3.16391030e-02   2.55971498e+01] 10.3432713681\n",
      "positions (x,y,z), reward: [ -0.13393545  -1.13528057  49.66973534] 118.261923261\n",
      "positions (x,y,z), reward: [ -0.97135674  -4.25569701  68.17883303] 164.976605311\n",
      "positions (x,y,z), reward: [ -2.72136114  -8.73185667  80.97628266] 159.185563867\n",
      "positions (x,y,z), reward: [ -8.79756669 -19.22908911  98.67240595] 164.842746348\n",
      "positions (x,y,z), reward: [ -14.474268    -26.63729953  107.11872902] 246.118011552\n",
      "positions (x,y,z), reward: [ -18.56551982  -31.36452277  111.46320675] 233.153021367\n",
      "positions (x,y,z), reward: [ -29.85990037  -43.27212536  119.59409739] 213.764033796\n",
      "Episode =  320, score = 290.079 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.67698035e-08   2.18226886e-07   2.00311038e+01] -6.44513633018\n",
      "positions (x,y,z), reward: [  1.75584351e-03  -4.36751797e-03   2.21771208e+01] 4.38568044034\n",
      "positions (x,y,z), reward: [  6.31115756e-03  -2.74435977e-01   3.33925223e+01] 15.8886408199\n",
      "positions (x,y,z), reward: [  5.26536101e-03  -3.72391230e-01   3.53578191e+01] 16.5550744434\n",
      "positions (x,y,z), reward: [  4.23271583e-03  -4.29133929e-01   3.63619440e+01] 66.8281008189\n",
      "positions (x,y,z), reward: [ -2.74539194e-02  -1.10466831e+00   4.47608512e+01] 117.861998354\n",
      "positions (x,y,z), reward: [ -4.44533461e-02  -1.34530041e+00   4.69312579e+01] 117.858938026\n",
      "positions (x,y,z), reward: [ -0.20187311  -3.10229543  57.99098757] 166.578282411\n",
      "positions (x,y,z), reward: [ -0.32768946  -4.40697619  63.57051505] 165.133392027\n",
      "positions (x,y,z), reward: [ -0.46681955  -5.87214749  68.57257883] 163.332491522\n",
      "positions (x,y,z), reward: [ -0.4837216   -6.05291443  69.12575321] 163.101638898\n",
      "positions (x,y,z), reward: [ -0.60911574  -7.42172668  72.97644309] 161.315592903\n",
      "positions (x,y,z), reward: [ -0.6660802   -8.06443885  74.61283934] 160.459086616\n",
      "positions (x,y,z), reward: [ -1.21328784 -15.71878631  89.26906277] 163.875940712\n",
      "positions (x,y,z), reward: [  -1.74332317  -41.82249968  113.62460911] 245.080382943\n",
      "positions (x,y,z), reward: [  -1.72184899  -46.32920653  115.9270767 ] 239.888542416\n",
      "positions (x,y,z), reward: [  -1.64353189  -55.88852705  119.66330172] 230.680740333\n",
      "positions (x,y,z), reward: [  -1.60361815  -60.89964415  121.08555691] 228.350338303\n",
      "Episode =  321, score = 298.983 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.14127015e-03  -1.43139769e-04   2.17082593e+01] 3.09800653318\n",
      "positions (x,y,z), reward: [  9.40449489e-02   1.28670093e-02   2.67457138e+01] 11.5729777854\n",
      "positions (x,y,z), reward: [  1.39794235e-01   2.27656710e-02   2.79616851e+01] 12.6628187972\n",
      "positions (x,y,z), reward: [  0.21956633   0.04253138  29.6821825 ] 13.8832518046\n",
      "positions (x,y,z), reward: [  1.44497965   0.45039698  43.69393269] 67.0016705829\n",
      "positions (x,y,z), reward: [  24.87823525   11.83516568  115.24003156] 245.325256887\n",
      "positions (x,y,z), reward: [  25.19519928   11.99230534  115.80016391] 244.29301123\n",
      "positions (x,y,z), reward: [  27.80773558   13.28218402  120.25576346] 236.41772247\n",
      "positions (x,y,z), reward: [  34.56926029   16.53585351  130.65321489] 232.476262449\n",
      "positions (x,y,z), reward: [  39.2312083    18.66303145  137.08763547] 229.953366806\n",
      "positions (x,y,z), reward: [  42.50132576   20.087723    141.33077421] 228.430162846\n",
      "Episode =  322, score = 301.126 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.19806826e-02  -1.20466901e-02   2.32648920e+01] 6.76773269329\n",
      "positions (x,y,z), reward: [  0.28231726  -0.16730223  32.90615008] 15.5113712016\n",
      "positions (x,y,z), reward: [  0.90126437  -0.3185609   42.61062223] 67.4706873814\n",
      "positions (x,y,z), reward: [  2.22795557  -0.42000788  55.75106622] 167.149950625\n",
      "positions (x,y,z), reward: [  3.50531265  -0.45303753  65.23076697] 165.947503179\n",
      "positions (x,y,z), reward: [  4.82063296  -0.46399344  73.59585605] 164.575125311\n",
      "positions (x,y,z), reward: [  4.91299784  -0.46371641  74.15310574] 164.481735785\n",
      "positions (x,y,z), reward: [  7.09874496  -0.38474465  86.99926822] 173.084268626\n",
      "positions (x,y,z), reward: [  9.43205626e+00   8.34903156e-02   1.02395212e+02] 288.066091606\n",
      "positions (x,y,z), reward: [  10.48057671    1.28706929  116.98915133] 266.70638169\n",
      "positions (x,y,z), reward: [  10.17805547    2.55115783  126.29435051] 263.867445399\n",
      "positions (x,y,z), reward: [   8.96587611    4.24901933  136.46016396] 267.003477196\n",
      "positions (x,y,z), reward: [   3.86543405    8.28263464  159.3793202 ] 182.34855226\n",
      "positions (x,y,z), reward: [   3.00565276    8.81520595  162.61908387] 185.70927568\n",
      "Episode =  323, score = 317.525 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.33945937e-02   5.32201697e-02   2.67404773e+01] 11.6089444785\n",
      "positions (x,y,z), reward: [ -1.56248244e-02   2.24727015e-01   3.29098054e+01] 15.7179668333\n",
      "positions (x,y,z), reward: [ -7.78678342e-03   4.93651850e-01   3.89211671e+01] 67.4388969343\n",
      "positions (x,y,z), reward: [ -7.64073534e-03   6.07631247e-01   4.10145376e+01] 67.762139162\n",
      "positions (x,y,z), reward: [ -1.39893625e-02   8.01001462e-01   4.42119462e+01] 118.069795354\n",
      "positions (x,y,z), reward: [ -0.16671804   1.77973848  56.84156252] 167.88038572\n",
      "positions (x,y,z), reward: [ -0.43557747   2.6712671   65.78187047] 166.908490904\n",
      "positions (x,y,z), reward: [ -0.80312952   3.60322682  73.63446009] 165.649647727\n",
      "positions (x,y,z), reward: [ -0.99793857   4.05079822  77.00032604] 164.988118503\n",
      "positions (x,y,z), reward: [ -2.19817512   6.75263131  93.7494001 ] 181.445293585\n",
      "positions (x,y,z), reward: [  -4.36475655   12.89091365  120.20744466] 252.068126635\n",
      "positions (x,y,z), reward: [  -4.40930896   13.04492454  120.75379235] 251.856399138\n",
      "positions (x,y,z), reward: [  -4.67591711   13.99155749  124.02580179] 250.552625603\n",
      "positions (x,y,z), reward: [  -5.52269308   17.24214653  134.30715491] 246.116193247\n",
      "positions (x,y,z), reward: [  -5.70467493   17.97452487  136.45471083] 245.126774201\n",
      "Episode =  324, score = 315.145 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.49685673   1.26688737  67.53966331] 168.67217978\n",
      "positions (x,y,z), reward: [ -0.47183699   1.05351336  75.56283437] 169.316625672\n",
      "positions (x,y,z), reward: [   1.62568222   -9.52295201  111.84897461] 268.980351004\n",
      "Episode =  325, score = 314.975 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.49489264  -0.45564091  47.47807616] 118.350879768\n",
      "positions (x,y,z), reward: [ -0.51663722  -0.50421165  48.57243979] 118.38960592\n",
      "positions (x,y,z), reward: [ -0.62730808  -0.88205258  55.21427721] 168.384345471\n",
      "positions (x,y,z), reward: [ -0.67198047  -2.23454212  69.30872473] 167.516154279\n",
      "positions (x,y,z), reward: [ -0.58106256  -3.00434043  75.01249735] 167.026860171\n",
      "positions (x,y,z), reward: [ -0.11124191  -4.98409256  86.62416247] 176.472036067\n",
      "positions (x,y,z), reward: [   1.69698747   -9.18621324  104.2490029 ] 288.819883825\n",
      "positions (x,y,z), reward: [   5.97424706  -16.13500415  126.20512252] 266.289742699\n",
      "positions (x,y,z), reward: [  11.09024878  -24.24561031  148.86660731] 232.132473798\n",
      "Episode =  326, score = 350.043 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -4.25524154e-03   6.51305120e-03   2.24314254e+01] 5.01070297935\n",
      "positions (x,y,z), reward: [ -6.52414360e-03   9.13814618e-03   2.29766119e+01] 6.21400621137\n",
      "positions (x,y,z), reward: [ -0.05459919   0.04997062  28.37995034] 13.0757817048\n",
      "positions (x,y,z), reward: [ -0.08182799   0.06789638  30.12641185] 14.2968381167\n",
      "positions (x,y,z), reward: [ -0.47485625   0.24963021  44.21994379] 118.153677511\n",
      "positions (x,y,z), reward: [ -0.65691291   0.32503365  49.10675198] 118.398760928\n",
      "positions (x,y,z), reward: [ -0.81016111   0.39039751  52.95885717] 168.431600521\n",
      "positions (x,y,z), reward: [ -0.99501334   0.47444574  57.39594375] 168.347481308\n",
      "positions (x,y,z), reward: [ -1.11549607   0.53374567  60.18201822] 168.250726226\n",
      "positions (x,y,z), reward: [ -1.50751403   0.75445393  68.57714875] 167.786055093\n",
      "positions (x,y,z), reward: [ -3.11337901   1.8818927   92.21200562] 183.494460244\n",
      "positions (x,y,z), reward: [  -4.40375902    2.82974077  104.04291527] 286.856984457\n",
      "positions (x,y,z), reward: [  -4.47743243    2.88271281  104.60603854] 285.883853982\n",
      "positions (x,y,z), reward: [  -4.94733543    3.21690627  107.98379864] 279.996430776\n",
      "positions (x,y,z), reward: [  -5.0305262     3.27538257  108.5465194 ] 279.006331873\n",
      "positions (x,y,z), reward: [  -6.57647661    4.32306971  117.53153971] 262.800793948\n",
      "positions (x,y,z), reward: [  -6.80120755    4.46922772  118.65103306] 260.723600613\n",
      "positions (x,y,z), reward: [  -8.32224135    5.41893874  125.3402801 ] 256.006051573\n",
      "positions (x,y,z), reward: [  -9.51765735    6.12143633  129.76344867] 253.888374713\n",
      "positions (x,y,z), reward: [ -10.51836914    6.68447873  133.05481008] 252.114900128\n",
      "Episode =  327, score = 320.604 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -5.16524009e-03   3.30585192e-02   2.48772910e+01] 9.38977360106\n",
      "positions (x,y,z), reward: [ -4.63722965e-03   5.00000720e-02   2.59653074e+01] 10.7610785213\n",
      "positions (x,y,z), reward: [  2.25764655e-02   1.87575525e-01   3.14856450e+01] 15.0387806528\n",
      "positions (x,y,z), reward: [  0.18107721   0.72229119  42.60237362] 67.7671102569\n",
      "positions (x,y,z), reward: [  0.37284841   1.33341137  50.75313758] 117.847003859\n",
      "positions (x,y,z), reward: [  0.59457992   2.0298562   57.96652734] 167.258486372\n",
      "positions (x,y,z), reward: [  0.73387667   2.46627957  61.87545416] 166.74929608\n",
      "positions (x,y,z), reward: [  1.47032831   4.60761698  77.53884565] 163.865179595\n",
      "positions (x,y,z), reward: [   3.77597586    9.96716649  104.71723441] 278.6117605\n",
      "positions (x,y,z), reward: [   3.83827575   10.1020273   105.26571054] 277.576531826\n",
      "positions (x,y,z), reward: [   5.989929     14.50403147  121.03200302] 248.460460413\n",
      "Episode =  328, score = 312.319 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.67381506   0.62816474  41.54332448] 67.1575594461\n",
      "positions (x,y,z), reward: [ -0.77284882   0.71762822  43.13897494] 67.2266034643\n",
      "positions (x,y,z), reward: [ -2.20774256   1.86180491  58.50392899] 165.776042741\n",
      "positions (x,y,z), reward: [ -2.27953368   1.91229216  59.06099261] 165.665104715\n",
      "positions (x,y,z), reward: [ -4.08514475   3.04039307  70.21984429] 162.743444805\n",
      "positions (x,y,z), reward: [ -5.16062898   3.6132993   75.22847362] 160.991782947\n",
      "positions (x,y,z), reward: [ -16.85904754    7.50131288  105.86954388] 264.361969881\n",
      "positions (x,y,z), reward: [ -37.28584835    9.50478754  133.24070948] 234.212282621\n",
      "Episode =  329, score = 302.668 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  6.23430412e-05   1.38622310e-04   2.03790693e+01] -2.61337303764\n",
      "positions (x,y,z), reward: [  2.50210685e-03   2.02544692e-02   2.35670641e+01] 7.34176541857\n",
      "positions (x,y,z), reward: [  6.70908067e-03   7.43202188e-01   4.36792443e+01] 68.0581286401\n",
      "positions (x,y,z), reward: [  3.67052365e-02   1.23726334e+00   5.24025262e+01] 168.320978192\n",
      "positions (x,y,z), reward: [  0.6453855    5.04985072  99.98194611] 194.339260879\n",
      "positions (x,y,z), reward: [   0.71129639    5.29012412  102.22746116] 290.732225364\n",
      "positions (x,y,z), reward: [   1.10790016    6.42062074  112.91802339] 273.30264599\n",
      "Episode =  330, score = 323.405 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.11807617e-05  -1.19991028e-05   2.01938888e+01] -4.13188042236\n",
      "positions (x,y,z), reward: [ -0.08684654  -0.23219646  30.56666896] 14.3812373254\n",
      "positions (x,y,z), reward: [ -0.98254104  -2.0040774   54.5859989 ] 166.737223787\n",
      "positions (x,y,z), reward: [ -1.15768658  -2.23619317  56.80955039] 166.448849424\n",
      "positions (x,y,z), reward: [ -1.47947147  -2.61192671  60.1618392 ] 165.907638757\n",
      "positions (x,y,z), reward: [ -5.30834694  -5.31304218  78.15611002] 159.118938985\n",
      "positions (x,y,z), reward: [ -6.37656938  -5.86426064  80.91411094] 158.49280604\n",
      "positions (x,y,z), reward: [ -7.86400718  -6.57645241  84.16445806] 160.551366661\n",
      "positions (x,y,z), reward: [-13.30117815  -8.89484179  92.85136196] 163.206676096\n",
      "positions (x,y,z), reward: [-16.85584671 -10.30103774  97.03871556] 162.720220177\n",
      "positions (x,y,z), reward: [ -21.74941226  -12.17909348  101.68216158] 257.089678416\n",
      "positions (x,y,z), reward: [ -23.66409802  -12.90098386  103.22804631] 253.057408763\n",
      "positions (x,y,z), reward: [ -24.64626195  -13.26876893  103.97092922] 251.069020436\n",
      "positions (x,y,z), reward: [ -55.52194747  -23.64204541  116.26231653] 212.57798866\n",
      "positions (x,y,z), reward: [ -64.4927487   -25.91304003  117.32329241] 208.735112079\n",
      "Episode =  331, score = 288.252 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.22113947  -0.14408749  35.36459238] 16.5844660621\n",
      "positions (x,y,z), reward: [ -1.19370569  -0.53504903  49.68897295] 117.803596929\n",
      "positions (x,y,z), reward: [ -1.4363481   -0.61924335  51.89815698] 117.630392446\n",
      "positions (x,y,z), reward: [ -4.58559906  -1.54170281  69.76739444] 163.762199788\n",
      "positions (x,y,z), reward: [ -8.54361604  -2.52580967  83.0041593 ] 162.593783242\n",
      "positions (x,y,z), reward: [-14.64653922  -3.76406932  97.33379806] 175.437553172\n",
      "positions (x,y,z), reward: [ -19.38851203   -4.56489087  105.94770238] 263.91587428\n",
      "positions (x,y,z), reward: [ -21.22592903   -4.84924555  108.89821335] 258.181872883\n",
      "positions (x,y,z), reward: [ -29.81294103   -6.02783054  120.62580758] 238.442686346\n",
      "positions (x,y,z), reward: [ -33.69341931   -6.49220538  125.0355069 ] 237.109004035\n",
      "positions (x,y,z), reward: [ -39.15021528   -7.092751    130.49353955] 235.255742088\n",
      "Episode =  332, score = 303.467 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -7.06796793e-04  -4.92041736e-04   2.09294911e+01] 0.332141820369\n",
      "positions (x,y,z), reward: [ -9.25021668e-03  -7.30887234e-03   2.29772552e+01] 6.21240827239\n",
      "positions (x,y,z), reward: [ -0.06809666  -0.0500727   27.96074901] 12.7164568145\n",
      "positions (x,y,z), reward: [ -0.46021342  -0.3912717   44.23138152] 118.047838328\n",
      "positions (x,y,z), reward: [ -0.76606374  -0.66404839  52.97619986] 168.215708077\n",
      "positions (x,y,z), reward: [  -7.1874577     1.36595247  119.88674563] 268.297682257\n",
      "positions (x,y,z), reward: [  -9.35707836    2.61233447  135.48694341] 266.010242077\n",
      "positions (x,y,z), reward: [ -12.69923069    3.60692499  157.13245603] 161.684060438\n",
      "Episode =  333, score = 319.373 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.08134432e-02   6.82447860e-02   2.59686996e+01] 10.742909458\n",
      "positions (x,y,z), reward: [  0.08598473   1.09772756  41.5496011 ] 67.3789138819\n",
      "positions (x,y,z), reward: [  0.11331738   1.27535524  43.15292893] 67.472397238\n",
      "positions (x,y,z), reward: [  0.2667493    2.14974736  49.72549324] 117.436110136\n",
      "positions (x,y,z), reward: [  0.39626436   2.78918141  53.66215573] 167.178035895\n",
      "positions (x,y,z), reward: [  0.56234787   3.53090872  57.66942052] 166.774273912\n",
      "positions (x,y,z), reward: [  0.64610073   3.88153758  59.40870983] 166.564517753\n",
      "positions (x,y,z), reward: [  1.38453082   6.58903868  70.76070353] 164.71883225\n",
      "positions (x,y,z), reward: [  3.76094167  13.2443652   92.16591336] 177.821067568\n",
      "positions (x,y,z), reward: [   7.24448658   20.58985755  113.41340924] 267.19226613\n",
      "positions (x,y,z), reward: [   7.71207184   21.45366564  116.00907646] 264.258626675\n",
      "positions (x,y,z), reward: [   8.87701171   23.51119352  122.43896114] 261.179210002\n",
      "Episode =  334, score = 354.554 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.31437878e-07   5.77551719e-07   2.00699563e+01] -5.66965347256\n",
      "positions (x,y,z), reward: [  2.47500797e-03   7.45768597e-04   2.17074218e+01] 3.08917599396\n",
      "positions (x,y,z), reward: [  4.12028791e-02  -2.09940781e-03   2.55983600e+01] 10.3359050017\n",
      "positions (x,y,z), reward: [  4.79100374e-02  -2.92569435e-03   2.59704547e+01] 10.7732189052\n",
      "positions (x,y,z), reward: [  0.77578988  -0.1453587   39.4572519 ] 67.2559683541\n",
      "positions (x,y,z), reward: [  0.82504043  -0.15601845  39.98223303] 67.3224710411\n",
      "positions (x,y,z), reward: [  2.04906468  -0.43791813  49.79695148] 117.62129392\n",
      "positions (x,y,z), reward: [  4.53933056  -0.98418345  62.61741074] 166.667823525\n",
      "positions (x,y,z), reward: [ 11.98524804  -2.0612242   88.53692662] 175.864431401\n",
      "positions (x,y,z), reward: [ 12.68112995  -2.12692747  90.66097397] 178.87650477\n",
      "positions (x,y,z), reward: [  19.08537105   -2.40112633  109.43874772] 280.180463945\n",
      "positions (x,y,z), reward: [  28.52423757   -1.68341885  136.58293835] 290.750977897\n",
      "positions (x,y,z), reward: [  44.67933518   -1.84142869  190.80214708] 269.965512541\n",
      "positions (x,y,z), reward: [  45.90458751   -2.17434282  195.417334  ] 291.520604759\n",
      "positions (x,y,z), reward: [  47.24260582   -2.60203406  200.51633812] 317.587289575\n",
      "Episode =  335, score = 398.362 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.00156080e-04  -1.79403886e-05   2.04944591e+01] -1.86219510833\n",
      "positions (x,y,z), reward: [  1.32972877e-03   2.46597631e-04   2.14917724e+01] 2.41641483966\n",
      "positions (x,y,z), reward: [  4.82858669e-03   2.12668894e-03   2.26968439e+01] 5.61665490403\n",
      "positions (x,y,z), reward: [  3.70977956e-02   2.32761238e-02   2.71372957e+01] 12.011591845\n",
      "positions (x,y,z), reward: [  0.29016955   0.1870532   39.96584107] 67.7094735685\n",
      "positions (x,y,z), reward: [  0.36862959   0.24682678  42.6097185 ] 68.0529986866\n",
      "positions (x,y,z), reward: [  1.66298688   2.04142915  73.83570194] 167.158838631\n",
      "positions (x,y,z), reward: [  1.72216095   2.16400851  74.99316051] 167.099285896\n",
      "positions (x,y,z), reward: [  2.73679068   4.41242571  90.64546511] 182.280198282\n",
      "positions (x,y,z), reward: [   4.28434004    7.60954454  105.93384877] 286.578986172\n",
      "positions (x,y,z), reward: [   4.55141287    8.11866997  108.0786769 ] 283.31946878\n",
      "positions (x,y,z), reward: [   8.38117336   14.46481926  132.30232393] 269.259465363\n",
      "positions (x,y,z), reward: [  12.98185116   21.18913117  157.30794223] 189.745903365\n",
      "positions (x,y,z), reward: [  19.97225634   35.99395113  211.64383375] 286.064683112\n",
      "positions (x,y,z), reward: [  21.73433725   44.09955838  237.93936129] 462.594955033\n",
      "Episode =  336, score = 350.537 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -3.06801364e-02   4.77767328e-03   2.35682257e+01] 7.32377242624\n",
      "positions (x,y,z), reward: [ -3.61792889e-01  -4.03348617e-03   3.14861098e+01] 14.8432546296\n",
      "positions (x,y,z), reward: [ -1.87805839  -0.35978385  44.73306777] 116.697816229\n",
      "positions (x,y,z), reward: [ -3.64462411  -1.02725156  53.48000061] 164.904824273\n",
      "positions (x,y,z), reward: [ -5.68411372  -1.97971695  60.65615104] 161.839154693\n",
      "positions (x,y,z), reward: [-12.29106211  -5.29244515  75.04484092] 149.641124208\n",
      "positions (x,y,z), reward: [-32.07278434 -12.44720037  93.06957495] 143.342505897\n",
      "positions (x,y,z), reward: [-49.42751421 -14.70511004  97.94588498] 137.695858483\n",
      "positions (x,y,z), reward: [-50.11860761 -14.7187177   98.01173246] 137.354111217\n",
      "positions (x,y,z), reward: [-59.94191674 -14.25168282  98.02815825] 105.776194045\n",
      "Episode =  337, score = 205.651 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.58659950e-05   1.71837327e-06   2.01242628e+01] -4.89754619173\n",
      "positions (x,y,z), reward: [ -2.02427578e-04  -2.37003703e-06   2.03792902e+01] -2.60953848635\n",
      "positions (x,y,z), reward: [ -1.27446849e-02  -5.26009555e-03   2.26986314e+01] 5.61759640301\n",
      "positions (x,y,z), reward: [ -1.56180019e-02  -6.68250788e-03   2.29773125e+01] 6.20877266978\n",
      "positions (x,y,z), reward: [ -3.19352256e-02  -1.46738369e-02   2.42061570e+01] 8.40004922123\n",
      "positions (x,y,z), reward: [ -0.52449056  -0.15046275  35.86070414] 16.4148275493\n",
      "positions (x,y,z), reward: [-13.49778177  -1.99057321  80.57009834] 152.72923748\n",
      "positions (x,y,z), reward: [-31.42264213  -4.15968512  99.52412444] 165.031546895\n",
      "positions (x,y,z), reward: [ -39.47685657   -4.9760073   104.37529282] 254.803430621\n",
      "positions (x,y,z), reward: [ -43.49768412   -5.33374238  106.25953034] 249.815564377\n",
      "positions (x,y,z), reward: [ -52.59170611   -5.98113003  109.41966253] 240.359605231\n",
      "positions (x,y,z), reward: [ -64.1658397    -6.40613762  111.56735558] 231.683285321\n",
      "positions (x,y,z), reward: [ -72.13026245   -6.40226949  112.00084618] 217.774463191\n",
      "Episode =  338, score = 288.162 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.70054304e-03   1.27479706e-02   2.92379909e+01] 13.8246592781\n",
      "positions (x,y,z), reward: [ -1.66232499e-02   2.89233278e-02   3.24359843e+01] 15.7018519707\n",
      "positions (x,y,z), reward: [ -0.59638469   0.59502327  55.78396162] 168.767809371\n",
      "positions (x,y,z), reward: [ -0.88366133   0.95111678  61.97555728] 168.478512207\n",
      "positions (x,y,z), reward: [  -5.42359396    8.39160596  110.75876284] 276.014748271\n",
      "positions (x,y,z), reward: [  -8.38401964   12.09796934  127.16223518] 259.270560875\n",
      "positions (x,y,z), reward: [ -12.65104531   16.07774934  147.01863185] 259.43557977\n",
      "positions (x,y,z), reward: [ -16.24040119   18.43620479  163.55301149] 166.052430162\n",
      "positions (x,y,z), reward: [ -17.51335238   19.07548221  169.74009817] 120.708016173\n",
      "Episode =  339, score = 306.785 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.51207559e-05  -5.70579889e-06   2.03791740e+01] -2.61180676182\n",
      "positions (x,y,z), reward: [ -3.68547323e-05  -6.07847334e-06   2.04944286e+01] -1.86281110163\n",
      "positions (x,y,z), reward: [ -0.07082546  -0.07471463  31.02995947] 14.8461328878\n",
      "positions (x,y,z), reward: [ -0.25510995  -0.2134411   38.40478908] 67.3665598207\n",
      "positions (x,y,z), reward: [ -0.50908776  -0.34283987  44.21903948] 118.064767135\n",
      "positions (x,y,z), reward: [ -0.5680987   -0.36797243  45.29852993] 118.117752868\n",
      "positions (x,y,z), reward: [ -0.63129415  -0.39348832  46.38321851] 118.1519518\n",
      "positions (x,y,z), reward: [ -2.05299425  -0.77680324  62.44694764] 167.140088535\n",
      "positions (x,y,z), reward: [ -2.11875926  -0.78930081  63.00640476] 167.067566876\n",
      "positions (x,y,z), reward: [ -2.25336008  -0.81397146  64.12562132] 166.917417243\n",
      "positions (x,y,z), reward: [ -5.23973567  -1.16664367  83.69276811] 168.986170744\n",
      "positions (x,y,z), reward: [ -7.15379312  -1.27509101  93.14046417] 180.999800549\n",
      "positions (x,y,z), reward: [ -7.40424592  -1.28388593  94.24896588] 182.387275094\n",
      "positions (x,y,z), reward: [ -8.60747468  -1.30911884  99.22890348] 188.550301962\n",
      "positions (x,y,z), reward: [ -11.08031512   -1.27661771  108.04412932] 275.035627742\n",
      "positions (x,y,z), reward: [ -16.48261139   -0.90378665  123.29200404] 251.551784592\n",
      "positions (x,y,z), reward: [ -17.36496891   -0.81360038  125.44313397] 250.659290228\n",
      "Episode =  340, score = 316.309 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -4.04746452e-03   8.68862157e-03   2.42036352e+01] 8.42702007898\n",
      "positions (x,y,z), reward: [ -6.26213116e-02  -9.71756348e-03   3.33950755e+01] 16.1160487226\n",
      "positions (x,y,z), reward: [ -0.18268632  -0.08605172  41.02501548] 68.1285938135\n",
      "positions (x,y,z), reward: [ -0.22672382  -0.11767251  43.15133074] 68.4029842264\n",
      "positions (x,y,z), reward: [ -0.32398921  -0.19784305  47.47499186] 118.738578446\n",
      "positions (x,y,z), reward: [ -0.33663703  -0.20965033  48.02075316] 118.764442187\n",
      "positions (x,y,z), reward: [ -0.61109801  -1.55914     73.86817179] 168.715549429\n",
      "positions (x,y,z), reward: [   6.3863324   -21.01593806  126.21129995] 244.631248186\n",
      "positions (x,y,z), reward: [   9.21101248  -30.24487904  137.25481639] 242.078335014\n",
      "positions (x,y,z), reward: [  10.23382099  -34.25653992  141.38543913] 241.520169663\n",
      "Episode =  341, score = 315.208 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.69616195e-02  -2.06270975e-02   2.56024755e+01] 10.3572633437\n",
      "positions (x,y,z), reward: [  0.1388526   -0.12851389  36.87948744] 67.1618894737\n",
      "positions (x,y,z), reward: [  0.34900259  -0.36594214  51.86928899] 118.875076546\n",
      "positions (x,y,z), reward: [  0.40261452  -0.48762346  57.97295753] 168.982323023\n",
      "positions (x,y,z), reward: [  0.4138092   -0.79413238  68.6232346 ] 168.949029805\n",
      "positions (x,y,z), reward: [  0.40675495  -0.83929596  69.75024871] 168.938447075\n",
      "positions (x,y,z), reward: [  0.30708036  -1.23785323  77.10408225] 168.831732742\n",
      "positions (x,y,z), reward: [  0.15558637  -1.72226419  82.7948304 ] 172.826115581\n",
      "positions (x,y,z), reward: [ -0.1227421   -2.60397372  89.65182198] 182.345456366\n",
      "positions (x,y,z), reward: [ -0.20993555  -2.88734126  91.36777753] 184.544322307\n",
      "positions (x,y,z), reward: [ -0.40687729  -3.5402153   94.79671102] 188.785535084\n",
      "positions (x,y,z), reward: [  -2.06022906   -9.582048    113.2431424 ] 267.424830932\n",
      "positions (x,y,z), reward: [  -3.47604497  -15.67000728  124.13064304] 247.678312671\n",
      "positions (x,y,z), reward: [  -3.75901152  -17.0049051   126.09894943] 245.615140456\n",
      "positions (x,y,z), reward: [  -3.90141163  -17.69169947  127.06965671] 244.560513367\n",
      "positions (x,y,z), reward: [  -6.01296686  -28.91140332  140.11650292] 236.843021147\n",
      "Episode =  342, score = 317.291 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -3.14873118e-03  -1.97653186e-04   2.12897189e+01] 1.72868409192\n",
      "positions (x,y,z), reward: [ -4.22247377e-02  -3.12957885e-03   2.45352430e+01] 8.89083101927\n",
      "positions (x,y,z), reward: [ -1.18768277e-01  -5.86109027e-04   2.79514580e+01] 12.6895351178\n",
      "positions (x,y,z), reward: [ -0.58564207   0.18751438  39.44183696] 67.3317900242\n",
      "positions (x,y,z), reward: [ -1.10984679   0.56803019  47.49599659] 117.775476844\n",
      "positions (x,y,z), reward: [ -1.15200501   0.60272069  48.04588147] 117.766657407\n",
      "positions (x,y,z), reward: [ -2.02523142   1.39781505  57.58573565] 167.14043869\n",
      "positions (x,y,z), reward: [ -2.34407121   1.71251198  60.45853232] 166.821862585\n",
      "positions (x,y,z), reward: [ -2.92115225   2.30122224  65.12353652] 166.205412803\n",
      "positions (x,y,z), reward: [ -6.82306736   6.40901322  87.51896088] 173.538687688\n",
      "positions (x,y,z), reward: [ -9.29024878   9.01942151  98.10126856] 188.228357578\n",
      "positions (x,y,z), reward: [ -10.25232314   10.05177241  101.93189408] 288.05565037\n",
      "positions (x,y,z), reward: [ -13.1297588    13.23846896  112.98283345] 272.523352533\n",
      "positions (x,y,z), reward: [ -32.35047628   67.96799945  281.1846049 ] 1269.12888637\n",
      "Episode =  343, score = 344.119 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  7.94304545e-03  -2.91529722e-02   2.48875530e+01] 9.42871059449\n",
      "positions (x,y,z), reward: [  0.15414331  -0.25604027  33.4032864 ] 15.7678889674\n",
      "positions (x,y,z), reward: [  0.30652211  -0.45946604  37.90195825] 66.9291842836\n",
      "positions (x,y,z), reward: [  1.49255854  -1.68786137  57.39666912] 166.632401642\n",
      "positions (x,y,z), reward: [  1.53908437  -1.72768272  57.95314402] 166.565391198\n",
      "positions (x,y,z), reward: [  1.58641021  -1.76773568  58.50999978] 166.496572547\n",
      "positions (x,y,z), reward: [  2.46139364  -2.44103129  67.46133209] 165.173083177\n",
      "positions (x,y,z), reward: [  2.85313019  -2.71127397  70.83501625] 164.583941477\n",
      "positions (x,y,z), reward: [  4.09635104  -3.48787832  79.87258806] 162.73957102\n",
      "positions (x,y,z), reward: [  4.27352014  -3.59031402  81.00593445] 163.985771421\n",
      "positions (x,y,z), reward: [  16.54274313   -8.91595952  127.28531492] 245.154448636\n",
      "positions (x,y,z), reward: [  17.68881805   -9.43885024  130.14231738] 243.384064351\n",
      "positions (x,y,z), reward: [  23.58070987  -12.45037911  143.03292623] 236.872015727\n",
      "positions (x,y,z), reward: [  25.84124913  -13.7277147   147.34943402] 234.879749119\n",
      "positions (x,y,z), reward: [  26.13030744  -13.894753    147.88061103] 234.612832744\n",
      "Episode =  344, score = 310.997 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.12667107e-03  -9.36436363e-05   2.11022990e+01] 1.03562621916\n",
      "positions (x,y,z), reward: [ -2.91965770e-02   2.69649351e-04   2.56000042e+01] 10.3703473277\n",
      "positions (x,y,z), reward: [ -6.37774709e-02   1.43343571e-03   2.88072480e+01] 13.463164914\n",
      "positions (x,y,z), reward: [ -7.46302766e-02   1.98045092e-03   2.96811844e+01] 14.0848713529\n",
      "positions (x,y,z), reward: [ -1.32892573e-01   7.33355160e-03   3.38855216e+01] 16.2592369644\n",
      "positions (x,y,z), reward: [ -2.69006559e-01   3.48811468e-02   4.26227333e+01] 68.3629010096\n",
      "positions (x,y,z), reward: [ -6.83997251e-01  -1.10063550e-02   6.58038948e+01] 169.365627398\n",
      "positions (x,y,z), reward: [ -0.76614892  -0.07787227  69.73747346] 169.283494385\n",
      "positions (x,y,z), reward: [ -1.86699187  -1.65779559  98.56747553] 194.761001971\n",
      "positions (x,y,z), reward: [  -2.30930087   -2.28119579  103.69264659] 290.362645338\n",
      "positions (x,y,z), reward: [  -4.94516958   -5.63997584  120.69270514] 259.368742574\n",
      "positions (x,y,z), reward: [  -5.19956346   -5.93840935  121.80949276] 258.734001158\n",
      "positions (x,y,z), reward: [ -10.33167641  -11.36855434  137.4573891 ] 246.071320469\n",
      "positions (x,y,z), reward: [ -13.07900471  -13.93276679  142.99198169] 239.473923961\n",
      "Episode =  345, score = 321.565 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -4.34118747e-06  -2.40618472e-06   2.01243508e+01] -4.89511362464\n",
      "positions (x,y,z), reward: [  2.48637354e-02  -5.09744049e-02   2.67432477e+01] 11.5985665005\n",
      "positions (x,y,z), reward: [  0.1048384   -0.22602662  33.88017034] 16.0478471929\n",
      "positions (x,y,z), reward: [  0.18027376  -0.39534327  38.40816884] 67.2505765351\n",
      "positions (x,y,z), reward: [  0.47229779  -0.99063547  49.6558683 ] 117.977682171\n",
      "positions (x,y,z), reward: [  0.87097635  -1.66637201  59.07814065] 167.378068924\n",
      "positions (x,y,z), reward: [  1.34259271  -2.35742189  66.9247749 ] 166.416685784\n",
      "positions (x,y,z), reward: [  2.55898718  -3.93647137  80.50618763] 164.722250495\n",
      "positions (x,y,z), reward: [  3.80482409  -5.44409316  90.19870037] 176.56128473\n",
      "positions (x,y,z), reward: [  5.28562988  -7.16793863  99.30379242] 186.875844305\n",
      "positions (x,y,z), reward: [   7.4589765   -9.5598652  110.0622663] 268.180871986\n",
      "positions (x,y,z), reward: [   8.67017102  -10.80817446  115.16384726] 258.175169788\n",
      "Episode =  346, score = 310.514 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.41849675e-06  -3.26145796e-06   2.01243347e+01] -4.89545436565\n",
      "positions (x,y,z), reward: [  0.08262316  -0.03856247  30.57969187] 14.6047145154\n",
      "positions (x,y,z), reward: [  0.16019588  -0.03948979  33.88378367] 16.1845392335\n",
      "positions (x,y,z), reward: [  2.34976200e-01  -3.19098179e-02   3.63684187e+01] 67.004479486\n",
      "positions (x,y,z), reward: [  0.59179123   0.06251956  44.76982448] 118.353704096\n",
      "positions (x,y,z), reward: [  1.37999705   0.42837715  56.89857972] 168.13700335\n",
      "positions (x,y,z), reward: [  3.55818724   1.84644866  78.31048375] 164.843218462\n",
      "positions (x,y,z), reward: [  3.92378568   2.11730968  81.13419668] 165.884261652\n",
      "positions (x,y,z), reward: [  3.99905716   2.17398036  81.69861977] 166.592759265\n",
      "positions (x,y,z), reward: [  4.07504407   2.23149296  82.2629187 ] 167.299475682\n",
      "positions (x,y,z), reward: [  5.38938429   3.27006014  91.2703054 ] 178.322050263\n",
      "positions (x,y,z), reward: [  6.2134756    3.95700688  96.31467773] 184.270014634\n",
      "positions (x,y,z), reward: [   8.83288031    6.2841408   110.20225622] 269.14689247\n",
      "positions (x,y,z), reward: [   9.17906076    6.60806703  111.85484133] 265.947304165\n",
      "positions (x,y,z), reward: [  11.25161842    8.65313486  121.17077198] 249.398230414\n",
      "positions (x,y,z), reward: [  11.63208371    9.05511412  122.8089069 ] 248.604671392\n",
      "positions (x,y,z), reward: [  11.75947557    9.19219056  123.35485429] 248.339448758\n",
      "positions (x,y,z), reward: [  11.88709343    9.33085939  123.90079857] 248.073615558\n",
      "positions (x,y,z), reward: [  16.02821578   15.19778188  142.59599633] 238.560322634\n",
      "Episode =  347, score = 314.183 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.38551401e-05   1.59670612e-04   2.09295751e+01] 0.335152033253\n",
      "positions (x,y,z), reward: [ -1.33643940e-02  -1.23642884e-02   2.67454539e+01] 11.6608712186\n",
      "positions (x,y,z), reward: [ -0.16568416  -0.2482015   48.02204818] 118.905405557\n",
      "positions (x,y,z), reward: [ -0.24544407  -0.91377314  67.51121404] 169.005550373\n",
      "positions (x,y,z), reward: [ -0.220254    -1.149481    71.46261424] 168.906637448\n",
      "positions (x,y,z), reward: [ -0.15024622  -1.53856225  76.56706271] 168.741663489\n",
      "positions (x,y,z), reward: [   2.9516435   -11.37376544  115.75775858] 261.02126891\n",
      "positions (x,y,z), reward: [   3.1276687   -11.91035076  116.83361484] 258.507674898\n",
      "positions (x,y,z), reward: [   4.09208778  -14.84260131  122.09065748] 248.788642124\n",
      "positions (x,y,z), reward: [   4.51894346  -16.13412408  124.129587  ] 246.577668485\n",
      "positions (x,y,z), reward: [   7.89770411  -26.16434329  136.26108289] 235.269282297\n",
      "positions (x,y,z), reward: [   9.62289852  -31.18727307  140.68488166] 231.372037585\n",
      "Episode =  348, score = 316.460 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.65348545e-02   1.15188454e-02   2.52379220e+01] 9.88173353972\n",
      "positions (x,y,z), reward: [  6.29216377e-02   1.94420173e-02   2.67440163e+01] 11.5982744706\n",
      "positions (x,y,z), reward: [  9.52760336   5.11003109  89.32306317] 175.248660894\n",
      "positions (x,y,z), reward: [ 10.55878077   5.70528018  92.06686609] 178.485250315\n",
      "positions (x,y,z), reward: [ 11.11233022   6.02280959  93.46175543] 180.101760521\n",
      "positions (x,y,z), reward: [  23.68320216   12.89815297  117.69078664] 256.946933217\n",
      "positions (x,y,z), reward: [  25.95558658   14.10100769  121.32215821] 254.305656711\n",
      "positions (x,y,z), reward: [  48.15224954   26.01668195  154.20254001] 230.668384392\n",
      "Episode =  349, score = 334.240 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.75147856e-03  -4.72478640e-02   2.67459900e+01] 11.6388966741\n",
      "positions (x,y,z), reward: [  1.71541803e-02  -3.21183002e-01   3.58699893e+01] 16.7846941149\n",
      "positions (x,y,z), reward: [  2.91698006e-02  -6.36411100e-01   4.15639709e+01] 67.8445060538\n",
      "positions (x,y,z), reward: [  2.47377766e-02  -1.25191389e+00   4.91322125e+01] 118.154321471\n",
      "positions (x,y,z), reward: [ -0.48256571  -4.9366143   73.09343206] 164.49723408\n",
      "positions (x,y,z), reward: [ -1.36775544  -8.21318633  86.39267548] 169.440890914\n",
      "positions (x,y,z), reward: [ -2.28511015 -11.11668559  96.18393699] 179.846750938\n",
      "positions (x,y,z), reward: [  -4.78164542  -19.87580547  120.36449419] 244.579855556\n",
      "Episode =  350, score = 310.750 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  7.97184342e-04   2.17239854e-04   2.07693397e+01] -0.393659920659\n",
      "positions (x,y,z), reward: [  2.18205004e-02   9.45266388e-03   2.32655139e+01] 6.76507272864\n",
      "positions (x,y,z), reward: [  0.14260816   0.05702559  27.95293821] 12.601864992\n",
      "positions (x,y,z), reward: [  0.56131643   0.20350145  35.846571  ] 16.3140941136\n",
      "positions (x,y,z), reward: [  1.22430391   0.44901079  44.19467395] 117.172603559\n",
      "positions (x,y,z), reward: [  4.65084038   2.17605556  72.97993426] 163.29422525\n",
      "positions (x,y,z), reward: [  5.66175612   2.88983353  79.75260496] 161.768375932\n",
      "positions (x,y,z), reward: [  5.74997524   2.95678221  80.31937013] 162.113590635\n",
      "positions (x,y,z), reward: [  7.07017192   4.0345365   88.31331364] 172.147232175\n",
      "positions (x,y,z), reward: [  8.37334194   5.19203377  95.2823758 ] 180.639546074\n",
      "positions (x,y,z), reward: [  8.8522805    5.62792574  97.63129868] 183.399205869\n",
      "positions (x,y,z), reward: [   9.88252973    6.57100026  102.36212062] 281.694299494\n",
      "positions (x,y,z), reward: [  10.8655326     7.47013645  106.53291191] 273.748545535\n",
      "positions (x,y,z), reward: [  12.73053864    9.15877821  113.74026555] 259.664165189\n",
      "positions (x,y,z), reward: [  18.69017381   14.35755419  133.17428746] 239.332984659\n",
      "positions (x,y,z), reward: [  22.21162575   17.394472    143.46239438] 234.738962036\n",
      "Episode =  351, score = 305.999 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  8.50966317e-03  -6.51794224e-03   2.32673483e+01] 6.79177723497\n",
      "positions (x,y,z), reward: [  2.11593866e-02  -1.93185330e-02   2.56006070e+01] 10.3521019612\n",
      "positions (x,y,z), reward: [  0.08073955  -0.1103704   33.88452764] 16.2092890718\n",
      "positions (x,y,z), reward: [  0.22172343  -0.339514    44.7710072 ] 118.417892342\n",
      "positions (x,y,z), reward: [  0.31601471  -0.48732363  49.67368059] 118.650845947\n",
      "positions (x,y,z), reward: [  0.36644578  -0.56063478  51.87615279] 118.673641076\n",
      "positions (x,y,z), reward: [  1.17425066  -1.24225451  72.04700259] 167.937341828\n",
      "positions (x,y,z), reward: [  2.88053923  -1.50792974  91.10042283] 183.896582518\n",
      "positions (x,y,z), reward: [   6.20787871   -0.87704615  109.77549271] 283.17622266\n",
      "positions (x,y,z), reward: [  10.58180829    0.53274194  125.05089123] 267.632678263\n",
      "positions (x,y,z), reward: [  13.01158135    1.41738523  131.85444388] 266.466289331\n",
      "positions (x,y,z), reward: [  15.88430639    2.52898955  139.09129743] 265.186223047\n",
      "positions (x,y,z), reward: [  19.26562761    3.92969049  146.88583881] 263.951243643\n",
      "positions (x,y,z), reward: [  22.3183551     5.28314871  153.45120706] 215.476684071\n",
      "positions (x,y,z), reward: [  30.58019644    9.39534764  169.70163653] 123.407525891\n",
      "Episode =  352, score = 313.532 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.21141549e-03  -9.21610092e-04   2.17069105e+01] 3.08866892586\n",
      "positions (x,y,z), reward: [ -6.34778868e-03  -5.25036405e-03   2.32661276e+01] 6.793495513\n",
      "positions (x,y,z), reward: [ -2.38295850e-02  -3.84254886e-02   2.88055620e+01] 13.4562028419\n",
      "positions (x,y,z), reward: [ -0.09834614  -0.11540642  37.89810396] 67.5017307596\n",
      "positions (x,y,z), reward: [ -0.10532154  -0.119941    38.41372446] 67.6207630569\n",
      "positions (x,y,z), reward: [ -0.12841705  -0.13360176  39.9753838 ] 67.9382691995\n",
      "positions (x,y,z), reward: [ -0.35535786  -0.21470436  50.21907395] 118.926944808\n",
      "positions (x,y,z), reward: [ -0.51174062  -0.24215385  55.19566088] 169.020296785\n",
      "positions (x,y,z), reward: [ -2.3886537    0.99454572  99.73719484] 198.626695767\n",
      "positions (x,y,z), reward: [  -1.79629357    6.10960683  131.80826827] 276.239950659\n",
      "positions (x,y,z), reward: [   0.62176216   15.05899127  164.93901812] 153.313630013\n",
      "Episode =  353, score = 318.716 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -5.37116198e-03  -1.01197265e-02   2.32700259e+01] 6.79813667296\n",
      "positions (x,y,z), reward: [ -1.34012817  -2.24767321  55.73199007] 166.158928353\n",
      "positions (x,y,z), reward: [ -2.10201445  -4.63811039  68.55877576] 163.185421465\n",
      "positions (x,y,z), reward: [ -2.55450742  -6.93099651  76.91132455] 160.206772513\n",
      "positions (x,y,z), reward: [  -3.89706279  -24.09653176  111.97564994] 254.698799664\n",
      "positions (x,y,z), reward: [  -4.01393943  -33.0285408   123.97445592] 241.399566652\n",
      "positions (x,y,z), reward: [  -3.87861631  -46.15439229  138.08508747] 240.34962323\n",
      "Episode =  354, score = 304.877 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.068413    -0.10093792  30.56619144] 14.5478906964\n",
      "positions (x,y,z), reward: [  0.10015187  -0.15362471  32.90236058] 15.703922598\n",
      "positions (x,y,z), reward: [  0.26115486  -0.58299619  43.67399344] 67.9958433928\n",
      "positions (x,y,z), reward: [  0.35466055  -1.04290821  50.21005366] 118.157823963\n",
      "positions (x,y,z), reward: [  0.45348755  -2.32096859  60.81492556] 167.380669146\n",
      "positions (x,y,z), reward: [  0.46447057  -2.822592    63.63515975] 166.932491564\n",
      "positions (x,y,z), reward: [  0.4603862   -5.83877677  74.89106235] 163.54493384\n",
      "positions (x,y,z), reward: [  0.54372105 -12.47524639  88.3161406 ] 166.90891776\n",
      "positions (x,y,z), reward: [  0.69900365 -16.11592716  93.25826521] 168.9646199\n",
      "positions (x,y,z), reward: [   2.35426798  -35.36711528  108.93407   ] 252.364695581\n",
      "positions (x,y,z), reward: [   2.9101566   -40.83312227  111.67633321] 245.914762619\n",
      "positions (x,y,z), reward: [   3.36041822  -45.37824243  113.58974069] 241.236441844\n",
      "positions (x,y,z), reward: [   4.93570239  -66.24002984  119.21354986] 226.05040194\n",
      "Episode =  355, score = 300.278 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -6.00529758e-02   2.40002773e-02   2.75511802e+01] 12.3907430786\n",
      "positions (x,y,z), reward: [ -9.77801982e-02   2.54791667e-02   2.92459983e+01] 13.7316704163\n",
      "positions (x,y,z), reward: [ -2.15976451e-01   1.42863440e-02   3.29233148e+01] 15.7509607456\n",
      "positions (x,y,z), reward: [ -2.35181956e-01   1.13003869e-02   3.34051235e+01] 15.9496042855\n",
      "positions (x,y,z), reward: [ -0.65754542  -0.07695978  41.03811208] 67.6757625368\n",
      "positions (x,y,z), reward: [ -1.87013495  -0.28954086  53.5426508 ] 167.531106465\n",
      "positions (x,y,z), reward: [ -2.23941627  -0.32949719  56.31837208] 167.242901411\n",
      "positions (x,y,z), reward: [ -4.37690211  -0.40822165  68.61435421] 165.209945035\n",
      "positions (x,y,z), reward: [ -4.61362775  -0.4056098   69.73404946] 164.969214571\n",
      "positions (x,y,z), reward: [ -8.79041723  -0.15828423  85.86761508] 169.413575513\n",
      "positions (x,y,z), reward: [ -1.00060536e+01  -3.65064244e-02   8.97157241e+01] 173.939636822\n",
      "positions (x,y,z), reward: [ -1.03691982e+01   3.13602508e-03   9.08112475e+01] 175.209008824\n",
      "positions (x,y,z), reward: [ -23.86585076    2.1146795   120.48079463] 245.159996524\n",
      "positions (x,y,z), reward: [ -27.101126      2.699996    125.46771509] 243.860993203\n",
      "positions (x,y,z), reward: [ -29.18358615    3.07594937  128.38587855] 242.983609996\n",
      "positions (x,y,z), reward: [ -31.00073535    3.40184369  130.76979591] 242.204724975\n",
      "positions (x,y,z), reward: [ -32.12670233    3.60243925  132.17790028] 241.718609996\n",
      "positions (x,y,z), reward: [ -34.85729118    4.08382527  135.39471296] 240.532698704\n",
      "Episode =  356, score = 310.592 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.99734930e-06   7.13580434e-07   2.01243476e+01] -4.89560100687\n",
      "positions (x,y,z), reward: [  2.62983934e-02   1.78657873e-01   4.05001202e+01] 68.1162641722\n",
      "positions (x,y,z), reward: [ -0.52327981   0.4152695   55.2431905 ] 169.011068126\n",
      "positions (x,y,z), reward: [ -0.5631029    0.42465058  55.80258428] 168.993024598\n",
      "positions (x,y,z), reward: [ -1.06871022   0.5165371   61.42623569] 168.641616379\n",
      "positions (x,y,z), reward: [ -1.13088534   0.52544568  61.99100766] 168.587793586\n",
      "positions (x,y,z), reward: [ -2.06329397   0.62668701  68.78723673] 167.665226355\n",
      "positions (x,y,z), reward: [ -2.15775268   0.6346075   69.35445358] 167.564719791\n",
      "positions (x,y,z), reward: [ -2.78470337   0.68043349  72.75746022] 166.877771446\n",
      "positions (x,y,z), reward: [ -4.2286881    0.75495448  78.97996944] 165.201022373\n",
      "positions (x,y,z), reward: [ -5.19418644   0.7871423   82.35327289] 167.562907724\n",
      "positions (x,y,z), reward: [-10.21100546   0.80280963  94.98200939] 180.154287819\n",
      "positions (x,y,z), reward: [ -2.45636198e+01  -4.84655147e-02   1.15065385e+02] 251.182423739\n",
      "positions (x,y,z), reward: [ -34.09882347   -1.22845834  123.56501519] 239.368191081\n",
      "positions (x,y,z), reward: [ -35.06220316   -1.37090245  124.30261237] 238.907140643\n",
      "positions (x,y,z), reward: [ -39.50028115   -2.07519772  127.46325138] 236.756408554\n",
      "positions (x,y,z), reward: [ -43.06410447   -2.69290398  129.74056429] 234.999827441\n",
      "Episode =  357, score = 309.982 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.52574148e-03   2.81301098e-02   2.52361194e+01] 9.8991995856\n",
      "positions (x,y,z), reward: [ -0.1649377    1.30633047  56.32898886] 168.413820867\n",
      "positions (x,y,z), reward: [ -0.19209648   1.38980689  57.44557548] 168.354591476\n",
      "positions (x,y,z), reward: [ -2.52874172   5.18694328  88.1691718 ] 175.24036694\n",
      "positions (x,y,z), reward: [ -2.68675533   5.39343454  89.31741201] 176.59984377\n",
      "positions (x,y,z), reward: [  -5.44014856    8.71356798  104.82803125] 279.357182418\n",
      "positions (x,y,z), reward: [  -7.1989135    10.69129374  112.31081373] 264.457030624\n",
      "positions (x,y,z), reward: [  -8.26649647   11.86574384  116.35132008] 256.248287066\n",
      "positions (x,y,z), reward: [ -16.97931398   21.24612018  142.3272931 ] 237.575263041\n",
      "Episode =  358, score = 311.032 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.12310565e-03   1.88076372e-03   2.29785373e+01] 6.23252627117\n",
      "positions (x,y,z), reward: [  7.49336717e-03   2.88765895e-03   2.52400635e+01] 9.92674903356\n",
      "positions (x,y,z), reward: [  2.34731202e-02   4.11580496e-03   2.83831709e+01] 13.1597351602\n",
      "positions (x,y,z), reward: [  6.27475970e-02   6.14167952e-03   3.24433799e+01] 15.6864130229\n",
      "positions (x,y,z), reward: [  6.87425678e-02   6.39444622e-03   3.29207383e+01] 15.9051757759\n",
      "positions (x,y,z), reward: [  0.44672823   0.08468043  50.22549924] 118.980691443\n",
      "positions (x,y,z), reward: [  0.85493327   0.34553888  61.92234768] 168.908963083\n",
      "positions (x,y,z), reward: [  1.04844595   0.51653738  66.43189124] 168.68852971\n",
      "positions (x,y,z), reward: [   3.66713284    3.44579701  100.2054104 ] 293.461313124\n",
      "positions (x,y,z), reward: [   5.6873121     5.77721852  114.62005718] 267.299498948\n",
      "positions (x,y,z), reward: [   7.58971791    8.0398865   125.48376528] 254.903580851\n",
      "positions (x,y,z), reward: [  11.60102907   13.78040659  145.73793073] 246.259050097\n",
      "Episode =  359, score = 319.645 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -5.50422217e-05   1.87032661e-05   2.03792389e+01] -2.61168577637\n",
      "positions (x,y,z), reward: [ -7.03504395e-03  -3.03522324e-03   2.29739228e+01] 6.20005613921\n",
      "positions (x,y,z), reward: [ -0.13839235  -0.16237883  32.42791414] 15.4315197387\n",
      "positions (x,y,z), reward: [ -0.18752625  -0.23175132  34.36145542] 16.1564842997\n",
      "positions (x,y,z), reward: [ -0.33848449  -0.44967632  38.92009943] 67.1792591616\n",
      "positions (x,y,z), reward: [ -0.66546645  -0.94859343  45.84152967] 117.524630055\n",
      "positions (x,y,z), reward: [ -0.93153405  -1.38971524  50.21900968] 117.222085355\n",
      "positions (x,y,z), reward: [ -1.9798632   -3.45069054  63.56205665] 164.434796895\n",
      "positions (x,y,z), reward: [ -2.18231256  -3.90340324  65.78993725] 163.741015389\n",
      "positions (x,y,z), reward: [ -3.09502665  -6.15647055  75.20387138] 160.270042662\n",
      "positions (x,y,z), reward: [ -3.598617    -7.55997863  80.14025116] 158.374530599\n",
      "positions (x,y,z), reward: [ -3.71131779  -7.89137568  81.23230948] 159.5233336\n",
      "positions (x,y,z), reward: [ -4.6685536  -10.98114962  90.44260406] 168.912824546\n",
      "positions (x,y,z), reward: [  -6.04555178  -16.33743182  103.74670851] 270.265835872\n",
      "positions (x,y,z), reward: [  -8.49272399  -27.59763532  125.61204257] 238.049605107\n",
      "positions (x,y,z), reward: [  -8.81483586  -29.08007568  128.05547547] 237.507400852\n",
      "positions (x,y,z), reward: [  -9.49711006  -32.16268496  132.87292708] 236.342001971\n",
      "Episode =  360, score = 303.626 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.78380223e-04   2.10772428e-04   2.06249413e+01] -1.11785697609\n",
      "positions (x,y,z), reward: [ -0.17536722   0.08902502  31.50106434] 14.9989241468\n",
      "positions (x,y,z), reward: [ -0.50874251   0.3112821   46.398151  ] 118.401403912\n",
      "positions (x,y,z), reward: [ -0.54565493   0.40864418  52.46435409] 168.938739545\n",
      "positions (x,y,z), reward: [ -0.5193142    0.47275432  56.39692817] 169.282545567\n",
      "positions (x,y,z), reward: [  0.14420012   0.72263115  73.83625152] 170.981336198\n",
      "positions (x,y,z), reward: [  0.22319776   0.73116647  75.03247915] 171.000568089\n",
      "positions (x,y,z), reward: [  2.29390831   0.26333309  95.990418  ] 194.977218694\n",
      "positions (x,y,z), reward: [   3.47011801   -0.46214395  104.23751102] 293.548106433\n",
      "positions (x,y,z), reward: [   4.20056831   -1.04527393  108.69755294] 285.556046942\n",
      "positions (x,y,z), reward: [   4.53475394   -1.34123288  110.60782898] 282.026436631\n",
      "positions (x,y,z), reward: [   6.26490625   -3.12056317  119.46153803] 264.747489403\n",
      "positions (x,y,z), reward: [   7.23885198   -4.27328202  123.81782451] 261.363286034\n",
      "positions (x,y,z), reward: [  10.28710613   -8.36632913  135.23219815] 252.38788685\n",
      "Episode =  361, score = 320.886 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.03508793  -0.02751335  27.14324514] 12.0254649372\n",
      "positions (x,y,z), reward: [ -0.03947555  -0.03099418  27.54883404] 12.3997012008\n",
      "positions (x,y,z), reward: [ -0.68962576  -0.49589568  51.31141864] 118.344555573\n",
      "positions (x,y,z), reward: [ -1.42696829  -0.9583847   67.46192575] 167.689158405\n",
      "positions (x,y,z), reward: [ -1.64228249  -1.09947298  72.53523287] 167.556224237\n",
      "positions (x,y,z), reward: [ -1.70629507  -1.14317409  74.23704658] 167.559311666\n",
      "positions (x,y,z), reward: [ -1.91349901  -1.3015091   81.71454274] 170.523238517\n",
      "positions (x,y,z), reward: [ -1.96411236  -1.38871328  88.84318516] 182.191397766\n",
      "positions (x,y,z), reward: [  7.88902044e-02  -1.12105656e+00   1.28143775e+02] 283.259676759\n",
      "positions (x,y,z), reward: [   0.86099585   -0.77050392  143.91810168] 291.453275624\n",
      "positions (x,y,z), reward: [   0.90318469   -0.71143169  145.98891169] 292.851775334\n",
      "Episode =  362, score = 320.007 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.34277851e-02   3.24095145e-03   2.52336431e+01] 9.87607361578\n",
      "positions (x,y,z), reward: [  1.06859508e-01   2.79772868e-02   2.92326130e+01] 13.6849011713\n",
      "positions (x,y,z), reward: [  0.16863073   0.0514118   31.48835529] 15.0203756478\n",
      "positions (x,y,z), reward: [  0.58471467   0.21149581  40.48822856] 67.528504357\n",
      "positions (x,y,z), reward: [  0.80526994   0.29645772  43.68484249] 67.8168157794\n",
      "positions (x,y,z), reward: [  1.90052228   0.70454503  54.73942913] 167.62486513\n",
      "positions (x,y,z), reward: [  6.87521493   2.1951368   81.05086242] 166.890304133\n",
      "positions (x,y,z), reward: [  16.02924438    2.86481518  109.90192151] 281.312005472\n",
      "positions (x,y,z), reward: [  25.9531778    -1.25856007  134.41319839] 277.024563167\n",
      "positions (x,y,z), reward: [  31.94711474   -5.92872032  146.51649481] 281.440562993\n",
      "positions (x,y,z), reward: [  46.1413714   -20.89598666  169.72596287] 146.391667114\n",
      "Episode =  363, score = 320.167 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -5.10973238e-08   4.07423710e-08   2.00310970e+01] -6.44547421528\n",
      "positions (x,y,z), reward: [  1.33598117   2.52398815  65.27233665] 166.150312293\n",
      "positions (x,y,z), reward: [  1.55523689   2.79159457  68.07332809] 165.658339862\n",
      "positions (x,y,z), reward: [  1.93228328   3.24598714  72.55217721] 164.794398586\n",
      "positions (x,y,z), reward: [   4.00990722    7.25675622  103.52184712] 284.164737974\n",
      "positions (x,y,z), reward: [   3.86550196    7.9730627   108.13338646] 276.866101863\n",
      "Episode =  364, score = 318.681 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -3.92393549e-07   6.93030102e-07   2.00699492e+01] -5.66962396205\n",
      "positions (x,y,z), reward: [ -8.87185164e-04   4.25503727e-03   2.26979183e+01] 5.62559689977\n",
      "positions (x,y,z), reward: [ -2.54711416e-03   2.28775889e-02   2.63531566e+01] 11.2398729192\n",
      "positions (x,y,z), reward: [ -2.96928482e-03   2.74698119e-02   2.71401499e+01] 12.0459648364\n",
      "positions (x,y,z), reward: [  0.24175756  -0.40402379  60.25403728] 169.497789378\n",
      "positions (x,y,z), reward: [  0.49904227  -0.95832171  68.1713593 ] 168.923688601\n",
      "positions (x,y,z), reward: [  1.16830674  -2.41996888  80.68656312] 167.878615868\n",
      "positions (x,y,z), reward: [  1.36977045  -2.8606972   83.52836538] 171.456934683\n",
      "positions (x,y,z), reward: [  1.45564234  -3.04827348  84.66372052] 172.863644797\n",
      "positions (x,y,z), reward: [   3.35643493   -7.08682196  103.22318175] 284.546290902\n",
      "positions (x,y,z), reward: [   4.0570783    -8.51884074  108.212746  ] 274.709248602\n",
      "positions (x,y,z), reward: [   4.94128517  -10.29687007  113.70653864] 263.51981283\n",
      "Episode =  365, score = 314.722 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.04802059   0.09792894  28.38335876] 13.0387770634\n",
      "positions (x,y,z), reward: [  0.24162716   0.54861032  39.45172858] 67.2710653412\n",
      "positions (x,y,z), reward: [  0.41951708   1.02291729  46.92481332] 117.731450632\n",
      "positions (x,y,z), reward: [  0.43300594   1.06171861  47.46880703] 117.729832402\n",
      "positions (x,y,z), reward: [  0.59399033   1.57232578  54.06029043] 167.489614089\n",
      "positions (x,y,z), reward: [  0.85076139   2.91128369  68.55631241] 166.267210128\n",
      "positions (x,y,z), reward: [  0.77137936   4.42415193  82.61705364] 168.933349794\n",
      "positions (x,y,z), reward: [  0.17084292   5.98347781  96.18056438] 188.392558133\n",
      "positions (x,y,z), reward: [  9.26440150e-02   6.11651904e+00   9.73115824e+01] 190.032523455\n",
      "positions (x,y,z), reward: [  -0.69890593    7.19731385  106.35003652] 282.779654628\n",
      "positions (x,y,z), reward: [  -1.71663689    8.24051288  114.79254794] 267.927304654\n",
      "positions (x,y,z), reward: [  -1.9541668     8.45310981  116.47615813] 264.92487845\n",
      "positions (x,y,z), reward: [  -2.92838647    9.24263633  122.6345724 ] 257.763903844\n",
      "Episode =  366, score = 320.657 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.26405132  -0.31139731  32.90670739] 15.3645510751\n",
      "positions (x,y,z), reward: [ -7.70545824  -3.2546175   74.03742798] 158.820125243\n",
      "positions (x,y,z), reward: [-10.89099223  -3.77726147  81.81314537] 157.805889832\n",
      "positions (x,y,z), reward: [-11.67500619  -3.88465908  83.4798251 ] 159.432065329\n",
      "positions (x,y,z), reward: [ -23.421565     -5.25863126  102.64281686] 271.725867282\n",
      "positions (x,y,z), reward: [ -30.85696905   -6.3024007   112.20624483] 258.456828941\n",
      "positions (x,y,z), reward: [ -55.71165163  -11.29879492  145.6809253 ] 262.500231717\n",
      "Episode =  367, score = 298.498 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.23370795   0.04769365  29.23809619] 13.5432342361\n",
      "positions (x,y,z), reward: [ -0.84252684   0.16118304  37.88451787] 66.656091954\n",
      "positions (x,y,z), reward: [ -7.3368729    2.44759977  77.29529177] 159.796091335\n",
      "positions (x,y,z), reward: [ -8.99610927   3.23171675  84.45082335] 163.918869254\n",
      "positions (x,y,z), reward: [-11.16732981   4.37266457  93.24443425] 173.86187455\n",
      "positions (x,y,z), reward: [-11.58840771   4.61328334  94.89835561] 175.732581481\n",
      "positions (x,y,z), reward: [ -13.90048005    6.08601845  103.80672786] 274.468818544\n",
      "positions (x,y,z), reward: [ -17.24659294    8.84856751  116.59221691] 251.305490168\n",
      "positions (x,y,z), reward: [ -17.87320665    9.48264461  119.04311197] 247.047785888\n",
      "positions (x,y,z), reward: [ -20.4114875    12.6314958   129.54553665] 244.402436652\n",
      "Episode =  368, score = 301.950 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  7.36795728e-03   1.45728129e-03   2.19366637e+01] 3.74125835421\n",
      "positions (x,y,z), reward: [  1.53184074e-02   3.58646500e-03   2.26986944e+01] 5.60938855494\n",
      "positions (x,y,z), reward: [  7.20988845e-02   2.05050839e-02   2.55998935e+01] 10.2905525102\n",
      "positions (x,y,z), reward: [  2.24846824   0.77734888  54.05523963] 166.66988852\n",
      "positions (x,y,z), reward: [  2.81138539   1.01850669  58.50321765] 166.058169871\n",
      "positions (x,y,z), reward: [  6.2929026    2.98350447  79.96644759] 161.368478305\n",
      "positions (x,y,z), reward: [  7.55735141   3.86986828  86.29909592] 168.939912381\n",
      "positions (x,y,z), reward: [  8.30221639   4.42147413  89.7793857 ] 173.025537065\n",
      "positions (x,y,z), reward: [  13.49498338    8.48211     109.90610008] 265.239759307\n",
      "positions (x,y,z), reward: [  15.01357323    9.65082771  114.73793992] 255.541144911\n",
      "Episode =  369, score = 304.972 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.0436174   -0.0551622   27.55270718] 12.3686225971\n",
      "positions (x,y,z), reward: [  0.82289933  -0.5989926   48.03133226] 117.906684886\n",
      "positions (x,y,z), reward: [  1.21003446  -0.80551433  53.53954291] 167.703240416\n",
      "positions (x,y,z), reward: [  2.18848023  -1.30602999  64.1583674 ] 166.626069371\n",
      "positions (x,y,z), reward: [  3.22382835  -1.84249261  72.62801225] 165.263210988\n",
      "positions (x,y,z), reward: [  3.71335193  -2.10159262  76.03312545] 164.601937904\n",
      "positions (x,y,z), reward: [  7.08381465  -3.94089922  93.83559621] 180.801249353\n",
      "positions (x,y,z), reward: [   8.83255168   -4.89929457  100.86768029] 286.529908039\n",
      "positions (x,y,z), reward: [  17.9168459    -9.98275332  127.56557018] 249.491113249\n",
      "positions (x,y,z), reward: [  20.3197203   -11.35862523  133.41775367] 248.507322524\n",
      "positions (x,y,z), reward: [  27.07981612  -15.20579524  149.51316879] 204.99816523\n",
      "Episode =  370, score = 305.884 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.29714450e-05  -4.67563805e-06   2.02792941e+01] -3.36145388282\n",
      "positions (x,y,z), reward: [ -2.02367285e-01  -1.51785610e-03   3.43821837e+01] 16.3960851979\n",
      "positions (x,y,z), reward: [ -2.80503950e-01  -2.15200973e-02   3.63792864e+01] 66.9950195846\n",
      "positions (x,y,z), reward: [ -0.40408668  -0.05990379  38.94595718] 67.5334843827\n",
      "positions (x,y,z), reward: [ -1.26125594  -0.43523741  49.71686667] 117.901985451\n",
      "positions (x,y,z), reward: [ -2.21556779  -0.94593008  56.95506364] 166.845799631\n",
      "positions (x,y,z), reward: [ -3.41495019  -1.66814409  63.69203994] 164.998783318\n",
      "positions (x,y,z), reward: [ -4.00733075  -2.05436521  66.49882836] 163.976471471\n",
      "positions (x,y,z), reward: [ -4.25976601  -2.22432157  67.61995739] 163.523889127\n",
      "positions (x,y,z), reward: [ -5.50880165  -3.1052081   72.64435889] 161.17167991\n",
      "positions (x,y,z), reward: [-14.43879714  -9.91704828  95.46047672] 165.575870079\n",
      "positions (x,y,z), reward: [ -19.85278868  -13.77121586  103.9967736 ] 254.978684584\n",
      "positions (x,y,z), reward: [ -40.53330303  -26.73928866  123.54645579] 216.72821016\n",
      "positions (x,y,z), reward: [ -45.14793035  -29.47026089  126.32818768] 215.084702177\n",
      "positions (x,y,z), reward: [ -47.03701315  -30.5815766   127.34852837] 214.421684652\n",
      "positions (x,y,z), reward: [ -47.51299868  -30.86106805  127.59531205] 214.255115778\n",
      "Episode =  371, score = 290.224 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -4.90283416e-14   6.17745007e-12   2.00310862e+01] -6.44600762337\n",
      "positions (x,y,z), reward: [ -6.16711209e-10  -6.88883025e-09   2.00699129e+01] -5.67132645566\n",
      "positions (x,y,z), reward: [  2.06065094e-07  -4.64944130e-07   2.01938774e+01] -4.13296115119\n",
      "positions (x,y,z), reward: [ -2.84019392e-07  -1.20624088e-03   2.17052901e+01] 3.0775490025\n",
      "positions (x,y,z), reward: [  2.21551458e-05  -7.02868221e-03   2.32625520e+01] 6.77844084503\n",
      "positions (x,y,z), reward: [  0.03707915  -0.26770437  36.85948602] 67.1080523107\n",
      "positions (x,y,z), reward: [  0.12892092  -0.68754821  49.6398912 ] 118.616719682\n",
      "positions (x,y,z), reward: [  0.14638108  -0.7421299   51.28961169] 118.66433301\n",
      "positions (x,y,z), reward: [  0.26406846  -0.99608015  59.62449079] 168.703715772\n",
      "positions (x,y,z), reward: [  0.29429143  -1.04164758  61.30391961] 168.679679504\n",
      "positions (x,y,z), reward: [  0.36140993  -1.12647405  64.67102778] 168.610292742\n",
      "positions (x,y,z), reward: [  0.45037761  -1.21390201  68.6100253 ] 168.506199941\n",
      "positions (x,y,z), reward: [  0.62632645  -1.33257191  75.38207246] 168.291509847\n",
      "positions (x,y,z), reward: [  0.98319133  -1.45730909  87.24888193] 178.670402533\n",
      "positions (x,y,z), reward: [  1.16871036  -1.49217209  92.89383964] 186.889953572\n",
      "positions (x,y,z), reward: [   1.46906698   -1.54262308  101.35259229] 295.143450491\n",
      "positions (x,y,z), reward: [   1.89104171   -4.63705246  142.97285536] 264.269143509\n",
      "Episode =  372, score = 327.805 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.30467018e-02   6.05935893e-03   2.32680562e+01] 6.79076063347\n",
      "positions (x,y,z), reward: [ -0.16509458   0.09873958  30.57728375] 14.4565460301\n",
      "positions (x,y,z), reward: [ -0.27730903   0.18566321  33.88036013] 15.9119161553\n",
      "positions (x,y,z), reward: [ -0.29579971   0.20116252  34.36986036] 16.0729537915\n",
      "positions (x,y,z), reward: [ -0.37583967   0.27165203  36.36434175] 66.6179326488\n",
      "positions (x,y,z), reward: [ -0.59094654   0.48480552  41.02390031] 67.34313546\n",
      "positions (x,y,z), reward: [ -0.95209523   0.9033323   47.49107044] 117.529601311\n",
      "positions (x,y,z), reward: [ -1.36209402   1.44232051  53.58832179] 167.208398462\n",
      "positions (x,y,z), reward: [ -1.44566201   1.55808663  54.71130337] 167.11728964\n",
      "positions (x,y,z), reward: [ -1.71457794   1.94114541  58.10640008] 166.793453189\n",
      "positions (x,y,z), reward: [ -2.96704351   3.86589832  70.93363629] 165.107088486\n",
      "positions (x,y,z), reward: [ -3.17551079   4.19880425  72.73758477] 164.80741297\n",
      "positions (x,y,z), reward: [ -4.20048603   5.84144906  80.72706666] 164.327198416\n",
      "positions (x,y,z), reward: [ -4.55767857   6.40926728  83.24369639] 167.530888808\n",
      "positions (x,y,z), reward: [ -6.43182233   9.27754211  94.93985176] 182.089033379\n",
      "positions (x,y,z), reward: [ -12.37511087   16.54866735  123.80960546] 252.911962224\n",
      "positions (x,y,z), reward: [ -12.74930632   16.90803723  125.41428156] 252.736885184\n",
      "positions (x,y,z), reward: [ -12.93975597   17.08651703  126.22518996] 252.662030843\n",
      "positions (x,y,z), reward: [ -17.50020779   20.49461559  145.03221052] 254.550841173\n",
      "Episode =  373, score = 294.914 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -8.00565432e-05  -2.47008386e-05   2.06246277e+01] -1.12145654972\n",
      "positions (x,y,z), reward: [  0.21045878  -0.16547969  34.86431323] 16.3881281749\n",
      "positions (x,y,z), reward: [  0.42632929  -0.3587265   41.55124953] 67.6962983932\n",
      "positions (x,y,z), reward: [  0.9987466   -1.13804874  55.19648687] 167.704175074\n",
      "positions (x,y,z), reward: [  1.28481127  -1.69475677  60.78879817] 167.074008256\n",
      "positions (x,y,z), reward: [  3.33573865  -6.76817673  86.57059308] 169.498819418\n",
      "positions (x,y,z), reward: [  3.46579985  -7.10166576  87.680002  ] 170.659740868\n",
      "positions (x,y,z), reward: [   6.11714741  -13.64632035  104.08847925] 272.975892587\n",
      "positions (x,y,z), reward: [  12.20931674  -27.68669261  124.12851835] 233.836328654\n",
      "Episode =  374, score = 303.484 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.06343082   0.12531588  28.80134687] 13.3123969909\n",
      "positions (x,y,z), reward: [ -0.1948785    0.46024239  35.85409517] 16.4493674873\n",
      "positions (x,y,z), reward: [ -1.46366533   3.70882351  62.14570559] 165.722627294\n",
      "positions (x,y,z), reward: [ -3.33074349   7.64457525  78.98205814] 162.647198788\n",
      "positions (x,y,z), reward: [  -9.21017033   16.746274    105.71437063] 280.586207339\n",
      "positions (x,y,z), reward: [ -13.39709341   22.30124089  120.34728791] 264.568597798\n",
      "positions (x,y,z), reward: [ -15.43712997   24.99898047  127.56011075] 271.281603561\n",
      "positions (x,y,z), reward: [ -19.76212252   31.12667449  144.51735031] 295.311352232\n",
      "Episode =  375, score = 395.612 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -9.72690502e-02  -1.20219702e-02   2.67392167e+01] 11.5536407195\n",
      "positions (x,y,z), reward: [ -2.04942530e-01  -1.77249960e-02   2.96728064e+01] 13.9038535327\n",
      "positions (x,y,z), reward: [ -2.24430954e-01  -1.85982534e-02   3.01183161e+01] 14.1792244754\n",
      "positions (x,y,z), reward: [ -1.56691015  -0.13397228  47.44612716] 117.522864132\n",
      "positions (x,y,z), reward: [ -3.51087012  -0.39551233  60.1621373 ] 165.987236361\n",
      "positions (x,y,z), reward: [ -6.16059584  -0.75554603  70.20392473] 162.809237389\n",
      "positions (x,y,z), reward: [ -7.15723424  -0.87583907  72.96728285] 161.46446944\n",
      "positions (x,y,z), reward: [ -8.28852439  -1.00257379  75.70250086] 159.873477386\n",
      "positions (x,y,z), reward: [ -8.53166116  -1.0285726   76.24522447] 159.524541881\n",
      "positions (x,y,z), reward: [-22.42444101  -2.11988188  95.31787411] 163.868017897\n",
      "positions (x,y,z), reward: [-22.88095792  -2.14864922  95.73616456] 164.265391828\n",
      "positions (x,y,z), reward: [-24.27420337  -2.2350437   96.9667643 ] 165.416579993\n",
      "positions (x,y,z), reward: [ -50.7775721    -3.63584489  111.72163682] 240.466221009\n",
      "positions (x,y,z), reward: [ -61.81675138   -4.06446929  114.4422603 ] 231.65795585\n",
      "Episode =  376, score = 295.468 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -5.62224086e-06  -1.50339941e-05   2.02790965e+01] -3.36489457815\n",
      "positions (x,y,z), reward: [ -3.59860630e-03  -7.46149841e-03   2.29768963e+01] 6.21301798832\n",
      "positions (x,y,z), reward: [ -7.99932912e-03  -2.17131334e-02   2.45390809e+01] 8.92235287988\n",
      "positions (x,y,z), reward: [ -9.07438567e-03  -2.59614155e-02   2.48830942e+01] 9.41272138893\n",
      "positions (x,y,z), reward: [ -1.38442985e-02  -4.86337949e-02   2.63532972e+01] 11.2020235726\n",
      "positions (x,y,z), reward: [ -2.02092404e-02  -9.15641022e-02   2.83784569e+01] 13.0642305629\n",
      "positions (x,y,z), reward: [  0.10055286  -0.84608954  44.76809537] 118.060907661\n",
      "positions (x,y,z), reward: [  3.06029133  -5.21529277  83.62756983] 167.790656147\n",
      "positions (x,y,z), reward: [  4.96150401  -7.50239759  95.61120971] 181.349420885\n",
      "positions (x,y,z), reward: [  10.89793887  -14.31307927  120.72028243] 243.857927076\n",
      "positions (x,y,z), reward: [  11.39084757  -14.87965845  122.33914736] 242.617382043\n",
      "positions (x,y,z), reward: [  11.89581344  -15.46175162  123.94680446] 241.338592717\n",
      "positions (x,y,z), reward: [  14.60288122  -18.61007779  131.79790963] 234.393322009\n",
      "positions (x,y,z), reward: [  15.77033054  -19.9816179   134.84152863] 231.361709201\n",
      "positions (x,y,z), reward: [  16.16999228  -20.45306263  135.84274499] 230.774280139\n",
      "positions (x,y,z), reward: [  19.11110127  -23.9529288   142.65640119] 226.603859631\n",
      "Episode =  377, score = 308.988 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.25514640e-07   5.08609263e-06   2.01241996e+01] -4.89919359462\n",
      "positions (x,y,z), reward: [ -2.70641048e-04   3.10975434e-04   2.07692869e+01] -0.392716822958\n",
      "positions (x,y,z), reward: [ -1.08002806e-02   5.53224371e-03   2.35668720e+01] 7.3452384562\n",
      "positions (x,y,z), reward: [ -1.54909483e-02   7.60412692e-03   2.42030440e+01] 8.41464275292\n",
      "positions (x,y,z), reward: [ -0.84680694   0.70641014  47.50096689] 117.846446869\n",
      "positions (x,y,z), reward: [ -5.45626416   5.05541068  82.43886432] 163.081747235\n",
      "positions (x,y,z), reward: [ -12.33500019    9.17517271  103.12057923] 272.257705151\n",
      "positions (x,y,z), reward: [ -32.17134959   13.43087124  129.54343954] 228.371320157\n",
      "positions (x,y,z), reward: [ -33.67371658   13.53546193  130.71274616] 227.602215665\n",
      "Episode =  378, score = 301.591 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -7.03400965e-03  -1.39737623e-02   2.42061147e+01] 8.42247140449\n",
      "positions (x,y,z), reward: [  0.07666397  -0.50795188  50.22061005] 118.897365552\n",
      "positions (x,y,z), reward: [  0.14320864  -0.70685502  57.97602317] 169.018201017\n",
      "positions (x,y,z), reward: [  0.20841026  -0.84269106  64.13028766] 169.020225679\n",
      "positions (x,y,z), reward: [  0.57672115  -0.76944874  87.64685563] 181.804083878\n",
      "positions (x,y,z), reward: [  -1.39562983    7.38161007  151.41111018] 246.183445917\n",
      "Episode =  379, score = 321.912 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.21077901e-02  -4.30273600e-03   2.29770774e+01] 6.21672735607\n",
      "positions (x,y,z), reward: [ -1.70790970e-02  -6.28185797e-03   2.35694260e+01] 7.35161670042\n",
      "positions (x,y,z), reward: [ -3.67226182  -6.83576522  77.41634991] 158.883225406\n",
      "positions (x,y,z), reward: [ -3.7910424   -7.16782652  78.51076364] 158.369930885\n",
      "positions (x,y,z), reward: [ -5.0905068  -11.11733001  89.83791683] 167.136076983\n",
      "positions (x,y,z), reward: [ -5.87159653 -13.77923467  96.16326845] 172.69887624\n",
      "positions (x,y,z), reward: [  -6.80737442  -17.35383645  103.38175255] 268.169915064\n",
      "positions (x,y,z), reward: [  -9.10405198  -28.07150452  119.30168184] 236.532947236\n",
      "positions (x,y,z), reward: [  -9.17654246  -28.4426363   119.75244126] 235.67994784\n",
      "positions (x,y,z), reward: [ -10.44606178  -35.1048956   127.08640336] 232.192082034\n",
      "positions (x,y,z), reward: [ -11.22934568  -39.31433893  131.10268676] 230.293092577\n",
      "positions (x,y,z), reward: [ -12.12278509  -44.17854423  135.26130282] 228.157285903\n",
      "Episode =  380, score = 299.935 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -3.24321991e-03   2.17532377e-03   2.17066620e+01] 3.0832548672\n",
      "positions (x,y,z), reward: [ -1.68665319e-02   8.27561470e-03   2.32653030e+01] 6.76969014956\n",
      "positions (x,y,z), reward: [ -0.54758895   0.30554882  35.85308997] 16.2422211413\n",
      "positions (x,y,z), reward: [ -0.87314263   0.49702978  39.96112023] 66.8063951502\n",
      "positions (x,y,z), reward: [ -6.32593395   3.95440805  72.54680573] 159.797033502\n",
      "positions (x,y,z), reward: [ -7.72141959   4.83559702  77.60151235] 157.517692547\n",
      "positions (x,y,z), reward: [ -9.2998424    5.82060146  82.65389071] 158.906182445\n",
      "positions (x,y,z), reward: [-11.28153031   7.03443934  88.25474368] 164.011082197\n",
      "positions (x,y,z), reward: [ -29.75437628   17.44271697  123.32493579] 228.631028123\n",
      "positions (x,y,z), reward: [ -35.45737159   20.41747708  130.73931399] 224.20458651\n",
      "positions (x,y,z), reward: [ -38.10608906   21.77109071  133.78526696] 223.29466944\n",
      "positions (x,y,z), reward: [ -38.88121821   22.16375959  134.63179674] 223.026079556\n",
      "positions (x,y,z), reward: [ -40.85563865   23.15692552  136.70044215] 222.338664822\n",
      "Episode =  381, score = 295.758 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.25625758e-02   6.47940515e-02   3.48622805e+01] 16.6874073406\n",
      "positions (x,y,z), reward: [  3.95210934e-01   8.54579485e-03   4.91546397e+01] 119.234044178\n",
      "positions (x,y,z), reward: [  2.6489352   -2.07668613  72.79231664] 167.113917475\n",
      "positions (x,y,z), reward: [  7.42228431  -7.98991107  94.28268427] 179.786246477\n",
      "positions (x,y,z), reward: [  23.13589243  -29.22076908  130.44237075] 252.413463061\n",
      "positions (x,y,z), reward: [  61.67001853  -83.66511535  184.82398338] 257.864268793\n",
      "Episode =  382, score = 335.045 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.07671454e-02  -1.50409474e-03   2.29762180e+01] 6.20934115083\n",
      "positions (x,y,z), reward: [  0.28620014  -0.08025581  32.91330298] 15.5970232502\n",
      "positions (x,y,z), reward: [  0.36169434  -0.10574974  34.37052792] 16.1121032719\n",
      "positions (x,y,z), reward: [  1.26477738  -0.53713169  45.34187374] 117.488525466\n",
      "positions (x,y,z), reward: [  1.73839269  -0.82968162  49.20590548] 117.300113238\n",
      "positions (x,y,z), reward: [  5.60525731  -3.99757133  68.29442909] 162.082737934\n",
      "positions (x,y,z), reward: [  8.33254366  -6.67493265  76.62763074] 156.685281948\n",
      "positions (x,y,z), reward: [ 19.6163468  -19.28330848  97.53284328] 155.038410612\n",
      "positions (x,y,z), reward: [  26.54269578  -27.73748499  105.14364961] 245.946768997\n",
      "positions (x,y,z), reward: [  29.45047399  -31.45113602  107.63395376] 240.310070056\n",
      "positions (x,y,z), reward: [  37.45273317  -42.21895614  112.69103603] 226.466757315\n",
      "positions (x,y,z), reward: [  44.10656847  -51.71721152  114.98508432] 216.481041206\n",
      "positions (x,y,z), reward: [  64.42169868  -81.7705387   112.07413673] 162.539591115\n",
      "Episode =  383, score = 261.335 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.62456394  -1.18831658  48.0094085 ] 117.545403245\n",
      "positions (x,y,z), reward: [  0.85167743  -1.50182577  51.86429084] 117.336998549\n",
      "positions (x,y,z), reward: [  1.95416031  -2.82631018  64.77555362] 165.589216841\n",
      "positions (x,y,z), reward: [  2.07849086  -2.96554387  65.91138671] 165.370829729\n",
      "positions (x,y,z), reward: [  4.91921076  -5.94620744  84.92594406] 167.749010247\n",
      "positions (x,y,z), reward: [  13.68649668  -15.0092094   119.25511038] 242.494239467\n",
      "positions (x,y,z), reward: [  13.86798243  -15.20558982  119.81600175] 241.2168999\n",
      "Episode =  384, score = 306.247 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.32524193e-05   7.44228287e-05   2.03792540e+01] -2.61172860422\n",
      "positions (x,y,z), reward: [  3.91780772e-04   5.15968101e-04   2.14916971e+01] 2.41669114242\n",
      "positions (x,y,z), reward: [  8.32765098e-04  -1.75908129e-04   2.26966430e+01] 5.6198985049\n",
      "positions (x,y,z), reward: [  7.75270174e-03  -2.65885319e-02   2.71356359e+01] 12.0295334778\n",
      "positions (x,y,z), reward: [  0.11992506  -0.37436221  41.01277156] 67.8895819975\n",
      "positions (x,y,z), reward: [  0.21401787  -0.61066337  46.3740315 ] 118.336534157\n",
      "positions (x,y,z), reward: [  0.27608299  -0.75570194  49.10391933] 118.391617827\n",
      "positions (x,y,z), reward: [  1.31667557  -2.99575746  72.06173004] 166.079847773\n",
      "positions (x,y,z), reward: [  1.35901325  -3.08573262  72.63001185] 165.967538891\n",
      "positions (x,y,z), reward: [  2.09436739  -4.60211332  80.63983334] 165.07902543\n",
      "positions (x,y,z), reward: [  4.54562083  -9.12069672  96.02219812] 182.807381281\n",
      "positions (x,y,z), reward: [  18.09275001  -31.96859256  128.95473   ] 236.605224347\n",
      "positions (x,y,z), reward: [  20.90971556  -36.85296221  132.91188959] 235.251544948\n",
      "positions (x,y,z), reward: [  23.60839791  -41.59511176  136.26876766] 235.877926207\n",
      "positions (x,y,z), reward: [  33.72497862  -60.0106051   146.09877691] 238.525320435\n",
      "positions (x,y,z), reward: [  37.74383397  -67.57685369  149.06250066] 189.565305145\n",
      "Episode =  385, score = 302.661 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -6.90836834e-04   1.03772534e-02   2.52377470e+01] 9.92205181904\n",
      "positions (x,y,z), reward: [  1.20500849e-02   1.63086037e-02   2.71417587e+01] 12.0524636054\n",
      "positions (x,y,z), reward: [  0.65890342   0.06459657  45.85680622] 118.404933841\n",
      "positions (x,y,z), reward: [  0.68960055   0.06305969  46.39999835] 118.43515021\n",
      "positions (x,y,z), reward: [  1.30307129e+00  -3.47072065e-02   5.57683346e+01] 168.476738763\n",
      "positions (x,y,z), reward: [  1.34387804e+00  -4.55005553e-02   5.63248649e+01] 168.445484562\n",
      "positions (x,y,z), reward: [  3.00163408  -1.07131223  81.11616252] 168.196703635\n",
      "positions (x,y,z), reward: [  3.06282832  -1.44997747  88.01254307] 178.36580472\n",
      "positions (x,y,z), reward: [   1.10594423   -2.57398327  108.87393517] 283.832301177\n",
      "positions (x,y,z), reward: [   1.00103361   -2.60526469  109.45014578] 283.016117788\n",
      "positions (x,y,z), reward: [   0.67072929   -2.69935177  111.17551414] 280.578943465\n",
      "positions (x,y,z), reward: [  -1.92623249   -3.30870011  121.95683481] 264.756813332\n",
      "positions (x,y,z), reward: [  -7.02810245   -4.23271981  136.74835389] 257.495522656\n",
      "Episode =  386, score = 325.801 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -8.77954575e-07  -3.29106377e-07   2.00699896e+01] -5.66878438403\n",
      "positions (x,y,z), reward: [ -2.03232204e-04  -1.19417191e-04   2.06250515e+01] -1.11721910157\n",
      "positions (x,y,z), reward: [ -1.82661775e-02  -4.66077888e-02   2.71410843e+01] 12.0155692377\n",
      "positions (x,y,z), reward: [  8.92631218e-03  -2.37681622e-01   3.63697202e+01] 67.0379874287\n",
      "positions (x,y,z), reward: [  1.57908677  -1.45745387  67.25876984] 167.96492573\n",
      "positions (x,y,z), reward: [  1.95744711  -1.66317712  70.75497042] 167.640533178\n",
      "positions (x,y,z), reward: [  4.28318685  -2.97291531  86.84203737] 175.265674444\n",
      "positions (x,y,z), reward: [  5.06092536  -3.47270037  91.09063058] 180.50955215\n",
      "positions (x,y,z), reward: [  13.87977083  -11.93055805  123.35886458] 242.976721664\n",
      "positions (x,y,z), reward: [  15.60407539  -14.00474194  127.55253957] 237.988447155\n",
      "Episode =  387, score = 311.291 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.68123228e-06   6.31518912e-06   2.01243405e+01] -4.89554946185\n",
      "positions (x,y,z), reward: [  9.21860466e-06   1.04000679e-03   2.11039471e+01] 1.0509177165\n",
      "positions (x,y,z), reward: [  1.46115969e-02  -5.32284420e-03   4.58649329e+01] 119.094387994\n",
      "positions (x,y,z), reward: [ -7.98048711e-01  -3.32474382e-02   7.03718665e+01] 169.382934325\n",
      "positions (x,y,z), reward: [ -2.31054632   0.08729344  86.75083561] 177.95892612\n",
      "positions (x,y,z), reward: [ -2.52837072   0.09982829  88.44470674] 180.265386531\n",
      "positions (x,y,z), reward: [ -3.09286124   0.12373156  92.39572973] 185.587025549\n",
      "positions (x,y,z), reward: [  -9.29033617   -0.17845202  118.10083684] 262.828967294\n",
      "positions (x,y,z), reward: [ -19.88104585   -1.61767368  139.10426553] 244.897952555\n",
      "positions (x,y,z), reward: [ -24.85073427   -2.30476653  145.20192195] 242.092126413\n",
      "Episode =  388, score = 322.020 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.16499826e-03   4.07215722e-02   2.67409843e+01] 11.6285898217\n",
      "positions (x,y,z), reward: [ -5.54010637e-05   4.44965819e-02   2.71383720e+01] 12.023158048\n",
      "positions (x,y,z), reward: [  1.39701367   0.54619645  66.41728054] 168.297402169\n",
      "positions (x,y,z), reward: [  1.92749887   0.70665378  72.64696846] 167.74852137\n",
      "positions (x,y,z), reward: [  2.03590426   0.74134974  73.78276651] 167.627096289\n",
      "positions (x,y,z), reward: [  2.14814986   0.77793175  74.91943331] 167.500088171\n",
      "positions (x,y,z), reward: [   6.64704865    2.61645311  104.66706713] 284.40919675\n",
      "positions (x,y,z), reward: [   8.32847991    3.40642945  112.10860463] 270.658477237\n",
      "positions (x,y,z), reward: [  11.60937027    5.02130958  124.06913426] 253.762925965\n",
      "positions (x,y,z), reward: [  16.36360531    7.45591205  137.62600753] 246.240443947\n",
      "positions (x,y,z), reward: [  21.26034475    9.98720848  148.76821681] 189.619010435\n",
      "Episode =  389, score = 318.463 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.40790735e-02   2.22574793e-02   2.45392055e+01] 8.92077134041\n",
      "positions (x,y,z), reward: [  0.03300223   0.04168437  26.74351108] 11.6099203907\n",
      "positions (x,y,z), reward: [  0.35973049   0.2519272   42.08627821] 67.972173712\n",
      "positions (x,y,z), reward: [  0.95000024   0.75353198  57.43609325] 168.256424098\n",
      "positions (x,y,z), reward: [  3.10989972   3.50731717  87.23788495] 175.688007418\n",
      "positions (x,y,z), reward: [  4.45763091   5.36503124  98.56223076] 190.19316712\n",
      "positions (x,y,z), reward: [   4.9634688     6.05830455  102.19881948] 288.114274066\n",
      "positions (x,y,z), reward: [   5.60461266    6.93111828  106.48196975] 280.493562089\n",
      "positions (x,y,z), reward: [   8.48812386   10.78205453  122.91119083] 255.478419147\n",
      "positions (x,y,z), reward: [   9.14020575   11.64388859  126.2184738 ] 254.620092467\n",
      "positions (x,y,z), reward: [  10.10987605   12.92479157  130.9727548 ] 253.515028597\n",
      "positions (x,y,z), reward: [  12.24896135   15.7857076   141.08838235] 251.959653682\n",
      "Episode =  390, score = 311.087 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.56968922e-04  -1.48291982e-04   2.04942404e+01] -1.86693855447\n",
      "positions (x,y,z), reward: [  0.0794233   -0.04801131  27.54063534] 12.3193448425\n",
      "positions (x,y,z), reward: [  0.42636566  -0.23853915  42.07172655] 67.9108981548\n",
      "positions (x,y,z), reward: [  0.47354612  -0.26507522  44.21142066] 118.162047469\n",
      "positions (x,y,z), reward: [  0.48464729  -0.27140175  44.75022563] 118.216607589\n",
      "positions (x,y,z), reward: [  0.35598788  -0.3227815   64.2359524 ] 169.775557998\n",
      "positions (x,y,z), reward: [ -2.68360149   0.25961148  87.18008159] 178.377507505\n",
      "positions (x,y,z), reward: [ -4.65646233   0.59791819  94.54714811] 186.639541375\n",
      "positions (x,y,z), reward: [  -9.95186885    1.3397367   108.25335382] 274.968050045\n",
      "positions (x,y,z), reward: [ -11.27286398    1.48091856  110.90002881] 269.169047029\n",
      "positions (x,y,z), reward: [ -20.05902157    1.9875337   124.42885531] 243.623926838\n",
      "positions (x,y,z), reward: [ -32.0112422     1.69070975  136.58429481] 239.915931605\n",
      "positions (x,y,z), reward: [ -35.86106033    1.40503456  139.61877915] 238.90035844\n",
      "Episode =  391, score = 317.386 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00777565] -7.22243512084\n",
      "positions (x,y,z), reward: [  6.35405710e-04  -4.00287544e-04   2.11017505e+01] 1.03159420022\n",
      "positions (x,y,z), reward: [  0.05864357  -0.07803187  31.03306773] 14.8695882625\n",
      "positions (x,y,z), reward: [  2.15667844  -7.69515784  74.29179059] 159.272055389\n",
      "positions (x,y,z), reward: [  5.00204136 -18.08497024  89.22802803] 154.620872503\n",
      "positions (x,y,z), reward: [  16.12299596  -51.5904074   103.6551778 ] 231.030821601\n",
      "positions (x,y,z), reward: [  20.31459576  -61.55148627  102.86056256] 195.70377932\n",
      "positions (x,y,z), reward: [ 26.00566668 -73.53990162  99.2142991 ] 90.4281996829\n",
      "Episode =  392, score = 261.751 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.45193725e-06  -1.31392728e-06   2.01243105e+01] -4.89618081081\n",
      "positions (x,y,z), reward: [  1.88463602e-02   5.89667061e-02   2.75490371e+01] 12.3881866436\n",
      "positions (x,y,z), reward: [  0.06766661   0.26971896  36.87682027] 67.0868708559\n",
      "positions (x,y,z), reward: [  0.07683115   0.45285961  43.15449907] 68.2219898269\n",
      "positions (x,y,z), reward: [  0.07031604   0.51869148  45.30671598] 118.453501109\n",
      "positions (x,y,z), reward: [  0.06464964   0.55202974  46.39101688] 118.551120012\n",
      "positions (x,y,z), reward: [ -0.34712111   0.99484409  63.61980023] 168.880386425\n",
      "positions (x,y,z), reward: [ -3.30933131   0.22924256  89.89723159] 181.969718\n",
      "positions (x,y,z), reward: [ -10.83641343   -3.83556065  112.225799  ] 265.333366888\n",
      "positions (x,y,z), reward: [ -13.55601672   -5.29913754  116.85884254] 252.924044389\n",
      "positions (x,y,z), reward: [ -20.18128572   -8.68064333  125.32274396] 235.131153001\n",
      "positions (x,y,z), reward: [ -25.40102778  -11.15233273  130.26128281] 230.140376009\n",
      "positions (x,y,z), reward: [ -26.79700328  -11.78458673  131.39950852] 228.847794083\n",
      "positions (x,y,z), reward: [ -31.69360079  -13.90687631  134.90231069] 224.457609463\n",
      "positions (x,y,z), reward: [ -33.75215718  -14.75449814  136.1749749 ] 222.678719218\n",
      "Episode =  393, score = 312.075 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.75661868e-05  -1.83803209e-05   2.01940823e+01] -4.12868032918\n",
      "positions (x,y,z), reward: [ -1.53169428e-04  -2.07983283e-04   2.04946741e+01] -1.86142086082\n",
      "positions (x,y,z), reward: [ -3.16161864e-03  -5.75048035e-03   2.21767891e+01] 4.37748589267\n",
      "positions (x,y,z), reward: [ -1.74571950e-02  -4.62908604e-02   2.63507327e+01] 11.1921689543\n",
      "positions (x,y,z), reward: [ -2.03388254e-02  -5.75412470e-02   2.71373527e+01] 11.9887133045\n",
      "positions (x,y,z), reward: [ -0.03496215  -0.22308714  34.85912586] 16.5091782391\n",
      "positions (x,y,z), reward: [ -2.69330354e-02  -2.95115169e-01   3.73778485e+01] 67.2492757585\n",
      "positions (x,y,z), reward: [  0.10624978  -0.60464522  46.93519148] 118.577831027\n",
      "positions (x,y,z), reward: [  1.00516539  -1.0162549   64.42186298] 169.179542483\n",
      "positions (x,y,z), reward: [  1.05526657  -1.02077211  65.00695408] 169.206459345\n",
      "positions (x,y,z), reward: [  11.95415898    2.67791543  115.62570297] 275.268127505\n",
      "positions (x,y,z), reward: [  17.42370925    5.55846371  132.48635023] 266.853465008\n",
      "positions (x,y,z), reward: [  21.53997303    8.02721072  145.74183161] 268.563574375\n",
      "positions (x,y,z), reward: [  34.74960953   15.09939961  205.39448369] 164.03944765\n",
      "Episode =  394, score = 302.775 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -9.48042884e-05  -1.26544664e-04   2.03789956e+01] -2.61490964526\n",
      "positions (x,y,z), reward: [ -1.37843827e-03  -1.60516035e-03   2.11019834e+01] 1.03158301964\n",
      "positions (x,y,z), reward: [ -5.11012996e-03  -5.44351226e-03   2.19344146e+01] 3.73028206971\n",
      "positions (x,y,z), reward: [ -0.11768586  -0.08423697  28.37178324] 12.9603821145\n",
      "positions (x,y,z), reward: [ -0.25711205  -0.1336497   32.4275204 ] 15.3367936199\n",
      "positions (x,y,z), reward: [ -2.63896659   0.58328951  59.2770281 ] 167.330420918\n",
      "positions (x,y,z), reward: [ -4.05406268   1.25681839  67.36304631] 165.890224645\n",
      "positions (x,y,z), reward: [ -4.68052094   1.5584133   70.29715129] 165.222308496\n",
      "positions (x,y,z), reward: [ -5.38050995   1.89311042  73.2583158 ] 164.467820209\n",
      "positions (x,y,z), reward: [ -7.0300724    2.66111892  79.2722695 ] 162.696452478\n",
      "positions (x,y,z), reward: [ -7.79531811   3.00352295  81.71637134] 164.457332343\n",
      "Episode =  395, score = 348.214 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.80040583e-07   7.62825477e-06   2.01243094e+01] -4.89735156543\n",
      "positions (x,y,z), reward: [  0.06481429   0.03429532  29.23842575] 13.7364413339\n",
      "positions (x,y,z), reward: [  0.43172437   0.18673658  38.41495404] 67.2611913071\n",
      "positions (x,y,z), reward: [  1.16252911   0.55249224  47.53792656] 117.889407212\n",
      "positions (x,y,z), reward: [  1.65845223   0.83792814  52.00508304] 167.705108574\n",
      "positions (x,y,z), reward: [  2.60667549   1.44121365  58.88351836] 167.068628314\n",
      "positions (x,y,z), reward: [  3.28807493   1.90726156  63.00751519] 166.588829308\n",
      "positions (x,y,z), reward: [  3.72533085   2.21663955  65.4092117 ] 166.289185052\n",
      "positions (x,y,z), reward: [  4.32516127   2.65181735  68.46604897] 165.909840111\n",
      "positions (x,y,z), reward: [  5.56775609   3.58751033  74.15697552] 165.228516485\n",
      "positions (x,y,z), reward: [ 11.65976347   8.476236    96.6834901 ] 188.414855356\n",
      "positions (x,y,z), reward: [  19.27543893   13.81922227  123.70636397] 271.100773502\n",
      "positions (x,y,z), reward: [  25.61316945   15.83807334  154.30094953] 264.361759398\n",
      "Episode =  396, score = 349.203 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.16422582  -0.08261526  29.23767084] 13.5875943455\n",
      "positions (x,y,z), reward: [ -0.23843332  -0.11909805  31.03218268] 14.6345230766\n",
      "positions (x,y,z), reward: [ -0.53211403  -0.26946227  36.36116632] 66.449786342\n",
      "positions (x,y,z), reward: [ -1.1748562   -0.60872435  44.21194851] 117.086221043\n",
      "positions (x,y,z), reward: [ -5.066735    -2.60346551  66.85134254] 162.112598362\n",
      "positions (x,y,z), reward: [-15.0933578   -7.06611288  90.33532813] 160.168362812\n",
      "positions (x,y,z), reward: [-16.74544763  -7.67764094  92.78671949] 160.938736933\n",
      "positions (x,y,z), reward: [-20.76909087  -9.05968038  97.93389945] 162.39887459\n",
      "positions (x,y,z), reward: [ -50.06062255  -16.98220905  118.52870855] 218.769213139\n",
      "Episode =  397, score = 288.281 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00778148] -7.22185197327\n",
      "positions (x,y,z), reward: [ -9.29424160e-05  -1.71944282e-04   2.09299459e+01] 0.339882102326\n",
      "positions (x,y,z), reward: [ -1.46924901e-04  -2.36500239e-04   2.11038521e+01] 1.05002495695\n",
      "positions (x,y,z), reward: [ -4.17051952e-02   1.16956639e-02   3.01343482e+01] 14.4149476846\n",
      "positions (x,y,z), reward: [ -0.0831559    0.04258124  36.88900735] 67.3204456482\n",
      "positions (x,y,z), reward: [  2.36868943e-01   4.33780935e-02   5.80957903e+01] 170.016652347\n",
      "positions (x,y,z), reward: [  4.50720804  -2.20222816  98.64537823] 193.122688246\n",
      "positions (x,y,z), reward: [   5.34135      -2.6831332   103.42913716] 288.764014953\n",
      "positions (x,y,z), reward: [   6.86483116   -3.49246003  111.24663173] 275.01393449\n",
      "positions (x,y,z), reward: [   8.64458168   -4.29988877  119.18283933] 261.120616113\n",
      "positions (x,y,z), reward: [  10.22386403   -4.89970497  125.41032654] 258.313892258\n",
      "positions (x,y,z), reward: [  17.57671324   -6.81467548  148.94175171] 201.640124199\n",
      "Episode =  398, score = 319.540 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.10271169   2.59783256  58.16740163] 166.980364755\n",
      "positions (x,y,z), reward: [ -1.32578633   3.15833711  61.63720617] 166.649636851\n",
      "positions (x,y,z), reward: [ -1.90330409   4.51436255  68.76169958] 165.848322464\n",
      "positions (x,y,z), reward: [ -4.44613749   9.3552199   87.51450275] 174.56930719\n",
      "positions (x,y,z), reward: [ -17.62410719   29.02516201  140.0552717 ] 294.321852034\n",
      "positions (x,y,z), reward: [ -22.14365778   38.16067787  160.02847978] 240.898099509\n",
      "Episode =  399, score = 361.327 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.196956    -0.05084679  31.49869076] 15.0219638178\n",
      "positions (x,y,z), reward: [  0.94420138  -0.05996009  43.16987722] 67.826932019\n",
      "positions (x,y,z), reward: [  1.42355724e+00  -2.95430263e-02   4.80594626e+01] 117.997509763\n",
      "positions (x,y,z), reward: [  2.15477794e+00   4.68225456e-02   5.41581387e+01] 167.752397264\n",
      "positions (x,y,z), reward: [  2.79348217   0.13715361  58.65669242] 167.332663668\n",
      "positions (x,y,z), reward: [  3.43548558   0.24565427  62.635423  ] 166.8848524\n",
      "positions (x,y,z), reward: [  4.2767687    0.40843765  67.23861183] 166.282410515\n",
      "positions (x,y,z), reward: [  4.99084449   0.55963232  70.73681235] 165.774869983\n",
      "positions (x,y,z), reward: [  6.50828047   0.90594298  77.2798531 ] 164.774013907\n",
      "positions (x,y,z), reward: [ 12.82349745   2.5196113   97.91776107] 188.68175244\n",
      "Episode =  400, score = 363.925 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.54569435e-03   2.92193392e-02   2.59706615e+01] 10.8047347071\n",
      "positions (x,y,z), reward: [  0.16064896   0.38663429  38.93036624] 67.4219708519\n",
      "positions (x,y,z), reward: [  1.03072056   1.58444406  59.64129175] 167.234419931\n",
      "positions (x,y,z), reward: [  1.09188309   1.6652546   60.75586347] 167.113399784\n",
      "positions (x,y,z), reward: [  1.92573796   3.22733476  83.36206488] 170.761984929\n",
      "positions (x,y,z), reward: [  1.74919009   3.44220053  88.59419184] 178.930360864\n",
      "positions (x,y,z), reward: [  1.63052088   3.49090093  90.35226348] 181.746807831\n",
      "positions (x,y,z), reward: [  -8.21801451    1.17696992  120.17784607] 258.284029784\n",
      "positions (x,y,z), reward: [ -30.91923117   -5.54938171  138.20757585] 229.601590505\n",
      "Episode =  401, score = 317.498 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -4.56943839e-09   8.57213974e-10   2.00699614e+01] -5.67023841468\n",
      "positions (x,y,z), reward: [  1.03697591e-02  -7.31451127e-03   2.59686495e+01] 10.811539023\n",
      "positions (x,y,z), reward: [  1.13986196e-02  -8.08340046e-03   2.63495378e+01] 11.2396266894\n",
      "positions (x,y,z), reward: [  1.81607471e-02  -1.15948545e-02   2.83743280e+01] 13.1448857456\n",
      "positions (x,y,z), reward: [  7.21811287e-02   2.12151627e-03   3.58575737e+01] 17.0408255861\n",
      "positions (x,y,z), reward: [  0.13888566   0.05401464  41.02115655] 68.2187950045\n",
      "positions (x,y,z), reward: [  0.25986062   0.20492426  48.02821471] 118.920959636\n",
      "positions (x,y,z), reward: [  0.32411174   0.31433285  51.3332401 ] 119.043562107\n",
      "positions (x,y,z), reward: [  0.68325653   1.58721574  70.63006643] 168.838008575\n",
      "positions (x,y,z), reward: [  0.72623613   1.89208887  73.55484107] 168.76183715\n",
      "positions (x,y,z), reward: [  0.81671749   3.03875216  82.5256379 ] 172.424429783\n",
      "positions (x,y,z), reward: [  0.83983934   4.13423766  89.35743377] 182.710280046\n",
      "positions (x,y,z), reward: [   0.82348106    6.30472218  100.51679103] 298.249817465\n",
      "positions (x,y,z), reward: [   1.08369535   14.59271946  136.23957256] 277.417154286\n",
      "positions (x,y,z), reward: [   1.54781857   20.75063445  175.27832904] 172.547289982\n",
      "Episode =  402, score = 322.415 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.40601381e-06  -3.22399514e-06   2.01243459e+01] -4.89599594714\n",
      "positions (x,y,z), reward: [ -2.72598782e-03  -2.45397447e-03   2.24314731e+01] 5.0114190928\n",
      "positions (x,y,z), reward: [ -0.02935028  -0.04394483  29.23727622] 13.7626428877\n",
      "positions (x,y,z), reward: [ -0.05931809  -0.13579421  34.86195903] 16.5691636793\n",
      "positions (x,y,z), reward: [ -0.08675059  -0.33844323  41.5508926 ] 68.0722403555\n",
      "positions (x,y,z), reward: [ -4.58062666e-03  -1.28399325e+00   5.63335879e+01] 168.66906514\n",
      "positions (x,y,z), reward: [  0.22962958  -2.28815131  65.34366165] 167.809342254\n",
      "positions (x,y,z), reward: [  1.6442543   -6.11527794  85.51414402] 171.886288271\n",
      "positions (x,y,z), reward: [  3.19310469  -9.57944928  97.38268311] 185.237735258\n",
      "positions (x,y,z), reward: [   4.78673683  -13.07273482  107.03931336] 274.037687026\n",
      "positions (x,y,z), reward: [  12.03297741  -35.18526858  150.62197028] 195.557573401\n",
      "positions (x,y,z), reward: [  12.53235705  -39.30528573  157.21226538] 147.276894427\n",
      "Episode =  403, score = 309.550 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.87125269e-04   5.49051147e-04   2.12902287e+01] 1.73327343801\n",
      "positions (x,y,z), reward: [  2.66266391e-03   2.38664313e-03   2.29754833e+01] 6.21743940119\n",
      "positions (x,y,z), reward: [ -5.04119216e-02   2.79297847e+00   7.76185605e+01] 167.267728694\n",
      "positions (x,y,z), reward: [ -0.18452289   3.62854692  84.92175214] 173.629971876\n",
      "positions (x,y,z), reward: [ -0.30710524   4.27072012  89.96873187] 180.392095538\n",
      "positions (x,y,z), reward: [  -1.84550665    8.60046082  117.92123557] 262.616687056\n",
      "positions (x,y,z), reward: [  -3.49671097   10.9927063   133.08653159] 255.844617841\n",
      "positions (x,y,z), reward: [  -5.31137956   12.1572684   145.7093748 ] 253.539067378\n",
      "positions (x,y,z), reward: [  -5.40709118   12.17898964  146.28989324] 253.44383922\n",
      "Episode =  404, score = 322.333 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.60538472e-03  -1.35307456e-03   2.21760355e+01] 4.38041036113\n",
      "positions (x,y,z), reward: [ -3.25228821e-03  -1.63764699e-03   2.24299937e+01] 5.00643655552\n",
      "positions (x,y,z), reward: [ -2.16270784e-02  -1.47900871e-02   2.67397486e+01] 11.6378729384\n",
      "positions (x,y,z), reward: [ -3.25563347e-02  -2.52798366e-02   2.83751720e+01] 13.1141613928\n",
      "positions (x,y,z), reward: [ -0.34542575  -0.39342038  44.75962107] 118.250289856\n",
      "positions (x,y,z), reward: [ -0.59386518  -0.65267601  50.76639554] 118.313116047\n",
      "positions (x,y,z), reward: [ -1.34067015  -1.26954021  61.89970465] 167.411594233\n",
      "positions (x,y,z), reward: [ -1.89174424  -1.62670907  67.5129352 ] 166.575182475\n",
      "positions (x,y,z), reward: [ -1.95405969  -1.66370007  68.07484099] 166.478491769\n",
      "positions (x,y,z), reward: [ -2.01770889  -1.70089772  68.63678473] 166.378939911\n",
      "positions (x,y,z), reward: [ -5.38558177  -3.23181715  89.90519024] 176.035690828\n",
      "positions (x,y,z), reward: [  -8.69694465   -4.32518509  104.28556254] 280.059652805\n",
      "positions (x,y,z), reward: [ -10.19990748   -4.73503601  109.77374731] 269.765905887\n",
      "positions (x,y,z), reward: [ -13.12021449   -5.41646603  119.02117978] 251.928746838\n",
      "positions (x,y,z), reward: [ -18.56940385   -6.41618589  132.30344504] 243.016475992\n",
      "Episode =  405, score = 313.295 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -4.54602724e-04  -1.05861062e-03   2.14912800e+01] 2.41211169878\n",
      "positions (x,y,z), reward: [ -5.29007456e-03  -1.35383694e-02   2.38780304e+01] 7.87968876855\n",
      "positions (x,y,z), reward: [ -6.56856034e-03  -1.64323296e-02   2.42013022e+01] 8.40457891115\n",
      "positions (x,y,z), reward: [ -1.64511804e-02  -3.73004169e-02   2.59670386e+01] 10.7667326893\n",
      "positions (x,y,z), reward: [ -0.06241628  -0.1243642   30.56815653] 14.5296912605\n",
      "positions (x,y,z), reward: [ -0.23929618  -0.39448732  40.48285537] 67.6464039289\n",
      "positions (x,y,z), reward: [ -0.38244049  -0.5560856   45.82601696] 118.142869737\n",
      "positions (x,y,z), reward: [ -0.51127059  -0.67310591  49.64417004] 118.257219209\n",
      "positions (x,y,z), reward: [ -0.95262196  -0.97451103  59.0677185 ] 167.989972535\n",
      "positions (x,y,z), reward: [ -1.43921844  -1.24317728  66.3485997 ] 167.382667609\n",
      "positions (x,y,z), reward: [ -3.51772337  -2.30312029  86.01470645] 173.244443022\n",
      "positions (x,y,z), reward: [ -5.19969148  -3.0677556   96.64237736] 186.580348829\n",
      "positions (x,y,z), reward: [ -5.50776498  -3.19606469  98.3148021 ] 188.627277166\n",
      "positions (x,y,z), reward: [  -8.06829518   -4.12261064  109.97188119] 272.475031154\n",
      "positions (x,y,z), reward: [  -8.64626568   -4.30192889  112.17941209] 268.342849269\n",
      "positions (x,y,z), reward: [ -12.20856098   -5.23754012  123.66469795] 251.649180984\n",
      "positions (x,y,z), reward: [ -16.00802594   -6.01147837  133.32247382] 246.513738426\n",
      "positions (x,y,z), reward: [ -22.35159365   -6.97185185  145.83801475] 240.551989962\n",
      "Episode =  406, score = 316.090 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.44952279e-01   2.18440042e-02   3.73908598e+01] 67.2184592753\n",
      "positions (x,y,z), reward: [  1.02137863   0.07929019  48.04953081] 118.317935466\n",
      "positions (x,y,z), reward: [  1.15969201   0.09381268  49.69956467] 118.322656369\n",
      "positions (x,y,z), reward: [  3.87769282   0.52206512  71.61779946] 165.926455125\n",
      "positions (x,y,z), reward: [  6.19900833   1.07175583  84.07309561] 169.100169528\n",
      "positions (x,y,z), reward: [  7.59315109   1.46600458  90.28312744] 176.549198398\n",
      "positions (x,y,z), reward: [  12.21359496    3.06771727  107.17647446] 274.210534925\n",
      "positions (x,y,z), reward: [  12.74360809    3.28003964  108.87461688] 270.999008475\n",
      "positions (x,y,z), reward: [  22.08141677    7.93891108  134.50472592] 246.113630085\n",
      "positions (x,y,z), reward: [  24.77621952    9.50696822  141.07117254] 246.152592935\n",
      "positions (x,y,z), reward: [  26.78460259   10.69600644  145.87835898] 246.357548171\n",
      "positions (x,y,z), reward: [  27.37709697   11.04838642  147.2898934 ] 246.46659791\n",
      "Episode =  407, score = 311.800 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  8.67210099e-03   7.50189888e-03   2.27001397e+01] 5.62153946691\n",
      "positions (x,y,z), reward: [  0.14590402   0.10687474  29.68273845] 13.8961246528\n",
      "positions (x,y,z), reward: [  0.39792259   0.28883514  35.86514276] 16.4199602409\n",
      "positions (x,y,z), reward: [  0.82672027   0.62370075  43.15474635] 67.3218775613\n",
      "positions (x,y,z), reward: [  2.6488787    2.30567961  62.04523983] 165.551502136\n",
      "positions (x,y,z), reward: [  2.72332599   2.37686639  62.6158209 ] 165.439324963\n",
      "positions (x,y,z), reward: [  4.54391156   4.10445566  74.17981577] 162.665517725\n",
      "positions (x,y,z), reward: [  5.61392305   5.09680067  79.50038943] 161.086652884\n",
      "positions (x,y,z), reward: [  9.50865673   8.5168757   94.19571097] 176.788395127\n",
      "positions (x,y,z), reward: [ 10.76473115   9.55145764  98.01366804] 180.805175571\n",
      "positions (x,y,z), reward: [  18.907492     15.42965125  117.90913474] 248.201723034\n",
      "positions (x,y,z), reward: [  19.61313079   15.87630385  119.4186625 ] 245.429582109\n",
      "positions (x,y,z), reward: [  25.58000176   19.35290459  131.81780159] 248.111916185\n",
      "positions (x,y,z), reward: [  31.79709846   22.74471595  145.13030419] 260.263493731\n",
      "positions (x,y,z), reward: [  45.78295826   35.78286825  185.79526788] 160.044556467\n",
      "Episode =  408, score = 298.641 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -3.07988497e-06   4.43445164e-07   2.00699934e+01] -5.66849596283\n",
      "positions (x,y,z), reward: [ -1.48370382e-03   2.67237083e-04   2.09298231e+01] 0.336607316247\n",
      "positions (x,y,z), reward: [ -6.90055391e-03   1.11935176e-03   2.19373090e+01] 3.74948281669\n",
      "positions (x,y,z), reward: [ -4.42036800e-02   8.08893213e-03   2.48853662e+01] 9.39985844532\n",
      "positions (x,y,z), reward: [ -5.06594602e-02   9.52580494e-03   2.52391981e+01] 9.8700411264\n",
      "positions (x,y,z), reward: [ -0.12349316   0.02908169  28.38056704] 13.0182147171\n",
      "positions (x,y,z), reward: [ -0.49451348   0.18760901  38.40882401] 67.145448335\n",
      "positions (x,y,z), reward: [ -0.56526212   0.22542973  39.96929211] 67.387949221\n",
      "positions (x,y,z), reward: [ -1.31990982   0.79662371  55.73872377] 167.702883849\n",
      "positions (x,y,z), reward: [ -1.51525218   1.02216284  60.20624915] 167.47627469\n",
      "positions (x,y,z), reward: [ -1.6495953    1.2092866   63.57555281] 167.277601419\n",
      "positions (x,y,z), reward: [ -1.89542306   1.66236732  70.92053602] 166.791043843\n",
      "positions (x,y,z), reward: [ -2.20696472   3.35268834  91.98980214] 183.004351224\n",
      "positions (x,y,z), reward: [  -2.09242712    4.51376814  102.33102746] 290.808273685\n",
      "positions (x,y,z), reward: [  -1.52706567    6.55973649  115.82448202] 270.039240243\n",
      "positions (x,y,z), reward: [   0.83655626   11.73870621  138.25194272] 262.066917459\n",
      "positions (x,y,z), reward: [   2.31492445   14.62986588  147.58027336] 259.04678902\n",
      "Episode =  409, score = 322.001 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.03269623   0.04223071  27.14017814] 12.0018043557\n",
      "positions (x,y,z), reward: [  0.20543143   0.1678978   35.86135111] 16.7377387471\n",
      "positions (x,y,z), reward: [  1.45323964   0.89898414  58.58375897] 167.734284475\n",
      "positions (x,y,z), reward: [  1.69751104   1.0595348   61.39812779] 167.437310312\n",
      "positions (x,y,z), reward: [  2.25038627   1.43964448  67.05073157] 166.621638607\n",
      "positions (x,y,z), reward: [  2.68869906   1.75212894  71.01599342] 165.885254286\n",
      "positions (x,y,z), reward: [  3.93218271   2.66525559  80.63074455] 164.555783133\n",
      "positions (x,y,z), reward: [  4.52156929   3.10505653  84.5751009 ] 169.37534595\n",
      "positions (x,y,z), reward: [  7.28707263   5.17600837  99.68676708] 186.853593639\n",
      "positions (x,y,z), reward: [  11.07653485    8.04093449  115.08924448] 257.42991763\n",
      "positions (x,y,z), reward: [  11.38657663    8.27800899  116.1754253 ] 255.197757684\n",
      "positions (x,y,z), reward: [  12.51599773    9.14391368  119.95882491] 247.320110465\n",
      "positions (x,y,z), reward: [  17.56733871   13.04900377  134.24302624] 237.313226449\n",
      "positions (x,y,z), reward: [  19.07029178   14.22051387  137.85111354] 234.314643269\n",
      "positions (x,y,z), reward: [  21.59655538   16.20042565  143.42034471] 230.802029841\n",
      "Episode =  410, score = 311.224 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -8.53359995e-03   4.00130436e-03   2.45408226e+01] 8.94556547649\n",
      "positions (x,y,z), reward: [ -3.34665328e-02   1.66209371e-02   2.75483023e+01] 12.4139058714\n",
      "positions (x,y,z), reward: [ -0.7949926    0.6484792   50.22851979] 118.099103413\n",
      "positions (x,y,z), reward: [ -2.6615676    3.26315805  78.35447401] 164.407590684\n",
      "positions (x,y,z), reward: [ -2.70903901   3.34039017  78.92103444] 164.273084373\n",
      "positions (x,y,z), reward: [ -2.95251489   3.74084375  81.75032933] 166.190140459\n",
      "positions (x,y,z), reward: [ -3.4145971    4.519987    86.82324549] 172.402462342\n",
      "positions (x,y,z), reward: [  -4.99929193    7.42211462  102.42746944] 283.600543054\n",
      "positions (x,y,z), reward: [  -8.00120641   14.78720949  129.33532287] 246.456801055\n",
      "Episode =  411, score = 314.344 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  5.37910196e-03  -1.07774201e-03   2.21788681e+01] 4.39381088785\n",
      "positions (x,y,z), reward: [  2.41436233e-02  -9.93324371e-03   2.52396773e+01] 9.89963669214\n",
      "positions (x,y,z), reward: [  0.04799927  -0.03297693  29.68177824] 14.0601427203\n",
      "positions (x,y,z), reward: [  0.047134    -0.07003502  33.88209534] 16.2568670013\n",
      "positions (x,y,z), reward: [  0.0424406   -0.08235817  34.86489081] 16.6311535962\n",
      "positions (x,y,z), reward: [  3.57892180e-02  -9.66807343e-02   3.58622616e+01] 16.9710400121\n",
      "positions (x,y,z), reward: [ -0.99428673  -2.19789137  65.37206089] 167.075123755\n",
      "positions (x,y,z), reward: [ -1.18910911  -2.67648538  68.20008146] 166.412136497\n",
      "positions (x,y,z), reward: [ -1.55342912  -3.58613852  72.72192978] 165.080547161\n",
      "positions (x,y,z), reward: [ -2.11911457  -4.9854315   78.34864743] 162.909820054\n",
      "positions (x,y,z), reward: [  -7.55255918  -15.42700608  103.56437843] 268.646881053\n",
      "positions (x,y,z), reward: [ -10.77400868  -20.43408685  111.23853608] 247.268030796\n",
      "positions (x,y,z), reward: [ -14.10742235  -25.3820858   117.35430464] 232.594319558\n",
      "positions (x,y,z), reward: [ -19.25805735  -32.84948151  124.61597222] 220.150370151\n",
      "Episode =  412, score = 298.875 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.56933827e-07  -2.54492968e-07   2.00699584e+01] -5.67005495321\n",
      "positions (x,y,z), reward: [  2.34610188e-04  -1.46966494e-04   2.07696747e+01] -0.388941859158\n",
      "positions (x,y,z), reward: [  1.45845699e-03  -3.58540103e-04   2.17076037e+01] 3.09582512927\n",
      "positions (x,y,z), reward: [  1.60398426e-02   7.01465187e-03   2.48849755e+01] 9.43874013828\n",
      "positions (x,y,z), reward: [  1.87661751e-02   8.98503925e-03   2.52390161e+01] 9.91327958645\n",
      "positions (x,y,z), reward: [  0.06626302   0.04897394  29.24389485] 13.7342502984\n",
      "positions (x,y,z), reward: [  1.35540778   0.81071285  55.78699652] 167.752880782\n",
      "positions (x,y,z), reward: [  1.76343763   0.92695393  60.27201403] 167.439783335\n",
      "positions (x,y,z), reward: [  3.15966122   1.02025826  72.17961769] 166.364693206\n",
      "positions (x,y,z), reward: [  3.40250037   0.9927137   73.89422286] 166.198905203\n",
      "positions (x,y,z), reward: [  5.12279221   0.44977099  84.22376575] 171.474233638\n",
      "positions (x,y,z), reward: [  8.17193284  -1.89446918  97.90551797] 186.861814207\n",
      "positions (x,y,z), reward: [  10.17387733   -4.29066006  105.09013721] 276.98601646\n",
      "positions (x,y,z), reward: [  12.69049185   -8.2653618   112.96902812] 256.879240213\n",
      "positions (x,y,z), reward: [  13.03359634   -8.90114267  113.97514247] 254.093333854\n",
      "positions (x,y,z), reward: [  16.55767537  -17.08852686  123.69771348] 229.416239748\n",
      "positions (x,y,z), reward: [  19.74460159  -28.3185724   131.8304975 ] 217.952013752\n",
      "positions (x,y,z), reward: [  21.19931861  -36.01385357  135.44585132] 214.052827646\n",
      "Episode =  413, score = 305.614 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -9.84069487e-04   9.70981489e-04   2.12897397e+01] 1.72941890387\n",
      "positions (x,y,z), reward: [ -2.14649499e-02   1.50354986e-01   3.19579730e+01] 15.3247175353\n",
      "positions (x,y,z), reward: [  0.51006451   2.24675611  61.49719564] 167.8313186\n",
      "positions (x,y,z), reward: [  0.81274287   3.29658849  68.99730975] 166.982857321\n",
      "positions (x,y,z), reward: [  0.99330209   3.86763308  72.50358787] 166.476284964\n",
      "positions (x,y,z), reward: [  1.75192107   5.94372037  83.22249787] 169.39340619\n",
      "positions (x,y,z), reward: [  2.35450232   7.35547182  89.33989447] 177.227843535\n",
      "positions (x,y,z), reward: [  17.69690476   27.6928462   156.95576653] 166.464620798\n",
      "Episode =  414, score = 302.188 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.87200094e-03  -1.17390642e-03   2.12904327e+01] 1.73232474553\n",
      "positions (x,y,z), reward: [  9.28849888e-03  -5.61398603e-03   2.29755881e+01] 6.20448484583\n",
      "positions (x,y,z), reward: [ -1.51602052e-02   4.24793118e-02   4.15636950e+01] 68.4802343613\n",
      "positions (x,y,z), reward: [ -0.06219538   0.06679156  43.70104927] 68.7544093385\n",
      "positions (x,y,z), reward: [ -0.70339113   0.31493021  58.0246368 ] 168.923944689\n",
      "positions (x,y,z), reward: [ -2.5866709    0.78658068  79.91344496] 166.738654312\n",
      "positions (x,y,z), reward: [ -4.70002138   0.65753787  97.94862044] 191.816811304\n",
      "positions (x,y,z), reward: [  -5.15424251    0.51293927  101.33970037] 292.584525007\n",
      "positions (x,y,z), reward: [  -6.92282456   -0.39038552  113.19501918] 273.047910686\n",
      "positions (x,y,z), reward: [  -9.78012993   -2.62683607  128.83939434] 257.24446812\n",
      "positions (x,y,z), reward: [ -13.78631411   -6.40389242  145.70406131] 248.507943504\n",
      "Episode =  415, score = 322.832 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.20223669e-02  -4.27216922e-02   2.63553590e+01] 11.2106254916\n",
      "positions (x,y,z), reward: [  0.37877561  -0.38054414  42.61878546] 67.8957603106\n",
      "positions (x,y,z), reward: [  1.27223907  -1.24747338  64.67070857] 167.516605007\n",
      "positions (x,y,z), reward: [  2.46125746  -2.27191841  80.47756396] 166.401817045\n",
      "positions (x,y,z), reward: [  3.13938921  -2.78807893  86.75503883] 174.864447531\n",
      "positions (x,y,z), reward: [  3.42335069  -2.99524688  89.05301383] 177.942680271\n",
      "positions (x,y,z), reward: [  4.50570747  -3.75303935  96.60106698] 187.941615607\n",
      "positions (x,y,z), reward: [   5.98444831   -4.73672021  104.91830676] 284.055504133\n",
      "positions (x,y,z), reward: [   6.10395808   -4.81415974  105.52228608] 283.027711608\n",
      "positions (x,y,z), reward: [   8.7625854    -6.45680552  117.34567195] 262.910322063\n",
      "positions (x,y,z), reward: [  14.55111528   -9.61773234  138.15694784] 255.913410233\n",
      "positions (x,y,z), reward: [  16.9261298   -10.82151866  146.11447462] 255.935810614\n",
      "positions (x,y,z), reward: [  19.49928313  -12.10117419  154.92912937] 207.150107496\n",
      "Episode =  416, score = 313.109 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.16633565e-06  -2.13120479e-06   2.01243240e+01] -4.89686139112\n",
      "positions (x,y,z), reward: [ -5.55751429e-05   1.97537513e-03   2.21781317e+01] 4.39898502241\n",
      "positions (x,y,z), reward: [  1.12023029e-03   6.11275548e-03   2.32684545e+01] 6.80877297116\n",
      "positions (x,y,z), reward: [  0.08572175   0.56836099  39.99528761] 67.6217673968\n",
      "positions (x,y,z), reward: [ -0.4922317    2.55486489  58.25933998] 167.674048257\n",
      "positions (x,y,z), reward: [ -1.76455356   4.51010138  69.36822695] 165.450813199\n",
      "positions (x,y,z), reward: [ -8.44642531  10.51021908  93.99794173] 175.972983445\n",
      "positions (x,y,z), reward: [ -9.45981403  11.20070764  96.56440623] 178.409588972\n",
      "positions (x,y,z), reward: [-10.53462856  11.89661437  99.1555065 ] 180.852614514\n",
      "positions (x,y,z), reward: [ -11.96342516   12.76966562  102.43394166] 276.635938749\n",
      "positions (x,y,z), reward: [ -12.26042166   12.94420525  103.09545971] 275.274869601\n",
      "positions (x,y,z), reward: [ -12.56113797   13.11860185  103.75906188] 273.910141391\n",
      "positions (x,y,z), reward: [ -45.83992835   22.94164081  178.15255643] 150.962761938\n",
      "positions (x,y,z), reward: [ -49.32461098   23.35426806  191.78664094] 163.245029259\n",
      "Episode =  417, score = 295.035 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.13978137e-02  -2.74169307e-02   2.63544324e+01] 11.2205654349\n",
      "positions (x,y,z), reward: [  0.17862046  -0.19099801  38.41551996] 67.468423345\n",
      "positions (x,y,z), reward: [  0.23357444  -0.24222318  41.0284612 ] 67.9212026292\n",
      "positions (x,y,z), reward: [  0.28422123  -0.28709425  43.15483943] 68.1787625353\n",
      "positions (x,y,z), reward: [  0.49331459  -0.45069893  50.21758429] 118.547696025\n",
      "positions (x,y,z), reward: [  1.46319177  -1.01807288  69.74619112] 167.631380107\n",
      "positions (x,y,z), reward: [  3.16722815  -1.68704341  88.91730313] 178.749595266\n",
      "positions (x,y,z), reward: [  3.23136488  -1.70651951  89.48186176] 179.512118631\n",
      "positions (x,y,z), reward: [  4.14557078  -1.9524385   96.81843126] 189.330759073\n",
      "positions (x,y,z), reward: [  4.2999063   -1.98848312  97.94644228] 190.827571279\n",
      "positions (x,y,z), reward: [   5.13003527   -2.15631862  103.5847323 ] 287.526212073\n",
      "positions (x,y,z), reward: [   5.67787711   -2.24313779  106.96908946] 281.837694181\n",
      "positions (x,y,z), reward: [  11.02286931   -2.22352056  131.18191012] 258.888234412\n",
      "positions (x,y,z), reward: [  11.37376013   -2.18044895  132.39229339] 258.800595028\n",
      "positions (x,y,z), reward: [  12.11186763   -2.07929587  134.8410426 ] 258.651465025\n",
      "positions (x,y,z), reward: [  13.52907882   -1.85266884  139.22953467] 258.47177942\n",
      "positions (x,y,z), reward: [  15.12134231   -1.56254675  143.77530281] 258.414797251\n",
      "Episode =  418, score = 321.729 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.37627457e-02   7.41692914e-03   2.45396300e+01] 8.94263511321\n",
      "positions (x,y,z), reward: [  1.93007920e-02   1.15971685e-02   2.52379037e+01] 9.90816766133\n",
      "positions (x,y,z), reward: [  0.46797899   0.34315701  39.97948038] 67.4009048699\n",
      "positions (x,y,z), reward: [  3.73935156   2.16199122  71.0676222 ] 164.704389865\n",
      "positions (x,y,z), reward: [  4.42809531   2.47157686  75.08374558] 163.862503064\n",
      "positions (x,y,z), reward: [  4.96492273   2.7035655   77.96587982] 163.20761532\n",
      "positions (x,y,z), reward: [  5.19045497   2.79893742  79.12197735] 162.9335824\n",
      "positions (x,y,z), reward: [  5.66044979   2.99412004  81.43989169] 164.52499384\n",
      "positions (x,y,z), reward: [  6.54535303   3.35005632  85.51564298] 169.580002167\n",
      "positions (x,y,z), reward: [  11.10325022    5.04228287  102.70077497] 281.910582557\n",
      "positions (x,y,z), reward: [  15.99733634    6.7952886   117.39638056] 254.286537665\n",
      "positions (x,y,z), reward: [  17.60563254    7.37536726  121.78791741] 248.586330724\n",
      "positions (x,y,z), reward: [  22.05391143    8.98867761  133.35292036] 245.684294931\n",
      "positions (x,y,z), reward: [  25.17799807   10.13288751  141.27220551] 245.165442961\n",
      "positions (x,y,z), reward: [  26.75647462   10.71635866  145.28480647] 244.862101623\n",
      "positions (x,y,z), reward: [  28.60135121   11.39919735  150.01047499] 194.533133792\n",
      "Episode =  419, score = 308.988 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  5.04566463e-04   1.37651978e-04   2.07698216e+01] -0.388317042409\n",
      "positions (x,y,z), reward: [  7.61685708e-02  -1.18541357e-02   3.05788134e+01] 14.642168687\n",
      "positions (x,y,z), reward: [  0.3198934   -0.33667409  48.02450652] 118.682769297\n",
      "positions (x,y,z), reward: [  0.40945037  -0.56450111  53.53544175] 168.760400336\n",
      "positions (x,y,z), reward: [  0.23554572  -3.91334107  88.3697428 ] 178.498533047\n",
      "positions (x,y,z), reward: [ -1.95332168e-02  -4.83541595e+00   9.45454477e+01] 187.014531386\n",
      "positions (x,y,z), reward: [ -0.24281988  -5.46652243  98.47210605] 192.038440241\n",
      "positions (x,y,z), reward: [  -0.48291867   -6.0354069   101.83689732] 290.759943861\n",
      "positions (x,y,z), reward: [  -0.62269582   -6.32979225  103.51899469] 287.798885509\n",
      "positions (x,y,z), reward: [  -2.25132781   -8.80857827  116.39103263] 264.23130501\n",
      "positions (x,y,z), reward: [  -3.67906638  -10.3650184   123.60979346] 255.587333727\n",
      "positions (x,y,z), reward: [  -4.06300827  -10.73694908  125.26589783] 254.765846712\n",
      "positions (x,y,z), reward: [  -4.74779672  -11.36590632  128.01724896] 253.340908551\n",
      "positions (x,y,z), reward: [  -6.28588108  -12.65458946  133.48916616] 250.325614891\n",
      "positions (x,y,z), reward: [ -10.50008353  -15.62989205  145.42892465] 242.895487581\n",
      "Episode =  420, score = 320.293 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.28281550e-04   5.52755290e-04   2.14915700e+01] 2.41735592315\n",
      "positions (x,y,z), reward: [ -0.17354364   0.15519343  37.38007306] 67.2400912293\n",
      "positions (x,y,z), reward: [ -2.45153048   2.41884302  77.1488455 ] 165.405387357\n",
      "positions (x,y,z), reward: [ -2.67630642   2.66142063  79.41077059] 164.93207835\n",
      "positions (x,y,z), reward: [ -4.2972652    4.4251022   92.94274374] 180.738372482\n",
      "positions (x,y,z), reward: [ -5.3047198    5.49986834  99.64560383] 188.461834689\n",
      "positions (x,y,z), reward: [  -6.33783163    6.58887351  105.73305274] 278.014737265\n",
      "positions (x,y,z), reward: [  -6.43637981    6.69244401  106.28369023] 276.96373066\n",
      "positions (x,y,z), reward: [  -7.88338191    8.213007    113.95132718] 262.252395575\n",
      "positions (x,y,z), reward: [ -12.00565879   12.45211125  133.71238413] 245.617351617\n",
      "positions (x,y,z), reward: [ -12.36606563   12.78463683  135.40379237] 245.136559292\n",
      "positions (x,y,z), reward: [ -14.66058247   14.46526233  146.47210852] 242.91956488\n",
      "Episode =  421, score = 315.615 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.57992935e-02  -1.67777941e-02   2.52362758e+01] 9.8956433268\n",
      "positions (x,y,z), reward: [  2.04629382e-02  -2.28599561e-02   2.59717518e+01] 10.792656094\n",
      "positions (x,y,z), reward: [  0.28176797  -0.35005432  39.97605982] 67.579470302\n",
      "positions (x,y,z), reward: [  0.31738868  -0.39271506  41.0289114 ] 67.7118524975\n",
      "positions (x,y,z), reward: [  3.14416794  -4.55950159  76.05456581] 162.352655347\n",
      "positions (x,y,z), reward: [  4.29249356  -6.49132373  83.86241614] 164.696372274\n",
      "positions (x,y,z), reward: [  5.2388904   -8.11099899  89.36697412] 170.046932308\n",
      "positions (x,y,z), reward: [  5.96883097  -9.3696919   93.17716608] 173.503197058\n",
      "positions (x,y,z), reward: [  6.87558343 -10.94088833  97.48178633] 177.123884688\n",
      "positions (x,y,z), reward: [  6.99452913 -11.14745928  98.01569879] 177.550710019\n",
      "positions (x,y,z), reward: [   9.50488586  -15.51289475  107.95830039] 260.655894489\n",
      "positions (x,y,z), reward: [  16.75075602  -28.03489078  127.6400775 ] 227.219451311\n",
      "positions (x,y,z), reward: [  20.81785573  -35.04986289  135.12837932] 221.554367647\n",
      "Episode =  422, score = 300.948 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.53361229e-03   1.38249824e-03   2.14930638e+01] 2.42520680264\n",
      "positions (x,y,z), reward: [ -5.55233378e-03   4.94845212e-03   2.26992793e+01] 5.62548290964\n",
      "positions (x,y,z), reward: [ -0.0684025    0.09911211  30.13002377] 14.2855463419\n",
      "positions (x,y,z), reward: [ -0.13064825   0.19804449  33.8876124 ] 16.0657594553\n",
      "positions (x,y,z), reward: [ -0.35202945   0.52119966  41.56575302] 67.6571684758\n",
      "positions (x,y,z), reward: [ -0.56717409   0.81503634  46.40995029] 117.856665558\n",
      "positions (x,y,z), reward: [ -0.624682     0.89121047  47.50204015] 117.843432069\n",
      "positions (x,y,z), reward: [ -1.91528475   2.45581848  63.68197104] 165.792510681\n",
      "positions (x,y,z), reward: [ -4.53811255   5.84103211  85.54230605] 167.931615476\n",
      "positions (x,y,z), reward: [ -5.83085195   7.98266907  96.29450998] 181.325547642\n",
      "positions (x,y,z), reward: [ -5.89658528   8.10342733  96.86911778] 182.057170337\n",
      "positions (x,y,z), reward: [  -6.41180936    9.09352055  101.51088529] 283.510686877\n",
      "positions (x,y,z), reward: [  -8.00213429   12.93130232  119.57911413] 255.756397702\n",
      "positions (x,y,z), reward: [  -6.86038819   18.86761591  154.40522599] 228.870483579\n",
      "positions (x,y,z), reward: [  -5.23596801   20.47846745  165.59173145] 145.214616974\n",
      "Episode =  423, score = 306.865 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.01196696e-05  -6.12937413e-05   2.03791582e+01] -2.61169393435\n",
      "positions (x,y,z), reward: [  1.51387723e-02  -3.29578400e-02   2.52364662e+01] 9.88145386949\n",
      "positions (x,y,z), reward: [  1.75523278e-02  -3.82527658e-02   2.55997035e+01] 10.3355222458\n",
      "positions (x,y,z), reward: [  0.12303925  -0.26313347  33.39335447] 15.7835479728\n",
      "positions (x,y,z), reward: [  0.57251809  -1.07679253  46.37887014] 117.493422764\n",
      "positions (x,y,z), reward: [  5.12609095  -6.27287924  88.49653581] 172.182178021\n",
      "positions (x,y,z), reward: [  5.45278459  -6.53261551  90.22976563] 174.290748246\n",
      "positions (x,y,z), reward: [  7.44520057  -7.95819271  99.5693815 ] 185.372074413\n",
      "positions (x,y,z), reward: [   9.68877424   -9.35951954  108.44525698] 270.000055616\n",
      "positions (x,y,z), reward: [  13.77522372  -11.67170701  122.17961135] 246.592911638\n",
      "positions (x,y,z), reward: [  15.59386348  -12.65853368  127.61318356] 244.091811735\n",
      "positions (x,y,z), reward: [  22.51806276  -16.58069951  145.76545894] 237.947662278\n",
      "Episode =  424, score = 307.640 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.00466162e-04   1.73625063e-04   2.04948558e+01] -1.85760155552\n",
      "positions (x,y,z), reward: [ -4.16768850e-03   6.44452986e-03   2.35699799e+01] 7.35882611383\n",
      "positions (x,y,z), reward: [ -0.05518053  -0.10500397  36.37061256] 67.1230949903\n",
      "positions (x,y,z), reward: [ -0.10544897  -1.11809642  56.8802485 ] 168.6555889\n",
      "positions (x,y,z), reward: [ -0.09592548  -1.56222234  61.91283285] 168.363616741\n",
      "positions (x,y,z), reward: [ -5.51367806e-02  -3.08914600e+00   7.42713665e+01] 166.95960363\n",
      "positions (x,y,z), reward: [  0.12937808  -8.90554243  99.35518528] 189.417370918\n",
      "positions (x,y,z), reward: [   0.15974044  -13.86135175  111.75657521] 266.734364013\n",
      "positions (x,y,z), reward: [   0.15156479  -14.37036437  112.8099523 ] 264.532029886\n",
      "positions (x,y,z), reward: [  8.48822705e-02  -1.68286128e+01   1.17484585e+02] 254.501723816\n",
      "positions (x,y,z), reward: [  1.00108253e-02  -1.86234835e+01   1.20533075e+02] 248.515083581\n",
      "positions (x,y,z), reward: [  -0.21917842  -22.5887644   126.43266482] 245.750423368\n",
      "positions (x,y,z), reward: [  -1.2812875   -35.02644704  140.10277096] 240.588398607\n",
      "Episode =  425, score = 315.236 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.08908868e-04   2.56501163e-04   2.06247919e+01] -1.12201322826\n",
      "positions (x,y,z), reward: [  5.16342866e-04   8.50699105e-04   2.11027452e+01] 1.03778700825\n",
      "positions (x,y,z), reward: [  1.12139293e-03   1.57655237e-03   2.14920660e+01] 2.41745768955\n",
      "positions (x,y,z), reward: [  0.19849522   0.10015022  34.36950492] 16.2861736663\n",
      "positions (x,y,z), reward: [  0.40921529   0.17078091  41.02349793] 67.8214444084\n",
      "positions (x,y,z), reward: [  0.89242965   0.2910236   52.41482692] 168.432069426\n",
      "positions (x,y,z), reward: [  1.06627237   0.3300351   55.73877894] 168.377829832\n",
      "positions (x,y,z), reward: [  1.15975835   0.35074886  57.40712102] 168.324770724\n",
      "positions (x,y,z), reward: [  1.43138359   0.40987501  61.87125983] 168.116608881\n",
      "positions (x,y,z), reward: [  2.35771704   0.59231514  74.20899009] 167.133400937\n",
      "positions (x,y,z), reward: [  3.09500917   0.70305448  82.0739728 ] 169.398216438\n",
      "positions (x,y,z), reward: [   6.03615672    0.65999036  105.10221317] 285.715658358\n",
      "positions (x,y,z), reward: [  8.40440974e+00   7.93972726e-02   1.18545029e+02] 263.618171975\n",
      "positions (x,y,z), reward: [  14.86257488   -2.82003057  146.11945989] 251.585030662\n",
      "Episode =  426, score = 323.012 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.70792060e-05   2.38760162e-04   2.11028622e+01] 1.04122189142\n",
      "positions (x,y,z), reward: [  7.22273171e-05   7.29760840e-04   2.26977935e+01] 5.62876339053\n",
      "positions (x,y,z), reward: [  1.74876834e-04   4.92476360e-04   2.38812014e+01] 7.91463541026\n",
      "positions (x,y,z), reward: [  2.67603541e-04  -7.25566299e-04   2.56002792e+01] 10.3984747911\n",
      "positions (x,y,z), reward: [ -2.61032160e-02   2.82265490e-02   3.63728778e+01] 67.233627898\n",
      "positions (x,y,z), reward: [ -3.35065289e-02   3.97592288e-02   3.73905717e+01] 67.5143339862\n",
      "positions (x,y,z), reward: [ -0.45677635   1.18850517  62.08729036] 168.855251432\n",
      "positions (x,y,z), reward: [ -0.76363093   2.4274467   74.12230187] 167.507795172\n",
      "positions (x,y,z), reward: [ -0.95231728   3.4105811   81.56373217] 168.496994207\n",
      "positions (x,y,z), reward: [ -1.17439933   5.02403472  91.77204827] 181.669413097\n",
      "positions (x,y,z), reward: [ -1.21341994   5.42200403  94.02682933] 184.56325349\n",
      "positions (x,y,z), reward: [ -1.23112495   5.6263167   95.15272473] 186.005864512\n",
      "positions (x,y,z), reward: [  -1.31932475    7.26752771  103.5705775 ] 286.056688044\n",
      "positions (x,y,z), reward: [  -1.15426164   11.15789449  120.95965387] 257.958804261\n",
      "positions (x,y,z), reward: [  -0.41027276   14.52400908  135.93545248] 256.496684461\n",
      "Episode =  427, score = 321.933 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.1327558   -0.05353405  37.90694935] 67.5329872183\n",
      "positions (x,y,z), reward: [  0.27995341  -0.50484498  50.79917066] 118.848110243\n",
      "positions (x,y,z), reward: [  0.3688486   -2.25958532  68.73456477] 167.547517807\n",
      "positions (x,y,z), reward: [  0.42707061  -3.5334966   76.61294872] 166.111296283\n",
      "positions (x,y,z), reward: [  0.4327712   -3.6356972   77.17426472] 165.990615503\n",
      "positions (x,y,z), reward: [  0.503542    -4.73318435  82.77171707] 168.828897827\n",
      "positions (x,y,z), reward: [  0.53032578  -5.08821376  84.44481168] 170.907984617\n",
      "positions (x,y,z), reward: [  0.58188027  -5.70561343  87.22699964] 174.335207888\n",
      "positions (x,y,z), reward: [  0.60522381  -5.96149353  88.33782375] 175.694517991\n",
      "positions (x,y,z), reward: [   1.19557367  -10.25992655  104.36263893] 281.535665692\n",
      "positions (x,y,z), reward: [   1.29003248  -10.77122102  106.01418547] 278.43158959\n",
      "positions (x,y,z), reward: [   4.16110142  -21.94348547  134.63399788] 243.907282914\n",
      "positions (x,y,z), reward: [   5.11721596  -25.01130647  140.81814188] 242.338918086\n",
      "positions (x,y,z), reward: [   5.37428519  -25.81227468  142.34089717] 241.922594748\n",
      "Episode =  428, score = 315.289 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  5.76057502e-03   8.66595077e-03   2.29758121e+01] 6.20381529736\n",
      "positions (x,y,z), reward: [  0.04118637   0.06251955  27.9550895 ] 12.7065697314\n",
      "positions (x,y,z), reward: [  0.13311396   0.14267326  32.90716894] 15.6759700722\n",
      "positions (x,y,z), reward: [  0.17483853   0.16760531  34.36353304] 16.2270998537\n",
      "positions (x,y,z), reward: [  0.24444361   0.20118378  36.35855808] 66.8263750579\n",
      "positions (x,y,z), reward: [  0.26455651   0.20947747  36.86571968] 66.9544199446\n",
      "positions (x,y,z), reward: [  0.6407904    0.2986797   43.69923863] 68.0593293726\n",
      "positions (x,y,z), reward: [  0.80510976   0.31372709  45.87532178] 118.256404032\n",
      "positions (x,y,z), reward: [  0.89691244   0.31806927  46.97446965] 118.340978525\n",
      "positions (x,y,z), reward: [  1.33435776   0.30859556  51.44263514] 118.626295871\n",
      "positions (x,y,z), reward: [  3.49890608  -0.1068473   65.62613092] 169.467254479\n",
      "positions (x,y,z), reward: [ 12.12594154  -3.03548407  95.97580996] 194.506276763\n",
      "positions (x,y,z), reward: [  24.54154734   -9.89755354  142.24294222] 311.020825244\n",
      "positions (x,y,z), reward: [  28.9463361  -17.3390376  193.019925 ] 312.594840668\n",
      "Episode =  429, score = 361.227 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  5.38607275e-04  -1.81233987e-04   2.06255607e+01] -1.11238299617\n",
      "positions (x,y,z), reward: [  6.22331244e-02  -1.33403161e-03   2.59760152e+01] 10.7739166569\n",
      "positions (x,y,z), reward: [  0.48102039  -0.10208007  41.55072468] 67.8948326661\n",
      "positions (x,y,z), reward: [  0.60410792  -0.16483403  45.29788999] 118.249554808\n",
      "positions (x,y,z), reward: [  0.62227862  -0.17527383  45.8388964 ] 118.282769306\n",
      "positions (x,y,z), reward: [  0.73380434  -0.24686823  49.10833872] 118.411215258\n",
      "positions (x,y,z), reward: [  1.69822435  -1.96103163  75.98388841] 166.638803113\n",
      "positions (x,y,z), reward: [  1.86922574  -2.65405751  81.07967289] 167.404305671\n",
      "positions (x,y,z), reward: [  2.07952967  -3.93490597  88.43095404] 176.852733363\n",
      "positions (x,y,z), reward: [  2.19255857  -5.99068566  97.43950734] 188.052268004\n",
      "positions (x,y,z), reward: [   2.137454     -7.0711526   101.36829416] 288.76564536\n",
      "positions (x,y,z), reward: [   1.90605273   -8.63968369  106.40799093] 279.775559523\n",
      "positions (x,y,z), reward: [   1.49505869  -10.21443078  110.86648148] 271.742755575\n",
      "positions (x,y,z), reward: [  -0.83711967  -15.20354177  122.3019482 ] 252.394654851\n",
      "positions (x,y,z), reward: [  -7.90828831  -23.97517903  136.4809171 ] 235.984359717\n",
      "Episode =  430, score = 314.978 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -6.09307740e-03  -3.26510198e-02   2.48808029e+01] 9.3994669706\n",
      "positions (x,y,z), reward: [ -1.02973550e-02  -6.09003582e-02   2.63502363e+01] 11.1801358272\n",
      "positions (x,y,z), reward: [ -0.0508305   -0.29082974  32.43000955] 15.3834941071\n",
      "positions (x,y,z), reward: [ -0.42937427  -1.62968401  47.4557065 ] 117.174137176\n",
      "positions (x,y,z), reward: [ -4.17747458  -9.33096557  84.34719233] 162.093761946\n",
      "positions (x,y,z), reward: [ -5.19894952 -10.93491371  89.74025821] 167.322275142\n",
      "positions (x,y,z), reward: [  -8.86961311  -15.87763435  104.60996488] 266.611719596\n",
      "positions (x,y,z), reward: [ -10.47861541  -17.79243101  109.84335012] 255.022656508\n",
      "positions (x,y,z), reward: [ -10.98974107  -18.38255132  111.40496339] 251.514862901\n",
      "positions (x,y,z), reward: [ -14.31715427  -22.08519545  120.69620748] 233.316938008\n",
      "positions (x,y,z), reward: [ -15.11591892  -22.94824407  122.74432616] 232.453642512\n",
      "positions (x,y,z), reward: [ -15.31896279  -23.16645437  123.25556675] 232.235167976\n",
      "Episode =  431, score = 298.789 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  7.20189595e-05  -2.54781113e-04   2.06256072e+01] -1.10981345532\n",
      "positions (x,y,z), reward: [ -0.27354843  -0.47438474  37.91002997] 66.9736594115\n",
      "positions (x,y,z), reward: [ -0.63648626  -1.0168599   44.78822038] 117.384013175\n",
      "positions (x,y,z), reward: [ -1.69047542  -2.55810097  56.35678058] 165.578271137\n",
      "positions (x,y,z), reward: [ -4.17129407  -6.27802992  72.43127966] 158.935648601\n",
      "positions (x,y,z), reward: [ -4.39134736  -6.60863341  73.5253485 ] 158.310217656\n",
      "positions (x,y,z), reward: [ -5.86519717  -8.80736938  80.01744981] 154.102092624\n",
      "positions (x,y,z), reward: [ -13.93105374  -20.13615258  102.01908483] 257.789699829\n",
      "positions (x,y,z), reward: [ -16.16001097  -23.02999257  106.0134159 ] 248.430159906\n",
      "positions (x,y,z), reward: [ -19.18799012  -26.76447032  110.60613794] 237.015505847\n",
      "positions (x,y,z), reward: [ -23.90482969  -32.1161103   116.31306435] 225.413784914\n",
      "Episode =  432, score = 287.444 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.22290896e-02   6.88348016e-01   3.84102689e+01] 67.1184937075\n",
      "positions (x,y,z), reward: [ -0.08660866   1.0161075   42.61424701] 67.5605222347\n",
      "positions (x,y,z), reward: [ -0.43539378   2.18145325  54.07650394] 167.090696719\n",
      "positions (x,y,z), reward: [ -1.02220176   3.6861582   65.21224727] 165.17845755\n",
      "positions (x,y,z), reward: [ -1.62640035   5.0505375   73.56892623] 163.131011158\n",
      "positions (x,y,z), reward: [ -2.93303587   7.76329932  87.40648324] 169.933965876\n",
      "positions (x,y,z), reward: [ -2.99171946   7.88351838  87.95676653] 170.567467646\n",
      "positions (x,y,z), reward: [ -3.79286416   9.53161546  95.08570045] 178.629454666\n",
      "positions (x,y,z), reward: [  -6.57837277   15.5386764   116.15701223] 252.306752433\n",
      "positions (x,y,z), reward: [  -7.21907522   16.99931627  120.4083373 ] 244.259008415\n",
      "positions (x,y,z), reward: [  -9.03458204   21.24003412  131.41219068] 238.865486921\n",
      "Episode =  433, score = 307.984 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -3.27849500e-03   5.52865561e-04   2.19359488e+01] 3.74668651836\n",
      "positions (x,y,z), reward: [ -4.36870423e-03   6.50664275e-04   2.21773833e+01] 4.38719857225\n",
      "positions (x,y,z), reward: [ -0.09049093   0.03026144  28.37751581] 13.051248763\n",
      "positions (x,y,z), reward: [ -0.61373846   0.37921792  40.49653999] 67.3187692157\n",
      "positions (x,y,z), reward: [ -0.91720019   0.61266057  44.76861867] 117.50804757\n",
      "positions (x,y,z), reward: [ -1.50434083   1.1050246   51.35962974] 117.22493071\n",
      "positions (x,y,z), reward: [ -1.79653204   1.36818788  54.15973458] 166.979021288\n",
      "positions (x,y,z), reward: [ -4.19520549   4.02739726  71.96446682] 165.768828672\n",
      "positions (x,y,z), reward: [ -4.50468383   4.4493289   73.90722235] 165.762916783\n",
      "positions (x,y,z), reward: [ -4.82848318   4.91412569  75.89607753] 165.785405083\n",
      "positions (x,y,z), reward: [ -5.28334998   5.60962948  78.62885731] 165.862602734\n",
      "positions (x,y,z), reward: [ -14.63630632   33.56170849  135.32805002] 310.131193403\n",
      "positions (x,y,z), reward: [ -20.73827245  150.          269.58925062] 1853.41880831\n",
      "Episode =  434, score = 366.565 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -8.96520318e-06  -7.12806575e-05   2.04944837e+01] -1.86326114165\n",
      "positions (x,y,z), reward: [ -6.20732190e-03  -1.19305269e-02   2.38789190e+01] 7.88347986664\n",
      "positions (x,y,z), reward: [ -0.04398272  -0.04612054  27.54126643] 12.3605481134\n",
      "positions (x,y,z), reward: [ -7.203892    -1.93818634  72.46976648] 160.115524816\n",
      "positions (x,y,z), reward: [ -8.97725319  -2.20286325  76.24673007] 157.463900575\n",
      "positions (x,y,z), reward: [-12.32819253  -2.62614432  81.96768779] 155.266221177\n",
      "positions (x,y,z), reward: [-12.66691922  -2.66491162  82.47172525] 155.496307149\n",
      "positions (x,y,z), reward: [ -37.34945358   -4.67728167  102.88888939] 255.500936581\n",
      "Episode =  435, score = 283.375 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.13329429  -0.18708253  42.62041384] 67.3884492389\n",
      "positions (x,y,z), reward: [  1.71983     -0.44016516  48.03923547] 117.251274943\n",
      "positions (x,y,z), reward: [  3.16161203  -1.4597205   58.60095957] 165.410683029\n",
      "positions (x,y,z), reward: [  6.34639192  -5.36828598  75.32917224] 157.639163114\n",
      "positions (x,y,z), reward: [ 10.8130529  -12.80527949  91.54142621] 160.393139665\n",
      "positions (x,y,z), reward: [  30.95948577  -54.81092708  125.89320777] 209.599480184\n",
      "Episode =  436, score = 286.913 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.57768240e-02  -8.55468865e-03   2.79631915e+01] 12.8025097717\n",
      "positions (x,y,z), reward: [  1.45013947e-01   6.59413575e-03   4.05054903e+01] 68.1515166937\n",
      "positions (x,y,z), reward: [  1.76803370e-01   6.53951471e-03   4.26252614e+01] 68.4942960197\n",
      "positions (x,y,z), reward: [  1.85311427e-01   6.14413110e-03   4.31596402e+01] 68.5678467337\n",
      "positions (x,y,z), reward: [  1.04375427  -1.05832572  77.1598254 ] 168.304342374\n",
      "positions (x,y,z), reward: [  1.83578187  -5.15807251  99.31580521] 192.054601955\n",
      "positions (x,y,z), reward: [   4.0403404   -19.51363093  127.8070217 ] 242.668693395\n",
      "positions (x,y,z), reward: [   4.65280544  -22.89730361  132.09974331] 240.818788646\n",
      "positions (x,y,z), reward: [   5.02438438  -24.89000216  134.42676048] 240.038178091\n",
      "positions (x,y,z), reward: [   5.91534286  -29.56156104  139.40303715] 238.256867722\n",
      "Episode =  437, score = 316.558 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.19829184e-05  -4.24094325e-04   2.09281916e+01] 0.322582342388\n",
      "positions (x,y,z), reward: [  2.01888369e-04  -7.29461257e-04   2.12893685e+01] 1.72881134949\n",
      "positions (x,y,z), reward: [  3.05239551e-02   2.25272383e-02   2.87989882e+01] 13.4525500395\n",
      "positions (x,y,z), reward: [  0.05160369   0.05790572  31.95626595] 15.3837289946\n",
      "positions (x,y,z), reward: [  0.23429527   0.83595429  50.80085831] 118.704755376\n",
      "positions (x,y,z), reward: [  0.25224795   3.49878102  74.14694265] 167.141096717\n",
      "positions (x,y,z), reward: [ -0.65995978   7.74461966  95.60666199] 185.932443741\n",
      "positions (x,y,z), reward: [ -0.87840159   8.45861463  98.4945868 ] 189.231299025\n",
      "positions (x,y,z), reward: [  -1.74353191   10.96292247  107.64684054] 276.150206614\n",
      "positions (x,y,z), reward: [  -3.55097062   15.34439816  120.97580232] 250.266236963\n",
      "positions (x,y,z), reward: [  -4.3947994    17.18578385  125.82148907] 247.096096602\n",
      "positions (x,y,z), reward: [  -6.95097179   22.40921077  137.79962721] 240.442459272\n",
      "positions (x,y,z), reward: [  -7.07427071   22.65360754  138.30693791] 240.26312622\n",
      "Episode =  438, score = 316.572 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.35836702e-06   5.77482583e-06   2.01242205e+01] -4.89959986\n",
      "positions (x,y,z), reward: [ -0.07320516   2.09247297  63.70814439] 168.347770811\n",
      "positions (x,y,z), reward: [  -6.43503467    8.34719635  100.22259472] 284.392094488\n",
      "positions (x,y,z), reward: [ -15.97935362   13.46882677  118.88378121] 238.175021949\n",
      "positions (x,y,z), reward: [ -26.76199801   17.81883761  131.20750583] 224.14078658\n",
      "positions (x,y,z), reward: [ -33.01921721   20.04572055  136.49874712] 219.829514323\n",
      "Episode =  439, score = 305.526 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.09918926   0.13254711  30.12268011] 14.2121486324\n",
      "positions (x,y,z), reward: [  0.12969442   0.17556419  31.49422163] 14.9505160774\n",
      "positions (x,y,z), reward: [  1.41506249   1.73426441  55.77428737] 166.800721398\n",
      "positions (x,y,z), reward: [  2.57595127   3.05252887  67.05675595] 164.786616228\n",
      "positions (x,y,z), reward: [  3.83239388   4.45644896  76.18773128] 162.326516383\n",
      "positions (x,y,z), reward: [  4.10323348   4.75632271  77.90509557] 161.766907575\n",
      "positions (x,y,z), reward: [  4.98449673   5.72528272  83.05675125] 164.468750855\n",
      "positions (x,y,z), reward: [  11.12016093   12.23204775  108.89420568] 262.755663152\n",
      "positions (x,y,z), reward: [  13.9453196    15.04112266  117.61822319] 243.669996182\n",
      "Episode =  440, score = 304.961 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  6.49503536e-02   2.63467765e-01   6.94176772e+01] 170.516492155\n",
      "positions (x,y,z), reward: [ -0.17617508   0.38760611  72.31319419] 170.484730442\n",
      "positions (x,y,z), reward: [ -1.818538     1.14864407  84.11575542] 175.186868066\n",
      "positions (x,y,z), reward: [ -2.29750033   1.35457166  86.52359883] 178.331059862\n",
      "positions (x,y,z), reward: [  -6.85136171    3.07873139  102.65961326] 290.046489832\n",
      "positions (x,y,z), reward: [  -7.31071147    3.23177725  103.94200083] 287.685743974\n",
      "positions (x,y,z), reward: [  -9.04364173    3.77756004  108.48929333] 279.273717584\n",
      "positions (x,y,z), reward: [ -10.39872377    4.17081783  111.80089634] 273.13706495\n",
      "positions (x,y,z), reward: [ -12.14961611    4.63726165  115.85811512] 265.654015454\n",
      "positions (x,y,z), reward: [ -26.66577876    6.35958134  146.73178664] 260.303621898\n",
      "positions (x,y,z), reward: [ -28.72308907    6.15713684  151.30835587] 212.763305212\n",
      "positions (x,y,z), reward: [ -29.97266011    5.95328941  154.16888373] 214.496728499\n",
      "Episode =  441, score = 309.445 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.17340276e-03   1.16711533e-03   2.12909614e+01] 1.73640690697\n",
      "positions (x,y,z), reward: [  0.12165688  -0.08020969  36.36997955] 67.0758899354\n",
      "positions (x,y,z), reward: [  0.22404712  -0.2798508   44.76576392] 118.455380342\n",
      "positions (x,y,z), reward: [  0.25668724  -0.33976672  46.93253475] 118.603104243\n",
      "positions (x,y,z), reward: [  0.35429054  -0.49314417  52.41830419] 168.772303795\n",
      "positions (x,y,z), reward: [  0.37695352  -0.52345406  53.52437425] 168.780632498\n",
      "positions (x,y,z), reward: [  0.6601573   -0.78390583  64.12624875] 168.633863738\n",
      "positions (x,y,z), reward: [  0.75871255  -0.83864468  66.93837961] 168.562923563\n",
      "positions (x,y,z), reward: [  0.91680285  -0.90012965  70.88919045] 168.459305819\n",
      "positions (x,y,z), reward: [  1.15867853  -0.94604992  75.99500252] 168.349802805\n",
      "positions (x,y,z), reward: [  1.66848547  -0.91306404  84.58681048] 175.132447844\n",
      "positions (x,y,z), reward: [  3.54537695e+00  -7.34237141e-02   1.05834724e+02] 290.038150921\n",
      "positions (x,y,z), reward: [   4.57050193    0.60941495  114.48621016] 276.510792329\n",
      "positions (x,y,z), reward: [   5.31354047    1.16061315  120.21639451] 267.805296514\n",
      "positions (x,y,z), reward: [   7.73863111    3.3036421   137.99664069] 267.645588926\n",
      "positions (x,y,z), reward: [   9.50771561    5.27706755  152.15003053] 219.539563757\n",
      "positions (x,y,z), reward: [   9.70187241    5.50655544  153.85845338] 219.890114092\n",
      "Episode =  442, score = 322.206 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -3.20006632e-05   1.73711682e-05   2.01937876e+01] -4.13355283754\n",
      "positions (x,y,z), reward: [ -1.30992713e-02   3.07223924e-03   2.29730687e+01] 6.19570787525\n",
      "positions (x,y,z), reward: [ -0.43837698   0.29831079  39.43513185] 67.3268527464\n",
      "positions (x,y,z), reward: [ -0.46166671   0.31573521  39.95753818] 67.3980621396\n",
      "positions (x,y,z), reward: [ -0.76705338   0.54504227  45.82608307] 117.773363227\n",
      "positions (x,y,z), reward: [ -0.7993035    0.56945433  46.36841286] 117.77589628\n",
      "positions (x,y,z), reward: [ -1.04640316   0.758328    50.19411801] 117.681401629\n",
      "positions (x,y,z), reward: [ -2.09780973   1.5878681   62.43743644] 166.3850652\n",
      "positions (x,y,z), reward: [ -2.27936477   1.73215126  64.12298518] 166.100178949\n",
      "positions (x,y,z), reward: [ -3.02846504   2.32877275  70.31582037] 164.804023376\n",
      "positions (x,y,z), reward: [ -3.97873182   3.09913576  77.06526099] 162.979392626\n",
      "positions (x,y,z), reward: [ -4.32210258   3.38250703  79.30738005] 162.28610501\n",
      "positions (x,y,z), reward: [ -15.86764761   13.88013249  140.18657478] 243.754504101\n",
      "positions (x,y,z), reward: [ -17.51632323   15.51341853  148.60240541] 192.252421827\n",
      "Episode =  443, score = 310.665 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.           0.          20.00778482] -7.22151889118\n",
      "positions (x,y,z), reward: [  1.21438938e-05  -3.63883479e-06   2.01941527e+01] -4.127123882\n",
      "positions (x,y,z), reward: [  1.85504604e-04  -1.09889431e-04   2.07700959e+01] -0.386724277308\n",
      "positions (x,y,z), reward: [  2.97391590e-03   2.35114669e-02   2.59721368e+01] 10.8089900181\n",
      "positions (x,y,z), reward: [  2.42660303e-02   5.05973084e-01   3.84148129e+01] 67.3389650434\n",
      "positions (x,y,z), reward: [  2.09452251e-02   1.12661290e+00   4.58714978e+01] 118.096904069\n",
      "positions (x,y,z), reward: [ -7.25659223e-02   5.31399807e+00   7.28490877e+01] 164.874690752\n",
      "positions (x,y,z), reward: [ -0.09512647   6.29900876  77.35761231] 163.694189751\n",
      "positions (x,y,z), reward: [ -0.12742553   7.49779421  82.39352102] 165.826995746\n",
      "positions (x,y,z), reward: [ -0.29200669  11.01551048  95.08179978] 180.632671332\n",
      "positions (x,y,z), reward: [  -0.49267852   13.5159778   102.68753987] 280.965742272\n",
      "positions (x,y,z), reward: [  -0.96052646   17.43109204  112.8702196 ] 260.88212772\n",
      "positions (x,y,z), reward: [  -0.99350325   17.65597795  113.40170593] 259.804817346\n",
      "positions (x,y,z), reward: [  -1.34142765   19.77387363  118.16514908] 249.994254135\n",
      "positions (x,y,z), reward: [  -1.48072984   20.51888016  119.74475554] 247.188564327\n",
      "positions (x,y,z), reward: [  -1.58079873   21.02672834  120.79534754] 246.654634297\n",
      "Episode =  444, score = 312.242 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -6.33403042e-03   5.17511909e-03   2.38793572e+01] 7.89531461135\n",
      "positions (x,y,z), reward: [ -2.76798187e-02   3.89836236e-02   2.79553979e+01] 12.7570262425\n",
      "positions (x,y,z), reward: [ -0.12025997   0.1961487   34.86222638] 16.4572725811\n",
      "positions (x,y,z), reward: [ -0.31032849   0.48417077  41.55829055] 67.7518606706\n",
      "positions (x,y,z), reward: [ -2.67356574   3.26767419  68.04093899] 165.802566903\n",
      "positions (x,y,z), reward: [ -4.8931347    5.65223545  80.36376887] 164.015335082\n",
      "positions (x,y,z), reward: [ -8.02958029   8.71395773  93.112101  ] 180.24189417\n",
      "positions (x,y,z), reward: [ -8.42869857   9.07618347  94.53418909] 182.067093541\n",
      "positions (x,y,z), reward: [ -10.88710496   11.17335787  102.72119474] 284.666986593\n",
      "positions (x,y,z), reward: [ -12.69753113   12.57649804  108.33117536] 275.654612907\n",
      "positions (x,y,z), reward: [ -17.94103319   16.05811461  123.97353833] 259.790531234\n",
      "positions (x,y,z), reward: [ -22.78274557   18.59186654  139.26612301] 271.006832614\n",
      "positions (x,y,z), reward: [ -24.84144718   19.48009667  146.50074478] 280.103582564\n",
      "positions (x,y,z), reward: [ -33.23832648   22.12169442  187.62626805] 211.467040375\n",
      "Episode =  445, score = 337.271 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.34171890e-02  -4.35523565e-03   2.42020910e+01] 8.40673008257\n",
      "positions (x,y,z), reward: [ -1.10277332e-01  -2.66824733e-02   2.83742021e+01] 13.0334116602\n",
      "positions (x,y,z), reward: [ -0.59396829  -0.1920096   39.43887999] 67.2683039165\n",
      "positions (x,y,z), reward: [ -1.20587401  -0.41015702  48.54594236] 117.707515396\n",
      "positions (x,y,z), reward: [ -1.24854381  -0.42475117  49.09286777] 117.693729206\n",
      "positions (x,y,z), reward: [ -1.33619757  -0.45431269  50.18921662] 117.656669702\n",
      "positions (x,y,z), reward: [ -1.76998559  -0.59062169  55.1556297 ] 167.34771349\n",
      "positions (x,y,z), reward: [ -4.75109157  -0.97947238  78.7012881 ] 164.554310602\n",
      "positions (x,y,z), reward: [ -11.23369754   -0.17563147  108.01966616] 276.287802846\n",
      "positions (x,y,z), reward: [ -1.23727080e+01   4.83239799e-02   1.11885363e+02] 269.240173819\n",
      "positions (x,y,z), reward: [ -14.67617344    0.52240019  118.97166079] 255.352966597\n",
      "positions (x,y,z), reward: [ -16.63334933    0.92102912  124.33814425] 251.091792166\n",
      "positions (x,y,z), reward: [ -25.65271192    2.10003847  143.60788847] 245.251077809\n",
      "Episode =  446, score = 316.603 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.60134741e-08   2.30050860e-09   2.00310891e+01] -6.44586746915\n",
      "positions (x,y,z), reward: [ -8.62818847e-03   6.21320278e-02   3.53638589e+01] 16.8859176035\n",
      "positions (x,y,z), reward: [  0.53780626   0.61245473  56.37894928] 169.000350203\n",
      "positions (x,y,z), reward: [  1.2990677    1.32429741  67.29033026] 168.743384006\n",
      "positions (x,y,z), reward: [  4.78073017   4.29171539  89.23179247] 180.699924977\n",
      "positions (x,y,z), reward: [   9.94735961    7.66561841  105.35092019] 286.24409637\n",
      "positions (x,y,z), reward: [  12.02840855    8.74392666  110.28617767] 278.179378035\n",
      "positions (x,y,z), reward: [  15.32243729   10.20944765  117.40687243] 267.157215858\n",
      "positions (x,y,z), reward: [  25.56005705   13.49801827  138.47753927] 275.838761177\n",
      "positions (x,y,z), reward: [  30.16705932   14.58902254  148.89991671] 240.061160394\n",
      "positions (x,y,z), reward: [  48.17587053   19.63174121  222.99051846] 405.791082788\n",
      "positions (x,y,z), reward: [  51.59025693   23.46451166  267.03813908] 861.608103338\n",
      "Episode =  447, score = 345.149 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.07566521e-05  -6.11368876e-06   2.02792469e+01] -3.36245100941\n",
      "positions (x,y,z), reward: [  9.81664183e-05  -1.74646585e-05   2.03795679e+01] -2.60591768598\n",
      "positions (x,y,z), reward: [  7.95956938e-02  -1.45715854e-02   2.59736666e+01] 10.7405143551\n",
      "positions (x,y,z), reward: [  0.26309706  -0.05655957  31.03449738] 14.6711356915\n",
      "positions (x,y,z), reward: [  1.71649341  -0.70554609  50.21249214] 117.078129076\n",
      "positions (x,y,z), reward: [  3.17624733  -1.52567269  61.88150207] 165.257534566\n",
      "positions (x,y,z), reward: [  5.89944795  -3.295404    77.53820336] 160.645003559\n",
      "positions (x,y,z), reward: [  7.21789767  -4.2647086   83.63855284] 163.575070807\n",
      "positions (x,y,z), reward: [  8.80137472  -5.52188359  90.22394858] 170.282349153\n",
      "positions (x,y,z), reward: [  9.21823686  -5.87092223  91.85775403] 171.883971163\n",
      "positions (x,y,z), reward: [  16.44874494  -13.47887966  116.81929396] 242.674361432\n",
      "positions (x,y,z), reward: [  19.93808816  -18.36383595  127.46968384] 228.509501946\n",
      "Episode =  448, score = 300.761 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.08303234e-04   3.76181404e-03   2.21769126e+01] 4.38647655877\n",
      "positions (x,y,z), reward: [ -4.29042506e-02   2.19581856e-02   2.92375572e+01] 13.768142976\n",
      "positions (x,y,z), reward: [ -1.19760387  -1.494403    56.40046329] 167.365261333\n",
      "positions (x,y,z), reward: [ -2.20946042  -4.04906737  68.21913428] 163.752773471\n",
      "positions (x,y,z), reward: [ -2.91891793  -6.16387139  74.32972179] 160.368306682\n",
      "positions (x,y,z), reward: [ -3.81055607  -8.88317187  80.27190055] 156.181559631\n",
      "positions (x,y,z), reward: [ -4.95275997 -12.23365579  85.94749801] 158.752639393\n",
      "positions (x,y,z), reward: [ -17.41156186  -38.81560716  107.54528855] 234.276725556\n",
      "positions (x,y,z), reward: [ -17.74097377  -39.35539153  107.76289765] 233.34621192\n",
      "positions (x,y,z), reward: [ -22.79746603  -46.95945757  110.24264536] 223.630855523\n",
      "positions (x,y,z), reward: [ -30.08003803  -56.04469305  111.91382903] 217.048849645\n",
      "Episode =  449, score = 284.638 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  5.70175455e-03  -1.85280266e-01   3.15023912e+01] 15.0712739733\n",
      "positions (x,y,z), reward: [ -2.70300099e-02  -8.63419851e-01   4.36982699e+01] 67.9730693915\n",
      "positions (x,y,z), reward: [ -0.14180882  -1.59279758  50.79493992] 117.901640871\n",
      "positions (x,y,z), reward: [ -0.7515346   -3.4202704   61.98769124] 166.025410385\n",
      "positions (x,y,z), reward: [ -28.48326976  -23.12355871  106.40222226] 235.731381482\n",
      "positions (x,y,z), reward: [ -32.5826409   -24.495006    108.11301098] 230.900130361\n",
      "positions (x,y,z), reward: [ -34.40143051  -25.04620834  108.74789269] 228.948614406\n",
      "Episode =  450, score = 279.632 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.75741159   1.15299775  49.68022996] 117.675916618\n",
      "positions (x,y,z), reward: [ -1.23786352   1.70240367  55.80682053] 167.132698801\n",
      "positions (x,y,z), reward: [ -4.2429222    4.43101306  75.76679364] 162.126162005\n",
      "positions (x,y,z), reward: [ -5.03544175   5.0586291   79.22746051] 160.772454366\n",
      "positions (x,y,z), reward: [ -8.5246906    7.62023048  91.37785991] 171.869242926\n",
      "positions (x,y,z), reward: [ -9.71920483   8.44793593  94.850161  ] 175.024555773\n",
      "positions (x,y,z), reward: [ -15.75557027   12.42318404  109.78510719] 257.623559103\n",
      "positions (x,y,z), reward: [ -25.99908809   18.9733333   130.25084299] 231.724085498\n",
      "Episode =  451, score = 302.552 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.30715318e-06   1.36239567e-07   2.00699441e+01] -5.67033345541\n",
      "positions (x,y,z), reward: [ -6.52409110e-06   8.05693073e-07   2.01242575e+01] -4.89836325023\n",
      "positions (x,y,z), reward: [ -2.69549177e-03  -1.09844491e-03   2.17076148e+01] 3.09329447362\n",
      "positions (x,y,z), reward: [ -0.06954824  -0.14869645  31.96660173] 15.2957394877\n",
      "positions (x,y,z), reward: [ -0.24072946  -0.56969977  43.15324578] 67.9345186877\n",
      "positions (x,y,z), reward: [ -0.32706875  -0.80532461  47.47616727] 118.121789805\n",
      "positions (x,y,z), reward: [ -0.63186961  -1.90484313  61.31893424] 167.41919084\n",
      "positions (x,y,z), reward: [ -0.7448381   -2.48258592  66.36178101] 166.83430404\n",
      "positions (x,y,z), reward: [ -0.83915156  -3.11470772  70.85868166] 166.178294678\n",
      "positions (x,y,z), reward: [ -0.8612475   -3.29384943  71.98458898] 165.990732336\n",
      "positions (x,y,z), reward: [ -0.91293905  -3.78477589  74.80141918] 165.472555845\n",
      "positions (x,y,z), reward: [  -0.9421      -14.04526475  102.25667397] 279.088523182\n",
      "positions (x,y,z), reward: [  -0.58443663  -23.55681882  113.49663585] 252.167622208\n",
      "positions (x,y,z), reward: [   1.72075049  -52.35245491  127.4879932 ] 226.056625585\n",
      "Episode =  452, score = 307.564 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.92434833e-05  -4.13028287e-05   2.02789477e+01] -3.36853142288\n",
      "positions (x,y,z), reward: [  5.98093350e-04  -1.30638929e-03   2.11023608e+01] 1.03539166846\n",
      "positions (x,y,z), reward: [  4.97813753e-03  -9.88296253e-03   2.26966948e+01] 5.6097486214\n",
      "positions (x,y,z), reward: [  0.75336626  -0.74716237  45.83873062] 117.631770605\n",
      "positions (x,y,z), reward: [  7.19198095 -10.58556656  88.19396711] 162.860117325\n",
      "positions (x,y,z), reward: [  21.0642007   -34.67144916  110.83635162] 227.23515137\n",
      "positions (x,y,z), reward: [  33.19354727  -54.04051164  114.98693068] 210.167015481\n",
      "Episode =  453, score = 285.073 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.05553953  -0.07519318  27.96371312] 12.7104646758\n",
      "positions (x,y,z), reward: [ -0.12358356  -0.14386507  31.04153211] 14.7472499773\n",
      "positions (x,y,z), reward: [ -0.17986143  -0.19435995  32.9224907 ] 15.6024520338\n",
      "positions (x,y,z), reward: [ -0.27006527  -0.27010845  35.3707283 ] 16.4069538662\n",
      "positions (x,y,z), reward: [ -0.75233656  -0.64737922  44.22954642] 117.479332133\n",
      "positions (x,y,z), reward: [ -2.10737642  -1.74895348  60.16268879] 165.920193365\n",
      "positions (x,y,z), reward: [ -2.82235997  -2.36206511  66.83602001] 164.637145374\n",
      "positions (x,y,z), reward: [ -5.13036023  -4.40382174  84.61609532] 167.099300471\n",
      "positions (x,y,z), reward: [ -5.29065576  -4.55065428  85.72438239] 168.447542211\n",
      "positions (x,y,z), reward: [ -6.19422588  -5.39788952  91.81719   ] 175.825933821\n",
      "positions (x,y,z), reward: [ -12.17484246  -12.21912252  128.94497441] 245.071154252\n",
      "positions (x,y,z), reward: [ -14.95915572  -16.12981695  144.23899534] 238.108804253\n",
      "Episode =  454, score = 310.947 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -8.30541347e-05   5.53214297e-05   2.03795539e+01] -2.60553175761\n",
      "positions (x,y,z), reward: [ -3.39161183e-03   1.19812119e-03   2.17090873e+01] 3.100147635\n",
      "positions (x,y,z), reward: [ -0.36026956   0.13934561  33.39910433] 15.6728328064\n",
      "positions (x,y,z), reward: [ -0.91988827   0.39933023  41.02447348] 67.0632049642\n",
      "positions (x,y,z), reward: [ -1.60590958   0.7132453   47.47063908] 116.914589349\n",
      "positions (x,y,z), reward: [ -3.54351341   1.49945896  59.60447561] 164.701445045\n",
      "positions (x,y,z), reward: [-11.46683365   4.25340979  86.40071294] 162.500540875\n",
      "positions (x,y,z), reward: [-12.34156034   4.55173112  88.52422255] 164.352918474\n",
      "positions (x,y,z), reward: [-17.84974504   6.43212528  99.94413864] 173.006235171\n",
      "positions (x,y,z), reward: [ -21.09982419    7.52914751  105.45370617] 260.972675919\n",
      "positions (x,y,z), reward: [ -37.96942381   12.79591234  125.61154135] 229.934026205\n",
      "Episode =  455, score = 296.801 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.68555420e-03  -1.95125206e-03   2.24319965e+01] 5.01799629992\n",
      "positions (x,y,z), reward: [  0.03872738  -0.04982972  27.96053195] 12.740653627\n",
      "positions (x,y,z), reward: [  0.12793177  -0.20501426  34.37373414] 16.2490396261\n",
      "positions (x,y,z), reward: [  0.17949834  -0.29918239  36.87628115] 66.9493119423\n",
      "positions (x,y,z), reward: [  0.45881087  -0.77997895  45.31846538] 117.885491286\n",
      "positions (x,y,z), reward: [  1.38433978  -2.3121598   58.68966107] 166.735930873\n",
      "positions (x,y,z), reward: [  2.43454709  -4.1266853   67.28959466] 164.226492134\n",
      "positions (x,y,z), reward: [  2.7960271   -4.76444702  69.59419792] 163.224649232\n",
      "positions (x,y,z), reward: [  3.3038788   -5.66775436  72.47100923] 161.728226282\n",
      "positions (x,y,z), reward: [  4.12879785  -7.14712672  76.4724863 ] 159.116272864\n",
      "positions (x,y,z), reward: [ 10.0974499  -17.84913517  93.94450365] 158.695609525\n",
      "positions (x,y,z), reward: [ 12.59692567 -22.27696374  98.4894157 ] 158.848012707\n",
      "positions (x,y,z), reward: [  43.97619761  -85.49684332  117.41811456] 175.578935914\n",
      "positions (x,y,z), reward: [  45.49820708  -88.99776239  117.20525444] 173.778431582\n",
      "positions (x,y,z), reward: [  48.01705795  -94.81806565  116.70896555] 170.63665181\n",
      "Episode =  456, score = 282.465 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -5.80261676e-08   8.97455511e-10   2.00310912e+01] -6.44576242929\n",
      "positions (x,y,z), reward: [  1.71651595e-04  -2.23180681e-05   2.06244882e+01] -1.12404905177\n",
      "positions (x,y,z), reward: [  3.58517648e-03  -1.11395588e-03   2.29744351e+01] 6.21261572988\n",
      "positions (x,y,z), reward: [  0.23414276  -0.04628212  39.9671925 ] 67.9100859843\n",
      "positions (x,y,z), reward: [  0.87009331  -0.1131962   54.10925584] 168.920691173\n",
      "positions (x,y,z), reward: [  1.14756276  -0.11591797  58.03485388] 168.899791878\n",
      "positions (x,y,z), reward: [  1.32933532  -0.11169066  60.29342577] 168.853165002\n",
      "positions (x,y,z), reward: [  2.23995953e+00  -3.78397410e-02   6.94257720e+01] 168.495907755\n",
      "positions (x,y,z), reward: [  2.37598526e+00  -2.06980223e-02   7.05779945e+01] 168.434875361\n",
      "positions (x,y,z), reward: [  4.86038909   0.45928263  86.94119014] 176.660749061\n",
      "positions (x,y,z), reward: [  6.27538381   0.81019871  94.07577324] 185.924246277\n",
      "positions (x,y,z), reward: [  25.09794814    2.42209848  153.46892846] 206.776283777\n",
      "positions (x,y,z), reward: [  25.976584      2.19761482  155.71102724] 207.32916688\n",
      "Episode =  457, score = 316.662 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.93487948e-05  -2.34233260e-05   2.02788739e+01] -3.37009242742\n",
      "positions (x,y,z), reward: [ -1.60491285e-02  -2.01170048e-02   2.48806166e+01] 9.41239842895\n",
      "positions (x,y,z), reward: [ -0.21350688  -0.1022694   34.86185266] 16.4466401335\n",
      "positions (x,y,z), reward: [ -2.31854385  -0.24227826  64.67851504] 167.467157486\n",
      "positions (x,y,z), reward: [ -2.74723553  -0.23746935  68.04264576] 167.049195209\n",
      "positions (x,y,z), reward: [ -6.58816011   0.09163527  91.53526254] 180.629291955\n",
      "positions (x,y,z), reward: [  -8.44037325    0.47045284  101.74355411] 289.355514805\n",
      "positions (x,y,z), reward: [ -11.70052087    1.44982301  122.39557531] 263.688489937\n",
      "positions (x,y,z), reward: [ -11.88082178    1.49435782  123.80205177] 264.08237158\n",
      "positions (x,y,z), reward: [ -13.88862213    1.1283567   146.0970973 ] 276.031178227\n",
      "positions (x,y,z), reward: [ -13.99090063    0.97411119  148.09143966] 227.676389446\n",
      "positions (x,y,z), reward: [ -14.2344963     0.31792795  154.49363039] 233.682684755\n",
      "positions (x,y,z), reward: [ -14.34977689   -1.43097368  165.59954602] 144.152790197\n",
      "positions (x,y,z), reward: [ -14.29156238   -2.30435395  169.83021048] 148.574489514\n",
      "Episode =  458, score = 315.695 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.68281789e-05  -1.10933997e-05   2.02789917e+01] -3.36641882943\n",
      "positions (x,y,z), reward: [ -0.25624761  -0.28825767  37.89332305] 67.1673597775\n",
      "positions (x,y,z), reward: [ -0.44200731  -0.422166    42.08267985] 67.7294516043\n",
      "positions (x,y,z), reward: [ -0.75570985  -0.62293336  47.47564047] 117.89417995\n",
      "positions (x,y,z), reward: [ -0.7921032   -0.64498085  48.02158437] 117.884344552\n",
      "positions (x,y,z), reward: [ -0.82939963  -0.66738128  48.56847424] 117.870674678\n",
      "positions (x,y,z), reward: [ -1.43987023  -1.01848026  56.29765446] 167.31691912\n",
      "positions (x,y,z), reward: [ -3.05937903  -2.02264138  72.47879106] 164.90134537\n",
      "positions (x,y,z), reward: [ -3.48343174  -2.34697162  76.40056229] 164.206149446\n",
      "positions (x,y,z), reward: [ -5.38129109  -4.53288632  94.51370527] 182.572887004\n",
      "Episode =  459, score = 313.015 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.78908610e-04   5.23379554e-04   2.07693377e+01] -0.394816192273\n",
      "positions (x,y,z), reward: [ -2.41079254e-03   6.22148563e-03   2.21760087e+01] 4.37576921089\n",
      "positions (x,y,z), reward: [ -2.73894858e-02   9.53879504e-02   2.79529886e+01] 12.6867377966\n",
      "positions (x,y,z), reward: [ -0.16131955   0.66142218  41.53679092] 67.6520429102\n",
      "positions (x,y,z), reward: [ -0.34285272   1.78175807  55.73664549] 167.762488506\n",
      "positions (x,y,z), reward: [   2.14252184   11.71005276  104.943988  ] 281.539638058\n",
      "positions (x,y,z), reward: [   7.57113176   22.74855725  133.93794251] 249.234930216\n",
      "positions (x,y,z), reward: [   9.95460107   26.56789674  142.66738229] 250.262491521\n",
      "positions (x,y,z), reward: [  10.64372481   27.59685092  144.99625859] 250.76370987\n",
      "positions (x,y,z), reward: [  14.43702077   32.90042527  157.08722028] 155.432175708\n",
      "positions (x,y,z), reward: [  15.38562534   34.17460713  160.03963858] 157.192485142\n",
      "Episode =  460, score = 309.926 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -8.62465105e-02  -1.10406423e-02   3.05836168e+01] 14.6376414497\n",
      "positions (x,y,z), reward: [ -1.55031081e-01  -2.80960736e-02   3.38886329e+01] 16.2052111249\n",
      "positions (x,y,z), reward: [ -1.24898753  -0.34686368  53.00677868] 168.153088121\n",
      "positions (x,y,z), reward: [ -1.47918831  -0.40735072  55.23140724] 167.971474983\n",
      "positions (x,y,z), reward: [ -1.54089373  -0.42305057  55.78883367] 167.916604838\n",
      "positions (x,y,z), reward: [ -2.58995509  -0.65798202  63.62523948] 166.798777697\n",
      "positions (x,y,z), reward: [-11.02003075  -1.30355433  94.86030595] 179.651325938\n",
      "positions (x,y,z), reward: [ -34.15069524   -1.68217696  128.90864852] 246.01921664\n",
      "positions (x,y,z), reward: [ -36.24923032   -1.898321    130.95771662] 245.581504164\n",
      "positions (x,y,z), reward: [ -48.38496023   -4.0103262   141.49011812] 242.846915396\n",
      "Episode =  461, score = 312.005 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  8.55146101e-03   2.42359624e-02   2.45348325e+01] 8.91205171895\n",
      "positions (x,y,z), reward: [  0.12750718   0.25043169  35.85559689] 16.7378650154\n",
      "positions (x,y,z), reward: [  0.21964868   0.40921819  40.4912099 ] 67.6709253186\n",
      "positions (x,y,z), reward: [  0.8104222    1.59672466  61.31601829] 167.568809045\n",
      "positions (x,y,z), reward: [  1.19941829   2.70320778  73.12771722] 166.349582093\n",
      "positions (x,y,z), reward: [  1.49158625   3.76616872  81.63307417] 167.651579861\n",
      "positions (x,y,z), reward: [  1.69715111   4.63020306  87.345269  ] 175.350753527\n",
      "positions (x,y,z), reward: [   2.73960597    9.40260924  109.97346625] 274.102200271\n",
      "positions (x,y,z), reward: [   3.1365137    11.16452788  116.40273131] 262.336433562\n",
      "positions (x,y,z), reward: [   5.31356647   23.45039798  149.48659638] 198.704594221\n",
      "Episode =  462, score = 316.904 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.72701062e-04  -3.48725485e-04   2.14927897e+01] 2.42517131492\n",
      "positions (x,y,z), reward: [  4.75125971e-03   9.02524643e-03   2.59746250e+01] 10.8289718535\n",
      "positions (x,y,z), reward: [  7.19261339e-03   1.71751598e-02   2.75484691e+01] 12.4392787308\n",
      "positions (x,y,z), reward: [  8.82984767e-03   2.23323189e-02   2.83815408e+01] 13.1511115646\n",
      "positions (x,y,z), reward: [  1.44873620e-02   3.90298990e-02   3.05800743e+01] 14.6801963438\n",
      "positions (x,y,z), reward: [  0.11532712   0.60514519  51.89036584] 118.986892822\n",
      "positions (x,y,z), reward: [  0.12996715   0.75480365  54.67144344] 169.020498632\n",
      "positions (x,y,z), reward: [  0.26381343   4.0273165   86.39388961] 175.571915656\n",
      "positions (x,y,z), reward: [  0.18970747   5.51557446  95.43014555] 187.65674898\n",
      "positions (x,y,z), reward: [  0.12440651   6.15126616  98.81700735] 192.176152278\n",
      "positions (x,y,z), reward: [  4.71849722e-02   6.71764956e+00   1.01641163e+02] 291.022252386\n",
      "positions (x,y,z), reward: [  -1.35846986   11.7889708   121.50431308] 257.257732495\n",
      "positions (x,y,z), reward: [  -3.10227878   16.02638736  133.92225519] 250.82883333\n",
      "positions (x,y,z), reward: [  -5.58931101   21.55393055  147.14713145] 243.490603249\n",
      "Episode =  463, score = 320.014 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.63362842e-04   4.10990954e-04   2.17079976e+01] 3.09642503252\n",
      "positions (x,y,z), reward: [  2.41932138e-02   5.57591173e-03   2.59749246e+01] 10.8173346728\n",
      "positions (x,y,z), reward: [  5.85711185e-02   1.53948644e-02   2.83824945e+01] 13.1124498166\n",
      "positions (x,y,z), reward: [  0.56526624   0.15912701  42.62493693] 67.9541116458\n",
      "positions (x,y,z), reward: [  0.65055176   0.18461601  44.2327801 ] 118.075050906\n",
      "positions (x,y,z), reward: [  0.71061987   0.20303093  45.31193174] 118.131443125\n",
      "positions (x,y,z), reward: [  0.77320596   0.2226209   46.39619106] 118.170239365\n",
      "positions (x,y,z), reward: [  0.90576      0.26539848  48.57791588] 118.198088248\n",
      "positions (x,y,z), reward: [  1.19913995   0.36500423  52.98128033] 168.084103439\n",
      "positions (x,y,z), reward: [  2.81652527   0.92436533  71.93691814] 166.236440519\n",
      "positions (x,y,z), reward: [  2.92856221   0.95934163  73.05619233] 166.095294238\n",
      "positions (x,y,z), reward: [  3.21701256   1.04414184  75.85535567] 165.73633959\n",
      "positions (x,y,z), reward: [  3.96094971   1.21763017  82.58104269] 168.743416963\n",
      "positions (x,y,z), reward: [  11.22223996   -3.15535073  128.31495057] 255.338819307\n",
      "positions (x,y,z), reward: [  12.36363566   -5.04958701  133.24570371] 251.562825929\n",
      "Episode =  464, score = 319.291 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  5.68169976e-05   1.15051609e-04   2.04949309e+01] -1.85692390896\n",
      "positions (x,y,z), reward: [  1.03554918e-04   3.61249021e-04   2.07701711e+01] -0.386520249398\n",
      "positions (x,y,z), reward: [ -0.10424592   0.04194762  31.96552684] 15.36291708\n",
      "positions (x,y,z), reward: [ -1.51658752   0.13728898  65.78351099] 168.363871096\n",
      "positions (x,y,z), reward: [ -1.5462818    0.14228557  66.34404858] 168.341935633\n",
      "positions (x,y,z), reward: [ -2.16717532   0.30115195  79.32231879] 167.970982046\n",
      "positions (x,y,z), reward: [ -2.56334303   0.57781367  95.57586458] 192.073159618\n",
      "positions (x,y,z), reward: [  -2.20848727    0.7858057   113.74609632] 281.634252385\n",
      "positions (x,y,z), reward: [  -1.75302439    0.71544799  121.99880541] 275.154254172\n",
      "positions (x,y,z), reward: [  -1.60926085    0.67343855  124.15717133] 276.03752073\n",
      "positions (x,y,z), reward: [  -1.0054189     0.4197834   132.45852736] 279.813496082\n",
      "positions (x,y,z), reward: [ -1.25837747e-01  -2.71692753e-01   1.45837641e+02] 286.23514686\n",
      "positions (x,y,z), reward: [  3.10350131e-02  -5.16313216e-01   1.49472531e+02] 237.712518539\n",
      "positions (x,y,z), reward: [  1.43379188e-01  -1.39051566e+00   1.60204213e+02] 191.945207842\n",
      "Episode =  465, score = 323.071 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -3.98083386e-03   2.95025278e-03   2.29801511e+01] 6.23360282521\n",
      "positions (x,y,z), reward: [ -0.1905568    0.07664576  50.23791119] 119.255665419\n",
      "positions (x,y,z), reward: [ -0.25845266  -0.06813228  59.12642238] 169.638427439\n",
      "positions (x,y,z), reward: [ -0.26246537  -0.08218199  59.6859148 ] 169.637548079\n",
      "positions (x,y,z), reward: [ -0.37101271  -1.75951035  85.08661453] 175.878493217\n",
      "positions (x,y,z), reward: [ -0.36627468  -2.05520288  87.35742349] 178.998137954\n",
      "positions (x,y,z), reward: [ -0.36453737  -2.13423123  87.92514852] 179.772188514\n",
      "positions (x,y,z), reward: [ -6.95742239e-02  -6.72907041e+00   1.08790316e+02] 279.797403636\n",
      "positions (x,y,z), reward: [   0.24274808   -9.71628415  117.58256585] 262.816043731\n",
      "positions (x,y,z), reward: [   0.64978824  -12.96316399  125.62831102] 254.870646869\n",
      "positions (x,y,z), reward: [   0.84407017  -14.36394821  128.79060547] 253.011568968\n",
      "positions (x,y,z), reward: [   0.87820452  -14.60252812  129.31460759] 252.696069926\n",
      "positions (x,y,z), reward: [   1.16930854  -16.56114869  133.47685196] 250.122488652\n",
      "Episode =  466, score = 321.923 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  9.46907213e-04  -3.08662319e-02   2.42053402e+01] 8.41089642536\n",
      "positions (x,y,z), reward: [  2.04057035e-03  -5.51821035e-02   2.56005148e+01] 10.3373295791\n",
      "positions (x,y,z), reward: [  0.18161003  -1.13972246  60.2054089 ] 168.645887931\n",
      "positions (x,y,z), reward: [  0.39619671  -1.43971978  76.02959717] 168.774024397\n",
      "positions (x,y,z), reward: [  0.51090126  -1.41929154  83.52149925] 174.369958976\n",
      "positions (x,y,z), reward: [  0.54979101  -1.37753087  86.43141197] 178.894450111\n",
      "positions (x,y,z), reward: [  0.56356209  -1.35533792  87.59972152] 180.716124317\n",
      "positions (x,y,z), reward: [  0.60274785  -1.06151582  97.03171435] 195.602597866\n",
      "positions (x,y,z), reward: [   0.49298449   -0.72891895  103.61874449] 295.519543956\n",
      "positions (x,y,z), reward: [   0.38084045   -0.53794798  106.64929985] 291.53359054\n",
      "positions (x,y,z), reward: [  -0.25522083    0.14390664  115.29308342] 279.991589779\n",
      "positions (x,y,z), reward: [  -0.72537956    0.50441882  119.08143462] 273.928029396\n",
      "positions (x,y,z), reward: [  -4.55671966    2.28969646  135.40939978] 268.552962907\n",
      "positions (x,y,z), reward: [  -8.31897528    3.21482187  144.87700313] 264.668599795\n",
      "Episode =  467, score = 326.708 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.44195977e-06  -3.10096992e-06   2.01241963e+01] -4.89951484408\n",
      "positions (x,y,z), reward: [  4.63853334e-05  -5.85857746e-05   2.03790611e+01] -2.61278286777\n",
      "positions (x,y,z), reward: [  1.52434666e-02  -4.06627249e-03   2.42031149e+01] 8.41655360793\n",
      "positions (x,y,z), reward: [  4.82372847e-02   4.77951720e-03   2.75425615e+01] 12.3963448288\n",
      "positions (x,y,z), reward: [  6.96354560e-02   1.77539025e-02   2.92352033e+01] 13.7413720038\n",
      "positions (x,y,z), reward: [  0.16704835   0.13723409  35.85754942] 16.8167908647\n",
      "positions (x,y,z), reward: [  0.42723014   1.34452423  55.86252157] 168.45914088\n",
      "positions (x,y,z), reward: [  0.43441545   1.57186933  58.12812023] 168.392675568\n",
      "positions (x,y,z), reward: [ -0.48378377   6.1980548   86.84592296] 175.674204224\n",
      "positions (x,y,z), reward: [  -4.66633911   17.26810908  126.25191037] 250.637263307\n",
      "positions (x,y,z), reward: [  -4.9047563    17.91106211  128.08884015] 249.83867636\n",
      "positions (x,y,z), reward: [  -8.04330327   27.69637103  152.76327774] 197.104523838\n",
      "Episode =  468, score = 315.255 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.12498792   0.56007629  35.85798283] 16.4314062039\n",
      "positions (x,y,z), reward: [ -0.43761582   1.38613739  44.25036209] 117.294706487\n",
      "positions (x,y,z), reward: [ -0.89200537   2.31212427  50.87887826] 116.84803991\n",
      "positions (x,y,z), reward: [ -0.9900887    2.49302893  52.00389442] 166.698759272\n",
      "positions (x,y,z), reward: [ -1.09507252   2.68164455  53.1340248 ] 166.530863107\n",
      "positions (x,y,z), reward: [ -19.47804215   26.48665681  130.06112755] 266.653524016\n",
      "Episode =  469, score = 334.023 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  5.29395664e-04  -6.52366704e-05   2.11024742e+01] 1.03753632687\n",
      "positions (x,y,z), reward: [  1.80975757e-03  -1.74870921e-04   2.19353349e+01] 3.74736135503\n",
      "positions (x,y,z), reward: [  2.34027236e-03  -2.48726578e-04   2.21767445e+01] 4.38878252951\n",
      "positions (x,y,z), reward: [  0.62999501  -0.91087099  59.69618119] 168.617442746\n",
      "positions (x,y,z), reward: [  2.42795867  -5.855117    83.01908093] 165.978099492\n",
      "positions (x,y,z), reward: [  2.6722117   -6.59972577  84.67335151] 167.079664337\n",
      "positions (x,y,z), reward: [  3.42846124  -8.93357373  88.94412036] 168.94600553\n",
      "positions (x,y,z), reward: [  4.47204428 -12.17635262  93.40970961] 169.021273289\n",
      "positions (x,y,z), reward: [  14.25872834  -39.65826588  106.4493544 ] 223.505103198\n",
      "positions (x,y,z), reward: [  19.13556647  -50.50340344  105.12832452] 191.067967515\n",
      "positions (x,y,z), reward: [  22.34769881  -56.65121164  103.05145578] 188.771777734\n",
      "Episode =  470, score = 275.471 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -0.34214157   0.18030219  31.4840704 ] 14.6925881239\n",
      "positions (x,y,z), reward: [ -1.05889938   0.45358544  39.41912472] 66.4907904211\n",
      "positions (x,y,z), reward: [ -2.93147467   0.92233226  51.77644133] 115.540927825\n",
      "positions (x,y,z), reward: [-11.29275357   0.3789131   83.74915102] 163.427005386\n",
      "positions (x,y,z), reward: [ -1.22084045e+01   5.63072416e-02   8.64936758e+01] 166.882760897\n",
      "positions (x,y,z), reward: [-12.96166929  -0.24749054  88.68365536] 169.15153205\n",
      "positions (x,y,z), reward: [-16.15739012  -1.90418087  97.37318483] 176.933534327\n",
      "positions (x,y,z), reward: [ -22.95475874   -7.29028847  113.15987936] 250.445710381\n",
      "positions (x,y,z), reward: [ -30.69719252  -16.36519424  127.08989257] 227.602886314\n",
      "positions (x,y,z), reward: [ -31.57975966  -17.59036269  128.39164822] 225.772950647\n",
      "positions (x,y,z), reward: [ -34.02228118  -21.16920232  131.66453996] 221.412321261\n",
      "Episode =  471, score = 298.687 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.18078219e-04  -2.00575237e-04   2.06248089e+01] -1.12096848347\n",
      "positions (x,y,z), reward: [ -0.33425086  -0.24671141  34.36360836] 15.982821711\n",
      "positions (x,y,z), reward: [ -1.88887691  -1.13502061  51.8441545 ] 116.536906675\n",
      "positions (x,y,z), reward: [ -2.33816078  -1.39413768  55.1612978 ] 165.977031745\n",
      "positions (x,y,z), reward: [ -2.41880703  -1.44067736  55.71570652] 165.868067511\n",
      "positions (x,y,z), reward: [ -5.4387876   -3.12538491  71.26959605] 161.080412782\n",
      "positions (x,y,z), reward: [ -8.07941283  -4.46529286  80.59131145] 157.487825644\n",
      "positions (x,y,z), reward: [ -26.45760107  -12.81043104  118.55825875] 234.511626473\n",
      "positions (x,y,z), reward: [ -28.68094417  -13.82884648  121.76739789] 230.853251463\n",
      "positions (x,y,z), reward: [ -30.65521076  -14.73420459  124.46431302] 229.530176883\n",
      "positions (x,y,z), reward: [ -35.50884154  -16.95701912  130.56046958] 226.317514149\n",
      "positions (x,y,z), reward: [ -41.10238907  -19.50164958  136.78124005] 222.690650269\n",
      "Episode =  472, score = 297.076 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.03822471e-07   5.72885846e-09   2.00311087e+01] -6.4448896213\n",
      "positions (x,y,z), reward: [ -3.63720249e-04  -5.97329710e-05   2.06250210e+01] -1.11722676941\n",
      "positions (x,y,z), reward: [ -1.72724457e-02  -4.55075896e-03   2.38839843e+01] 7.90338093931\n",
      "positions (x,y,z), reward: [ -0.45549593  -0.32360732  41.55841277] 67.7022375235\n",
      "positions (x,y,z), reward: [ -0.61961637  -0.48344476  45.84724028] 117.981312087\n",
      "positions (x,y,z), reward: [ -0.89818835  -0.81766256  52.41966619] 167.912478312\n",
      "positions (x,y,z), reward: [ -1.1045261   -1.1179503   56.85858508] 167.618045794\n",
      "positions (x,y,z), reward: [ -1.13148043  -1.16049319  57.41563493] 167.569750775\n",
      "positions (x,y,z), reward: [ -1.24188527  -1.3426806   59.64773356] 167.35121894\n",
      "positions (x,y,z), reward: [ -1.445135    -1.71081742  63.56611197] 166.875530945\n",
      "positions (x,y,z), reward: [ -1.75817092  -2.3568245   69.18022702] 165.977757269\n",
      "positions (x,y,z), reward: [ -1.95936481  -2.81933389  72.55199767] 165.318636023\n",
      "positions (x,y,z), reward: [ -3.31566267  -6.59119734  91.01259773] 176.329104203\n",
      "positions (x,y,z), reward: [  -4.53548903  -10.20941696  101.98657   ] 281.329235265\n",
      "Episode =  473, score = 306.097 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.01980152e-02  -9.41785703e-03   2.29767081e+01] 6.20657755815\n",
      "positions (x,y,z), reward: [ -0.10318881  -0.13321642  29.23939149] 13.5984423153\n",
      "positions (x,y,z), reward: [ -0.2692651   -0.34305755  34.86270391] 16.1417439314\n",
      "positions (x,y,z), reward: [ -1.33049414  -1.49999234  51.30660205] 116.742299022\n",
      "positions (x,y,z), reward: [ -1.94083869  -2.13543128  56.85256278] 165.770398557\n",
      "positions (x,y,z), reward: [ -3.39394794  -3.61266747  66.34451575] 162.894208864\n",
      "positions (x,y,z), reward: [ -8.40346073  -8.55466171  85.52509386] 159.870199164\n",
      "positions (x,y,z), reward: [ -9.76448146  -9.92656713  89.20432079] 162.10393483\n",
      "positions (x,y,z), reward: [-10.38432141 -10.56054879  90.75596709] 162.908246529\n",
      "positions (x,y,z), reward: [-11.68771593 -11.9139104   93.80783304] 164.232651607\n",
      "positions (x,y,z), reward: [ -32.99495919  -36.24428431  122.41204795] 215.344498417\n",
      "positions (x,y,z), reward: [ -34.45502723  -37.95270055  123.44633985] 214.496622282\n",
      "positions (x,y,z), reward: [ -38.58215481  -42.79104688  125.93432937] 212.086491184\n",
      "Episode =  474, score = 288.336 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  4.97037497e-03  -2.47855324e-02   3.15028773e+01] 15.2429753077\n",
      "positions (x,y,z), reward: [ -2.90152347e-03  -5.08877711e-02   3.53695849e+01] 16.9009061394\n",
      "positions (x,y,z), reward: [ -0.06953338  -0.17008798  45.85470828] 118.86619466\n",
      "positions (x,y,z), reward: [ -0.1121999   -0.23311365  49.67545682] 119.109538484\n",
      "positions (x,y,z), reward: [ -0.21445661  -0.38047165  56.86864952] 169.235230645\n",
      "positions (x,y,z), reward: [ -0.5830486   -1.00360611  75.92486313] 168.551864039\n",
      "positions (x,y,z), reward: [ -0.76305078  -1.35952824  82.68364993] 172.083573966\n",
      "positions (x,y,z), reward: [ -0.98237512  -1.81746742  89.44901552] 181.564872394\n",
      "positions (x,y,z), reward: [  -1.62520483   -3.19491279  104.08911857] 289.138211983\n",
      "positions (x,y,z), reward: [  -1.81741993   -3.58093837  107.45849873] 283.475337407\n",
      "positions (x,y,z), reward: [  -2.70282999   -5.07929275  119.22883296] 263.373503281\n",
      "positions (x,y,z), reward: [  -3.84680156   -6.50518448  129.30444335] 259.616441324\n",
      "Episode =  475, score = 325.192 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -6.22892976e-05   3.69263109e-04   2.07694997e+01] -0.392869792598\n",
      "positions (x,y,z), reward: [ -6.92309470e-03   1.38098024e-02   2.45377871e+01] 8.93437487614\n",
      "positions (x,y,z), reward: [ -0.04095465   0.11998507  36.37168743] 67.1294774852\n",
      "positions (x,y,z), reward: [ -0.04047888   0.12593432  36.8790196 ] 67.2755354407\n",
      "positions (x,y,z), reward: [  0.06810686   0.36252858  50.77812029] 119.122453043\n",
      "positions (x,y,z), reward: [  0.12224977   0.44568211  54.09668153] 169.177197301\n",
      "positions (x,y,z), reward: [  0.13239169   0.46075019  54.65184785] 169.178049199\n",
      "positions (x,y,z), reward: [  0.76826594   1.45633844  77.65755998] 167.998199397\n",
      "positions (x,y,z), reward: [  1.02745192   2.1634061   87.27627269] 178.083841564\n",
      "positions (x,y,z), reward: [  1.0726621    2.4636851   90.68433866] 182.921874891\n",
      "positions (x,y,z), reward: [  1.0131822    3.15076204  97.53224995] 192.76368724\n",
      "positions (x,y,z), reward: [  -5.82228245    7.85180759  128.397141  ] 255.549699508\n",
      "positions (x,y,z), reward: [  -7.2641872     8.39150815  131.09036283] 252.954438191\n",
      "positions (x,y,z), reward: [ -14.05625635   10.45476405  140.64973557] 240.996591243\n",
      "positions (x,y,z), reward: [ -16.59346431   11.09254802  143.4011368 ] 236.643680378\n",
      "Episode =  476, score = 321.291 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -3.01481522e-03  -5.94206946e-04   2.19360655e+01] 3.74925139116\n",
      "positions (x,y,z), reward: [ -5.14258221e-03  -1.16999389e-04   2.26982530e+01] 5.62767022145\n",
      "positions (x,y,z), reward: [ -1.49678402e-02   3.54469196e-02   2.88077638e+01] 13.4729191705\n",
      "positions (x,y,z), reward: [  0.06741028   0.20779835  38.41711657] 67.5787039272\n",
      "positions (x,y,z), reward: [  0.1208755    0.28188547  41.03283272] 68.0279791962\n",
      "positions (x,y,z), reward: [  0.52665077   0.76475024  51.92925642] 118.602117872\n",
      "positions (x,y,z), reward: [  3.81259197   4.1721167   81.37842638] 167.634800717\n",
      "positions (x,y,z), reward: [  6.54736861   6.58840062  93.1834399 ] 182.815953334\n",
      "positions (x,y,z), reward: [   9.1597675     8.60213569  101.68328853] 288.484202035\n",
      "positions (x,y,z), reward: [  11.34103017   10.09565651  107.75560588] 278.137108021\n",
      "positions (x,y,z), reward: [  12.90666172   11.07601463  111.77404429] 271.534995591\n",
      "positions (x,y,z), reward: [  13.23947782   11.27547786  112.60258061] 270.207290168\n",
      "positions (x,y,z), reward: [  15.75942974   12.69553331  118.68375778] 260.917960661\n",
      "positions (x,y,z), reward: [  23.28931229   16.29962167  136.61631518] 268.266823492\n",
      "positions (x,y,z), reward: [  37.89290545   27.5874288   189.74604097] 213.394237504\n",
      "positions (x,y,z), reward: [  43.1238387    48.83540081  241.06931286] 512.301148631\n",
      "Episode =  477, score = 338.696 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -6.34958476e-07  -2.21431700e-07   2.00699295e+01] -5.67051519113\n",
      "positions (x,y,z), reward: [ -1.42602152  -0.39439917  63.00916864] 168.216830273\n",
      "positions (x,y,z), reward: [ -1.91917318  -0.32639351  71.45228428] 167.995384269\n",
      "positions (x,y,z), reward: [ -3.0275619    0.19758442  88.48715452] 180.013263143\n",
      "positions (x,y,z), reward: [  -5.96794266    3.02346989  119.6267765 ] 263.063271048\n",
      "positions (x,y,z), reward: [  -6.93230427    4.1359304   126.78325556] 261.09715354\n",
      "positions (x,y,z), reward: [ -10.43417865    7.98458405  145.68084928] 256.809712828\n",
      "positions (x,y,z), reward: [ -11.77952933    9.27959842  151.10084711] 205.487137428\n",
      "Episode =  478, score = 322.065 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.22705669e-04  -1.53808183e-03   2.12909172e+01] 1.73976321151\n",
      "positions (x,y,z), reward: [ -0.09738427  -0.22967548  35.37350709] 16.6303318399\n",
      "positions (x,y,z), reward: [ -0.49822961  -0.85380171  50.22948954] 118.142691446\n",
      "positions (x,y,z), reward: [ -0.56480809  -0.94559058  51.88245957] 118.090974365\n",
      "positions (x,y,z), reward: [ -1.30341362  -1.85414573  65.80393722] 166.819092142\n",
      "positions (x,y,z), reward: [ -1.41395096  -1.97633823  67.48305614] 166.601551827\n",
      "positions (x,y,z), reward: [ -2.36506098  -2.87915872  79.25721847] 164.82672395\n",
      "positions (x,y,z), reward: [ -2.47702297  -2.96857435  80.38037918] 165.204057677\n",
      "positions (x,y,z), reward: [ -2.59387754  -3.05848124  81.50388934] 166.690768116\n",
      "positions (x,y,z), reward: [ -3.58432047  -3.69839824  89.38097715] 176.957962467\n",
      "positions (x,y,z), reward: [  -7.4603332    -5.05759164  106.3001785 ] 278.079863913\n",
      "positions (x,y,z), reward: [ -13.3187898    -6.08017019  119.53290196] 250.182768741\n",
      "positions (x,y,z), reward: [ -16.26756661   -6.48437161  124.31175668] 245.417802283\n",
      "positions (x,y,z), reward: [ -17.71478288   -6.67749162  126.39220375] 243.417554315\n",
      "Episode =  479, score = 313.218 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.55400916e-07   3.78883505e-09   2.00311161e+01] -6.44451718374\n",
      "positions (x,y,z), reward: [  9.09945356e-04   3.79069349e-04   2.09293306e+01] 0.334253820233\n",
      "positions (x,y,z), reward: [  0.40789725   0.19083602  39.97456578] 67.5872494595\n",
      "positions (x,y,z), reward: [  1.0384783    0.71822768  54.09710261] 168.057094655\n",
      "positions (x,y,z), reward: [  1.16533212   0.84384105  56.32758572] 167.931093271\n",
      "positions (x,y,z), reward: [  1.19848401   0.87736264  56.88675367] 167.894152493\n",
      "positions (x,y,z), reward: [   6.9508076     7.59114538  103.34148301] 285.881702833\n",
      "positions (x,y,z), reward: [   8.0697499     8.77297597  108.12182602] 277.837577046\n",
      "positions (x,y,z), reward: [  10.47464751   11.09628542  116.8767573 ] 263.409369549\n",
      "positions (x,y,z), reward: [  13.0672032    13.32699105  124.95018958] 258.298456972\n",
      "positions (x,y,z), reward: [  23.51217258   21.13716332  154.48994854] 225.930119517\n",
      "positions (x,y,z), reward: [  38.87346862   49.75174007  239.96244158] 457.453091716\n",
      "Episode =  480, score = 316.234 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -9.92323395e-08   7.06697767e-08   2.00310982e+01] -6.44541332769\n",
      "positions (x,y,z), reward: [  6.25526987e-03  -2.17553604e-02   2.35696048e+01] 7.34061440786\n",
      "positions (x,y,z), reward: [  8.55280734e-03  -3.66981084e-02   2.45399469e+01] 8.9078992523\n",
      "positions (x,y,z), reward: [  1.01495595e-02  -4.95372130e-02   2.52376982e+01] 9.86588012779\n",
      "positions (x,y,z), reward: [  1.50705092e-02  -1.02578127e-01   2.75459208e+01] 12.3337875805\n",
      "positions (x,y,z), reward: [  2.36881649e-02  -2.37513258e-01   3.19626505e+01] 15.234457935\n",
      "positions (x,y,z), reward: [  2.62248825e-02  -2.88102240e-01   3.33930317e+01] 15.855273448\n",
      "positions (x,y,z), reward: [  2.94644732e-02  -3.61974759e-01   3.53578641e+01] 16.5365974487\n",
      "positions (x,y,z), reward: [  0.0461985   -0.71857895  43.67352077] 68.0260924892\n",
      "positions (x,y,z), reward: [  0.0496718   -0.76871582  44.74799674] 118.112274277\n",
      "positions (x,y,z), reward: [  0.11675213  -1.34427228  56.26418618] 168.297624206\n",
      "positions (x,y,z), reward: [  0.15192078  -1.55307436  60.15994888] 168.181832335\n",
      "positions (x,y,z), reward: [  0.23254261  -1.93267493  66.87077017] 167.85752066\n",
      "positions (x,y,z), reward: [  0.2407583   -1.96569695  67.43132171] 167.82457453\n",
      "positions (x,y,z), reward: [  0.32796017  -2.27376167  72.48289612] 167.491556208\n",
      "positions (x,y,z), reward: [  0.40134815  -2.49123259  75.8560595 ] 167.230638979\n",
      "positions (x,y,z), reward: [  0.53913232  -2.83894023  80.92220736] 168.169030313\n",
      "positions (x,y,z), reward: [  0.57498764  -2.92035887  82.04909861] 169.753157582\n",
      "positions (x,y,z), reward: [  0.71824167  -3.22028715  85.99770315] 175.288811179\n",
      "positions (x,y,z), reward: [  1.14039843  -3.97083653  94.49524229] 187.059556469\n",
      "positions (x,y,z), reward: [   2.32549707   -5.79154111  108.82713668] 279.518064789\n",
      "positions (x,y,z), reward: [   7.57888606  -14.50407595  137.43046564] 247.29202496\n",
      "positions (x,y,z), reward: [   8.0650536   -15.35766976  139.06442143] 245.643615868\n",
      "positions (x,y,z), reward: [  10.84615681  -20.28270428  146.91646338] 236.333648841\n",
      "Episode =  481, score = 319.731 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.27218699e-02  -1.44800581e-02   2.63544417e+01] 11.2374755645\n",
      "positions (x,y,z), reward: [  0.33768682   0.14055897  51.87195074] 119.118131467\n",
      "positions (x,y,z), reward: [  0.35980477   0.15662747  52.97708134] 169.141811056\n",
      "positions (x,y,z), reward: [  0.50037594   0.24972934  59.09114336] 169.151347722\n",
      "positions (x,y,z), reward: [   2.58035267   -0.38068341  100.29489347] 296.977012176\n",
      "positions (x,y,z), reward: [   3.13335365   -1.09222325  107.68356915] 284.699268458\n",
      "positions (x,y,z), reward: [   3.62500361   -2.09643959  114.52223967] 273.013084174\n",
      "positions (x,y,z), reward: [   4.19311685   -4.50321935  124.78373468] 261.685845263\n",
      "positions (x,y,z), reward: [   4.14619985  -10.92804263  139.73121268] 253.440210874\n",
      "Episode =  482, score = 325.107 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -1.80595985e-08   4.76517826e-10   2.00310964e+01] -6.44550144836\n",
      "positions (x,y,z), reward: [ -2.32869664e-04  -5.58368330e-05   2.06245657e+01] -1.12314001536\n",
      "positions (x,y,z), reward: [ -1.65660242e-02  -3.16011262e-03   2.35668972e+01] 7.33547752434\n",
      "positions (x,y,z), reward: [ -1.97689112e-02  -3.39746129e-03   2.38794434e+01] 7.87587801379\n",
      "positions (x,y,z), reward: [ -5.26637653e-02  -2.65801009e-03   2.63485895e+01] 11.18618225\n",
      "positions (x,y,z), reward: [ -2.00211300e-01   3.12178003e-02   3.33819584e+01] 15.9256513224\n",
      "positions (x,y,z), reward: [ -0.98284444   0.36042731  52.3921713 ] 168.284204031\n",
      "positions (x,y,z), reward: [ -3.64019729   1.35194181  77.05742579] 165.219130798\n",
      "positions (x,y,z), reward: [ -4.34364772   1.61056695  81.00617678] 165.745973888\n",
      "positions (x,y,z), reward: [ -6.30284867   2.33727345  90.00997852] 176.431506083\n",
      "positions (x,y,z), reward: [ -16.34008444    6.25150702  118.71269924] 248.489290905\n",
      "positions (x,y,z), reward: [ -16.58687573    6.35383046  119.25568032] 247.314180069\n",
      "positions (x,y,z), reward: [ -19.17014208    7.44170932  124.67549636] 242.446359175\n",
      "positions (x,y,z), reward: [ -19.98752184    7.79150398  126.29900226] 241.268045847\n",
      "positions (x,y,z), reward: [ -20.26450003    7.91054918  126.84004365] 241.134286054\n",
      "positions (x,y,z), reward: [ -30.77610345   12.54092799  144.78423312] 237.055869666\n",
      "Episode =  483, score = 312.132 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.09420865   0.15955776  31.03766169] 14.7414581767\n",
      "positions (x,y,z), reward: [  1.11109608   1.12500173  52.43987443] 167.543588175\n",
      "positions (x,y,z), reward: [  1.45307558   1.35303004  56.35315627] 167.304175245\n",
      "positions (x,y,z), reward: [  2.73643591   2.03236647  67.23617581] 166.458705945\n",
      "positions (x,y,z), reward: [  5.16548662   2.90451556  81.1170533 ] 166.884638295\n",
      "positions (x,y,z), reward: [  14.42531039    2.61286542  112.92998567] 276.827439495\n",
      "positions (x,y,z), reward: [  44.91943086  -18.06530603  165.20689195] 143.937058683\n",
      "positions (x,y,z), reward: [  53.79838493  -25.83318933  175.26237801] 165.256831523\n",
      "Episode =  484, score = 340.049 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  0.48056682  -0.74374199  49.64447083] 118.185702128\n",
      "positions (x,y,z), reward: [  0.95002781  -1.51759737  63.52539279] 167.532261106\n",
      "positions (x,y,z), reward: [  2.3166482   -3.41623875  83.87902573] 170.701249479\n",
      "positions (x,y,z), reward: [   5.78025648   -7.57409621  108.1780226 ] 275.167881942\n",
      "Episode =  485, score = 313.251 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.76843321e-04   1.35570914e-04   2.09290952e+01] 0.329598229017\n",
      "positions (x,y,z), reward: [  1.66950611e-02   8.10999345e-03   2.45377649e+01] 8.92596406842\n",
      "positions (x,y,z), reward: [  0.19672265   0.24295804  36.36520395] 66.8380874017\n",
      "positions (x,y,z), reward: [  1.02788078   2.33359649  63.09696784] 166.8054888\n",
      "positions (x,y,z), reward: [  2.13513673   4.70995266  79.49854833] 163.502489734\n",
      "positions (x,y,z), reward: [  2.9408267    6.15297692  87.44348384] 172.474807512\n",
      "positions (x,y,z), reward: [   5.88138137   10.47032008  107.32753543] 272.925933702\n",
      "positions (x,y,z), reward: [   5.98546104   10.60765504  107.89273465] 271.816010917\n",
      "positions (x,y,z), reward: [  12.47733468   18.53303513  134.75678539] 237.282327605\n",
      "positions (x,y,z), reward: [  15.57059375   22.10703442  144.03933703] 231.693304371\n",
      "Episode =  486, score = 310.617 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -7.53343630e-03   3.89505824e-04   2.29760148e+01] 6.22078882311\n",
      "positions (x,y,z), reward: [ -1.81392702e-02   1.31201764e-03   2.45387702e+01] 8.93943398472\n",
      "positions (x,y,z), reward: [ -2.79030126e-02   2.17527657e-03   2.56000642e+01] 10.3647960253\n",
      "positions (x,y,z), reward: [ -3.54501416e-01   3.74556750e-02   4.10179869e+01] 67.9833190983\n",
      "positions (x,y,z), reward: [ -4.60827750e-01   3.13852482e-02   4.47540746e+01] 118.466416659\n",
      "positions (x,y,z), reward: [ -0.79706091  -0.25006161  58.55704908] 169.033676361\n",
      "positions (x,y,z), reward: [ -0.83472791  -0.35222362  60.80795423] 168.999060594\n",
      "positions (x,y,z), reward: [ -0.87297531  -0.50778416  63.6324869 ] 168.915990432\n",
      "positions (x,y,z), reward: [ -0.91565813  -0.92198312  69.31087003] 168.639892069\n",
      "positions (x,y,z), reward: [   0.47215349   -8.2835828   104.27964206] 285.140552854\n",
      "positions (x,y,z), reward: [   1.87577567  -13.45676833  115.99179578] 260.069228131\n",
      "positions (x,y,z), reward: [   2.28521299  -14.90225033  118.71823628] 253.86793608\n",
      "positions (x,y,z), reward: [   2.72253675  -16.42966713  121.41906876] 249.72652517\n",
      "positions (x,y,z), reward: [   3.0921199   -17.71093119  123.56194936] 247.884835523\n",
      "positions (x,y,z), reward: [   7.88856268  -34.40450614  144.88830686] 239.70758107\n",
      "Episode =  487, score = 317.647 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.85294531e-02  -5.03889452e-02   2.71405589e+01] 12.0100440589\n",
      "positions (x,y,z), reward: [  0.04028314  -0.17553806  33.39631667] 15.965045259\n",
      "positions (x,y,z), reward: [  0.3466509   -2.36267833  65.84384089] 167.484286368\n",
      "positions (x,y,z), reward: [  0.44666696  -2.97117247  69.79771442] 166.850957827\n",
      "positions (x,y,z), reward: [  0.53372417  -3.48808804  72.62650412] 166.267563276\n",
      "positions (x,y,z), reward: [  1.80842229 -10.12854891  93.83474318] 177.932796825\n",
      "positions (x,y,z), reward: [   3.9598046   -19.56812873  110.4422923 ] 257.394956935\n",
      "positions (x,y,z), reward: [   8.22220839  -36.55333488  129.99899515] 234.960620362\n",
      "Episode =  488, score = 307.781 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -8.68851848e-05  -1.63709099e-05   2.06250211e+01] -1.11712202134\n",
      "positions (x,y,z), reward: [ -1.28528241e-03  -1.71409192e-03   2.26990980e+01] 5.63289037523\n",
      "positions (x,y,z), reward: [  0.04929303  -0.10141787  37.90498895] 67.5706301098\n",
      "positions (x,y,z), reward: [  0.10702711  -0.25113216  49.12560019] 119.0448881\n",
      "positions (x,y,z), reward: [  0.12298872  -0.30219807  52.98078927] 169.230265228\n",
      "positions (x,y,z), reward: [  0.13714593  -0.35050155  56.86542577] 169.341159712\n",
      "positions (x,y,z), reward: [  0.15002987  -0.39360656  60.77062699] 169.407692972\n",
      "positions (x,y,z), reward: [  5.91024091e-01   7.08590770e-02   9.92287948e+01] 198.666041207\n",
      "positions (x,y,z), reward: [   1.28298544    0.72662411  113.49374029] 278.347770319\n",
      "positions (x,y,z), reward: [   1.94047929    1.19605329  122.10113057] 267.660470406\n",
      "positions (x,y,z), reward: [   1.99205376    1.22851937  122.67727598] 267.592917108\n",
      "positions (x,y,z), reward: [   2.62993914    1.59274104  129.03888704] 266.799547616\n",
      "positions (x,y,z), reward: [   4.42913106    2.40433777  142.51976691] 264.780784346\n",
      "Episode =  489, score = 329.295 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  8.22286947e-03   2.76439397e-02   2.67448927e+01] 11.6441456035\n",
      "positions (x,y,z), reward: [  2.2150202    4.88871762  81.07877571] 166.173978662\n",
      "positions (x,y,z), reward: [  3.0946761   6.1835437  87.6657375] 174.442140927\n",
      "positions (x,y,z), reward: [   5.7244463     9.70603236  101.93547651] 285.585522655\n",
      "positions (x,y,z), reward: [  11.41554777   16.21468391  122.12693397] 250.340832284\n",
      "positions (x,y,z), reward: [  12.70276301   17.5057899   125.78448257] 248.971435537\n",
      "positions (x,y,z), reward: [  21.64779799   25.03880348  147.90947962] 252.564351584\n",
      "Episode =  490, score = 300.923 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -6.72668242e-04   4.60788537e-04   2.17075553e+01] 3.09325204975\n",
      "positions (x,y,z), reward: [ -1.07522664e-03   8.71147523e-04   2.21774578e+01] 4.39132417406\n",
      "positions (x,y,z), reward: [ -1.23048447e-02   8.21995819e-03   2.59726781e+01] 10.8190532326\n",
      "positions (x,y,z), reward: [ -5.41268917e-02   1.52315622e-02   3.01267876e+01] 14.3850068701\n",
      "positions (x,y,z), reward: [ -1.80354972e-01   8.04322398e-03   3.58671657e+01] 16.9426259413\n",
      "positions (x,y,z), reward: [ -1.95351028e-01   6.13430557e-03   3.63714114e+01] 67.0904122336\n",
      "positions (x,y,z), reward: [ -1.01445454  -0.20962239  52.44512632] 168.461856875\n",
      "positions (x,y,z), reward: [ -1.32611295  -0.32018004  56.33532499] 168.22714133\n",
      "positions (x,y,z), reward: [ -4.9383512   -1.84813927  82.12295341] 166.348767861\n",
      "positions (x,y,z), reward: [ -6.46502343  -2.53674539  88.81310169] 173.992601646\n",
      "positions (x,y,z), reward: [ -7.20122747  -2.86837024  91.58572866] 176.975339647\n",
      "positions (x,y,z), reward: [ -8.87381271  -3.61350616  97.0907362 ] 182.50373366\n",
      "positions (x,y,z), reward: [ -16.13759402   -6.65375804  114.0476374 ] 253.550272951\n",
      "positions (x,y,z), reward: [ -20.25253647   -8.21761247  120.99811012] 237.97971511\n",
      "positions (x,y,z), reward: [ -20.88627005   -8.44961955  121.96227812] 237.557792407\n",
      "positions (x,y,z), reward: [ -26.36007584  -10.37092626  129.38863316] 233.998325975\n",
      "positions (x,y,z), reward: [ -30.53158314  -11.75214117  134.17465885] 231.366730629\n",
      "positions (x,y,z), reward: [ -34.60481911  -13.04679208  138.276816  ] 228.834940131\n",
      "Episode =  491, score = 307.684 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  2.11894711e-01   4.87503614e-06   3.63710144e+01] 67.0676337049\n",
      "positions (x,y,z), reward: [  2.97337670e-01  -4.62469525e-03   3.94549660e+01] 67.7769040087\n",
      "positions (x,y,z), reward: [  6.97705921e-01  -4.73901359e-02   5.07668472e+01] 118.784702729\n",
      "positions (x,y,z), reward: [  0.79272043  -0.06550019  52.97525097] 168.812000966\n",
      "positions (x,y,z), reward: [  1.06180483  -0.14288219  58.53793906] 168.729254092\n",
      "positions (x,y,z), reward: [  2.26563948  -1.10270103  76.05420674] 167.140935455\n",
      "positions (x,y,z), reward: [  3.75670349  -3.86074853  90.87857062] 178.991484821\n",
      "positions (x,y,z), reward: [   5.0790869    -8.02362266  101.98355202] 282.923491566\n",
      "positions (x,y,z), reward: [   5.75551953  -10.91288979  107.27578647] 270.260546877\n",
      "positions (x,y,z), reward: [   7.47694095  -22.46229764  120.8668601 ] 235.063025895\n",
      "positions (x,y,z), reward: [   8.00260355  -29.63011188  126.13731531] 230.964130695\n",
      "positions (x,y,z), reward: [   8.14514826  -43.96871522  132.51890071] 223.170644827\n",
      "Episode =  492, score = 308.026 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -4.33143915e-04   1.21629230e-03   2.11032823e+01] 1.04405715979\n",
      "positions (x,y,z), reward: [ -0.05641992   0.20832584  32.43785433] 15.4747794405\n",
      "positions (x,y,z), reward: [ -0.05670754   0.26345587  33.8822501 ] 16.0656964726\n",
      "positions (x,y,z), reward: [  0.60963768   1.96193156  55.38530423] 167.99514226\n",
      "positions (x,y,z), reward: [  2.30131812   4.46124009  71.30454637] 165.670549052\n",
      "positions (x,y,z), reward: [  2.77143429   5.0792393   74.36984126] 165.003969573\n",
      "positions (x,y,z), reward: [  6.46119759   9.50090001  91.78329794] 177.476203442\n",
      "positions (x,y,z), reward: [  8.37320106  11.65545113  98.66782055] 185.069342635\n",
      "positions (x,y,z), reward: [  20.4895853    24.84978985  133.70911192] 249.256377354\n",
      "positions (x,y,z), reward: [  27.55138921   32.1112053   153.11463519] 214.952185483\n",
      "positions (x,y,z), reward: [  35.26250448   39.44160241  178.56154419] 156.204525062\n",
      "positions (x,y,z), reward: [  39.08960503   43.37612818  196.0572225 ] 183.409141104\n",
      "Episode =  493, score = 306.879 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.80281515e-06  -1.85824465e-06   2.01242792e+01] -4.8973145358\n",
      "positions (x,y,z), reward: [ -1.94417947e-03   1.01153718e-03   2.17081571e+01] 3.09762304174\n",
      "positions (x,y,z), reward: [ -5.61383541e-03   4.05940853e-03   2.26992602e+01] 5.62813545417\n",
      "positions (x,y,z), reward: [ -0.16960284   0.15900488  31.96784287] 15.1760752225\n",
      "positions (x,y,z), reward: [ -0.7889197    0.78650731  44.77025089] 117.428950603\n",
      "positions (x,y,z), reward: [ -1.16327362   1.21850188  50.23559196] 117.220381453\n",
      "positions (x,y,z), reward: [ -1.7107811    1.89694052  56.92567289] 166.510100243\n",
      "positions (x,y,z), reward: [ -1.76198235   1.96192325  57.48851817] 166.432638447\n",
      "positions (x,y,z), reward: [ -2.26696477   2.60931306  62.58805607] 165.616117917\n",
      "positions (x,y,z), reward: [ -2.85730546   3.37542416  67.74773917] 164.596698839\n",
      "positions (x,y,z), reward: [ -5.96824793   7.59868937  88.44444046] 171.484832394\n",
      "positions (x,y,z), reward: [ -11.31864425   16.28656761  117.57510503] 253.795039064\n",
      "positions (x,y,z), reward: [ -14.32331098   24.22116172  137.8957572 ] 255.207352068\n",
      "positions (x,y,z), reward: [ -15.50567187   42.77208877  179.74800626] 169.664926724\n",
      "Episode =  494, score = 301.125 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.03148071e-02  -2.29400488e-02   2.52363993e+01] 9.89415829131\n",
      "positions (x,y,z), reward: [  2.52136158e-02  -6.64427057e-02   2.88052695e+01] 13.4287707762\n",
      "positions (x,y,z), reward: [  2.74203084e-02  -7.31698915e-02   2.92389281e+01] 13.7443183214\n",
      "positions (x,y,z), reward: [  0.59250295  -1.0727152   56.33574288] 168.306600233\n",
      "positions (x,y,z), reward: [  1.98295525  -2.74667578  75.06665117] 165.916344093\n",
      "positions (x,y,z), reward: [  3.87206517  -5.14307075  89.45177867] 176.067428933\n",
      "positions (x,y,z), reward: [   8.65723085  -11.14338185  111.46048055] 266.340383031\n",
      "positions (x,y,z), reward: [  12.59544389  -15.85928466  124.02071531] 248.78324313\n",
      "positions (x,y,z), reward: [  19.30930776  -23.81644801  141.54775124] 248.848718435\n",
      "positions (x,y,z), reward: [  21.34641891  -26.25744241  146.38192517] 252.689936644\n",
      "Episode =  495, score = 303.349 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  1.21558407e-02   3.94522066e-02   2.48820503e+01] 9.39387130145\n",
      "positions (x,y,z), reward: [  2.63086323e-02   7.17347737e-02   2.63520076e+01] 11.1580818598\n",
      "positions (x,y,z), reward: [  0.04273436   0.10503186  27.54385486] 12.2976544327\n",
      "positions (x,y,z), reward: [  0.82368197   1.22387091  44.76093062] 116.998388473\n",
      "positions (x,y,z), reward: [  2.10083114   2.81853311  57.53258223] 165.426179622\n",
      "positions (x,y,z), reward: [  5.70902585   7.72272531  80.63494919] 161.115233757\n",
      "positions (x,y,z), reward: [  8.18949546  12.26788099  94.84367346] 180.4540541\n",
      "positions (x,y,z), reward: [  8.68882724  13.37320676  97.83316582] 184.787599999\n",
      "positions (x,y,z), reward: [  11.86676604   22.1533745   119.26914645] 265.084410277\n",
      "positions (x,y,z), reward: [  13.1652606    26.62984028  130.00325194] 275.296389815\n",
      "positions (x,y,z), reward: [  16.3839525    41.25876406  169.34283752] 211.54673905\n",
      "Episode =  496, score = 388.241 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -8.12382745e-08   7.66732718e-08   2.00311091e+01] -6.44486940395\n",
      "positions (x,y,z), reward: [  1.84480229e-04   2.38498059e-04   2.06249828e+01] -1.11821727969\n",
      "positions (x,y,z), reward: [  5.76169898e-04   5.87627475e-04   2.11032289e+01] 1.0437961451\n",
      "positions (x,y,z), reward: [  7.05497649e-03  -5.32407151e-02   2.83820832e+01] 13.1240440819\n",
      "positions (x,y,z), reward: [ -4.04796909e-02  -1.07257824e+00   4.91243515e+01] 118.302594417\n",
      "positions (x,y,z), reward: [ -3.50159877e-02  -1.67145373e+00   5.57557789e+01] 168.094849137\n",
      "positions (x,y,z), reward: [ -3.18688241e-02  -1.78755392e+00   5.68687778e+01] 168.024945445\n",
      "positions (x,y,z), reward: [  0.36340852  -5.69084033  81.49042339] 166.056744983\n",
      "positions (x,y,z), reward: [  0.4973622   -6.55348337  85.38581483] 170.795351317\n",
      "positions (x,y,z), reward: [   1.86004568  -13.71812658  110.50632873] 267.54695208\n",
      "Episode =  497, score = 314.336 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [  3.22935761  -1.52943263  71.89199228] 165.218031873\n",
      "positions (x,y,z), reward: [  3.59684233  -1.78687188  75.25150403] 164.626266374\n",
      "positions (x,y,z), reward: [  3.91284902  -2.03329255  78.05414482] 164.09092748\n",
      "positions (x,y,z), reward: [  5.24728166  -3.38422667  89.27996401] 175.356737458\n",
      "positions (x,y,z), reward: [  5.93676479  -4.31421068  94.89000846] 182.105227574\n",
      "positions (x,y,z), reward: [   7.85911097   -7.99926573  111.0411818 ] 267.21594916\n",
      "positions (x,y,z), reward: [   8.04149415   -8.46514874  112.69796505] 264.03246223\n",
      "positions (x,y,z), reward: [   8.7676474   -10.68501965  119.84009475] 250.131132131\n",
      "positions (x,y,z), reward: [   9.01087761  -11.6301482   122.57001679] 248.607335613\n",
      "positions (x,y,z), reward: [   9.68635465  -16.69326494  135.00308179] 242.399220867\n",
      "positions (x,y,z), reward: [   9.58691226  -19.81551952  141.3913995 ] 239.021834173\n",
      "positions (x,y,z), reward: [   9.42194135  -21.20785318  144.02486008] 238.809702922\n",
      "Episode =  498, score = 312.820 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -2.03291944e-04  -9.67800434e-04   2.09285643e+01] 0.325156568208\n",
      "positions (x,y,z), reward: [  8.52531940e-03  -2.65254433e-02   2.48800368e+01] 9.40412490045\n",
      "positions (x,y,z), reward: [  1.01363285e-02  -2.99407898e-02   2.52336167e+01] 9.87787665431\n",
      "positions (x,y,z), reward: [  3.85417227  -0.88913327  73.71423517] 167.023820682\n",
      "positions (x,y,z), reward: [  6.25049768  -1.40035524  85.38573416] 174.208043539\n",
      "positions (x,y,z), reward: [  8.21493286  -1.8700582   93.21696071] 185.290205141\n",
      "positions (x,y,z), reward: [  10.75375154   -2.52439089  102.26545093] 291.527594383\n",
      "positions (x,y,z), reward: [  13.47664715   -3.29133555  111.35566883] 277.95241286\n",
      "positions (x,y,z), reward: [  19.03443249   -5.15090341  130.11841948] 269.026455232\n",
      "positions (x,y,z), reward: [  20.21141164   -5.60643886  134.35857182] 271.288076481\n",
      "positions (x,y,z), reward: [  27.22151083   -8.96253744  162.54706344] 207.368335901\n",
      "positions (x,y,z), reward: [  39.10002267  -17.48100757  215.94612463] 322.921020137\n",
      "Episode =  499, score = 381.183 (best = 444.213), noise_scale = 0.1positions (x,y,z), reward: [ -6.06047247e-07   3.04890028e-07   2.00699039e+01] -5.67154559287\n",
      "positions (x,y,z), reward: [ -4.42950510e-03   1.42316730e-03   2.32631448e+01] 6.78462284094\n",
      "positions (x,y,z), reward: [ -6.35718972e-03   3.91557423e-03   2.45342010e+01] 8.93372079382\n",
      "positions (x,y,z), reward: [  0.15915691   0.18796705  39.44447138] 67.7358029519\n",
      "positions (x,y,z), reward: [  3.02519224   1.91635755  84.90471063] 172.453762655\n",
      "positions (x,y,z), reward: [  3.3648122    2.1278321   88.26845284] 176.933091741\n",
      "positions (x,y,z), reward: [  3.82789999   2.43290629  92.75203377] 182.8892975\n",
      "positions (x,y,z), reward: [   6.67205548    6.99235825  135.23705722] 257.167243306\n",
      "positions (x,y,z), reward: [   6.51854542    7.89810463  140.44295175] 256.575990299\n",
      "positions (x,y,z), reward: [   5.91030222    9.40595758  147.9991695 ] 255.768492672\n",
      "Episode =  500, score = 322.133 (best = 444.213), noise_scale = 0.1"
     ]
    }
   ],
   "source": [
    "## TODO: Train your agent here.\n",
    "import sys\n",
    "import pandas as pd\n",
    "from agents.agent import DDPG\n",
    "from task import Task\n",
    "\n",
    "num_episodes = 500\n",
    "\n",
    "''' \n",
    "target = takeoff (go z up a little bit)\n",
    "#x = 0, y = 0, z = 10\n",
    "'''\n",
    "\n",
    "init_pos = np.array([0., 0., 20.,0., 0., 0.])\n",
    "target_pos = np.array([0., 0., 100.])\n",
    "\n",
    "task = Task(init_pose=init_pos, target_pos=target_pos)\n",
    "agent = DDPG(task) \n",
    "agent_scores = []\n",
    "\n",
    "for i_episode in range(1, num_episodes+1):\n",
    "    state = agent.reset_episode() # start a new episode\n",
    "    while True:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done = task.step(action)\n",
    "        agent.step(action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            agent_scores.append(agent.score)\n",
    "            print(\"\\rEpisode = {:4d}, score = {:7.3f} (best = {:7.3f}), noise_scale = {}\".format(\\\n",
    "                i_episode, agent.score, agent.best_score, agent.noise_scale), end=\"\")  # [debug]\n",
    "            break\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final position: [   5.84243679    9.53169924  148.58089305]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final position:\", task.sim.pose[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot the Rewards\n",
    "\n",
    "Once you are satisfied with your performance, plot the episode rewards, either from a single run, or averaged over multiple runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd13f81588>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# multiple runs\n",
    "\n",
    "plt.plot(range(len(agent_scores)), agent_scores, label='episode rewards')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single run - latest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900.28755292696178, 900.07195529116291, 899.93852739081933, 900.26024944608002]\n",
      "[900.03040069361634, 899.74849342622031, 899.34587042867997, 899.75646555879143]\n",
      "[899.7634719180603, 900.387688525302, 899.1539280163455, 899.63251246425352]\n",
      "[900.17091200136974, 900.6850048389872, 899.35016272864243, 899.53270632941155]\n",
      "[900.15108606183503, 901.0225228282776, 899.35515097341431, 899.33334863224832]\n",
      "[900.26707031683748, 900.50272870247863, 899.41115954249585, 899.73055964308935]\n",
      "[900.35257194173926, 900.11120899827688, 899.27303919270753, 899.56264649200648]\n",
      "[900.76513828027157, 899.76349071499556, 898.71200234338289, 899.56658957363516]\n",
      "[901.07361377740017, 900.09145434057405, 898.89544064951201, 899.97344330917861]\n",
      "[901.18839473732055, 899.96486099770038, 899.13947874525627, 899.5252585958799]\n",
      "[901.44852123043074, 899.98847629412876, 899.57216432399991, 899.56357602475339]\n",
      "[901.07906833982565, 899.7150930386457, 899.83556300599696, 899.74699288711463]\n",
      "[900.93286889566411, 899.98169187193594, 899.54655328763329, 899.81279066165985]\n",
      "[900.87267914038068, 899.95133021056972, 899.50759272739913, 899.64553715482282]\n",
      "[900.20556090408331, 900.32261345455424, 899.89785313888831, 899.47980049459306]\n",
      "[899.57857343473745, 900.2411525970133, 899.93597773625197, 899.87420584995425]\n",
      "[900.03446287079657, 900.09904801696507, 900.18489562364709, 900.00854893323287]\n",
      "[899.98977939499616, 900.07472744508254, 900.30393871171532, 900.38897291392607]\n",
      "[899.89720331923752, 899.61424408420908, 899.42251679740548, 900.24968193406994]\n",
      "[899.47579468964375, 900.14680514737904, 899.67682849563766, 899.86378737781899]\n",
      "[899.54396487127462, 899.79694983490378, 900.32140598656474, 900.01648369069869]\n",
      "[899.34416547368619, 899.88019557033442, 900.7240987449959, 900.10861701098918]\n",
      "[899.59162311445277, 899.54644418607529, 900.47227932194085, 899.90274919410672]\n",
      "[899.57809294343144, 898.9794048321337, 900.64540340750011, 899.93392374368295]\n",
      "[899.7864056256924, 899.066080777568, 900.57558456625327, 899.92446863450641]\n",
      "[900.40713864917882, 899.04084746030617, 900.38701209276644, 899.99953592952238]\n",
      "[900.26140419035914, 898.94567466239289, 900.05895384832309, 899.70554619832035]\n",
      "[900.13656026406068, 899.2146575747721, 900.37562118870869, 899.78142230744936]\n",
      "[900.55976417286092, 899.19661653899516, 900.47836796898991, 899.45064242808405]\n",
      "[900.53079218043138, 899.00576585522947, 900.47475224469576, 899.26596740131322]\n",
      "positions (x,y,z), reward: [  0.09287505   0.27654799  39.97175371] 67.8198177265\n",
      "[900.91045788435054, 898.6802281501358, 900.49476101315054, 899.21631629273941]\n",
      "[900.38281690865847, 898.67895889247143, 900.84513415851734, 899.8043067641438]\n",
      "[900.23518372365413, 899.00693316651086, 900.58085336155432, 899.66626831106385]\n",
      "[900.53616078153277, 899.46266606538552, 900.79574362961739, 899.9087554413403]\n",
      "positions (x,y,z), reward: [  0.17089066   0.39796773  44.22323675] 118.334915155\n",
      "[900.29496306558929, 899.18000438076103, 900.28760336771302, 899.97623124145889]\n",
      "[900.02624233506288, 899.0776923844785, 900.26452312870742, 899.69953645676082]\n",
      "[900.08715355624554, 899.33508949126872, 900.15617532335716, 899.84470038766494]\n",
      "[899.69891428550454, 899.9431136433252, 900.49078639350989, 899.55599872412517]\n",
      "[899.33180177848442, 899.84579329526696, 900.04827460967215, 899.54436012100996]\n",
      "[899.18539217209343, 900.37451268190011, 899.90051152051399, 898.81665521825744]\n",
      "positions (x,y,z), reward: [  0.35272403   0.61005016  50.76891223] 118.617929473\n",
      "[899.02184794698587, 900.75724863749008, 899.86383406671041, 899.38919009405743]\n",
      "[898.90549233900617, 900.59799030449119, 899.92307906218218, 899.49349269100162]\n",
      "[898.42387812182824, 901.0248750037523, 900.00727665162776, 899.55356931667075]\n",
      "positions (x,y,z), reward: [  0.48105402   0.72386092  54.09409672] 168.621230564\n",
      "positions (x,y,z), reward: [  0.50520355   0.74301411  54.65103519] 168.614841325\n",
      "[898.47744674384535, 901.08072641872718, 899.93307383594617, 899.59715854097169]\n",
      "[898.44434522755716, 900.83409726403136, 899.70465134495896, 899.6583960340414]\n",
      "[898.66632961248501, 900.42642171542184, 900.26951394114212, 899.56526267249319]\n",
      "[898.62669712363606, 900.51028604511487, 900.74659197308893, 899.83098111049435]\n",
      "positions (x,y,z), reward: [  0.69742673   0.87632483  58.56844373] 168.51300996\n",
      "[899.41181559858614, 900.52910954520985, 900.83764255500603, 900.44311444736536]\n",
      "[899.44123808570282, 899.93576853868558, 900.8715112685029, 900.6353622183351]\n",
      "[899.829906440385, 900.29851829984079, 900.533689562934, 900.52097733622429]\n",
      "[900.28890038997815, 900.00000008454003, 900.383758059, 900.29857786834827]\n",
      "[901.05367401172896, 900.27136123711171, 900.6272687384444, 900.88600086654708]\n",
      "[900.51446904979025, 900.2141742101428, 900.09741004214027, 900.58455377316238]\n",
      "[900.42234732803809, 900.32477969064928, 899.98682583678044, 900.90582071860274]\n",
      "[900.44440008426182, 900.88419595002824, 900.20401868609065, 900.98598677271173]\n",
      "[900.30639500573977, 900.55462548451737, 900.32788696642774, 900.53053221505206]\n",
      "[900.73377603194228, 899.90298471810445, 900.00360841797703, 900.66756970530537]\n",
      "[900.19338928996183, 899.7955437065923, 899.52705591261906, 900.4342420375757]\n",
      "[899.9507851312128, 899.98069558919667, 899.96785323636516, 900.46912058544024]\n",
      "[899.37422656122726, 900.02290063366536, 900.1056362273697, 900.12137492073566]\n",
      "[899.57658748419612, 900.5221382438416, 899.92722395060105, 900.11483534803881]\n",
      "[899.88541261334854, 900.07026518215253, 899.94455737863473, 899.7346634108535]\n",
      "[900.14636126797393, 899.70308507432526, 899.64809518080233, 899.26095563041747]\n",
      "[899.90175566606604, 899.87878611172653, 899.45883363565838, 899.39125729026489]\n",
      "[900.17530803456623, 899.16629872004501, 899.35144219227345, 899.60173814748066]\n",
      "[900.65347529666053, 898.92852219284896, 899.62134794479823, 899.63513772326871]\n",
      "[900.32305330824772, 899.20375817019715, 900.06148652476998, 899.69429289358811]\n",
      "[900.49733117013511, 899.24788462679476, 900.1441682466683, 899.16905980027695]\n",
      "[900.12054906007029, 899.05807572741776, 899.83051251262771, 899.40080168784266]\n",
      "[900.65716192031391, 899.05269606156583, 900.06558085125675, 899.22482367851967]\n",
      "[900.31724012779955, 898.98911024885376, 900.44034969675886, 898.83097127004157]\n",
      "[900.12594222806376, 899.21053458628171, 900.19469043899801, 898.90421625525016]\n",
      "[900.30273680823473, 898.9947871385923, 900.48291076686462, 899.13685090913145]\n",
      "[900.29000546399777, 899.31809467951325, 900.30048927131315, 899.29792430873522]\n",
      "[900.09376903660154, 899.47379335986591, 900.44738124763683, 899.23525607686452]\n",
      "[899.75606561618281, 899.36621831001719, 900.31997949534832, 899.59500743647277]\n",
      "[899.29126321442368, 899.33582633490005, 900.38886719196864, 899.59500341869591]\n",
      "[899.70562459090127, 899.54891562504645, 900.5971479476259, 899.46101290221122]\n",
      "[899.16397040181448, 898.83803501099283, 900.20084051638003, 899.65602206818528]\n",
      "[899.81117361327381, 899.4849912638465, 900.50654400129486, 899.73542559261318]\n",
      "[900.01988559794609, 899.98591176355774, 901.09229067826948, 899.65815499228847]\n",
      "[899.59260920471081, 900.25411211597248, 901.11438819645957, 899.98614876387433]\n",
      "[899.64218333427266, 900.01936009125814, 901.5619773090358, 900.06538345458887]\n",
      "[899.48509990926891, 899.69918041643257, 901.89529013568051, 900.36066484815194]\n",
      "[900.04561280440657, 900.29877326803773, 901.58357018302229, 900.88215301974867]\n",
      "[900.08642586461565, 899.93223755549263, 900.94834884381851, 900.5135203415465]\n",
      "positions (x,y,z), reward: [   6.0319426     0.39984916  103.5896155 ] 288.853309852\n",
      "[900.36044908859958, 900.27978152218088, 900.64322055356217, 900.46667167440535]\n",
      "[899.98814064459475, 900.19269299122016, 900.20971785137215, 899.99591809007882]\n",
      "[900.37892803303941, 900.40849120328301, 900.4118622589009, 899.72480189198302]\n",
      "[900.32302631785933, 900.05724297330005, 899.96673431041984, 899.96750694562979]\n",
      "[900.32711168748688, 900.06861355535636, 900.5310735693746, 899.79784860874042]\n",
      "[900.03083020672761, 900.41241502026253, 900.24192147380268, 899.74866281790025]\n",
      "[900.32320193124349, 900.19225557375933, 899.85041552767916, 899.96949432255019]\n",
      "positions (x,y,z), reward: [   7.68608028   -0.52777557  111.0439195 ] 275.83902756\n",
      "[900.13434552833348, 900.31094531045528, 899.42085987171379, 899.44577598511125]\n",
      "[900.00704937347064, 900.78724822607342, 899.7977899565949, 899.63120672797334]\n",
      "[899.31394712677297, 900.70726512857482, 899.47182591022556, 898.94164486326599]\n",
      "positions (x,y,z), reward: [   8.56423099   -1.12038724  114.47297049] 269.109162251\n",
      "[899.74687511686886, 900.77579399177318, 899.26763923325655, 899.3943838078311]\n",
      "[899.75097802943515, 900.92156147213905, 899.08213325052816, 899.10717933290846]\n",
      "[899.93584336490619, 900.83827507327385, 899.48817765658998, 899.32991591784014]\n",
      "[899.81298336195687, 900.99443593358171, 899.23431305317717, 899.39759054766944]\n",
      "[900.03262461921349, 901.06968066951845, 898.79292029532178, 899.10762846938394]\n",
      "[900.06070779231538, 900.91387087975431, 899.10017335882299, 899.72257594250107]\n",
      "[899.86134577016878, 900.96073486877822, 899.26304614874084, 899.84068945261106]\n",
      "[900.25010180538777, 901.08373973483288, 899.36409353844556, 900.1011562059532]\n",
      "[900.12437836068545, 900.84327849641409, 898.97290715994779, 900.41185298641176]\n",
      "[900.07157616049119, 900.78018081497078, 899.0471326056653, 900.43237843235545]\n",
      "[900.8256650451267, 900.65569037808109, 898.9994341113528, 900.35118975460341]\n",
      "[900.85753682514928, 901.24580315824824, 899.34080305991847, 899.92949113151769]\n",
      "[900.18722957809371, 900.48767387285989, 899.37717060195951, 900.37363671444291]\n",
      "[900.45536975795881, 900.44304442816133, 899.82897959919035, 900.00010751607078]\n",
      "[900.63135935669902, 900.45708160898278, 899.87473522855714, 900.21157219003612]\n",
      "[900.54430567584063, 899.82735131607933, 900.50137233801843, 900.24816176369848]\n",
      "[900.56423338861623, 900.0110473995353, 900.96523050511325, 900.07759552842197]\n",
      "[900.86947588300188, 899.45072884654769, 900.98783768635178, 900.27479302369318]\n",
      "[900.88920684713912, 899.56950096846185, 901.06049031382997, 900.73596701431234]\n",
      "[900.81972187179326, 899.59874597581234, 900.6717847951852, 900.84155688936517]\n",
      "[900.90140216955035, 899.56861085154264, 900.88254633227643, 900.84694071681747]\n",
      "[900.66039335732398, 899.12822985360219, 901.15001932810196, 901.18194739576029]\n",
      "[900.57788037843727, 898.91209612956368, 901.1947132572077, 901.02521890605385]\n",
      "[900.62474448385638, 899.16680930578968, 901.05565166161944, 900.97298867281415]\n",
      "[900.75588415653885, 899.39351496434278, 900.76130548020149, 900.73194920740798]\n",
      "positions (x,y,z), reward: [  19.10306998  -11.06140813  141.16699003] 235.630906452\n",
      "[900.57571892447993, 899.65203605627175, 900.59636606340689, 900.82987196925956]\n",
      "positions (x,y,z), reward: [  19.63979321  -11.63974133  142.11300082] 234.21425552\n",
      "[900.56498712893472, 899.30127492029112, 900.09065474813042, 900.94616923365834]\n",
      "[900.62739907726689, 899.86846609726922, 899.632905626411, 900.75689766948108]\n",
      "[900.50492706321756, 899.50893563722752, 899.80396267596416, 900.38911033998124]\n",
      "[900.23459217214838, 899.82987857836872, 899.4859443536277, 900.23879744038038]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "done = False\n",
    "labels = ['time', 'x', 'y', 'z', 'phi', 'theta', 'psi', 'x_velocity',\n",
    "          'y_velocity', 'z_velocity', 'phi_velocity', 'theta_velocity',\n",
    "          'psi_velocity', 'rotor_speed1', 'rotor_speed2', 'rotor_speed3', 'rotor_speed4','reward']\n",
    "results = {x : [] for x in labels}\n",
    "\n",
    "\n",
    "state = agent.reset_episode() # start a new episode\n",
    "while True:\n",
    "    action = agent.act(state)\n",
    "    print(action)\n",
    "    #action = [500.,500.,500.,500.]\n",
    "    next_state, reward, done = agent.task.step(action*np.ones(4))\n",
    "    agent.step(action, reward, next_state, done)\n",
    "    state = next_state\n",
    "    to_write = [agent.task.sim.time] + list(agent.task.sim.pose) + list(agent.task.sim.v) + list(agent.task.sim.angular_v) + list(rotor_speeds) + list([reward])\n",
    "    for ii in range(len(labels)):\n",
    "        results[labels[ii]].append(to_write[ii])\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318.673319555\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcccbf53470>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['reward'], label='rewards')\n",
    "plt.legend()\n",
    "_ = plt.ylim()\n",
    "print(agent.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccd00f3da0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Run the code cell below to visualize how the position of the quadcopter evolved during the simulation.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(results['time'], results['x'], label='x')\n",
    "plt.plot(results['time'], results['y'], label='y')\n",
    "plt.plot(results['time'], results['z'], label='z')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccd0067198>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The next code cell visualizes the velocity of the quadcopter.\n",
    "\n",
    "plt.plot(results['time'], results['x_velocity'], label='x_hat')\n",
    "plt.plot(results['time'], results['y_velocity'], label='y_hat')\n",
    "plt.plot(results['time'], results['z_velocity'], label='z_hat')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcccbe794e0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next, you can plot the Euler angles (the rotation of the quadcopter over the $x$-, $y$-, and $z$-axes),\n",
    "\n",
    "plt.plot(results['time'], results['phi'], label='phi')\n",
    "plt.plot(results['time'], results['theta'], label='theta')\n",
    "plt.plot(results['time'], results['psi'], label='psi')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XlclVX+wPHPYUdlUTZBUBBREFlU3PctzbXMpcZSKzOzbZrfNNk007RM077aapZaWlmWmqW5556KioKIiIqAC6uigMj2/P44mBvKcpfnXjjv14vXhXuf+5zvFfnec89zzvcITdNQFEVRGhYbvQNQFEVRzE8lf0VRlAZIJX9FUZQGSCV/RVGUBkglf0VRlAZIJX9FUZQGSCV/RVGUBkglf0VRlAZIJX9FUZQGyE7vAG7G09NTCwwM1DsMRVEUq7Jnz54cTdO8qjvOKMlfCDEMeB+wBeZqmvbadY/3Bd4DIoG7NU1bUt05AwMDiY2NNUZ4iqIoDYYQ4kRNjjN42EcIYQt8BNwOtAfuEUK0v+6wNGAq8I2h7SmKoiiGM0bPvyuQomnaMQAhxHfAGCDx8gGapqVWPlZhhPYURVEUAxnjgm8LIP2qnzMq76s1IcR0IUSsECI2OzvbCKEpiqIoVTFG8hdV3FenOtGaps3RNC1G07QYL69qr1coiqIodWSM5J8BBFz1sz9wygjnVRRFUUzEGMl/NxAihAgSQjgAdwM/G+G8iqIoiokYnPw1TSsDHgNWA4eA7zVNOyiEeEkIMRpACNFFCJEBjAc+E0IcNLRdRVEUpe6MMs9f07SVwMrr7nv+qu93I4eDlJsoLi1n9cEz+Lo50zWomd7hKIpSz1nsCt+GorS8gg83pPD1HyfIKywBYHrf1vz9tnY42KnqG4qimIbKLjpbsD2V99cfoVNLd75+sCv3dm/JnM3HGP/pdgoulekdnqIo9ZTq+RtJ1vlifo0/zar4M2ScLWLO5Bg6tHC75XOKSsr4dNNRerXxYO6ULgD0CfGiZ7Anj32zl1d+TeTVsZHmCF9RlAZG9fxr4UjmBeLSz5FwMp/sC5cAOWzz2aaj9H1zIy+uSCT/YikVGkyau5OEk/m3PN9XO06QU1DC34a0veb+4RG+TO8bzLe70tmYlGWy16MoSsOlev41oGka76xNZvaGlGvub+HujIOdDcdzChnS3odnhoXSxrsJ6XlF3D3nDybN3ckj/YMJ9mpCuJ8rfu7Ofz634FIZn206Sr+2XnRudeMF3qeGhLAxKYtnfjzAmqf64t7IweSvU1GUhkNoWp0W45pcTEyMZglVPcsrNP61LIFvd6UxrrM/IyJ8uVRWQcbZIuLSz3E6v5iH+rRmWIfm1zwvPa+IB+bv5khWAQBCQP+2Xkzs0pKikjJ+SzjDmsRMlj/ai6gA9yrbTjiZzx0fbWNIex8+ntQJIapaTK0oinKFEGKPpmkx1R2nev7VeHvNYb7dlcbM/sE8PbRdjRNwQLNGrP1bP/KLSjmWU8Dvh7P5ZlcaGxfuAcDZ3pYHewfdNPEDdGjhxt+HtuO1VUks2pnGvd1bGeU1KYqiqOR/C8Wl5XyzK43hEc35x7DQOp3DrZE9HVs2pWPLpjw6oA27jufh7epIsFcTbG2qfyOZ3qc124/m8tIviXRu1ZQwX9c6xaEoinI1dcH3FtYkZnKuqJS/dDVOj9vBzobeIZ609XGpUeIHsLERvDMhCndnex77Zi+XysqNEouiKA2bSv63sHh3Gv5NnekZ7KFrHJ5NHHljXCRHswv5YutxXWNRFKV+UMn/JtJyi9iWksvEmABsathLN6X+7bwZ0t6H2etTOJ1/Ue9wFEWxcir538T3senYCBgXYzkliZ4f2Z5yTeN/K5P0DkVRFCunkn8VSssr+GFPOv3beePr5lz9E8wkoFkjZvQLZsX+U+w4mqt3OIqiWDGV/KuwdO9JMs9f4j4LnFr5SL9gApo588+l8RSXqou/iqLUjUr+1ykrr+DDjSlEtHCjfzvL20rS2cGWV++M5HhOIe+vP6J3OIqiWCmV/K+zPO4UaXlFPDEoxGJX1PYO8WRCjD9zNh+rtn6QoihKVVTyv0p5hcaHG1No7+vK4DBvvcO5peeGt6dZYwee/G4fWeeL9Q5HURQro5J/pfIKjffWJXM8p9Cie/2XuTWy54O7O3I6v5i7Pt3OidxCvUNSFMWKqORfXkb2zu/514fzmL0hhZGRvtzW3kfvqGqkR7AH3z7UnYLiMu76ZAfxGWoISFGUmmnYyf/IWi681w2vVQ/xat5TbAn+mtnDPS1iUVdNRQW488OMnjja2TD+s+2sjD+td0iKoliBBpX8Kyo0fj+cxcI/TrB7xeewaBw5+Rd40/VZznf7GwGZGxGf9oGLZ/UOtVbaeDdh+WO9aO/rysxFe/lSlYBQFKUaDaKqZ3mFxqKdJ5i3LZXjOYXYUMEah3c4REt+ilnI08Mj5GbpESNh7kDYtwh6PqZ32LXi2cSRbx7qzhPf7uO/vyYSFeBO51ZN9Q5LURQLVe97/pqm8fIviTy//CDujez54J6O7B13kTY2p/Aa/hzPjY6SiR/AvzMEdIfdc6GiQt/A68DJ3pa3J0Th5+7MXxfv40Jxqd4hKYpioep98p+75Tjzt6cyrXcQS2f2YnSkL+67PwCPEDy7jr/xCV0fgrPH4egG8wdrBC5O9rw3MZqTZy/yws+JeoejKIqFqtfJ/+f9p3hl5SFGRPjyz+Fh8s4jayAzHvr8DWxsb3xS2Gho7A275pg3WCOKCWzGYwPa8OPeDPacsK7rF4qimEe9Tf7L407y1+/20TWoGW9PiJIzeEoKYd0L4N4SIqro9QPYOUDM/fJNIs96L5w+3C+YJo52LPrjhN6hKIpigYyS/IUQw4QQh4UQKUKIWVU87iiEWFz5+E4hRKAx2r2ZJXsyeGpxHF2DmjFvahec7G1B02DZI5CdBCPeBVv7m5+g8/3yU8HuuaYM06QaO9pxZ8cW/BJ/mrOFJXqHoyiKhTE4+QshbIGPgNuB9sA9Qoj21x32IHBW07Q2wLvA64a2ezMpWQX8Y8l+egZ7Mm9qVxo7Vk5o2vwmJC6HwS9CyOBbn8TVF8JGwb6v5acFK3Vv91aUlMny1IqiKFcTmqYZdgIhegAvaJo2tPLnZwE0TXv1qmNWVx6zQwhhB5wBvLRbNB4TE6PFxsbWKaaZq56nkDRsLpdouHgOMhOgiTd4tq3ZSS6dh9MHwKMNuDSvUxyW4OCp85SWVxAd4K53KIqi1FBos1Ce6fpMnZ4rhNijaVpMdccZY9inBXB11zKj8r4qj9E0rQzIB27YGFcIMV0IESuEiM3Ozq5zQK2ci68k/ooyyD0C9s4ykdeUoys4NIYLp+ochyXwcXWkuLSc/Itq2qeiKFcYY5FXVbUQru/R1+QYNE2bA8wB2fOvUzS5R3lm85cQPABGvQ8bX4GTJ+HBteBf7ZvhtfYtguUzof8H0LpfncLR26Wycnq8ugFfdw8+urOT3uEoimIhjNHzzwACrvrZH7i+u/znMZXDPm5AnhHavlHTIBj6P0jdCh92hX0LodeTtU/8AB3ugkYesPMz48dpJo52toyI8GX9oUwKLpXpHY6iKBbCGMl/NxAihAgSQjgAdwM/X3fMz8CUyu/HARtuNd5vEBsb6DYdZmwFv2hoEQP9n63bueydoOO9kPwbFFrvnrmjo/0oLq1gbeIZvUNRFMVCGJz8K8fwHwNWA4eA7zVNOyiEeEkIMbrysC8ADyFECvA34IbpoEbnEQxTf4Fp68DOse7niRgPWjkcWm682Mysc8um+Lk58XOcdV+/UBTFeIxS2E3TtJXAyuvue/6q74uBm6yqMjFDN2Xx6SBnCCX8BDEPGCcmM7OxEYyK8uOLrcc5W1hC08YOeoekKIrO6u0KX6MRQo79p26F89ZbK390tB9lFRorE6z3NSiKYjwq+ddE+FhAg8RlekdSZ+19XQn2asxyNfSjKAoq+deMV1toHgEJP+odSZ0JIRgd1YJdx/M4k682fFeUhk4l/5rqcBdk7IazqXpHUmcjIuVK5dUH1awfRWnoVPKvqfA75W3Sr/rGYYA23i609WnCr9a8z++pOPmlKIpBVPKvqaaB4NkOjqzVOxKD3N7Bl92peWRdsMKhn/Rd8OUwmNMf1v4Hyi6Zp92iPMg7Zp62FMVMVPKvjZAhcGIbXCrQO5I6Gx7hi6bB6oOZeodSO9nJ8M0EWXG14yTY9h58PkgW7TOVnBRY8Vd4pz181A1S1puuLcX0Kirg8Co48L2s8Jt5UO+IdKWSf22E3AblJZC6Re9I6qytTxOCvRqzypqGfi6cgYVjwcYO7v0JxnwEd38jK7Vue880bRbmyk8Ycd9AxDj5qe+7SXBiu2naU0zr/Cn4+g749m746SH4fjJ80hPmDpZvBiYqOGDJjLLIq8Fo2QMcmshdvtrdrnc0dSKEYHiELx9tTCGn4BKeTQxY/WwOJUXyD7YoD+5fCc2C5P2hIyByAvzxCXSdDq5+xm13z5dQcgFmbIPmHaAgG+YPh0UT5CdARxdZPPDytSDFcqWsgx+nyWHCke9BYB8oK5aduN1z5ZvBpQvQ5UG9IzUr1fOvDTsHaN1fjvtbcU/h9g6+VGjwW4KFz/qpqICl0+UF3nFfyFpNVxvwT6goh99frfr5V59n79fwaR/IqMEeEWWXYNfn0GawTPwATbxg8nII6AJnDsDBZbDsUSjOr9trU0yjpBCSV0PpRflz/BL4ZiK4toCHN8stWj3byN9r90fgsVho1Rs2vCw7GA2ISv61FTIE8tMh+7DekdRZmK8L7XxcWLzbwnf42voOHFohq7RW9UmraSB0mSYrt2YnV32OzET4YjD8/BiciYc1/67+jTvhRyjIhB6PXnu/qx/ctxQe3wNTlkNpIcR9W6eXppjIyn/Ia0Nvh8IPU2WPP6A73L8KPENuPF4IuP11+Sa+8X9mD1dPKvnXVpsh8vbIGn3jMIAQgkndWxJ/Mp8DGSa8YGqI8jJZSjvkNtlDu5m+fwf7xrDoLkjbee1jmYlyqOZcGtz5Gdz+BqRth+Obbn4+TYMdH4F3e2g94ObH+XWUFWN3z7XqT4H1SkYsxC2UxRiDB8KhX6DdcLj3R3ByvfnzmneQnYjYL+BMgvni1ZlK/rXl1gK8w606+QPc0bEFzva2fLMzTe9QqpayDgqzoPPUWxfna+wJ9/0kv593O6x9HtJ3Q9Yh+GoM2DrCg2sg6m7oPEV+/N/4v5sn7KMb5IXkHo9WXxSw60Nyl7hjv9flFSrGVFEOv/4fNGkOI9+F8fNg1gm4e5EszV6d/s+Ckzv8/DiUlZg+Xgugkn9dtBsmZ31Y8Rihq5M9o6P8WB53ivPFFrjFY9wiaOQpe/7VCegq92+IGA/b3pfDPB93l6W4Jy+HZq3lcXaO0Of/IH0nHK1i2mZpMaz6B7i3hA7jqm+3/R1ys5/dc2v32hTj2/c1nI6D2/4rL8aD3Ia1plV9GzWD0R/Aqb2w5l+mi9OCqORfF+2Gy8Ri5Qu+/tKtJRdLy1m+76TeoVyrMFfOx46cCLb2NXuOkxuM/Qz+LxkmfAX9noGpK8E79NrjOt4Hbi1h5dOQf93r3vQa5KbAqA9q1lu0d4JOk+HwSsjPqFmcivFdPAvrXoSWPeW03LoKGwXdH4Vdn8HBpcaLz0Kp5F8Xfp3kx8vD1lvqASDS340OLVxZ+EcaptpYrU4SlkBFKUT/pfbPdfGB9mPkTKDrEz/IGVt3fS6nbn45DHKPyvtPxcG2DyD6XjmFs6ai7gGtQi0A09PGV6H4HAx/w/D9O4a8CP5dYfnjVr17X02o5F8XNjZy6CdlvflKDJiAEILJPQI5nHmBzUdy9A7nirhF4Bt1ZZqlsbXsDlNXQEkBzBkA70bAl0Pl9YOh/63duTzbQmNvufJbMb/MRDns1vl+WXnXULb2cvZPyQWrv65XHZX866rdCJk8jm/WOxKDjIn2w8fVkc82HdU7FOnsCTi9Xw75mJJfRzn9L2QIBPaSu7RN+gGcm9buPEJAq55q5a8eNA1+e0aO8Q804ji9X0dw8ZV7d9djaoVvXQX1lVMMk36VCcQUNE1ewMxPB5fmENBNtmtEjna2PNAriFdXJRGfkU+Ev5tRz19r6bvkbWBv07flHSoXjxmqVS+50c/ZE9C0leHnU2rm8CrZ+Rr+lrxgayxCyIkGB5fKmT929XPbU9Xzryt7J2gzSP4HrKgwTRtb34V1/5G1Rzb8FxaMMsm0wnu6tcTF0Y7PNltA7z9jl3xT9Q7XO5KaC+wlb1Xv33w0DX7/HzQNktOBja3tMLh0HtJ2GP/cFkIlf0OEjoSCM3LhkLEd3SiXnIePhVlp8suzLSx9xOhTTF2d7PlL95asjD/NidxCo5671tJ3QYtOYGtFH0q9wuRw0YmtekfScCT9Ilds9/tHzWeE1UbrfnKNSPJq45/bQqjkb4iwUfKP/o9PjHvezIOw5AFZSXL0bPkx1MkNxn4uFz798pTRV5U+0CsIOxsb5mzWsW59SZFcYBXQVb8Y6sLGRk4zVD1/86iogN9fh2bBEDHBNG04NJZDrPV43F8lf0M4NJIXCpN+Nc5mH5cuwOrn4LPKcf2JC8GxyZXH/aJhwHNyfNnI+wn7uDpxV2d/ftiTQdZ5nTZ6ObUPKsrkVDtr06qn/D9w3opKZVurpF8gM16u5TDlJ8S2QyHvqNzXoR5Syd9QXR6SdeZ3fmbYecpLYd5w2PGhnDv+WKysPni9Xk/KdQarn5NvFkY0o19rysor+GLrcaOet8bSK2vz+HfRp31DtOopb9WUT9Pb9h54tDFsQVdNtB0qb5NXmbYdnajkbyhXX+gwVlaWNKS8744PZang8fNhzIfQ2KPq42xsZYGygjOw5e26t1eFVh6NGRXlx8I/TpBfpEPJh4zd8o/6Zq/dkjWPBAcXq97oxypkHYKTeyDmQfm3YEruLcGnAyStNG07OlHJ3xi6z5Rz/vcsuPkxFRVyKmDyGjle+c3dsohUYQ7kHZf3hY6s2eYgAV0g6i+w/cMrK1SN5JH+wRSWlPP5FjOP/WuavNhrjUM+IIcfggfISpLlFlgrqb7Yt1B+0o400Vj/9cJGyRk/BVnmac+MDEr+QohmQoi1QogjlbdVrpARQvwmhDgnhPjFkPYsll+03B1o56dV/+HvnguvtoD3I+Gb8XLzkdwUWQv+o27ww5QrPfqaGvwfsHOS9emNKLS5KyMifflwYwrPLY2nuLTcqOe/qbPHoShHvrFZq+hJ8jXU85Whuikvhf3fyb0dGnuap83QkYAmr+vVM4b2/GcB6zVNCwHWV/5clTeB+wxsy7L1fALOn7zxQmzuUfjtn+AbLbeQu3+VnLb5eCw8vEmWiD69X65QdGtR8/ZcmkPXaXI80shTP9+dEM3DfVuzaGcad3y0jZwCM5SwSN8tb6215w9y56/G3rBvkd6R1E/Jq+Wba0czphKfcLmW4NAK87VpJoYm/zHA5bGOBcAdVR2kadp6wLhXJy1NyBA533vbB1emYWoarHhS9tDHz5NbyLXqeWVjCZ9wmLYeHlgD3WbUvs3QUbKomJHnIjvY2fDs8DDm39+F4zmFPLU4jooKExd+S/9Djpl7h5m2HVOytYOoiXBktSwcpxhX3CJZUDF4kPnaFEIO/RzfDBctdOOjOjI0+ftomnYaoPLW2/CQrJQQ0PNxyDp4pVZ83DfyAuCQF2VPvSq29tCyW92qEfp1NGl10f7tvHlhdDhbjuTw8e8mnu52Yof8dzD1RTxTi54kp6vGf693JPXL+dOykxN1t/kXAIaNklVm69lwXrXJXwixTgiRUMXXGGMHI4SYLoSIFULEZmdbYc8pYrwsCLXm3/DVHbLX37IHdJpimvZsbOT4Z8oGuRGJCdzdJYAx0X68szaZraaq/FmUB9mH5L+VtfMOk1Nx9y1S2zsa0/YP5G3M/eZvu0WM7GQd+tn8bZtQtclf07TBmqZ1qOJrOZAphPAFqLw16JK4pmlzNE2L0TQtxsvLy5BT6cPOQc7Dz0qE86eg28Mwbp5M0qYSOkJuJH6rfWkNIITglTsjaO3VhKnzdvHppqPGHwJK+0PeXp4rb+2i/yI/AWY2nP1gTepCJsR+KXv9TQPN376NDYSNhCProETn8idGZGhW+hm43K2dAiw38HzWr9sMePoYPLYLhr4i1wGYUlBfcGhi0tkITRzt+PGRngxp78Nrq5J4YMFuysqNWMwubTvYOsgec30QficImwaxG5RZ7JgN5SVyC069hN8JZRdlIcd6wtDk/xowRAhxBBhS+TNCiBghxJ8bmwohtgA/AIOEEBlCiKEGtmu5hDDvIiU7RznLJPk301UXBdyc7fl4Uif+OTyU3w9nsyrhjPFOfmIHtOhcs60TrUFjT/mmnPCTGvoxVGEO7P5C7qnsEaxfHC17yCHdhJ/0i8HIDEr+mqblapo2SNO0kMrbvMr7YzVNm3bVcX00TfPSNM1Z0zR/TdPqb6k8PYSOgIJMOBlr0maEEEzr3Zogz8bM3XLMOFs/lhTKjbfrw3j/1cLHyrULp/frHYl1++MTKL0Iff+ubxw2tvJ3mrK23sz6USt864OQ2+SqRzPMRbaxEUzrE8T+jHx2HTfC+oKM3XJ2TH0Z778sbJT8nRysPz1Fsysrgb0LZG19r3Z6RwMRd8nhp6T6sVZVJf/6wNkdgvrJ5G+GYYa7OvnTrLGDcUpAnNgBCOsr41ydRs2gdX857q+Gfurm8K9QmC0r51oCv05ywVf8Er0jMQqV/OuLsFFymCHzoMmbcrK3ZXKPVqw7lMXR7ALDTpa2XW7U7qTz9pGmEH4nnEuDk3v1jsQ6xc4DtwC5Y54lEAI63CVn1tWDRXwq+dcXoSMAYbZl6Pd1b4WTvQ3P/hRPSVkdLzRXVEDGnvo33n9Z6AiwsYf4H/SOxPrkHpVJtvMUy1r4FzFOrqpPXKZ3JAZTyb++aOItx83NtBDFo4kjr98Vya7jeTy3NL5uF3/PHpdrFJpHGD9AS+DcVL4BHPjOZIvw6q098+U1E3PW8akJ7zC5nWo9qPWjkn99EjZKLjAz085DY6Jb8NfBIfywJ4NPN9Vh/D8rUd5a4Gbt8Rn5/GtZPPO3HTessmnnqXDxbL1IFmZTViLr+LS7/eZlUfQUOhJStxq9oKK5qeRfn4SOlLdJ5ks0Tw4KYUSEL2+vOVz76p+ZiYAA71CTxFYbfxzL5cMNR3h11SH+8vkfjPpwK9/vzuCFFYn0fn0j87cdr9unm6B+clXqnvnGDrn+OroeinItr9d/WdhI0MqtfnN3lfzrE/cAuVgq7luTLvi6mhCCp4aEUFah8dPejNo9OeugTIwOjU0SW01tS8lh0tydvLUmmXlbU0k/W8Ss20OJ/fdgFk/vTrvmTXhhRSLP/hR/w8rmc0UlzN1yjDd+S+KFnw+yNjHz2pPb2MjaTie2Qs4RM74qK3bge2jkAcED9Y6kan6dwLWF1U/5NHN5PMXkuj4MS6fLxShtzbOQuo23CzGtmvLd7nQe6tMaUdMKpZmJsqy1jo7nFDJz0V6CvRrzw8M9cWtkf83j3Vp7sDCoGe+sTWb2hhRyCkp4bGAbWjVrxLpDmby6Kom8whLsbAT2tjbM357KU4Pb8sSgNlf+HaInwcZXZO9/6Cvmf5HW5NIFWUKh4yRZ8dYSCSGv5ez9Si5S1LnzUleq51/fdBgLrv6w7X2zNjuxSwDHsguJPXG2Zk8ovQh5R8G7vWkDu4ULxaVMW7AbGwFzJ3e5IfFfJoTg/25rx0tjwlmflMkdH22j48treXrJAYI8G7PyiT4ceeV29v/nNsZ2asG765L5vx/2XymA5+ID7YbLEt/lZWZ8hVYo6VdZQydivN6R3FroSCgrhpT1ekdSZ6rnX9/Y2kOPR2H1s3J3LDNtizgi0pcXVyTy3a50ugQ2q/4J2YfllDkf/ZL//G2pHM0u5NuHutPSo1G1x0/uEciAdt4knblAak4hPm5OjIzwxcZG9vAd7ARvj4+ihbszszekMLyDL4Pb+8gnh98hZ2KdjgP/GFO+LOt24Hu5cXpAN70jubVWveRsrqRfoP1ovaOpE9Xzr486TQYnd9huvt5/Iwc7Rkf78Wv8Kc4X12ADc51n+hSXlrNgRyoD2nnRI7jmhfgCmjViSHsfHurbmtFRfn8m/suEEDw5KAQ/Nye+3Hb8ygNB/eTtsY1GiL6eKsiCY7/LIm512dzInGztoO3t8qJvhZn2uTYylfzrI8cm0GUaHPoFzp4wW7N3dwmguLSC11clVT8zJvMg2DpCs9bmCe46P+7NIKeghOl9jV8p0s7Whvt6BLL9aC5JZ87LOxt7gk8EHDPNvgv1QvwPchZN5AS9I6mZNoOg+Byc2qd3JHWikn991fFeQDNpnf/rRfq783A/ufH77A3VrDXISpTFusy9JR9QXqExd8txovzd6N66BkNUdXBP1wCc7G2YtzX1yp2t+0H6TigpMkmbVq28VFbwbNnDevZxDh4ICKsd91fJv75qFiSHVMyY/AFmDQtlbKcWvLM2mUU7b/GpIzNRt4u9axPPcDynkIf7Bdd8ZlItuTdy4K5O/iyNO0nu5fUPrfvLqpDpf5ikTat2cBnkp8ud8KxFo2ZyH+2jKvkrliZ0uCycVphrtiaFELx+VyQD2nnx3NIEFu9Ou/GgojwoOKPLxd6y8greW3eEVh6NGBpu2tWj9/cKpKSsgnfXJcthsJY9ZK2fY7+btF2ro2lydppnOwixsn2eggdCRqxV1vhXyb8+Cx0hZ9QcMe9KRHtbGz65tzN923rxzI/xN74B6Hixd962VJLOXODZ28OwtTHtRcU23i7c3yuQhX+k8eqqJDSHxuDfRY37X+/oBsiMh15PmHa/a1NoM0hepzi+We9Ias3K/qWVWvGNrlyJaN6hH5Bln+fc15l+lW8AP8SmX3kw65C8NfPYbsbZIt5Zm8zgMG+GhvuYpc3nR7ZnSo9WzNl8jNd+S5JDP6f3W31dGKPa/oHcItHS5/ZXxb8LOLhY5dCPSv71mRBycVHKel0uMjrZ2/LZfZ3pE+LJMz8e4NcDp+UD2YflH4yrn9lU4okHAAAgAElEQVRiqajQeH75QYSAF8d0MNlY//WEELwwOpy/dGvJZ5uOcaRJJ0Czyp6iSZxLk8NgMQ/I/aitja29vJCfssHqNu1Ryb++Cx0hV0zqNL/88htA51ZNefK7faw+eAayk8CrrVnmcmuaxm8Jp7n9/S1sSMrib0Pa0sLd2eTtXk0IwT+Hh9GssQOv7m8s12Ak/2bWGCzW5V2xrGV6Z1WCB0J+GuSap5qusajkX98F9gZHNzi8UrcQGjnY8cXULoT7uTJj4R4KTiZS4WmePVlf/uUQMxbupbS8gvfvjubB3kFmafd6TRztmN63NRuOnCW3xUD5+yivwWK4+i7+B7mat2mg3pHUXfAAeWtlF/JV8q/vLORjqauTPYsf7sG9UW40Kc1l4VEnXlqRyEcbUziTb5qNTlJzCvlqRyrjOvuz5qm+jIluYbbhnqpM7tEKj8YOLDgXCcX5kLpFt1gswpkEefHfGsf6r9Y0SG43aWVDeSr5NwRtBsOFU1cutOrEyd6Wl3s5AHCotDnfx6bz5urDPPRVLOUVxn9jemdtMna2gn8MbYedrf7/1Rs52PFI/2A+OxlIuZ2z2uAl/nu5W1f4WL0jMYwQENhHbvBiplLqxqD/X4Riepc3wLaEGQnZhwF4dfo4El4cyvt3RxN/Mp9vbrUgrA4ST53n5/2nuL9XEN6uTkY9tyEmdWuFjb0zSU26y/IbVloXxmAVFRD/IwQPgsY1r61ksYL6wMW8K9OYrYBK/g2Bmz94hVrGMvScw7KmT+UY7+goP3q18eCN1YfJvlDLncBu4a01h3F1smOGCWr3GMLZwZYuQc1YdqkTFGZBxm69Q9LHiW1wPsO6L/ReLbCPvLWioTyV/BuK4EFwYrv+dWWyk8GjDdjYAnImzEtjOlBcWs7/VhpnWCrhZD4bkrJ4uF/wTWv066l3Gw++PRuGZuvQcId+9i6QExHaDdc7EuNwD5Bj/1Y07m9Q8hdCNBNCrBVCHKm8bVrFMdFCiB1CiINCiANCiImGtKnUUZuBUH5J9rj0lHNYTvO8SrBXEx7q05ql+06SnHnB4CbmbjlGYwdb7u3eyuBzmUKvNp4U0IhMj+6Q8FPDm/VTmAuJyyFqIjhUv4+C1QjqA6nbrGYoz9Ce/yxgvaZpIcD6yp+vVwRM1jQtHBgGvCeEcDewXaW2WvUCOyd9h35KL8oS0143btj+UJ/WONvb8ummowY1cercRX45cJqJXVri5mx5vX6AsOauNGvswArH4fJCfMKPeodkXvu/kQXuOt+vdyTGFdgXLuXDmQN6R1Ijhib/McCCyu8XAHdcf4Cmacmaph2p/P4UkAV4GdiuUlv2zvINQM+LvjlHAA08297wUNPGDtzTtSU/x50i42zdh6bmb0+lQtO4v1dg3eM0MRsbQY9gD744E4Lm3R62vmdVs0QMomlyL+OAbrru4mYSQZXj/setY9zf0OTvo2naaYDKW+9bHSyE6Ao4AIZ175S6ad0fcpKhIFuf9nOS5a1X1Qu8pvWRC7Dmbjle5ePVuVBcyrc707g9wpeAZpY9nNC7jSdnLlwiM/IRyD5k9uJ7ukndIlfC1rdeP4BLc9mxOW4dhfuqTf5CiHVCiIQqvsbUpiEhhC/wNXC/pmlVdnOEENOFELFCiNjsbJ0SVH3mFy1v9fpYmn0YhI284FsFP3dn7ujYgu92p5FXWFLr03/8+1EuXCrjoT767A5WG72CPQFYQ0+5Z+2Wd6yuNkyd7Fkgy1uE3zBIUD8ED5Lz/fWeWFED1SZ/TdMGa5rWoYqv5UBmZVK/nNyzqjqHEMIV+BX4l6ZpN93JQtO0OZqmxWiaFuPlpUaGjK55hLzVK/nnHJZTPG9RwGtGv9ZcKqtg5qI9NdsLuNKK/af45PejTIjxJzrA8i8ptfRoREAzZ7YeOwc9n4CMXfV/2mfZJVnTKPwOOQxZH7W9DcqKrWLKp6HDPj8DUyq/nwIsv/4AIYQDsBT4StO0HwxsTzGEc1PZyzytV88/WW7YcQttvF14d0I0salnmfDpjhqVftiffo6//7CfLoFNefmODsaK1uT6hHixLSWH4vAJ8mJ8wk96h2RaJ7ZBSYHc+Ly+atUL7BvLjd0tnKHJ/zVgiBDiCDCk8meEEDFCiLmVx0wA+gJThRBxlV/RBrar1FXzSH16/uVlcqzX68aLvde7o2ML5t3fhfS8Im5/fzOfbz5GcemN0+c0TWPZvpNM/nIXXi6OfHpvZxztbE0RvUnc3qE5hSXlbEq9KIcLDv1cvy/8Jq+Wb3JBffWOxHTsHOW1tSNrLH4Yz6DdszVNywUGVXF/LDCt8vuFwEJD2lGMqHmk3NzlUgE4NjFfu2dToaK02p7/ZX1CvPhxZk/+tzKJV1Ye4uPfU/Bo4khZeQWuzvYEezUhr7CETcnZdGzpzrsTovFoYl314Lu39sC9kT0r408ztP0YOPwrnNwDAV30Ds34NA0Or4KgfvVrbn9V2t4mf5dZhyx6RpNByV+xQr6RgAaZB6FlN/O1myNr+txspk9VQpu78tUDXdl1PI9vdp6gtFzD1kZwtqiEncdyuVBcxr9GhHF/ryCTb8loCva2Ngxt35xf409TPOI2nGzsIXFZ/Uz+Oclw7oR1bdBeVyG3ydsjq1XyVyxI80h5e+aAeZN/ZUE3PENq/dSuQc3oGtTshvs1TdO1RLMxDI/0ZXFsOlvSSxgSPAASf4bb/muWjW7M6vAqedvWyjZorwtXPzm5InkN9H5K72huStX2aWhc/cC5mdxH1pxyksHFD5zcjHZKa0/8AD2DPXBzlkM/tB8jd4Q6Had3WMaXvFomRDd/vSMxj5DbIH0nXDyrdyQ3pZJ/QyOEHPo5E2/edrNvrOmjyKGf29r7sC4xk0tthsn69geX6R2WcRXlQfof0HaY3pGYT9vbQSuHI2v1juSmVPJviJpHyrrj5ioopmmytIOZtm60NsMjfblwqYwt6eXQegDs/w7Kar/IzWLt/BS0CmhfTxd2VaVFZ2jS3KKrtqrk3xD5RsnCWpfH4U3t/CkouaB6/jfRK9gTF0c7ubl9txlQcAYOLtU7LOMozIEdH8khrebWswbDYDY2EDpcFlIsvah3NFVSyb8hMvdK38szfVTPv0oOdjYMDPNm3aFMyoIGyH+nHR9a/DzxGtn6LpQWwYDn9I7E/EJHQGmhxW7srpJ/Q+TRBhxdIX2XedrLvnVBNwWGhTfnbFEpu06chR4z5Ruz3nsvGCr/JOz6HKLuaZi/+8C+8u8s6Re9I6mSSv4NkY0ttOppvvojOYdlMa/Gql7TzfRr54WjnQ1rDmZC5ERo5CGHS8yhvPTmlV4Lc2H7bFjxJHx1B6yaJe+73oVMOVR1NlV+YkleDd/dI8f6+z1j0vAtlp2DnPVzeJVFbvCi5vk3VIG9ZZGt86fB1de0bWUny55fPZiaaSqNHOzo29aL1QfP8J9R7RExD8LmN+HUPvDraLqGM2Jh2Uz5Bu3TQc7I8QmHpq3g2CY5bHPpPDTyBLcWsOszuRlLv1nQZZpMcHnHYMFoyE+X53R0k5uauLWEsZ/JczVUoSMgYQmk/QGBvfSO5hoq+TdUgb3l7YltEDHOtG3lHG5Y0/zqaGh4c9YmZnIgI5+oHjNh30L48SF4eBM4NDZuY5cuwKY35LUFF1+ZzFO3wtZ3ZG/9sra3w+AXwLty97XMRFj9T1j9LOyaAz0fh81vQdlFuPtbOH8STu6V/78iJ4CtZe6mZjYhQ8DWQX4qUslfsQjNI+V4ZOoW0yb/ojwozG6YY761NDjMG1sbwW8HzxA1LFT2mheMhtXPwaj3jNNIRQUc+A7WvShnFXWaLFcUX158d+mC3Grz3Alo4gP+Mdc+36c93LdUzmJZ+zz8+jf5qWDqr/ITg3ItRxcIHwtx38CAf0KjG1eq60WN+TdUl8f9Tb3lXHaSvFUzfarl3siBXm08WbbvJKXlFbL6Zc/HYc8845R7Li+DpQ/DskfkStsH18Ho2deuunZ0kVMyQ0fcmPgvEwJCBsOMLTDhK5i2TiX+W+n1pJz1s2uO3pFcQyX/hiywD+QdlfPwTSVth7xt0dl0bdQjk7u34nR+sbzwCzDw3+DfBX58EHYakDzKSmDJ/RD/PQz4Fzy41vACcja2cv5+syDDzlPf+bSXw2c7P4WSQr2j+ZNK/g3Z5XH/VBNOKTyxHbzCoLGH6dqoRwaGetPKoxHztlXuY2znAPctg5ChsOpp+PYeWDAK3g6F+SPljKBz6bc+qabBTw/J/QKGvgr9npaLkBTz6fM3Wedn71d6R/In9T+gIWseIWdmpG42zfnLyyxyloMls7ERTO4RSOyJs8Rn5Ms7HZvA3Yugx2PyzfRSgfzUVpgjL77O7gx/fHrzjWAOrZClogf+W64hUMwvoKvc5Wv7bPl3YQFU8m/ILo/7H9tkmtWkZw7Ibfta9TT+ueux8TH+NHawvdL7B/m7GvoKzDoB0zfCXZ/Do3/AE/sgeAD89gwsHHvjEN6lAvhtlpzG2euv5n0hyrW6zZCzoSxkf1+V/Bu6dsPkzA5TlBG+vEK1ler514arkz3jYwJYceAUOQWXbn1ws9Zwz3cw8l1ZQvjjHtfWBdr8hkw4I94GWzW5T1cht4GDCyT8qHckgEr+SvsxYGMP8UuMf+4T26FZMLg0N/6567lJ3VpSWq6xYn8NLsYLATEPwMNbwCMYfpgq3wQ+6yevCUTfCy27mzxmpRr2TnIW1aEVFlG1VSX/hs65qeyRJPxo3CXoFRUy+ashnzoJ8XGhva8ry+JqMRPLsw08sBoG/QfcAuQ8/YgJMOQl0wWq1E6HsVB8Do5t1DsStchLQS7yOvyrHKYJ6mucc2Ylyv/kl2cUKbV2Z8cWvLLyEMdzCgnyrOEKX1t7ObNEsUytB8g6Vwk/6r6lper5K7L0gkMTiP/BeOf8c7xf9fzralSUH0LAsn0n9Q5FMRY7BwgbBUkrda/zr5K/Ag6NIHQkJC6HsmouMNbUiW1y6MG9pXHO1wA1d3OiZ7AHy+JOotWH2v6K1GGs3NwoeXWVDyedOc+Z/GKTh6GSvyJFjofifFnp01CaBid2qF6/EYyJbsGJ3CLi0s/pHYpiLIF9wb0VbHr9hjn/FRUaT/9wgElz/zD5G75K/ooU1B9cW8Ce+YafK+8YFGZByx6Gn6uBG9ahOY52Niz8I03vUBRjsbWTxfSyEiH2y2seWpVwhviT+czs3wZh4hLoKvkrkq0ddJoCRzfI5G2Iy/V8VPI3mKuTPVN6BvLj3gz2nMjTOxzFWMJGyckVG1+RlW+B0vIK3lpzmHY+LtzRsYXJQzAo+Qshmgkh1gohjlTeNq3imFZCiD1CiDghxEEhxAxD2lRMqNNkELaG9/5P7ADnZqqMs5E8OSgEXzcnnluaQFn5TUo4KNZFCBj2uiyhveG/ACzZk8HxnEKeHtoOWxvTb3xkaM9/FrBe07QQYH3lz9c7DfTUNC0a6AbMEkL4GdiuYgquvhA6XG4iYsiF37TtclGR2rnLKBo72vGfUe1JOnOB+dtT9Q5HMRaf9hBzP+xdwMXcNN5bl0znVk0ZFOZtluYNTf5jgAWV3y8A7rj+AE3TSjRNu5xJHI3QpmJKMQ9AUa5chVgXFzLlsJEa8jGqoeHNGdDOi3fXJpN13vQzQRQz6fk4aBXEfv8Gmecv8eztoSYf67/M0ETso2naaYDK2yrfsoQQAUKIA0A68LqmaSYsIK8YJKg/NA264UJUjV0e71czfYxKCMF/RoVTUl7BO2uT9Q5HMZamgeQGDCHizE881M2HmEDz7fRVbfIXQqwTQiRU8TWmpo1ompauaVok0AaYIoTwuUlb04UQsUKI2Ozs7Jq/CsV4bGyg8xQ5Tz/nSO2fn7YD7JzlNpGKUQV6Nua+7oF8H5vOodPn9Q5HMYLCS2U8n9kPd1HI0833mrXtapO/pmmDNU3rUMXXciBTCOELUHmbVc25TgEHgT43eXyOpmkxmqbFeHl51f7VKMYR9RewsavbxhNpO+T2f3YOxo9L4YlBbXBxsud/Kw+phV/1wEcbU1h5vhUFHpE4xM65+Z4MJmDosM/PwJTK76cAy68/QAjhL4Rwrvy+KdALOGxgu4opufjIkg9x39Su+mDxeTgTr4Z8TMi9kQNPDAphy5EcNh/J0TscxQDlFRpL9mQwOKw5Tfo9AblHYMdss7VvaPJ/DRgihDgCDKn8GSFEjBBibuUxYcBOIcR+YBPwlqZp8Qa2q5ha56lQlAPJq2r+nOTfQKuQxasUk7mveyt8XB2Zf/VmL4rV2XE0l6wLl7izYwsIv1OWWFn7PKx82iy7fRmU/DVNy9U0bZCmaSGVt3mV98dqmjat8vu1mqZFapoWVXlrWVvYK1ULHgiu/rBnQfXHXpbwE7j4QUA308Wl4GBnw7jO/mxKzjZLDZj6rLi0nGX7TpJXaP76+kv3ncTF0Y6Bod5ykeWEr+RWnbvmwHd/MW6J9SqoaZdK1WxsoeO9csXv2dTqj794DlLWyR6M2hzc5CbEBFChwZI91WzertzU+eJSpny5i78ujqPXaxv438pDZnsTuFhSzm8Jpxke4YuTva288/JWnSPfhVY95M8mpP5KlZvrPEVe+N3xUfXHJv0KFaWyYqFicq08GtO9dTO+j82gokJd+K2trAvF3P3ZH+w5cZZ/j2zP0HAf5m45xkNfxZrlQvraQ5kUlpRXXcYh5gHo/ZTJY1DJX7k5Vz+InAh7v4bCai4uHvxJlm9u0dk8sSlM7BJAWl4RO4+rmj81VXipjA83HGHQ25s4nlPIF1O78GDvIN67uyMvjenAnhNnzXIhfdm+k/i6OdEtyHzz+q+nkr9ya72egLJi2PnZzY8pyoNjv8shH1XSwWxu7+CLi5Md38eqoZ+aOFtYwuB3NvHWmmS6BXmw/LFe9Gt7ZUr5hJgAWrg78966ZJP2/k+du8im5GzGRLfAxgw1fG5GJX/l1rzayU2nd82RRaiqcnApVJRBuBryMScne1vu6uTP8riTbEjK1Dsci/fj3gxO5xfz9YNdmTslhrY+Ltc87mBnw6MD2rAv7Rybkk23yPSLrXKW1r3d9d3oSCV/pXq9n5L78cbOu/Gx/JOw4WXwjQbfKPPH1sD9Y1g7wv3ceOybfSSeUqt+b0bTNL7ZlUbnVk3pE3LzBaTjOvtX9v6PmKT3n19Uyre70hgd5Yd/00ZGP39tqOSvVM8/Rk793PIWFFzVIyovgx8flAvB7vpCDfnooJGDHXOnxODmbM+DC3aTdUFN/azKzuN5HMsu5J6ut+5tO9jZ8NjANsSln+Pn/cYvQfb1H6kUlZQzvW9ro5+7tlTyV2pm2GtQUgTrXrhy38ZXZDmHUe+BZxvdQmvofFydmDslhtzCEv736yG9w7FI3+5Kw9XJjpGRvtUeOyEmgOgAd15akchZI079LC4tZ/72VPq38yLM19Vo560rlfyVmvFqBz0ehbiFcGQt/DQdtr4j1wJETtA7ugYv3M+N6X1asyzuFLGpavbP1fIKS1gVf4axnfyvzKm/BVsbwWt3RZB/sZT/GunNtKikjH8tSyCnoISH+wYb5ZyGstM7AMWK9H0a4n+AReNA2ED/Z6HP3/WOSqk0c0AwP+7N4D8/H+Tnx3qbZTcoa/DtrjRKyiuqHfK5WmhzVx7u15qPNh5lcJg3t0fITwyaprHjWC6nzxVTVFJGxtmLxKWf42h2IWG+LvQN8aK9nytuzvY42dtScKmM0+cu8vpvSZzIK+Lhfq3p3lq/6Z1XU8lfqTnHJjD6A9j8Fgx+EVqqMg6WpJGDHf8cHsbj3+7ju91pTOrWSu+QdJeWW8SHG1IYFOpNu+Yu1T/hKo8PDGFjUjaPLNrL2E4tGBHhywcbUtiffu7PYxxsbSqTvicHTubzysqqPym0cHfmm2nd6RHsYdDrMSZhqWVhY2JitNjYWL3DUBSromka4z/dQXbBJX7/e3+z7QpliTRN494vdrI/PZ81T/XFz9251ucoLi3nww0pfLrpKGUVGr5uTjw1uC3dWjejkYMdbs72ONhdGT0/k1/MidxCzheXUVRSRhNHeUx7P1caOZinry2E2KNpWkx1x1lVz7+0tJSMjAyKi9WMBkvm5OSEv78/9vb2eofS4AghuKNjC/61LIGUrAJCfGrX261Pvo9NZ1tKLq/c2aFOiR/kWoq/D23HqCg/Dp0+z7AOzW953aC5mxPN3ZzqGrJZWVXyz8jIwMXFhcDAwAbdo7FkmqaRm5tLRkYGQUFBeofTIA0O8+FfyxJYeyizwSb/S2Xl/G9lEt2CmnFPF8MXU7Vr7lLrYSNLZ1WzfYqLi/Hw8FCJ34IJIfDw8FCfznTU3M2JSH831iU23FW/u47nkX+xlIf7tda1hIIls6rkD6jEbwXU70h/g8N82Jd+juwLl/QORRfrD2XhZG9Dz2BPvUOxWFaX/BVFqd6Q9j5oGg2y5o+maaxPyqRXsGeN5vU3VCr5G0lgYCA5OTeWgv3555957bXXjNbOCy+8wFtvvVXr5506dYpx48YBEBcXx8qVK40Wk2J5Qpu70MLdmbWJWXqHYnYpWQWk511kYJi33qFYNJX8TWz06NHMmjVL7zDw8/NjyZIlgEr+DYEQgiHtfdiaks3FEtNuB2hp1ifJN7yBoSr534pK/rWUmppKaGgoU6ZMITIyknHjxlFUVATA7Nmz6dSpExERESQlJQEwf/58HnvssSrPlZ+fT2BgIBUVFQAUFRUREBBAaWkpR48eZdiwYXTu3Jk+ffr8eb6rxcXF0b17dyIjI7nzzjs5e/YsACkpKQwePJioqCg6derE0aNHSU1NpUOHDpSUlPD888+zePFioqOjWbx4MSEhIWRny4JtFRUVtGnTpspPMYp1uS3ch+LSCtYkntE7FLPacCiL9r6u+LrVbXpnQ2FVUz2v9uKKg0YvYdvez5X/jAqv9rjDhw/zxRdf0KtXLx544AE+/vhjADw9Pdm7dy8ff/wxb731FnPnzr3ledzc3IiKimLTpk0MGDCAFStWMHToUOzt7Zk+fTqffvopISEh7Ny5k5kzZ7Jhw4Zrnj958mRmz55Nv379eP7553nxxRd57733mDRpErNmzeLOO++kuLiYiooKsrJkb8jBwYGXXnqJ2NhYPvzwQwCSkpJYtGgRf/3rX1m3bh1RUVF4eqoLZdaue5AHAc2c+W5XOmOiq9gusB46V1RC7Ik8Hh2gCg1WR/X86yAgIIBevXoBcO+997J161YAxo6Vm5l07tyZ1NTUGp1r4sSJLF68GIDvvvuOiRMnUlBQwPbt2xk/fjzR0dE8/PDDnD59+prn5efnc+7cOfr16wfAlClT2Lx5MxcuXODkyZPceeedgFxw1ajRreuGP/DAA3z11VcAfPnll9x///01il2xbDY2gru7tGTHsVyO5xTqHY5ZbErOpkJTQz41YbU9/5r00E3l+qmMl392dHQEwNbWlrKyshqda/To0Tz77LPk5eWxZ88eBg4cSGFhIe7u7sTFxdU6trqU6wgICMDHx4cNGzawc+dOFi1aVOtzKJZpfGd/3lmbzHe703j29jC9wzG5jUlZNGvsQKS/u96hWDzV86+DtLQ0duzYAcC3335L796963yuJk2a0LVrV5588klGjhyJra0trq6uBAUF8cMPPwAyoe/fv/+a57m5udG0aVO2bNkCwNdff02/fv1wdXXF39+fZcuWAXDp0qU/r0lc5uLiwoUL127JOG3aNO69914mTJiAra2aHldfeLs6MTjMmyWxGZSUVegdjkmVV2hsSs6mf1svVdG0BlTyr4OwsDAWLFhAZGQkeXl5PPLIIwadb+LEiSxcuJCJEyf+ed+iRYv44osviIqKIjw8nOXLl9/wvAULFvD0008TGRlJXFwczz//PCDfCD744AMiIyPp2bMnZ85ce8FvwIABJCYm/nnBF+QnkIKCAjXkUw/d3bUluYUlrDtUv+f87884x9miUvqrIZ8asaqqnocOHSIsTN+PrqmpqYwcOZKEhARd4zC22NhYnnrqqT8/SRjKEn5XilReodHn9Q2093Nl7pQueodjMu+sOcyHG1PY++8huDdy0Dsc3dS0qqdBPX8hRDMhxFohxJHK26a3ONZVCHFSCPGhIW0qxvfaa69x11138eqrr+odimICtjZyzv+2lFyKS+vvnP/fk7Pp2LJpg078tWHosM8sYL2maSHA+sqfb+ZlYJOB7ekuMDCwTr3+V155hejo6Gu+XnnlFRNEWHuzZs3ixIkTBl27UCzbwDAfLpaWs+NYrt6hmET2hUscyMhnQDsvvUOxGobO9hkD9K/8fgHwO/DM9QcJIToDPsBvQLUfR+qj5557jueee07vMJQGqltQM5ztbdlwKIsB7erfmPimZLlIsX89fG2mYmjP30fTtNMAlbc3/MsLIWyAt4GnDWxLUZQ6crK3pXeIJxuSsuo0HdjSbTychbeLI+F+rnqHYjWqTf5CiHVCiIQqvsbUsI2ZwEpN09Jr0NZ0IUSsECL2crkBRVGMY1CoNyfPXSQ5s0DvUIyqrLyCLcnZ9GvrpcqJ10K1wz6apg2+2WNCiEwhhK+maaeFEL5AVSUEewB9hBAzgSaAgxCiQNO0G64PaJo2B5gDcrZPTV+EoijVG1A5BXJ9Uma92pXqwMl8zheX0betGu+vDUOHfX4GplR+PwW4YTK6pmmTNE1rqWlaIPB34KuqEr+iKKbl4+pEhxaubDhUv8o8b07ORgjo3UbVo6oNQ5P/a8AQIcQRYEjlzwghYoQQt65qZqXOnTv3ZyG333//nZEjR9bq+fPnz+fUqVOmCO0GU6dO/bOMc23ExsbyxBNPAPI1bt++3dihKToZ2M6bvWlnOVtYoncoRrM5OZvIFm40baymeNaGQclf07RcTdMGaZoWUnmbV3l/rKZp06o4fr6maVXXN7YSVyf/ujBn8jGHMw0AAA8WSURBVK+rmJgYPvjgA0Al//pmQKg3FRpsPlI/rqnlXywlLv2cGvKpA6st7MaqWXAm3rjnbB4Bt996161Zs2Zx9OhRoqOjsbe3p3HjxowbN46EhAQ6d+7MwoULEUKwZ88e/va3v1FQUICnpyfz589n27ZtxMbGMmnSJJydndmxYwdvvvkmK1as4OLFi/Ts2ZPPPvusyotWhw4dYsqUKezatQuQK41Hjx7NgQMHqmzL19f3muevX7+ev//975SVldGlSxc++eQTHB0d2b17N08++SSFhYU4Ojqyfv169uzZw1tvvcWHH37Ip59+iq2tLQsXLmT27NlMnjyZ5ORk7O3tOX/+PJGRkRw5cgR7e3vj/R4Uk4nyd8ejsQMbk7LqRZnn7Sk5VGio5F8HqrZPLb322msEBwcTFxfHm2++yb59+3jvvfdITEzk2LFjbNu2jdLSUh5//HGWLFnCnj17eOCBB3juuecYN24cMTExLFq0iLi4OJydnXnsscfYvXs3CQkJXLx4kV9++aXKdsPCwigpKeHYsWMALF68mAkTJty0rasVFxczdepUFi9eTHx8PGVlZXzyySeUlJQwceJE3n//ffbv38+6detwdr6yAUZgYCAzZszgqaeeIi4ujj59+tC/f39+/fVXQJagvuuuu1TityI2NoJ+bb3YlJxNeYX1z6nYfCSbJo52RAeoKp61Zb09/2p66ObStWtX/P39AYiOjiY1NRV3d3cSEhIYMmQIAOXl5Tf0xC/buHEjb7zxBkVFReTl5REeHs6oUaOqPHbChAl8//33zJo1i8WLF7N48WIOHz5cbVuHDx8mKCiItm3bArL2/0cffcSgQYPw9fWlSxdZ78XVtfo50tOmTeONN97gjjvuYN68eXz++ec1+FdSLEn/UG9+2neS/Rnn6NTyphVZLJ6maWxOzqFnsAf2tqofW1vWm/wtxOUa/nCljr+maYSHh/9Z9vlmiouLmTlzJrGxsQQEBPDCCy9QXFx80+MnTpzI+PHjGTt2LEIIQkJCiI+Pr7atmy3q0TSt1vOie/XqRWpqKps2baK8vJwOHTrU6vmK/vqGeGIjZO17a07+R7MLOXnuIo/0D9Y7FKuk3i5rqapa+Ndr164d2dnZfybk0tJSDh48eMPzLyd6T09PCgoKqp2ZExwcjK2tLS+//PKf5Z9v1dZloaGhpKamkpKSAlyp/R8aGsqpU6fYvXs3ABcuXLhhE5qqXu/kyZO55557VPlnK+XeyIHOrZqy8bB1T/lcsD0Ve1vBoDBV0qEuVPKvJQ8PD3r16kWHDh14+umqK1Y4ODiwZMkSnnnmGaKiooiOjv5zxszUqVOZMWMG0dHRODo68tBDDxEREcEdd9zx5/DLrVyu/T9hwoRq27rMycmJefPmMX78eCIiIrCxsWHGjBk4ODiwePFiHn/8caKiohgyZMgNnzxGjRrF0qVLiY6O/rPc86RJkzh79iz33HNPrf/9FMvQv503CSfPk3X+5p80LdnJcxf5bncaE2IC1EbtdaTq+Su1tmTJEpYvX87XX39902PU78qyJZ46z/APtvDq2Aju6dpS73Bq7dmf4vlxTwa/P90fP3eV/K9W03r+asxfqZXHH3+cVatWsXLlSr1DUQwQ5utCaHMX3lmbzLDw5la1QCo9r4gfYtOZ1K2lSvwGUMM+FujRRx+9ofb/vHnz9A4LgNmzZ5OSkvLnzCHFOgkheHtCFOeKSvjXsgSrqvT57rpkbGwEMwe00TsUq6Z6/hboo48+0jsEpQEI93Pjr4Pb8ubqw9y238cqFn3tOp7HT3tPMqNfMD6uTnqHY9VUz19RGrAZ/YLp3Kops36MZ2X8ab3DuaWSsgr+uTQe/6bOPDFI9foNpZK/ojRgtjaCTyZ1ItTXhZmL9vLGb0mcLy7VO6wqzdl8lJSsAl4e04FGDmrQwlDqX1BRGjhvVye+m96d/yw/yMe/H+Xj34/i39SZqAB3erfxpG9bL1rofGE1LbeI2RtSGBHh++e+BIphVPL///buPraq+gzg+Pfpi1ykoiCveosFypsV0yEv1k7iK1QobGE6dYBukRSSGkEnOLeyVDOjJgQ0rZGxuYzODWbGeNlYZBQ0KoFVEC1cXopKwYYCtWoLWyu0ffbHPSpoob1tzz3tuc8nuem5b+f3/Hpvn/7yO+c8P2MM3RLieXbGaKanX8Xuo1+wv7KWneWfs7G0kjiBl2fdwOS0AZ7F98y/9hEfJyzOvtazGPzGpn1ctHz5coqKijpsf1af37hJRLhpaB9yb02l8Cdj2P7kbWx+dCJpV13OE2tKqayp8ySubR9+yqbQCXJvTWXA5XaQt6NY8nfRvHnzeOCBB7wOw+rzmzYREYb1v4wX70vnTEMTj/31AxqblIrP/8euI59HJYaGxiae+keI5N7deej7g6PSZqzostM+z5c8z4HPDnToPkf2HskT45+46GvKy8vJyspiwoQJ7N69m+HDh1NUVMTTTz/Nhg0bSEhIYNKkSSxZsoT8/HySkpJ4/PHHv7Mfq89vuoohfZPIn57Gor+VMv6ZYqqdVcBenjmGu0Y3X622o/zu7cOUnTjN8lk3EEiMd7WtWGMj/zY4ePAgOTk5lJaW0rNnTwoLC1m7di2hUIjS0lLy8vJa3IfV5zddyT03BMmZOIRxKb3Jn3Yt113dk7x1e6k+/aVrbb664wjPv36ArLQBTE7r71o7sarLjvxbGqG7KTk5mczMTABmzZrF0qVLCQQCzJkzh6lTp7Z6XV+rz2+6ChHhl1O+qdWUMbQP2QVv8+v1IV6aOabD2/vTjiMsXreXO0b148X70yMuPW5a1mWTv5e+/UVMTEykpKSELVu2sHr1agoLC9m6dWuL+7H6/KarGjHgsq+vDr5l5yfcMzb5vOePfVHHptBxjtfWk9zrUob2TWLC4N7ExV38+1l16kvyN4TYuKeS20f246WZY+iWYNM9brDk3wZHjx5l+/btZGRksGrVKtLT06mpqWHKlCnceOONpKa27urDlurzZ2RkcPbsWcrKykhLS/v6fefW509NTW22Pv+4ceM4derUedM+EK7PX1tbe95jX9XnX7x4cTt/MyaWzJ04hLfKqli0ppT6s43MzkjhnUOfsqy47OsDwonxwtnG8GDlx2ODPDfjeuLihMYm5a1DVby+5zjF+09wpqGJgVcEOFH7JXVnGlk4eQQ5E4fYCl0usuTfBqNGjWLlypXMnTuXYcOGkZ+fT3Z2NvX19agqy5Yta/W+7r33XhYuXMjhw4eBb+rzP/LII9TU1NDQ0MCCBQvOS/7n1uf/6oDvt+vz19XV0b17d4qLi89rb9q0adx9992sX7+egoICbr75ZmbOnEleXp7V5zcRSYiP448/G8/Df3mPxetDrCr5hH2VtQR7dWdR1giy0gaQcmUPTpyq59UdR3jpjY9QhRljgvxm4z5Cx2pJ6pbAbSP70evSRI7V1DO0bxI/nzSC1H5JXnfP96yef4TKy8vJzs5m7969nsbRkVpTnz9SneGzMtHR0NhE3rq9bAodJ/fWVGZnXNPsVM2yzWW8uOUQAFddHmBh1gimjB5o0zodzOr5m1ax+vymvRLi43juR9fz7IzRFz3m9Oidw+mTdAn/PdPIT29KsVM3PWbJP0IpKSkRj/pzc3PZtm3beY/Nnz+/U6yBW1BQ4HUIxidac7LB7IwU9wMxrWLJPwqsPr8xprNp16F0EektIptF5JDzs9cFXtcoIu87tw3tabOzHqMw37DPyJjOr73nUf0C2KKqw4Atzv3m1KlqunOb3tbGAoEA1dXVllw6MVWlurqaQMAKcBnTmbV32ucHwC3O9krgTcC1S2+DwSAVFRVUVVW51YTpAIFAgGAw6HUYxpiLaG/y76+qlQCqWikiF1plISAiO4EG4DlVXdeWxhITExk82Cr7GWNMe7WY/EWkGGhuFYdfNfPYhQxS1WMiMgTYKiJ7VPWjZtrKAXIABg0aFMHujTHGRKLF5K+qd1zoORE5ISIDnVH/QODkBfZxzPn5sYi8CXwP+E7yV9UVwAoIX+TVqh4YY4yJWHsP+G4AHnS2HwTWf/sFItJLRLo5232ATGBfO9s1xhjTDu0q7yAiVwKvAYOAo8A9qvqZiIwF5qnqHBG5Cfgt0ET4n80LqvpKK/ZdBRyJMKQ+wKcRvqersz7HButzbOiIPl+jqn1belGnre3TFiKyszU1LfzE+hwbrM+xIZp9tnqpxhgTgyz5G2NMDPJb8l/hdQAesD7HButzbIhan30152+MMaZ1/DbyN8YY0wq+Sf4ikiUiB0XkQxG5UIE53xCRP4jISRHxz5JiLRCRZBF5Q0T2i0hIROZ7HZObRCQgIiUi8oHT36e8jilaRCReRHaLyD+9jiUaRKRcRPY4lY93tvyODmjTD9M+IhIPlAF3AhXAu8D9qurbi8lEZCJwGihS1eu8jicanKvIB6rqeyJyGbAL+KFfP2cJr47SQ1VPi0gi8A4wX1V3eBya60TkMWAs0FNVs72Ox20iUg6MVdWoXdfgl5H/eOBDVf1YVc8AqwlXHPUtVX0L+MzrOKJJVStV9T1n+xSwH7ja26jco2GnnbuJzq3rj9ZaICJBYCrwe69j8TO/JP+rgU/OuV+Bj5OCARFJIVwj6j/eRuIuZ/rjfcJ1szarqq/763gBWES4KkCsUODfIrLLKXDpOr8k/+YWD/X9CClWiUgSsAZYoKq1XsfjJlVtVNV0IAiMFxFfT/GJSDZwUlV3eR1LlGWq6hjgLiDXmdZ1lV+SfwWQfM79IHDMo1iMi5y57zXAn1X1717HEy2q+gXhxZKyPA7FbZnAdGcOfDVwm4i86m1I7jun8vFJYC3hqWxX+SX5vwsME5HBInIJcB/hiqPGR5wDoK8A+1V1qdfxuE1E+orIFc52d+AO4IC3UblLVZ9U1aCqphD+O96qqrM8DstVItLDOYEBEekBTAJcP4vPF8lfVRuAh4FNhA8CvqaqIW+jcpeIrAK2AyNEpEJEHvI6pijIBGYTHg2+79ymeB2UiwYCb4hIKeEBzmZVjYlTH2NMf+AdEfkAKAE2qurrbjfqi1M9jTHGRMYXI39jjDGRseRvjDExyJK/McbEIEv+xhgTgyz5G2NMDLLkb4wxMciSvzHGxCBL/sYYE4P+D9BVyLHc04r3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcccbe91e10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# before plotting the velocities (in radians per second) corresponding to each of the Euler angles.\n",
    "plt.plot(results['time'], results['phi_velocity'], label='phi_velocity')\n",
    "plt.plot(results['time'], results['theta_velocity'], label='theta_velocity')\n",
    "plt.plot(results['time'], results['psi_velocity'], label='psi_velocity')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcccbd1bb38>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finally, you can use the code cell below to print the agent's choice of actions.\n",
    "plt.plot(results['time'], results['rotor_speed1'], label='Rotor 1 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed2'], label='Rotor 2 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed3'], label='Rotor 3 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed4'], label='Rotor 4 revolutions / second')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  22.15999025  -14.3963947   146.21634356    5.26238078    5.57184658\n",
      "    0.        ]\n",
      "[ 14.47709545 -15.99758353  22.07711198]\n",
      "[-0.2821359  -0.31438981  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# the pose, velocity, and angular velocity of the quadcopter at the end of the episode\n",
    "print(task.sim.pose)\n",
    "print(task.sim.v)\n",
    "print(task.sim.angular_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reflections\n",
    "\n",
    "**Question 1**: Describe the task that you specified in `task.py`.  How did you design the reward function?\n",
    "\n",
    "**Answer**: I specified a take off task. Since there was no floor (if drone hits z=0, the episode ends), I set the start position to x=0,y=0,z=20 and target to x=0,y=0,z=100. \n",
    "\n",
    "For the reward function, at first I tried to apply a penalty relative to the distance between the target position and current position, increasing the z penalty by 1.5. That didn't work, I noticed that the quadcopter was shaking, angle velocities were varying a lot. \n",
    "\n",
    "So I experimented creating penalties using angular velocity and the euler angles. Angular velocity penalty ended working best for stabilizing the quadcopter, but wasn't enough to make it go up, so I added z speed to the reward (so if it was going up, it received a reward bonus the size of z speed, and if it was falling received a penalty).\n",
    "\n",
    "I also created extra bonuses in case z velocity beats certain thresholds (for instance reward += 5 if self.sim.v[2] > 0.3 ).\n",
    "\n",
    "In my last attempts I rewarded the quadcopter if it could decrease its distance to the target relative to its initial distance (if it could be \"more close\" to the target than initially), I hardcoded this in the task but its easy to get this dynamically.\n",
    "\n",
    "The last resort was rewarding the quadcopter in case it reached or passed the z goal. Which  was obvious but I didn't think about in the beginning. For this he received a 100 reward.\n",
    "\n",
    "I felt a little loose designing the reward function, really didn't felt sure what I was doing, I guess there wasn't a concept or lesson about this. So what I did was a lot of trial and error, reshaping the reward function pieces and watching the results.\n",
    "\n",
    "This approach works but only 30% of the time, If run again there's a high risk of not obtaining the same results (perhaps I should freeze the seed next time :/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Discuss your agent briefly, using the following questions as a guide:\n",
    "\n",
    "- What learning algorithm(s) did you try? What worked best for you?\n",
    "- What was your final choice of hyperparameters (such as $\\alpha$, $\\gamma$, $\\epsilon$, etc.)?\n",
    "- What neural network architecture did you use (if any)? Specify layers, sizes, activation functions, etc.\n",
    "\n",
    "**Answer**: I used the udacity's provided DDPG agent which uses an off policy approach, didn't try other algorithms as I assumed (maybe incorrectly) the DDPG was the best for this job (continuous state and action spaces).\n",
    "\n",
    " I didn't use any architecture, only provided code.\n",
    " \n",
    " For the actor:\n",
    " \n",
    " 3 dense hidden layers 32 - 64 - 32 with Relu activation function\n",
    " 1 sigmout output layer (1D tensor with len 4), that was scaled to action range\n",
    " Adam Optimizer\n",
    " \n",
    " For the critic:\n",
    " \n",
    " 2 dense hidden layers 32 - 64 with Relu activation for the state pathway\n",
    " 2 dense hidden layers 32 - 64 with Relu activation for the action pathway\n",
    " 1 layers.add() of the paths and a Relu activation\n",
    " 1 final output layer with 1 node and no activation function for the Q values\n",
    " Adam Optimizer\n",
    " \n",
    " I Added Batchnorm and Dropout(.2) between the layers, but that didn't help at all, quadcopter performance went down, so at the end I used the default.\n",
    "\n",
    "Didn't play with the hyperparameters very much, but at the end these was best (obtained via trial and error):\n",
    "\n",
    "* gamma = 0.99\n",
    "* theta = 0.15\n",
    "* sigma = 0.3\n",
    "* tau = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Using the episode rewards plot, discuss how the agent learned over time.\n",
    "\n",
    "- Was it an easy task to learn or hard?\n",
    "- Was there a gradual learning curve, or an aha moment?\n",
    "- How good was the final performance of the agent? (e.g. mean rewards over the last 10 episodes)\n",
    "\n",
    "**Answer**: Hard task. At first I thought it was an easy task, but my dreams were crushed by gravity and the lesser boundary z.\n",
    "\n",
    "I believed z=0 to be ground, but the quadcopter started every episode already floating. When I finally found out about the lesser boundary from z to be 0 everything became much easier. \n",
    "\n",
    "Turns out that when you set the start position to [0,0,0], the physics sim sets z to 10, the quadcopter quickly falls to 0 and the episode ends.\n",
    "\n",
    "Maybe telling this to the studends should make this exercise easier, or perhaps I should have read the physics_sim before trying to play with the agent.\n",
    "\n",
    "Nothing seemed to work at first, but after solving the above enigma, shaping the reward function and experimenting became easier.\n",
    "\n",
    "The main problem here is that the quadcopter had to became stable to be able to fight gravity and go up, after it learned to keep angular v low and use very close speeds at all 4 propellers, it figured it out.\n",
    "\n",
    "It was a very \"AHA\" moment, as we can see in the rewards plot. It seems that the agent is experimenting with a wide range of actions, so the reward plot kind of reminds me of a electroencephalogram. Maybe because of the exploration sigma ? \n",
    "\n",
    "Overall I say the final performance was good, but need improvements:\n",
    "\n",
    "It was good in the sense that it was able to take off and it kept stable until certain heights. The problem is that the agent became a little insensible, it overcame the target z by 40%, wich is really bad, and started oscilating in X an Z axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Briefly summarize your experience working on this project. You can use the following prompts for ideas.\n",
    "\n",
    "- What was the hardest part of the project? (e.g. getting started, plotting, specifying the task, etc.)\n",
    "- Did you find anything interesting in how the quadcopter or your agent behaved?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "The hardest part was designing the reward function, and working with the scales of the rewards and penalties. I also spent too many time before figuring out about z boundary.\n",
    "\n",
    "The most interesting and sad part is that, as mentionet in question 1, sometimes the agent learns about how to get the best scores (and reach target), but then sort of \"forgets\" how to do it, in the middle of training, and start behaving oddly, even falling to z=0.\n",
    "\n",
    "Another interesting fact is that, if we check the quadcopter actions in the last run (cell after the rewards plot), we can see that the agent understood that it had to use very similar action to all propellers (900)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
